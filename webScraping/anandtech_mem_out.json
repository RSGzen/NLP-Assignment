[
{"title": "Micron Ships Denser & Faster 276 Layer TLC NAND, Arriving First In Micron 2650 Client SSDs", "paragraph": ["Micron on Tuesday announced that the company has begun shipping its 9th Generation (G9) 276 layer TLC NAND. The next generation of NAND from the prolific memory maker, Micron's latest NAND is designed to further push the envelope on TLC NAND performance, offering significant density and performance improvements over its existing NAND technology.", "Micron's G9 TLC NAND memory features 276 active layers, which is up from ", ". At this point the company is being light on technical details in their official material. However in a brief interview with ", ", the company confirmed that their 276L NAND still uses a six plane architecture, which was first introduced with the 232L generation. At this point we're assuming Micron is also string-stacking two decks of NAND together, as they have been for the past couple of generations, which means we're looking at 138 layer decks.", "On the density front, Micron told Blocks & Files that they have improved their NAND density by 44% over their 232L generation. Which, given what we know about that generation, would put the density at around 21 Gbit/mm", ". Or for a 1Tbit die of TLC NAND, that works out to a die size of roughly 48.9mm", ", comparable to the die size of a 512Gbit TLC die from Micron's older 176L NAND.", "Besides improving density, the other big push with Micron's newest generation of NAND was further improving its throughput. While the company's 232L NAND was built against the ONFi 5.0 specification, which topped out at transfer rates of 2400 MT/sec, their new 276L NAND can hit 3600 MT/sec, which is consistent with the ONFi 5.1 spec.", "Meanwhile, the eagle-eyed will likely also pick up on Micron's ninth-generation/G9 branding, which is new to the company. Micron's has not previously used this kind of generational branding for their NAND, which up until now has simply been identified by its layer count (and before the 3D era, its feature size). Internally, this is believed to be Micron's 7th generation 3D NAND architecture. However, taking a page from the logic fab industry, Micron seems to be branding it as ninth-generation in order to keep generational parity with its competitors, who are preparing their own 8th/9th generation NAND (and thus cliam that they are the first NAND maker to ship 9th gen NAND).", "And while this NAND will eventually end up in all sorts of devices – including, no doubt, high-end PCIe Gen5 drives thanks to its high transfer rates – Micron's launch vehicle for the NAND is their own Micron 2650 client SSD. The 2650 is a relatively straightforward PCIe Gen4 x4 SSD, using an unnamed, DRAMless controller alongside Micron's new NAND. The company is offering it in 3 form factors – M.2 2280, 2242, and 2230 – with a modest set of capacities ranging from 256GB to 1TB.", "Micron's 2650 NVMe SSDs offer sequential read performance of up to 7000 MB/s as well as sequential write performance of up to 6000 MB/s. As for random performance, we are talking about up to a million read and write IOPS, depending on the configuration.", "The performance of the drives scales pretty significantly with capacity, underscoring how much parallelism is needed to keep up with the PCIe Gen4 controller. The rated capacity of the drives scales similarly, with the smallest drive rated for 200TBW (800 drive writes), while the largest drive is rated for 600 TBW (600 drive writes).", "“The shipment of Micron G9 NAND is a testament to Micron’s prowess in process technology and design innovations,” said Scott DeBoer, executive vice president of Technology and Products at Micron. “Micron G9 NAND is up to 73% denser than competitive technologies in the market today, allowing for more compact and efficient storage solutions that benefit both consumers and businesses.”", "Micron's G9 276-layer TLC NAND memory is also in qualification with customers in component form, so expect the company's partners to adopt it for their high-end SSDs in the coming quarters. In addition, Micron plans Crucial-branded SSDs based on its G9 NAND memory.."]},
{"title": "Samsung Shrinks LPDDR5X Chips by 9%, Now Just 0.65mm Thick", "paragraph": ["Samsung is announcing today that it has begun mass production of 12 GB and 16 GB LPDDR5X modules in the industry's thinnest package. Samsung's shrunken memory packages measure approximately 0.65 mm in thickness, making them 0.06 mm (~9%) thinner than standard LPDDR5X packages. The company expects the new DRAM devices to be used to make for thinner smartphones, or improve their performance by enabling better airflow inside.", "According to the company's press release, Samsung achieved this ultra-thin design by employing new packaging methods, such as optimized printed circuit boards (PCBs) and epoxy molding compound (EMC). Additionally, an optimized back-lapping process was used to further reduce the height of the packages. The newly developed DRAM packages are not only thinner by 9% compared to previous models but also offer a 21.2% improvement in heat resistance. ", "Thinner LPDDR5X packaging help enhance airflow within smartphones, significantly improving thermal management, which means higher performance and longer battery life. Also, better thermal management help to prolong device's lifespan.", "Samsung's LPDDR5X DRAM sets a new standard for high-performance on-device AI solutions, offering not only superior LPDDR performance but also advanced thermal management in an ultra-compact package, said YongCheol Bae, Executive Vice President of Memory Product Planning at Samsung Electronics. We are committed to continuous innovation through close collaboration with our customers, delivering solutions that meet the future needs of the low-power DRAM market.", "While Samsung's thinner LPDDR5X DRAM packages contribute to making smartphones slimmer, they are just one part of the overall design strategy. Other components, such as thinner protective glass, PCBs, and batteries, play considerably more significant roles in reducing device thickness. Meanwhile, the primary benefit of these new memory modules may be in improving airflow inside smartphones.", "Samsung is looking to further expand its LPDDR5X product lineups by developing even more compact packages, including 6-layer 24 GB and 8-layer 32 GB modules. Specific details about the thickness of these future memory modules have not yet been disclosed, though making high-capacity DRAMs thinner in general is an important thing."]},
{"title": "G.Skill Intros Low Latency DDR5 Memory Modules: CL30 at 6400 MT/s", "paragraph": ["G.Skill on Tuesday introduced its ultra-low-latency DDR5-6400 memory modules that feature a CAS latency of 30 clocks, which appears to be the industry's most aggressive timings yet for DDR5-6400 sticks. The modules will be available for both AMD and Intel CPU-based systems.", "With every new generation of DDR memory comes an increase in data transfer rates and an extension of relative latencies. While for the vast majority of applications, the increased bandwidth offsets the performance impact of higher timings, there are applications that favor low latencies. However, shrinking latencies is sometimes harder than increasing data transfer rates, which is why low-latency modules are rare.", "Nonetheless, G.Skill has apparently managed to cherry-pick enough DDR5 memory chips and build appropriate printed circuit boards to produce DDR5-6400 modules with CL30 timings, which are substantially ", ". This means that while JEDEC-standard modules have an absolute latency of 14.375 ns, G.Skill's modules can boast a latency of just 9.375 ns – an approximately 35% decrease.", "G.Skill's DDR5-6400 CL30 39-39-102 modules have a capacity of 16 GB and will be available in 32 GB dual-channel kits, though the company does not disclose voltages, which are likely considerably higher than those standardized by JEDEC.", "The company plans to make its DDR5-6400 modules available both for AMD systems with EXPO profiles (Trident Z5 Neo RGB and Trident Z5 Royal Neo) and for Intel-powered PCs with XMP 3.0 profiles (Trident Z5 RGB and Trident Z5 Royal). For AMD AM5 systems that have a practical limitation of 6000 MT/s – 6400 MT/s for DDR5 memory (as this is roughly as fast as AMD's Infinity Fabric can operate at with a 1:1 ratio), the new modules will be particularly beneficial for AMD's Ryzen 7000 and Ryzen 9000-series processors.", "G.Skill notes that since its modules are non-standard, they will not work with all systems but will operate on high-end motherboards with properly cooled CPUs.", "The new ultra-low-latency memory kits will be available worldwide from G.Skill's partners starting in late August 2024. The company did not disclose the pricing of these modules, but since we are talking about premium products that boast unique specifications, they are likely to be priced accordingly."]},
{"title": "SK Hynix and TSMC Team Up for HBM4 Development", "paragraph": ["SK hynix and TSMC announced early on Friday that they had signed a memorandum of understanding to collaborate on developing the next-generation HBM4 memory and advanced packaging technology. The initiative is designed to speed up the adoption of HBM4 memory and solidify SK hynix's and TSMC's leading positions in high-bandwidth memory and advanced processor applications.", "The primary focus of SK hynix's and TSMC's initial efforts will be to enhance the performance of the HBM4 stack's base die, which (if we put it very simply) acts like an ultra-wide interface between memory devices and host processors. With HBM4, SK hynix plans to use one of TSMC's advanced logic process technologies to build base dies to pack additional features and I/O pins within the confines of existing spatial constraints. ", "This collaborative approach also enables SK hynix to customize HBM solutions to satisfy diverse customer performance and energy efficiency requirements. SK hynix has been touting custom HBM solutions for a while, and teaming up with TSMC will undoubtedly help with this.", "", " said Dr. Kevin Zhang, Senior Vice President of TSMC's Business Development and Overseas Operations Office, and Deputy Co-Chief Operating Officer. ", "", "Furthermore, the collaboration extends to optimizing the integration of SK hynix's HBM with TSMC's CoWoS advanced packaging technology. CoWoS is among the most popular specialized 2.5D packaging process technologies for integrating logic chips and stacked HBM into a unified module.", "For now, it is expected that HBM4 memory will be integrated with logic processors using direct bonding. However, some of TSMC's customers might prefer to use an ultra-advanced version of CoWoS to integrate HBM4 with their processors.", "", " said Justin Kim, President and the Head of AI Infra at SK hynix. ", ""]},
{"title": "JEDEC Extends DDR5 Memory Specification to 8800 MT/s, Adds Anti-Rowhammer Features", "paragraph": ["When JEDEC released its DDR5 specification (JESD79) back in 2020, the standard setting organization ", ", while leaving the spec open to further expansions with faster memory as technology progressed. Now, a bit more than three-and-a-half years later, and the standards body and its members are gearing up to release a faster generation of DDR5 memory, which is being laid out in the newly updated JESD79-JC5 specification. The latest iteration of the DDR5 spec defines official DDR timing specifications up to 8800 MT/s, as well as adding some new features when it comes to security.", "Diving in, the new specification outlines settings for memory chips (on all types of memory modules) with data transfer rates up to 8800 MT/s (AKA DDR5-8800). This suggests that all members of the JESD79 committee that sets the specs for DDR5 — including memory chip makers and memory controller designers — agree that DDR5-8800 is a viable extension of the DDR5 specification both from performance and cost point of view. Meanwhile, the addition of higher speed bins is perhaps enabled by another JEDEC feature introduced in this latest specification, which is the Self-Refresh Exit Clock Sync for I/O training optimization.", "When it comes to the JEDEC standard for DDR5-8800, it sets relatively loose timings of CL62 62-62 for A-grade devices and CL78 77-77 for lower-end C-grade ICs. Unfortunately, the laws of physics driving DRAM cells have not improved much over the last couple of years (or decades, for that matter), so memory chips still must operate with similar absolute latencies, driving up the relative CAS latency. In this case 14ns remains the gold standard, with CAS latencies at the new speeds being set to hold absolute latencies around that mark. But in exchange for systems willing to wait a bit longer (in terms of cycles) for a result, the new spec improves the standard's peak memory bandwidth by 37.5%.", "This of course is just the timings set in the JEDEC specification, which is primarily of concern for server vendors. So we'll have to see just how much harder consumer memory manufacturers can push things for their XMP/EXPO-profiled memory. Extreme overclockers are already hitting speeds as high as ", " with current-generation DRAM chips and CPUs, so there may be some more headroom to play with in the next generation.", "Meanwhile, on the security front, the updated spec makes a couple of changes that have been put in place seemingly to address ", ". The big item here is Per-Row Activation Counting (PRAC), which true to its name, enables DDR5 to keep a count of how often a row has been activated. Using this information, memory controllers can then determine if a memory row has been excessively activated and is at risk of causing a neighboring row's bits to flip, at which point they can back off to let the neighboring row properly refresh and the data re-stabilize.", "Notably here, the JEDEC press release doesn't use the rowhammer name at any point (unfortunately, we haven't been able to see the specification itself). But based on the description alone, this is clearly intended to thwart rowhammer attacks, since these normally operate by forcing a bit flip between refreshes through a large number of activations.", "Digging a bit deeper, PRAC seems to be based on a recent Intel patent, ", " (", "), which describes a very similar mechanism under the name Perfect row hammer tracking (PRHT). Notably, the Intel paper calls out that this technique has a performance cost associated with it because it increases the overall row cycle time. Ultimately, as the vulnerability underpinning rowhammer is a matter of physics (cell density) rather than logic, it's not too surprising to see that any mitigation of it comes with a cost.", "The updated DDR5 specification also deprecates support for Partial Array Self Refresh (PASR) within the standard, citing security concerns. PASR is primarily aimed at power efficiency for mobile memory to begin with, and as a refresh-related technology, presumably overlaps some with rowhammer – be it a means to attack memory, or an obstruction to defending against rowhammer. Either way, with mobile devices increasingly moving to low-power optimized LPDDR technologies anyhow, the depreciation of PASR does not immediately look like a major concern for consumer devices."]},
{"title": "Samsung Starts Mass Production of 9th Generation V-NAND: 1Tb 3D TLC NAND", "paragraph": ["Samsung Electronics has started mass production of its 9th generation of V-NAND memory. The first dies based on their latest NAND tech come in a 1 Tb capacity using a triple-level cell (TLC) architecture, with data transfer rates as high as 3.2 GT/s. The new 3D TLC NAND memory will initially be used to build high-capacity and high-performance SSDs, which will help to solidify Samsung's position in the storage market.", "Diving right in, Samsung is conspicuously avoiding to list the number of layers in their latest generation NAND, which is the principle driving factor in increasing capacity generation-on-generation. The company's current 8th gen V-NAND is 236 layers – similar to its major competitors – and word on the street is that 9th gen V-NAND ups that to 290 layers, though this remains to be confirmed.", "Regardless, Samsung says that its 9th generation V-NAND memory boasts an approximate 50% improvement in bit density over its 8th generation predecessor. Driving this gains, the company cites the miniaturization of the cell size, as well as the integration of enhanced memory cell technologies that reduce interference and extend the lifespan of the cells. With their latest NAND technology, Samsung has also been able to eliminate dummy channel holes, thus reducing the planar area of the memory cells.", "Interestingly, today's announcement also marks the first time that Samsung has publicly confirmed their use of string stacking in their NAND, referring to it as their double-stack structure. The company is widely believed to have been using sting stacking back in their 8th generation NAND as well, however this was never confirmed by the company. Regardless, the use of string stacking is only going to increase from here, as vendors look to keep adding layers to their NAND dies, while manufacturing variability and channel hole tolerances make it difficult to produce more than 150-200 layers in a single stack.", "Speaking of channel holes, another key technological enhancement in the 9th gen V-NAND is Samsung's advanced 'channel hole etching' technology. This process improves manufacturing productivity by enabling the simultaneous creation of electron pathways within a double-stack structure. This method is crucial as it enables efficient drilling through more layers, which is increasingly important as cell layers are added.", "The latest V-NAND also features the introduction of a faster NAND flash interface, Toggle DDR 5.1, which boosts peak data transfer rates by 33% to 3.2 GT/s, or almost 400MB/sec for a single die. Additionally, 9th gen V-NAND's power consumption has been reduced by 10%, according to Samsung. Though Samsung doesn't state under what conditions – presumably, this is at iso-frequency rather than max frequency.", "Samsung's launch of 1Tb TLC V-NAND is set to be followed by the release of a quad-level cell (QLC) model later this year.", "We are excited to deliver the industry’s first 9th-gen V-NAND which will bring future applications leaps forward, said SungHoi Hur, Head of Flash Product & Technology of the Memory Business at Samsung Electronics. In order to address the evolving needs for NAND flash solutions, Samsung has pushed the boundaries in cell architecture and operational scheme for our next-generation product. Through our latest V-NAND, Samsung will continue to set the trend for the high-performance, high-density solid-state drive (SSD) market that meets the needs for the coming AI generation."]},
{"title": "SK hynix Reports That 2025 HBM Memory Supply Has Nearly Sold Out", "paragraph": ["Demand for high-performance processors for AI training is skyrocketing, and consequently so is the demand for the components that go into these processors. So much so that SK hynix this week is very publicly announcing that the company's high-bandwidth memory (HBM) production capacity has already sold out for the rest of 2024, and even most of 2025 has already sold out as well.", "SK hynix currently produces various types of HBM memory for customers like Amazon, AMD, Facebook, Google (Broadcom), Intel, Microsoft, and, of course, NVIDIA. The latter is an especially prolific consumer of HBM3 and HBM3E memory for its H100/H200/GH200 accelerators, as NVIDIA is also working to fill what remains an insatiable (and unmet) demand for its accelerators.", "As a result, HBM memory orders, which are already placed months in advance, are now backlogging well into 2025 as chip vendors look to secure supplies of the memory stacks critical to their success.", "This has made SK hynix the secnd HBM memory vendor in recent months to announce that they've sold out into 2025, following an earlier announcement from Micron regarding its HBM3E production. But of the two announcements, SK hynix's is arguably the most significant yet, as the South Korean firm's HBM production capacity is far greater than Micron's. So while things were merely interesting with the smallest of the Big Three memory manufacturers being sold out into 2025, things are taking a more concerning (and constrained) outlook now that SK hynix is as well.", "SK hynix currently controls roughly 46% - 49% of HBM market, and its share is not expected to drop significantly in 2025, according to market tracking firm ", ". By contrast, Micron's share on HBM memory market is between 4% and 6%. Since HBM supply of both companies is sold out through the most of 2025, we're likely looking at a scenario where over 50% of the industry's total HBM3/HBM3E supply for the coming quarters is already sold out.", "This leaves Samsung as the only member of the group not to comment on HBM demand so far. Though with memory being a highly fungible commodity product, it would be surprising if Samsung wasn't facing similar demand. And, ultimately, all of this is pointing towards the indusry entering an HBM3 memory shortage.", "Separately, SK hynix said that it is sampling 12-Hi 36GB HBM3E stacks with customers and will begin volume shipments in the third quarter."]},
{"title": "Micron Ships Crucial-Branded LPCAMM2 Memory Modules: 64GB of LPDDR5X For $330", "paragraph": ["As LPCAMM2 adoption begins, the first retail memory modules are finally starting to hit the retail market, courtesy of Micron. The memory manufacturer has begun selling their LPDDR5X-based LPCAMM2 memory modules under their in-house Crucial brand, making them available on the latter's storefront. Timed to coincide with the release of Lenovo's ThinkPad P1 Gen 7 laptop – the first retail laptop designed to use the memory modules – this marks the de facto start of the eagerly-awaited modular LPDDR5X memory era.", "Micron's ", " (LPCAMM2) modules are available in capacities of 32 GB and 64 GB. These are dual-channel modules that feature a 128-bit wide interface, and are based around LPDDR5X memory running at data rates up to 7500 MT/s. This gives a single LPCAMM2 a peak bandwidth of 120 GB/s. Micron is not disclosing the latencies of its LPCAMM2 memory modules, but it says that high data transfer rates of LPDDR5X compensate for the extended timings.", "Micron says that LPDDR5X memory offers significantly lower power consumption, with active power per 64-bit bus being 43-58% lower than DDR5 at the same speed, and standby power up to 80% lower. Meanwhile, similar to DDR5 modules, LPCAMM2 modules include a power management IC and voltage regulating circuitry, which provides module manufacturers additional opportunities to reduce power consumption of their products.", "", "It's worth noting, however, that at least for the first generation of LPCAMM2 modules, system vendors will need to pick between modularity and performance. While soldered-down LPDDR5X memory is available at speeds up to 8533 MT/sec – and with 9600 MT/sec on the horizon – the fastest LPCAMM2 modules planned for this year by both Micron and rival Samsung will be running at 7500 MT/sec. So vendors will have to choose between the flexibility of offering modular LPDDR5X, or the higher bandwidth (and space savings) offered by soldering down their memory.", "Micron, for its part, is projecting that 9600 MT/sec LPCAMM2 modules will be available by 2026. Though it's all but certain that faster memory will also be avaialble in the same timeframe.", "Micron's Crucial LPDDR5X 32 GB module costs ", ", whereas a 64 GB module costs ", "."]},
{"title": "Samsung Unveils 10.7Gbps LPDDR5X Memory - The Fastest Yet", "paragraph": ["Samsung today has announced that they have developed an even faster generation of LPDDR5X memory that is set to top out at LPDDR5X-10700 speeds. The updated memory is slated to offer 25% better performance and 30% greater capacity compared to existing mobile DRAM devices from the company. The new chips also appear to be tangibly faster than Micron's LPDDR5X memory and SK hynix's ", " chips.", "Samsung's forthcoming LPDDR5X devices feature a data transfer rate of 10.7 GT/s as well as maximum capacity per stack of 32 GB. This allows Samsung's clients to equip their latest smartphones or laptops with 32 GB of low-power memory using just one DRAM package, which greatly simplifies their designs. Samsung says that 32 GB of memory will be particularly beneficial for on-device AI applications.", "Samsung is using its latest-generation 12nm-class DRAM process technology to make its LPDDR5X-10700 devices, which allows the company to achieve the smallest LPDDR device size in the industry, the memory maker said.", "In terms of power efficiency, Samsung claims that they have integrated multiple new power-saving features into the new LPDDR5X devices. These include an optimized power variation system that adjusts energy consumption based on workload, and expanded intervals for low-power mode that extend the periods of energy saving. These innovations collectively enhance power efficiency by 25% compared to earlier versions, benefiting mobile platforms by extending battery life, the company said.", "“As demand for low-power, high-performance memory increases, LPDDR DRAM is expected to expand its applications from mainly mobile to other areas that traditionally require higher performance and reliability such as PCs, accelerators, servers and automobiles,” said YongCheol Bae, Executive Vice President of Memory Product Planning of the Memory Business at Samsung Electronics. “Samsung will continue to innovate and deliver optimized products for the upcoming on-device AI era through close collaboration with customers.”", "Samsung plans to initiate mass production of the 10.7 GT/s LPDDR5X DRAM in the second half of this year. This follows a series of compatibility tests with mobile application processors and device manufacturers to ensure seamless integration into future products."]},
{"title": "TSMC Readies Next-Gen HBM4 Base Dies, Built on 12nm and 5nm Nodes", "paragraph": ["Of the several major changes coming with HBM4 memory, one of the most immediate is the sheer width of the memory interface. With the fourth-generation memory standard moving from an already wide 1024-bit interface to a ultra-wide 2048-bit interface, HBM4 memory stacks won't be business as usual; chip manufacturers are going to need to adopt more advanced packaging methods than are used today to accommodate the wider memory.", "As part of its European Technology Symposium 2024 presentation, TSMC offered some fresh details into the base dies it will be manufacturing for HBM4, which will be built using logic processes. With TSMC planning to employ variations of their N12 and N5 processes for this task, the company is expecting to occupy a favorable place in the HBM4 manufacturing process, as memory fabs are not currently equipped to economically produce such advanced logic dies – if they can produce them at all.", "For the first wave of HBM4, TSMC is preparing to use two fabrication processes: N12FFC+ and N5. While they serve the same purpose — integrating HBM4E memory with next-generation AI and HPC processors — they are going to be used in two different ways to connect memory for high-performance processors for AI and HPC applications.", "We are working with key HBM memory partners (Micron, Samsung, SK Hynix) over advanced nodes for HBM4 full stack integration, said Senior Director of Design and Technology Platform at TSMC. N12FFC+ cost effective base die can reach HBM for performance and N5 base die can provide even more logic with much lower power at HBM4 speeds.", "TSMC's base die made on N12FFC+ fabrication process (12nm FinFet Compact Plus, which formally belongs to a 12nm-class technology, but it lays its roots from TSMC's well-proven 16nm FinFET production node) will be used to install HBM4 memory stacks on a silicon interposer next to system-on-chips (SoCs). TSMC believes that their 12FFC+ process is well-suited to achieve HBM4 performance, enabling memory vendors to build 12-Hi(48 GB) and 16-Hi stacks (64 GB), with per-stack bandwidth well as over 2 TB/second. ", "We are also optimizing CoWoS-L and CoWoS-R for HBM4, the Senior Director said. Both CoWoS-L and CoWoS-R [use] over eight layers to enable HBM4's routing of over 2,000 interconnects with [proper] signal integrity.", "HBM4 base dies on N12FFC+ will be instrumental in building system-in-packages (SiPs) using TSMC's CoWoS-L or CoWoS-R advanced packaging technology, which offer interposers up to 8x reticle size – enough space for up to 12 HBM4 memory stacks. At present, HBM4 can achieve data transfer rates of 6 GT/s at currents of 14mA, according to TSMC figures.", "Meanwhile, as an even more advanced alternative, memory manufacturers will also have the option of tapping TSMC's N5 process for their HBM4 base dies. N5-built base dies will pack even more logic, consume less power, and will offer even higher performance. But arguably the most important benefit is that such an advanced process technology will enable are very small interconnect pitches, on the order of 6 to 9 microns. This will allow N5 base dies to be used in conjunction with direct bonding, enabling HBM4 to be 3D stacked right on top of logic chips. Direct bonding stands to allow for even greater memory performance, which is expected to be a big boost for AI and HPC chips that are always scrounging for more memory bandwidth.", "We already know that ", ". It is likely that TSMC will also produce HBM4 base dies for Micron. Otherwise, we'd be more surprised to see TSMC working with Samsung, as that conglomerate already has its own advanced logic fabs via its Samsung Foundry unit."]},
{"title": "G.Skill Demonstrates DDR5-10600 Memory Modules On Ryzen 8500G System", "paragraph": ["Ultra-high performance memory modules are a staple of of Computex, and it looks like this year G.Skill is showing off the highest performance dual-channel memory module kit to date. The company is demonstrating a DDR5 kit capable of 10,600 MT/s data transfer rate, which is a considerably higher speed compared to memory modules available today.", "The dual-channel kit that G.Skill is demonstrating is a 32 GB Trident Z5 RGB kit that uses cherry-picked DDR5 memory devices and which can work in a DDR5-10600 mode with CL56 62-62-126 timings at voltages that are way higher than standard. The demoed DIMMs are running the whole day in a fairly warm room, though it does not really run demanding applications or stress tests.", "Traditionally, memory module makers like G.Skill use Intel processors to demonstrate their highest-performing kits. But with the DDR5-10600 kit, the company uses AMD's Ryzen 5 8500G processor, which is a monolithic Zen 4-based APU with integrated graphics that's normally sold for budget systems. The motherboard is a high-end Asus ROG Crosshair X670E Gene and the APU is cooled down using a custom liquid cooling system The Asus ROG Crosshair X670E Gene motherboard has only two memory slots, which greatly helps to enable high data transfer rates, so it is a very good fit for the DDR5-10600 dual-channel kit.", "Though I have sincere doubts that someone is going to use an ultra-expensive DDR5-10600 memory kit and related gate with this inexpensive processor, it is interesting (and unexpected) to see an AMD APU as a good fit to demonstrate performance potential of G.Skill's upcoming modules.", "Speaking of availability of G.Skill's DDR5-10600 memory, it does not look like this kit is around the corner. The fastest DDR5 kit that G.Skill has today is its DDR5-8400 offering, so the DDR5-10600 will come to market a few speed bins later as G.Skill certainly needs to test the kit with various CPUs and ensure its stability. ", "One other thing to keep in mind is that both AMD and Intel are about to release new desktop processors this year, with the Ryzen 9000-series and Arrow Lake processors respectively. So G.Skill will undoubtedly focus on tuning its DDR5-10600 and other high-end kits primarily with those new CPUs."]},
{"title": "Micron's GDDR7 Chip Smiles for the Camera as Micron Aims to Seize Larger Share of HBM Market ", "paragraph": ["Micron notified us that it expects its HBM market share to rise to mid-20% in the middle of calendar 2025, not in the middle of fiscal 2025.", "", "For Computex week, Micron was at the show in force in order to talk about its latest products across the memory spectrum. The biggest news for the memory company was that it has kicked-off sampling of it's next-gen GDDR7 memory, which is expected to start showing up in finished products later this year and was being demoed on the show floor. Meanwhile, the company is also eyeing taking a much larger piece of the other pillar of the high-performance memory market – High Bandwidth Memory – with aims of capturing around 25% of the premium HBM market.", "Micron's first GDDR7 chip is a 16 Gb memory device with a 32 GT/sec (32Gbps/pin) transfer rate, which is significantly faster than contemporary GDDR6/GDDR6X. As ", ", the latest iteration of the high-performance memory technology is slated to improve on both memory bandwidth and capacity, with bandwidths starting at 32 GT/sec and potentially climbing another 50% higher to 48 GT/sec by the time the technology reaches its apex. And while the first chips are starting off at the same 2GByte (16Gbit) capacity as today's GDDR6(X) chips, the standard itself defines capacities as high as 64Gbit.", "Of particular note, GDDR7 brings with it the switch to PAM3 (3-state) signal encoding, moving from the industry's long-held NRZ (2-state) signaling. As Micron was responsible for the bespoke GDDR6X technology, which was the first major DRAM spec to use PAM signaling (in its case, 4-state PAM4), Micron reckons they have a leg-up with GDDR7 development, as they're already familiar with working with PAM.", "The GDDR7 transition also brings with it a change in how chips are organized, with the standard 32-bit wide chip now split up into four 8-bit sub-channels. And, like most other contemporary memory standards, GDDR7 is adding on-die ECC support to hold the line on chip reliability (though as always, we should note that on-die ECC isn't meant to be a replacement for full, multi-chip ECC). The standard also implements some other RAS features such as error checking and scrubbing, which although are not germane to gaming, will be a big deal for compute/AI use cases.", "The added complexity of GDDR7 means that the pin count is once again increasing as well, with the new standard adding a further 86 pins to accommodate the data transfer and power delivery changes, bringing it to a total of 266 pins. With that said, the actual package size is remaining unchanged from GDDR5/GDDR6, maintaining that familiar 14mm x 12mm package. Memory manufacturers are instead using smaller diameter balls, as well as decreasing the pitch between the individual solder balls – going from GDDR6's 0.75mm x 0.75mm pitch to a slightly shorter 0.75mm x 0.73mm pitch. This allows the same package to fit in another 5 rows of contacts.", "As for Micron's own production plans, the company is using its latest 1-beta (1β) fabrication process. While the major memory manufacturers don't readily publish the physical parameters of their processes these days, Micron believes that they have the edge on density with 1β, and consequently will be producing the densest GDDR7 at launch. And, while more nebulous, the company company believes that 1β will give them an edge in power efficiency as well.", "Micron says that the first devices incorporating GDDR7 will be available this year. And while video card vendors remain a major consumer of GDDR memory, in 2024 the AI accelerator market should not be overlooked. With AI accelerators still bottlenecked by memory capacity and bandwidth, GDDR7 is expected to pair very well with inference accelerators, which need a more cost-effective option than HBM.", "Speaking of HBM, Micron was the first company to formally announce its HBM3E memory last year, and it was among the first to start its volume shipments earlier this year. For now, Micron commands a 'mid-single digit' share of this lucrative market, but the company has said that it plans to rapidly gain share. If all goes well, by the middle of its calendar 2025 ", " the company hopes to capture a mid-20% share of the HBM market.", "As we go into fiscal year 2025, we expect our share of HBM to be very similar to our overall share on general DRAM market, said Praveen Vaidyanathan, vice president and general manager of the Compute Products Group at Micron. So, I would say mid-20%. […] We believe we have a very strong product as [we see] a lot of interest from various GPU and ASIC vendors, and continuing to engage with customers […] for the next, say 12 to 15 months.", "When asked whether Micron can accelerate output of HBM3E at such a rapid pace in terms of manufacturing capacity, Vaidyanathan responded that the company has a roadmap for capacity expansion and that the company would meet the demand for its HBM3E products. "]},
{"title": "SK hynix: GDDR7 Mass Production To Start in Q4'2024", "paragraph": ["Being a major JEDEC memory standard, GDDR7 is slated to be produced by all three of the Big Three memory manufacturers. But it seems that not all three vendors will be kicking off mass production at the same time.", "SK hynix was at this year's Computex trade show, showing off their full lineup of memory technologies – including, of course, GDDR7. SK hynix is the last of the major memory vendor's we've seen promoting their memory, and fittingly, they seem to be the last in terms of their mass production schedule. According to company representatives, the firm will kick off mass production of their GDDR7 chips in the last quarter of 2024.", "Comparatively, the company's cross-town rival, Samsung, is already sampling memory with the goal of getting it out the door in 2024. And Micron has been rather gung ho about not only starting mass production this year, but starting it early enough that at least some of their customers will be able to ship finished products this year.", "That said, it bears mentioning that with industry-standard memory technologies, mass production at one vendor does not indicate that another is late; it is just indicating that someone was first to validate with a partner and that partner plans to ship its product in 2024. And while mass production remains another 4+ months out, SK hynix does have sample chips for its partners to test right now, and the chips have been demonstrated at Computex.", "As far as SK hynix's floor booth at Computex 2024 is concerned, the company had GDDR7 chips on display along with a table essentially summarizing the company's roadmap. For now, SK hynix is planning on both 16Gbit and 24Gbit chips, with data transfer rates of up to 40 GT/s. Though when SK hynix intends to launch their higher-end configurations remains to be seen. Both of the company's rivals are starting out with 16Gbit chips running at 32 GT/sec, so being the first to get a faster/larger chip out would be a feather in SK hynix's cap."]},
{"title": "CUDIMM Standard Set to Make Desktop Memory a Bit Smarter and a Lot More Robust", "paragraph": ["While the new ", " for laptops have garnered a great deal of attention in recent months, it's not just the mobile side of the PC memory industry that is looking at changes. The desktop memory market is also coming due for some upgrades to further improve DIMM performance, in the form of a new DIMM variety called the Clocked Unbuffered DIMM (CUDIMM). And while this memory isn't in use quite yet, several memory vendors had their initial CUDIMM products on display at this year's Computex trade show, offering a glimpse into the future of desktop memory.", "A variation on traditional Unbuffered DIMMs (UDIMMs), Clocked UDIMMs (and Clocked SODIMMs) have been created as another solution to the ongoing signal integrity challenges presented by DDR5 memory. DDR5 allows for rather speedy transfer rates with removable (and easily installed) DIMMs, but further performance increases are running up against the laws of physics when it comes to the electrical challenges of supporting memory on a stick – particularly with so many capacity/performance combinations like we see today. And while those challenges aren't insurmountable, if DDR5 (and eventually, DDR6) are to keep increasing in speed, some changes appear to be needed to produce more electrically robust DIMMs, which is giving rise to the CUDIMM.", "Standardized by JEDEC earlier this year as ", ", CUDIMMs tweak the traditional unbuffered DIMM by adding a clock driver (CKD) to the DIMM itself, with the tiny IC responsible for regenerating the clock signal driving the actual memory chips. By generating a clean clock locally on the DIMM (rather than directly using the clock from the CPU, as is the case today), CUDIMMs are designed to offer improved stability and reliability at high memory speeds, combating the electrical issues that would otherwise cause reliability issues at faster memory speeds. In other words, adding a clock driver is the key to keeping DDR5 operating reliably at high clockspeeds.", "All told, JEDEC is proposing that CUDIMMs be used for DDR5-6400 speeds and higher, with the first version of the specification covering speeds up to DDR5-7200. The new DIMMs will also be drop-in compatible with existing platforms (at least on paper), using the same 288-pin connector as today's standard DDR5 UDIMM and allowing for a relatively smooth transition towards higher DDR5 clockspeeds.", "As outlined above, one of the biggest challenges for highly-clocked memory subsystems today is maintaining signal integrity, particularly over relatively long distances and with multiple interconnections (e.g. multiple DIMMs per channel). Traditionally, the weight of this task has primarily fallen on the memory controller/CPU, and to a lesser extent the motherboard, as UDIMMs are relatively dumb devices on their own. But with CUDIMMs, that paradigm is set to change by making DIMMs just a bit smarter, and thus making them capable of helping out with maintaining signal integrity.", "The big change here is the addition of a clock driver (CKD), which receives a base clock signal and regenerates it to redistribute to memory components on the module. A CKD essentially buffers the incoming clock signal, and then amplifies it on the way out when it drives the clock signal to the memory chips on the DIMM. CKDs also incorporate signal conditioning features such as duty cycle correction, which allows for for accurate timing and jitter reduction, and minimizing the overall rapid variations in the clock signal's timing.", "Minimizing clock skew – the difference in arrival times of the clock signal at different components – is another key function of the CKD. By matching propagation delays for each clock path, the CKD can ensure memory chips (and DIMMs) remain fully synchronized.", "", "Meanwhile, phase adjustment capabilities allow CKD to align the clock signal with the specific timing needs of different components, which means some additional work on the memory module maker's side. Which is perhaps why we have not seen many memory module vendors demonstrating their CKD-enabled products today as they still need to get familiar with the technology.", "", "All told, placing clock drivers in DIMMs isn't a new idea; the CUDIMM concept is largely a scaled-down version of the Registered DIMM (RDIMM), which has been used in servers for years and is the only type of DDR5 DIMM that Intel and AMD's server (and workstation) chips support. But whereas RDIMMs are a more expansive solution that buffers the command and address busses alongside the clock signal, CUDIMMs buffer only the clock signal and leave everything else untouched. In that context, CUDIMMs are essentially a half-step to RDIMMs.", "And while there are some CPU designers out there that would no doubt be ecstatic if all systems used RDIMMs (and ECC, as well), the economics of consumer PCs favors cheaper and less complex solutions when they're available. The design of the CKD itself reflects this; a JEDEC-standard CKD is just 35 pins, and nearly half of those are merely voltage/ground pins. So while CKDs represent an additional cost for DIMM construction, they are rather purposely designed to be cheaper to build than RDIMMs.", "", "In any case, CKDs will be coming to all of JEDEC's DDR5 memory form factors. So along with the CUDIMM, we'll have the Clocked SODIMM (CSODIMM), and even DDR5 CAMM2 memory modules will use clock drivers.", "Though since the need (or at least, standardization) around clocked DIMMs is based on the memory frequency, CUDIMMs and their other variations are all designed to be backwards compatible with existing DDR5 systems and memory controllers. Which means that a CUDIMM will use the same 288-pin DIMM slot as standard DDR5 DIMMs.", "", "Under the hood, this is accomplished by allowing a CUDIMM to either run a clock signal though the buffers on its CKD, or bypass those buffers entirely, running in the aptly named ", " mode. Officially, bypass mode is only supported for speeds up to DDR5-6000 (3000MHz), so JEDEC complaint DIMMs will be expecting to use CKD mode (", " or ", " at DDR5-6400 and beyond. The end result being that a CUDIMM should work with a slower/older DDR5 memory controller by going into bypass mode, whereas DIMMs without a CKD won't be available at the higher speeds that require a CKD (not at JEDEC-standard voltages and timings, at least).", "Several memory vendors, including G.Skill, TeamGroup, and V-Color, had CUDIMMs and CSODIMMs on display at Computex. Given that these new DIMMs go hand-in-hand with new platforms, the memory vendors aren't talking too much about specifics here. But since they had the hardware on display, don't be too surprised if we see them go into production systems (and retail shelves) sooner than later.", " is a relatively new name on the market of enthusiast-grade memory modules (as previously the company sold high-performance devices under the Acer Predator brand, and still does, so to speak). But it enters the game with advanced 16 GB and 32 GB modules rated for 6400 – 8800 MT/s operation, which is higher compared to 'regular' enthusiast-grade DIMMs . These devices are set to be available in September.", ", which has been a major enthusiast memory vendor for ages, demonstrated its Trident Z5 CK CUDIMMs at Computex as well. Though the company did not really highlight their performance, perhaps because it is still polishing off its CKD-enabled products and they are not yet setting records. At the end of the day, G.Skill has showcased a heavily overclocked system running at DDR5-10600 using regular DDR5 modules, so early CUDIMMs are not quite as eye-catching in comparison.", "By contrast, ", " demonstrated its DDR5-7200 memory modules with a CKD chip at the trade show.", "Finally, unlike some of its rivals, ", " seems to be taking some serious advantage of CKD chips for high-performance memory offerings, as it showcased both CUDIMMs and CSODIMMs at the trade show. The company is planning to offer 16GB and 24 GB CUDIMMs with speed bins between 6400 MT/s and 9000 MT/s at 1.1 V – 1.45 V. 9000 MT/s is faster than any easily-attainable enthusiast-class memory kits available today, so this is meant to highlight advantages of clock unbuffered memory modules.", "There are many suppliers of high-performance memory modules and yet only four of them demonstrated their CUDIMMs at Computex. Of those, only two decided to talk about expected performance of CUDIMMs (TeamGroup's demonstration looks like a work-in-progress type of thing). Though with the JEDEC standard having been on the books for almost half a year now, they will no doubt soon be joined by the myriad of other memory vendors that call the PC market home."]},
{"title": "Micron: U.S. Fabs Will Start Operating in 2026 - 2029", "paragraph": ["When Micron announced plans to build two new fabs in the U.S. in 2022, the company vaguely said both would come online by the decade's end. Then, in 2023, it began to optimize its spending, which pushed production at these fabrication facilities. This week, the company outlined more precise timeframes for when its fabs in ", " and ", " will start operations: this will happen from calendar 2026 to calendar 2029.", "", " a statement by Micron in its Q3 FY2024 financial results report ", ". ", "", "Micron's fiscal year 2027 starts in September 2026, so the new fab near Boise, Idaho, is set to start operations between September 2026 and September 2027. The company's fiscal 2028 starts in September 2027, so the fab will likely begin operations in calendar 2028 or later, probably depending on the demand for DRAM memory in the coming years. That said, Micron's U.S. memory fabs will begin operations between late 2026 and 2029, which aligns with the company's original plans. ", "Construction of the fab in Idaho is well underway. In contrast, construction of the New York facility has yet to begin as the company is working on regulatory and permitting processes in the state. ", "Micron's capital expenditure (CaPex) plan for FY2024 is approximately $8.0 billion, with a decrease in year-over-year spending on wafer fabrication equipment (WFE). In Q4 FY2024, the company will spend around $3 billion on fab construction, new wafer fab tools, and various expansions/upgrades.", "Looking ahead to FY2025, the company plans a substantial increase in capex, targeting a mid-30s percentage of revenue to support various technological and facility advancements. In particular, it expects its quarterly CapEx to average above the $3 billion level seen in the fourth quarter of FY2024, which means that it plans to spend about $12 billion in its fiscal 2025, which begins in late September.", "Half or more of the total CapEx increase in FY2025 (i.e., over $2 billion) will be allocated to constructing new fabs in Idaho and New York. Meanwhile, the FY2025 CapEx will significantly rise to fund high-bandwidth memory (HBM) assembly and testing and the construction of fabrication and back-end facilities. This increase also includes investments in technology transitions to meet growing demand. ", "", " said Sanjay Mehrotra, chief executive officer of Micron, at the company's conference call with investors and financial analysts (via ", "). ", ""]},
{"title": "Kioxia's High-Performance 3D QLC NAND Enables High-End High-Capacity SSDs", "paragraph": ["This week, Kioxia introduced its new 3D QLC NAND devices aimed at high-performance, high-capacity drives that could redefine what we typically expect from QLC-based SSDs. The components are 1 Tb and 2 Tb 3D QLC NAND ICs with a 3600 MT/s interface speed that could enable M.2-2230 SSDs with a 4 TB capacity and decent performance.", "Kioxia's 1 Tb (128 MB) and 2 Tb (256 TB) 3D QLC NAND devices are made on the company's BICS 8 process technology and feature 238 active layers as well as CMOS directly Bonded to Array (CBA) design, which implies that CMOS (including interface and buffers circuitry) is built on a specialized node and bonded to the memory array. Such a manufacturing process enabled Kioxia (and its manufacturing partner Western Digital) to achieve a particularly high interface speed of 3600 MT/s.", "In addition to being one of the industry's first 2 Tb QLC NAND devices, the component features a 70% higher write power efficiency compared to Kioxia's BICS 5 3D QLC NAND devices, which is a bit vague statement as the new ICs have higher capacity and performance in general. This feature will be valuable for data centre applications, though I do not expect someone to use 3D QLC memory for write-intensive applications in general. Yet, these devices will be just what the doctor ordered for AI: read-intensive, content distribution, and backup storage.", "It is interesting to note that Kioxia's 1 Tb 3D QLC NAND, optimized for performance, has a 30% faster sequential write performance and a 15% lower read latency than the 2 Tb 3D QLC component. These qualities (alongside a 3600 MT/s interface) promise to make Kioxia's 1 Tb 3D QLC competitive even for higher-end PCIe Gen5 x4 SSDs, which currently exclusively use 3D TLC memory.", "The remarkable storage density of Kioxia's 2Tb 3D QLC NAND devices will allow customers to create high-capacity SSDs in compact form factors. For instance, a 16-Hi stacked package (measuring 11.5 mm × 13.5 mm × 1.5 mm) can be used to build a 4TB M.2-2230 drive or a 16TB M.2-2280 drive. Even a single 16-Hi package could be enough to build a particularly fast client SSD.", "Kioxia is now sampling its 2 Tb 3D QLC NAND BiCS 8 memory with customers, such as Pure Storage.", "", " said Charles Giancarlo, CEO of Pure Storage. ", "", "", " said Hideshi Miyajima, CTO of Kioxia. ", "", "There is no word on when the 1 Tb 3D QLC BiCS 8 memory will be sampled or released to the market."]},
{"title": "SK hynix Ships LPDDR5T: 9600 MT/s Memory for Smartphones", "paragraph": ["SK hynix had started volume shipments of its LPDDR5T-9600 memory for high-end smartphones, the company announced this week. So far, the company's LPDDR6 'Turbo' memory with a 9600 MT/s data transfer speed has been certified to work with two range-topping mobile application processors from Qualcomm and MediaTek.", "SK hynix's LPDDR5T-9600 memory is available in 16 GB packages with a VDD voltage range of 1.01V to 1.12V and a VDDQ of 0.5v. Notably, this VDD range is just slightly over the LPDDR5X specfication (1.00V to 1.1V), which shouldn't be a serious problem, but likely warrants some extra compatibility testing with existing chips.", "Smartphone and SoC manufacturers have a great incentive to validate SK hynix's LPDDR5T-9600 and ", " as these modules offer a 76.8 GB/s peak bandwidth, up 12.5% from 68.2 GB/s offered by LPDDR5X-8533.", "So far, SK Hynix's LPDDR6T-9600 modules have been certified by Qualcomm for its Snapdragon 8 Gen 3 mobile SoC as well as MediaTek for its Dimensity 9300 and some subsequent processors. Meanwhile, SK Hynix confirmed that it had begun shipments of its LPDDR6T-9600 devices to Vivo, which will use it for X100 and X100 Pro mobile application processors.", "Following the latest trends, SK hynix mentions that its very fast LPDDR5T-9600 memory will be particularly useful for on-device AI applications. And, of course, faster DRAM is always welcomed for graphics intensive mobile applications, such as games.", "Smartphones are becoming essential devices for implementing on-device AI technology as the AI era kicks into full swing, said Myoungsoo Park, Vice President and Head of DRAM Marketing at SK hynix. There is a growing demand for high-performing, high-capacity mobile DRAMs in the market. We will continue to lead the premium DRAM market based on our technological leadership in AI memories, while staying in tune with market demands."]},
{"title": "G.Skill and V-Color Unveil Factory Overclocked ECC RDIMMs for Ryzen Threadripper 7000 [UPDATED]", "paragraph": ["With the launch of AMD new ", " and associated TRX50 platform comes the need for new memory kits. Thanks to UDIMMs and RDIMMs requiring different slot designs under DDR5, AMD has opted to go exclusively with RDIMMs for their latest generation of Threadripper processors. Which for memory makers has included putting together overclockable registered memory modules with ECC that support EXPO timings, such as the kits G.Skill and V-Color have announced this week with their Zeta R5 Neo and v-color DDR5 OC R-DIMM memory kits.", "G.Skill's ", " and ", " are exclusively designed for AMD's Ryzen Threadripper 7000-series processors. Both vendors are currently offering two types of kits: a 64 GB quad-channel kit consisting of four 16 GB RDIMMs, and a 128 GB quad-channel kit featuring four 32 GB RDIMMs. For systems using the TRX50 platform, a single kit suffices, while the high-end workstation-class WRX90 platform requires two of these quad-channel kits to fully populate all eight channels.", "G.Skill's modules with ECC are rated for of DDR5-6400 CL32 39-39-102 at massive 1.40 Volts, whereas v-color promises data transfer rates of up to 7200 MT/s, never mentions timings or voltages, but stresses that its kits are aimed at TRX50-based machines.", "G.Skill and v-color note that their overclockable RDIMMs, similar to other premium memory modules, are built using hand-selected memory ICs, making them better suited for overclocking. G.Skill's modules come with very basic heat spreaders, which in case of DDR5 may become a limiting factor for overclocking potential. By contrast, v-color's modules come with rather serious heat spreaders akin to those used for some server-grade modules.", "All the overclockable RDIMM modules from G.Skill and v-color come with AMD's EXPO profiles for simplified setup, with G.Skill using DDR5-6400 CL32 timings, while v-color runs at DDR5-7200 at unspecified timings.", "The exact overclocking potential of G.Skill's and v-color's Threadripper memory kits remain to be seen. The actual I/O die powering Threadripper is the same I/O die as AMD's other server processors, which is to say it's been optimized for stability over performance – not to mention supporting a much larger amount of memory. Still, as we've seen on AMD's consumer CPU platforms, the company's memory controllers are no slouches. All the while memory vendors are already offering high-clocked RDIMM kits for Intel's rival Sapphire Rapids Xeon platform.", "G.Skill's Zeta R5 Neo memory kits designed for AMD's Ryzen Threadripper 7000-series processors are already available at Newegg: the 64 GB kit is priced at ", ", whereas the 128GB kit costs ", ". This is of course a huge price premium, but this can be explained by the fact that we are talking about unique memory kits designed for very specific high-end CPUs.", "As for v-color's DDR5 OC R-DIMM memory kits for AMD's Ryzen Threadripper TRX50 platform, the company says that they will be available in November on its website.", "Sources: ", ", "]},
{"title": "Rambus Preps Updated RCD for Server-Grade DDR5-7200 Modules", "paragraph": ["Rambus has introduced its fourth-generation registering clock driver (RCD) chip for server-grade DDR5 memory modules. The updated RCD chip brings support for higher clockspeeds on DDR5 RDIMMs, allowing for future RDIMMs to run as fast as DDR5-7200, a step ahead of their current third-generation/DDR5-6400 RCD. Faster DDR5 RDIMMs will eventually go hand-in-hand with upcoming server platforms, with AMD, Intel, and others all eyeing significantly higher memory speeds for their next round of products.", "An RCD functions as a buffer between the memory controller and DRAM chips in RDIMMs, redistributing command and address signals across the module – and making up the Registered in Registered DIMM. This enhances signal integrity and enables more memory devices to be connected to a single DRAM channel. To work properly. the RCD must support a specific data transfer rate, so the new RCD buffer from Rambus will enable memory vendors to build server-grade DDR5-7200 modules.", "In addition to performing regular functions of RCD, the new Rambus chip also packs a serial presence detect (SPD) hub and temperature sensors, which are vital for DDR5 memory sticks on general and DDR5 datacenter memory modules in particular. Such functionality somewhat reduces costs of datacenter-grade DRAM sticks, though the costs of such devices are depend on the number of memory devices rather than by tiny chips like SPDs and temperature sensors.", "RCDs are crucial for contemporary server-grade memory modules, as these devices can only reach their full memory capacity with registered DIMMs. Rambus is the first company to officially introduce DDR5 RCDs that support a 7200 MT/s data transfer rate, which will be useful for next-generation server platforms.", "According to Rambus, their latest RCD chip is now shipping. Though given the long lead times in servers and server parts due to validation requirements, it's likely still some time off before it starts appearing in commercial servers and DIMMs."]},
{"title": "Micron Kicks Off Production of HBM3E Memory", "paragraph": ["Micron Technology on Monday said that it had initiated volume production of its HBM3E memory. The company's HBM3E known good stack dies (KGSDs) will be used for ", " for artificial intelligence (AI) and high-performance computing (HPC) applications, which will ship in the second quarter of 2024.", "Micron has announced it is mass-producing 24 GB 8-Hi HBM3E devices with a data transfer rate of 9.2 GT/s and a peak memory bandwidth of over 1.2 TB/s per device. Compared to HBM3, HBM3E increases data transfer rate and peak memory bandwidth by a whopping 44%, which is particularly important for bandwidth-hungry processors like Nvidia's H200.", "Nvidia's H200 product relies on the Hopper architecture and offers the same computing performance as the H100. Meanwhile, it is equipped with 141 GB of HBM3E memory featuring bandwidth of up to 4.8 TB/s, a significant upgrade from 80 GB of HBM3 and up to 3.35 TB/s bandwidth in the case of the H100.", "Micron's memory roadmap for AI is further solidified with the upcoming release of a 36 GB 12-Hi HBM3E product in March 2024. Meanwhile, it remains to be seen where those devices will be used.", "Micron uses its 1β (1-beta) process technology to produce its HBM3E, which is a significant achievement for the company as it uses its latest production node for its data center-grade products, which is a testament to the manufacturing technology.", "Starting mass production of HBM3E memory ahead of competitors SK Hynix and Samsung is a significant achievement for Micron, which currently holds a 10% market share in the HBM sector. This move is crucial for the company, as it allows Micron to introduce a premium product earlier than its rivals, potentially increasing its revenue and profit margins while gaining a larger market share.", "", "", "Source: "]},
{"title": "Samsung Launches 12-Hi 36GB HBM3E Memory Stacks with 10 GT/s Speed", "paragraph": ["Samsung announced late on Monday the completion of the development of its 12-Hi 36 GB HBM3E memory stacks, just hours after Micron said it had ", ". The new memory packages, codenamed Shinebolt, increase peak bandwidth and capacity compared to their predecessors, codenamed Icebolt, by over 50% and are currently the world's fastest memory devices.", "As the description suggests, Samsung's Shinebolt 12-Hi 36 GB HBM3E stacks pack 12 24Gb memory devices on top of a logic die featuring a 1024-bit interface. The new 36 GB HBM3E memory modules feature a data transfer rate of 10 GT/s and thus offer a peak bandwidth of 1.28 TB/s per stack, the industry's highest per-device (or rather per-module) memory bandwidth.", "Meanwhile, keep in mind that developers of HBM-supporting processors tend to be cautious, so they will use Samsung's HBM3E at much lower data transfer rates to some degree because of power consumption and to some degree to ensure ultimate stability for artificial intelligence (AI) and high-performance computing (HPC) applications.", "To make its Shinebolt 12-Hi 36 GB HBM3E memory stacks, Samsung had to use several advanced technologies. First, the 36 GB HBM3E memory products are based on memory devices made on Samsung's 4", " generation 10nm-class (14nm) fabrication technology, which is called and uses extreme ultraviolet (EUV) lithography.", "Secondly, to ensure that 12-Hi HBM3E stacks have the same z-height as 8-Hi HBM3 products, Samsung used its advanced thermal compression non-conductive film (TC NCF), which allowed it to achieve the industry's smallest gap between memory devices at seven micrometers (7 µm). By shrinking gaps between DRAMs, Samsung increases vertical density and mitigates chip die warping. Furthermore, Samsung uses bumps of various sizes between the DRAM ICs; smaller bumps are used in areas for signaling. In contrast, larger ones are placed in spots that require heat dissipation, which improves thermal management.", "Samsung estimates that its 12-Hi HBM3E 36 GB modules can increase the average speed for AI training by 34% and expand the number of simultaneous users of inference services by more than 11.5 times. However, the company has not elaborated on the size of the LLM.", "Samsung has already begun providing samples of the HBM3E 12H to customers, with mass production scheduled to commence in the first half of this year.", "Source: "]},
{"title": "SK Hynix Mulls 'Differentiated' HBM Memory Amid AI Frenzy", "paragraph": ["SK Hynix and AMD were at the forefront of the memory industry with the first generation of high bandwidth memory (HBM) back in 2013 – 2015, and SK Hynix is still leading this market in terms of share. In a bid to maintain and grow its position, SK Hynix has to adapt to the requirements of its customers, particularly in the AI space, and to do so it's mulling over how to make 'differentiated' HBM products for large customers.", "Developing customer-specific AI memory requires a new approach as the flexibility and scalability of the technology becomes critical, said Hoyoung Son, the head of Advanced Package Development at SK Hynix in the status of a vice president", "When it comes to performance, HBM memory with a 1024-bit interface has been evolving fairly fast: it started with a data transfer rate of 1 GT/s in 2014 – 2015 and reached upwards of 9.2 GT/s – 10 GT/s with the recently introduced HBM3E memory devices. With HBM4, the memory is set to transit to a 2048-bit interface, which will ensure steady bandwidth improvement over HBM3E.", "But there are customers which may benefit from differentiated (or semi-custom) HBM-based solutions, according to the vice president.", "For implementing diverse AI, the characteristics of AI memory also need to become more varied, Hoyoung Son said in an interview with ", ". Our goal is to have a variety of advanced packaging technologies capable of responding to these changes. We plan to provide differentiated solutions that can meet any customer needs.", "", "With a 2048-bit interface, many (if not the vast majority) of HBM4 solutions will likely be custom or at least semi-custom based on what we know from official and unofficial information about the upcoming standard. Some customers might want to keep using interposers (but this time they are going to get very expensive) and others will prefer to install HBM4 modules directly on logic dies using direct bonding techniques, which are also expensive.", "Making differentiated HBM offerings requires sophisticated packaging techniques, including (but certainly not limited to) SK Hynix's ", " technology. Given the company's vast experience with HBM, it may well come up with something else, especially for differentiated offerings.", "For different types of AI to be realized, the characteristics of AI memory also need to be more diverse, the VP said. Our goal is to have a range of advanced packaging technologies to respond to the shifting technological landscape. Looking ahead, we plan to provide differentiated solutions to meet all customer needs.", "Sources: ", ", "]},
{"title": "JEDEC Publishes GDDR7 Memory Spec: Next-Gen Graphics Memory Adds Faster PAM3 Signaling & On-Die ECC", "paragraph": ["JEDEC on Tuesday published the official specifications for GDDR7 DRAM, the latest iteration of the long-standing memory standard for graphics cards and other GPU-powered devices. The newest generation of GDDR brings a combination of memory capacity and memory bandwidth gains, with the later being driven primarily by the switch to PAM3 signaling on the memory bus. The latest graphics RAM standard also boosts the number of channels per DRAM chip, adds new interface training patterns, and brings in on-die ECC to maintain the effective reliability of the memory.", "“JESD239 GDDR7 marks a substantial advancement in high-speed memory design,” said Mian Quddus, JEDEC Board of Directors Chairman. “With the shift to PAM3 signaling, the memory industry has a new path to extend the performance of GDDR devices and drive the ongoing evolution of graphics and various high-performance applications.”", "GDDR7 has been in development for a few years now, with JEDEC members making the first disclosures around the memory technology about a year ago, when ", " as part of their validation tools. Since then we've heard from ", " ", " that we should expect the final version of the memory to launch in 2024, with JEDEC's announcement essentially coming right on schedule.", "As previously revealed, the biggest technical change with GDDR7 comes with the switch from two-bit non-return-to-zero (NRZ) encoding on the memory bus to ", ". This change allows GDDR7 to transmit 3 bits over two cycles, 50% more data than GDDR6 operating at an identical clockspeed. As a result, GDDR7 can support higher overall data transfer rates, the critical component to making each generation of GDDR successively faster than its predecessor.", "The first generation of GDDR7 is expected to run at data rates around 32 Gbps per pin, and memory manufacturers have previously talked about rates up to 36 Gbps/pin as being easily attainable. However the GDDR7 standard itself leaves room for even higher data rates – up to 48 Gbps/pin – with JEDEC going so far as touting GDDR7 memory chips reaching up to 192 GB/s [32b @ 48Gbps] per device in their press release. Notably, this is a significantly higher increase in bandwidth than what PAM3 signaling brings on its own, which means there are multiple levels of enhancements within GDDR7's design.", "Digging deeper into the specification, JEDEC has also once again subdivided a single 32-bit GDDR memory chip into a larger number of channels. Whereas GDDR6 offered two 16-bit channels, GDDR7 expands this to four 8-bit channels. The distinction is somewhat arbitrary from an end-user's point of view – it's still a 32-bit chip operating at 32Gbps/pin regardless – but it has a great deal of impact on how the chip works internally. Especially as JEDEC has kept the 256-bit per channel prefetch of GDDR5 and GDDR6, making GDDR7 a 32n prefetch design.", "", "The net impact of all of this is that, by halving the channel width but keeping the prefetch size the same, JEDEC has effectively doubled the amount of data that is prefetched per cycle of the DRAM cells. This is a pretty standard trick to extend the bandwidth of DRAM memory, and is essentially the same thing ", ". But it serves as a reminder that DRAM cells are still very slow (on the order of hundreds of MHz) and aren't getting any faster. So the only way to feed faster memory buses is by fetching ever-larger amounts of data in a single go.", "The change in the number of channels per memory chip also has a minor impact on how multi-channel clamshell mode works for higher capacity memory configurations. Whereas GDDR6 accessed a single memory channel from each chip in a clamshell configuration, GDDR7 will access two channels – what JEDEC is calling two-channel mode. Specifically, this mode reads channels A and C from each chip. It is effectively identical to how clamshell mode behaved with GDDR6, and it means that while clamshell configurations remain supported in this latest generation of memory, there aren't any other tricks being employed to improve memory capacity beyond ever-increasing memory chip densities.", "On that note, the GDDR7 standard officially adds support for 64Gbit DRAM devices, twice the 32Gbit max capacity of GDDR6/GDDR6X. Non-power-of-two capacities continue to be supported as well, allowing for 24Gbit and 48Gbit chips. Support for larger memory chips further pushes the maximum memory capacity of a theoretical high-end video card with a 384-bit memory bus to as high as 192GB of memory – a development that would no doubt be welcomed by datacenter operators in the era of large language AI models. With that said, however, we're still regularly seeing 16Gbit memory chips used on today's memory cards, even though GDDR6 supports 32Gbit chips. Coupled with the fact that Samsung and Micron have already disclosed that their first generation of GDDR7 chips will also top out at 16Gbit/24Gbit respectively, it's safe to say that 64Gbit chips are pretty far off in the future right now (so don't sell off your 48GB cards quite yet).", "For their latest generation of memory technology, JEDEC is also including several new-to-GDDR memory reliability features. Most notably, on-die ECC capabilities, similar to what we saw with the introduction of DDR5. And while we haven't been able to get an official comment from JEDEC on why they've opted to include ECC support now, its inclusion is not surprising given the reliability requirements for DDR5. In short, as memory chip densities have increased, it has become increasingly hard to yield a perfect die with no flaws; so adding on-chip ECC allows memory manufacturers to keep their chips operating reliably in the face of unavoidable errors.", "", "Internally, the GDDR7 spec requires a minimum of 16 bits of parity data per 256 bits of user data (6.25%), with JEDEC giving an example implementation of a 9-bit single error correcting code (SEC) plus a 7-bit cyclic redundancy check (CRC). Overall, GDDR7 on-die ECC should be able to correct 100% of 1-bit errors, and detect 100% of 2-bit errors – falling to 99.3% in the rare case of 3-bit errors. Information about memory errors is also made available to the memory controller, via what JEDEC terms their on-die ECC transparency protocol. And while technically separate from ECC itself, GDDR7 also throws in another memory reliability feature with command address parity with command blocking (CAPARBLK), which is intended to improve the integrity of the command address bus.", "Otherwise, while the inclusion of on-die ECC isn't likely to have any more of an impact on consumer video cards than its inclusion had for DDR5 memory and consumer platforms there, it remains to be seen what this will mean for workstation and server video cards. The vendors there have used soft ECC on top of unprotected memory for several generations now; presumably this will remain the case for GDDR7 cards as well, but the regular use of soft ECC makes things a lot more flexible than in the CPU space.", "", "Finally, GDDR7 is also introducing a suite of other reliability-related features, primarily related to helping PAM3 operation. This includes core independent LFSR (linear-feedback shift register) training patterns with eye masking and error counters. LFSR training patterns are used to test and adjust the interface (to ensure efficiency), eye masking evaluates signal quality, and error counters track the number of errors during training.", "Technical matters aside, this week's announcement includes statements of support from all of the usual players on both sides of the isle, including AMD and NVIDA, and the Micron/Samsung/SKhynix trifecta. It goes without saying that all parties are keen to getting to use or sell GDDR7 respectively, given the memory capacity and bandwidth improvements it will bring – and especially in this era where anything aimed at the AI market is selling like hotcakes.", "No specific products are being announced at this time, but with Samsung and Micron having previously announced their intentions to ship GDDR7 memory this year, we should see new memory (and new GPUs to pair it with) later this year."]},
{"title": "V-Color Has New RDIMM Octo-Kits For Threadripper 7000 CPUs: 768 GB Kits Starting at $4,840", "paragraph": ["V-Color has launched several EXPO-certified DDR5 RDIMM memory kits for AMD's Ryzen Threadripper 7000 Pro and non-Pro platforms. The new RDIMM memory kits, which only come in an eight-DIMM configuration, will enable workstation users to push the limits on the WRX90 platform with frequencies up to DDR5-7200 and memory kit capacities up to a staggering 768 GB (8 x 96 GB).", "These are your typical run-of-the-mill modules without the fancy heatsinks and flashy RGB lighting. The recipe for the RDIMMs revolves around a 10-layer PCB paired with SK hynix's DRAM chips. And as the Threadripper platforms are all one DIMM per channel (1DPC) designs, V-Color's octo-kits are intended to populate all the memory slots on the WRX90 motherboard in one go.", "V-Color is offering their RDIMM kits in several capacities and frequencies, with kit capacities ranging from 128 GB (8 x 16 GB) up to 768 GB (8 x 96 GB), while clockspeeds start at DDR5-5600 and top out at DDR5-7200.", "Typical for RDIMM kits, the maximum frequency will vary depending on the memory kit capacity. There are two factors to consider: binning costs and achieving stability at faster frequencies on higher capacities is more challenging for the processor. Ryzen Threadripper 7000 Pro and non-Pro chips officially support DDR5-5200 memory modules. Anything higher is overclocking; stability depends on the processor's integrated memory controller (IMC) quality. DDR5-7200 is only available on V-Color's 128 GB, 192 GB, and 256 GB memory kits. Meanwhile, the 512 GB and 768 GB memory kits top out at DDR5-6000.", "The DDR5-5600 and DDR5-6000 memory kits are the only ones rated to run at a relatively modest 1.25 V. The higher-end ones require 1.40 V due to the higher frequency and tighter memory timings. The memory timings on V-Color's RDIMM memory kits are decent, though they're far from rivaling premium DDR5 mainstream memory kits. The DDR5-5600 memory kit has 36-38-38-38-80 timings, whereas the DDR5-6000 and DDR5-6400 memory flaunts 32-39-39-102 timings. At the same time, V-Color binned the DDR5-6600 and DDR5-6800 memory kits for 34-46-46-92 and the DDR5-7000 and DDR5-7200 memory kits for 34-43-43-102 and 36-46-46-112, respectively.", "V-Color's RDIMM products are overclocked memory kits with a limited lifetime warranty. They come with AMD EXPO support to facilitate one-click memory overclocking. The memory kits are built specifically for the WRX90 platform but should work on Intel platforms (your mileage will vary, of course). Regarding the QVL, V-Color has validated the brand's overclocked RDIMMs on the Asus Pro WS WRX90E-Sage SE and the ASRock WRX90 WS Evo, motherboards that cost over $1,000.", "The 128 GB DDR5-5600 memory kit is the most affordable out of the lot, with an MSRP of $1,049.99, whereas the 192 GB counterpart sells for $1,579.99. At the other end of the spectrum, the flagship 768 GB DDR5-6000 memory kit has an hefty $4,919.99 price tag. V-Color's RDIMM memory kits are up for pre-order on the company's ", ", and the vendor will ship orders on March 15. The memory kits will be available worldwide through official distribution partners on the same date."]},
{"title": "Micron Unveils HBM3 Gen2 Memory: 1.2 TB/sec Memory Stacks For HPC and AI Processors", "paragraph": ["Micron today is introducing its first HBM3 memory products, becoming the latest of the major memory manufacturers to start building the high bandwidth memory that's widely used in server-grade GPUs and other high-end processors. Aiming to make up for lost time against its Korean rivals, Micron intends to essentially skip vanilla HBM3 and move straight on to even higher bandwidth versions of the memory they're dubbing HBM3 Gen2, developing 24 GB stacks that run at over 9 GigaTransfers-per-second. These new HBM3 memory stacks from Micron will target primarily AI and HPC datacenter, with mass production kicking off for Micron in early 2024.", "Micron's 24 GB HBM3 Gen2 modules are based on stacking eight 24Gbit memory dies made using the company's 1β (1-beta) fabrication process. Notably, Micron is the first of the memory vendors to announce plans to build HBM3 memory with these higher-density dies, while ", ", the company is using a 12-Hi configuration of 16Gbit dies. So Micron is on track to be the first vendor to offer 24 GB HBM3 modules in the more typical 8-Hi configuration. And Micron is not going to stop at 8-Hi 24Gbit-based HBM3 Gen2 modules, either, with the company saying that they plan to introduce even higher capacity class-leading 36 GB 12-Hi HBM3 Gen2 stacks next year.", "Besides taking the lead in density, Micron is also looking to take a lead in speed. The company expects its HBM3 Gen2 parts to hit date rates as high as 9.2 GT/second, 44% higher than the top speed grade of the base HBM3 specification, and 15% faster than the 8 GT/second target for ", ". The increased data transfer rate enables each 24 GB memory module to offer peak bandwidth of 1.2 TB/sec per stack.", "Micron says that 24GB HBM3 Gen2 stacks will enable 4096-bit HBM3 memory subsystems with a bandwidth of 4.8 TB/s and 6096-bit HBM3 memory subsystems with a bandwidth of 7.2 TB/s. To put the numbers into context, Nvidia's H100 SXM features a peak memory bandwidth of 3.35 TB/s.", "High frequencies aside, Micron's HBM3 Gen2 stacks are otherwise drop-in compatible with current HBM3-compliant applications (e.g., compute GPUs, CPUs, FPGAs, accelerators). So device manufacturers will finally have the option of tapping Micron as an HBM3 memory supplier as well, pending the usual qualification checks.", "Under the hood, Micron's goal to jump into an immediate performance leadership position within the HBM3 market means that they need to one-up their competition from a technical level. Among other changes and innovations to accomplish that, the company increased the number of through-silicon vias (TSVs) by two times compared to shipping HBM3 products. In addition, Micron shrunk the distance between DRAM devices in its HBM3 Gen2 stacks. These two changes to packaging reduced thermal impendence of these memory modules and made it easier to cool them down. Yet, the increased number of TSVs can bring other advantages too.", "Given that Micron uses 24 Gb memory devices (rather than 16 Gb memory devices) for its HBM3 Gen2 stacks, it is inevitable that it had to increase the number of TSVs to ensure proper connectivity. Yet, doubling the number of TSVs in an HBM stack can enhance overall bandwidth (and shrink latency), power efficiency, and scalability by facilitating more parallel data transfers. It also improves reliability by mitigating the impact of single TSV failures through data rerouting. However, these benefits come with challenges such as increased manufacturing complexity and increased potential for higher defect rates (already an ongoing concern for HBM), which can translate to higher costs.", "Just like other HBM3 memory modules, Micron's HBM3 Gen2 stacks feature Reed-Solomon on-die ECC, soft repair of memory cells, hard-repair of memory cells as well as auto error check and scrub support.", "Micron says it will mass produce its 24 GB HBM3 modules starting in Q1 2024, and will start sampling its 12-Hi 36GB HBM3 stacks around this time as well. The latter will enter high volume production in the second half of 2024.", "To date, the JEDEC has yet to approve a post-6.4GT/second HBM3 standard. So Micron's HBM3 Gen2 memory, as well as SK hynix's rival HBM3E memory, are both off-roadmap standards for the moment. Given the interest in higher bandwidth HBM memory and the need for standardization, we'd be surprised if the group didn't eventually release an updated version of the HBM3 standard that Micron's devices will conform to. Though as the group tends to shy away from naming battles (HBM2E was never a canonical product name for faster HBM2, despite its wide use), it's anyone's guess how this latest kerfuffle over naming will play out.", "Beyond their forthcoming HBM3 Gen2 products, Micron is also making it known that the company already working on HBMNext (HBM4?) memory. That iteration of HBM will provide 1.5 TB/s – 2+ TB/s of bandwidth per stack with capacities ranging from 36 GB to 64 GB."]},
{"title": "Micron Publishes Updated DRAM Roadmap: 32 Gb DDR5 DRAMs, GDDR7, HBMNext", "paragraph": ["In addition to unveiling its first ", ", Micron also published a fresh DRAM roadmap for its AI customers for the coming years. Being one of the world's largest memory manufacturers, Micron has a lot of interesting things planned, including high-capacity DDR5 memory devices and modules, GDDR7 chips for graphics cards and other bandwidth-hungry devices, as well as HBMNext for artificial intelligence and high-performance computing applications.", "We all love inexpensive high-capacity memory modules, and it looks like Micron has us covered. Sometimes in the late first half of 2024, the company plans to roll-out its first 32 Gb DDR5 memory dies, which will be produced on the company's 1β (1-beta) manufacturing process. This is Micron's latest process node and which does not use extreme ultraviolet lithography, but rather relies on multipatterning.", "32 Gb DRAM dies will enable Micron to build 32 GB DDR5 modules using just eight memory devices on one side of the module. Such modules can be made today with Micron's current 16 Gb dies, but this requires either placing 16 DRAM packages over both sides of a memory module – driving up production costs – or by placing two 16 Gb dies within a single DRAM package, which incurs its own costs due to the packaging required. 32 Gb ICs, by comparison, are easier to use, so 32 GB modules based on denser DRAM dies will eventually lead to lower costs compared to today's 32 GB memory sticks.", "But desktop matters aside, Micron's initial focus with their higher density dies will be to build even higher capacity data center-class parts, including RDIMMs, MRDIMMs, and CXL modules. Current high performance AI models tend to be very large and memory constrained, so larger memory pools open the door both to even larger models, or in bringing down inference costs by being able to run additional instances on a single server.", "For 2024, Micron is planning to release 128GB DDR5 modules based on these new dies. In addition, the company announced plans for 192+ GB and 256+ GB DDR5 modules for 2025, albeit without disclosing which chips these are set to use.", "Meanwhile, Micron's capacity-focused roadmap doesn't have much to say about bandwidth. While it would be unusual for newer DRAM dies not to clock at least somewhat higher, memory manufacturers as a whole have not offered much guidance about future DDR5 memory speeds. Especially with MRDIMMs in the pipeline, the focus is more on gaining additional speed through parallelism, rather than running individual DRAM cells faster. Though with this roadmap in particular, it's clear that Micron is more focused on promoting DDR5 capacity than promoting DDR5 performance.", "Micron was the first larger memory maker to ", " plans to roll out its GDDR7 memory in the first half of 2024. And following up on that, the new roadmap has the the company prepping 16 Gb and 24 Gb GDDR7 chips for late Q2 2024.", "As with ", ", Micron's plans for their first generation GDDR7 modules do not have them reaching the spec's highest transfer rates right away (36 GT/sec), and instead Micron is aiming for a more modest and practical 32 GT/sec. Which is still good enough to enable upwards of 50% greater bandwidth for next-generation graphics processors from AMD, Intel, and NVIDIA. And perhaps especially NVIDIA, since this roadmap also implies that we won't be seeing a GDDR7X from Micron, meaning that for the first time since 2018, NVIDIA won't have access to a specialty GDDR DRAM from Micron.", "In addition to GDDR7, which will be used by graphics cards, game consoles, and lower-end high-bandwidth applications like accelerators and networking equipment, Micron is also working on the forthcoming generations of its HBM memory for heavy-duty artificial intelligence (AI) and high-performance computing (HPC) applications.", "Micron expects its HBMNext (HBM4?) to be available in 36 GB and 64 GB capacities, which points to a variety of configurations, such as 12-Hi 24 Gb stacks (36 GB) or 16-Hi 32 Gb stacks (64 GB), though these are pure speculations at this point. As for performance, Micron is touting 1.5 TB/s – 2+ TB/s of bandwidth per stack, which points to data transfer rates in excess of 11.5 GT/s/pin."]},
{"title": "Samsung Begins to Produce Third 3nm Chip Amid Massive Losses On DRAM & NAND", "paragraph": ["Samsung this week reported their financial results for the second quarter of 2023, closing the book on an especially bleak quarter of the year with a massive $3.4 billion operating loss. The losses, stemming from its semiconductor business, come amid a continued slump in 3D NAND and DRAM sales volumes and prices. Though buried deep in Samsung's earnings report was a speck of good news, as well: the company has started to produce its third 3nm chip design with stable yield.", "Discussing Samsung Foundry's earnings, the company remains uncertain about demand recovery in the second half. Demand to recover gradually under considerable uncertainty over the intensity of a market recovery in 2H, with consumer sentiment to rebound amid easing inflation and as customers wind down inventory adjustments, a statement by Samsung reads.", "More broadly, Samsung revenue dropped sharply, with the company recording a 22% year-over-year decline to $46.915 billion. Earnings of Samsung's semiconductor divisions — including memory, SoCs, and foundry operations — declined to $29.86 billion, 48% YoY drop. Sales of memory hit $7 billion, a 57% year-over-year decline, though eking out a 1% quarter-over-quarter increase. Overall, Samsung recorded a $3.4 billion loss from its semiconductor operations due to low demand for commodity memory and declining commodity 3D NAND and DRAM prices.", "But there were some bright spots in Samsung's DRAM business, as well. Demand for high-performance high-density premium products like DDR5 modules and HBM memory increased, which helped to partly offset slow sales of commodity memory.", "Bit growth exceeded guidance as we expanded sales of server products while actively responding to rising demand for DDR5 and AI-use HBM, Samsung said. Demand for high-density/high-performance products stayed strong, driven by increased investments focusing on AI by major hyperscalers.", "While Samsung expects demand for memory to recover in the second half, the company is expecting to enact additional production cuts to further support memory prices.", "We expect to see a gradual recovery of the memory market in the second half of the year, but the pace of the market rebound is likely to depend on our macro variables, said Jaejune Kim, executive vice president of memory division. ", "Kim said that Samsung would be making further alterations to the output of some products, including 3D NAND.", "Production cuts across the industry are likely to continue in the second half, and demand is expected to gradually recover as clients continue to destock their (chip) inventory, a statement by Samsung reads.", "Finally, as noted earlier, as part of Samsung's earnings report the company also revealed that it's started production on its third 3nm (GAAFET) chip.", "Mass production of our third GAA product is going smoothly thanks to the stabilization of the 3nm process, and we are developing an improved process for 3nm as planned based on mass production experience with GAA, a ", " by Samsung reads.", "It ", " that Samsung Foundry has been producing the Whatsminer M56S++ cryptocurrency mining ASIC on its SF3E node (formerly known as 3GAE, 3nm gate-all-around early) for some time. It turned out a bit later that there is PanSemi, another developer of cryptocurrency mining hardware, that uses Samsung's SF3E to make its mining ASIC. Now, Samsung confirms that there is another customer that uses its latest production node, though the company isn't disclosing any further details about the client or their chip.", "Producing tiny cryptocurrency mining ASICs is a good way test a new fabrication process on a commercial application since even with a relatively high defect density, yields of such chips will likely be good enough to be viable. Meanwhile, Samsung Foundry's SF3E process technology promises to increase performance and cut down power consumption of cryptocurrency mining ASICs (vs. similar chips made on previous-generation nodes) and these are exactly that targets that miners would like to hit to boost their earnings.", "Sources: ", ", ", ", ", ", "]},
{"title": "TeamGroup Unveils JEDEC-Spec DDR5-6400 Memory Kits: Faster 1.1V DDR5 On The Way For Future CPUs", "paragraph": ["While DDR5 memory has been out and in use for a couple of years now, so far we haven't seen the memory reach its full potential – at least, not for rank-and-file standards-compliant DIMMs. The specification allows for ", ", but to date we've only seen on-spec kits (and processors) as fast as DDR5-5600. But at last, it looks like things are about to change and DDR5 is set to live up to its full potential, going by a new memory kit announcement from TeamGroup.", "The memory kit vendor on Monday introduced its new ElitePlus-series DDR5-6400 memory modules, the first DDR5-6400 kit to be announced as JEDEC specification compliant. This means their new kit not only hits 6400 MT/s with standards-compliant timings, but arguably more importantly, it does so at DDR5's standard voltage of 1.1V as well. And while there are no platforms on the market at this time that are validated for JEDEC DDR5-6400 speeds, TeamGroup's product page already lists compatibility with Intel's yet-to-be-announced Z790 Refresh platform – so suitable processors seem to be due soon.", "TeamGroup's ", " and ", " DDR5-6400 memory modules come in 16 GB and 32 GB capacities (32 GB and 64 GB dual-channel kits) and feature JEDEC-standard CL52 52-52-103 timings as well as 1.1V voltage, as specified by the organization overseeing DRAM specs. For the moment, at least, TeamGroup's DDR5-6400 modules are the industry's fastest UDIMMs that are fully compliant with the JEDEC specifications.", "And while DDR5-6400 speeds (and far higher) are available today with factory overclocked XMP/EXPO, the announcement of a JEDEC standards-compliant kit is still significant for a few different reasons. Being able to hit DDR5-6400B speeds and timings at 1.1V means DDR5 memory has improved to the point to make higher speeds at low voltages more viable, which has potential payoffs for memory at every speed grade by allowing for improved speeds and reduced power consumption/heat. And for OEM and other warrantied systems that only use JEDEC-complaint RAM, this allows for a straightforward improvement in memory speeds and bandwidth. About the only downside to faster on-spec kits is that they lack XMP or EXPO serial presence detect (SPD) profiles, which makes their configuration slightly more complicated on existing platforms from AMD and Intel, as they don't officially support DDR5-6400. ", "Meanwhile, on their ", " TeamGroup notes that the new RAM is compatible with Intel's Z790 Refresh platform, a platform that has yet to be officially announced, but is rumored to go hand-in-hand with Intel Raptor Lake Refresh processors. Despite the lack of formal announcements from Intel there, TeamGroup seems to have let the cat out of the bag. So, prospective owners of Z790 Refresh systems can look forward to having access to specs-compliant 1.1V DDR5-6400 memory when that platform launches later this year.", "As for the modules at hand, traditionally, TeamGroup's Elite and ElitePlus memory modules are minimalistic and are aimed both at system integrators and at enthusiasts who are not after fancy designs of heat spreaders, RGB lighting, and maximum performance. In fact, TeamGroup's Elite modules do not have heat spreaders at all, whereas ElitePlus modules have a minimalistic heat spreader that will not interfere with large CPU coolers.", "TeamGroup says its Elite and ElitePlus DDR5-6400 memory modules will be available separately and in dual-channel kits starting from August in North America and Taiwan. And from that, we'd assume, Raptor Lake Refresh will not be far behind."]},
{"title": "Micron's CZ120 CXL Memory Expansion Modules Unveiled: 128GB and 256GB", "paragraph": ["This week, Micron announced the sample availability of its first CXL 2.0 memory expansion modules for servers that promise easy and cheap DRAM subsystem expansions. ", "Modern server platforms from AMD and Intel boast formidable 12- and 8-channel DDR5 memory subsystems offering bandwidth of up to 460.8 – 370.2 GB/s and capacities of up to 6 – 4 TB per socket. But some applications consume all DRAM they can get and demand more. To satisfy the needs of such applications, Micron has developed its CZ120 CXL 2.0 memory expansion modules that carry 128 GB and 256 GB of DRAM and connect to a CPU using a PCIe 5.0 x8 interface.", "", " said Siva Makineni, vice president of the Micron Advanced Memory Systems Group.", "Micron's CZ120 memory expansion modules use Microchip's SMC 2000-series smart memory controller that supports two 64-bit DDR4/DDR5 channels as well as Micron's DRAM chips made on the company's 1α (1-alpha) memory production node. Every CZ120 module delivers bandwidth up to 36 GB/s (measured by running an MLC workload with a 2:1 read/write ratio on a single module), putting it only slightly behind a DDR5-4800 RDIMM (38.4 GB/s) but orders of magnitude ahead of a NAND-based storage device.", "Micron asserts that adding four of its 256 GB CZ120 CXL 2.0 Type 3 expansion modules to a server running 12 64GB DDR5 RDIMMs can increase memory bandwidth by 24%, which is significant. Perhaps more significant is that adding an extra 1 TB of memory enables such a server to handle nearly double the number of database queries daily.", "Of course, such an expansion means using PCIe lanes and thus reducing the number of SSDs that can be installed into such a machine. But the reward seems quite noticeable, especially if Micron's CZ120 memory expansion modules are cheaper than actual RDIMMs or have comparable costs.", "For now, Micron has announced sample availability, and it is unclear when the company will start to ship its CZ120 memory expansion modules commercially. Micron claims that it has already tested its modules with major server platform developers, so right now, its customers are probably validating and qualifying the modules with their machines and workloads, so it is reasonable to expect CZ120 to be deployed already in 2024.", "", " added Makineni. ", ""]},
{"title": "SK Hynix Shows Off 321-Layer 3D TLC NAND Device", "paragraph": ["SK Hynix showcased its 321-layer TLC NAND memory at the Flash Memory Summit 2023. The South Korean company is the first NAND maker to publicly demonstrate 3D NAND with over 300 layers. Although such memory is expected in mass production in 2025, the demonstration is meant to showcase SK Hynix's preparedness for the next wave of non-volatile memory technology.", "This showcased 321-layer 3D NAND memory device boasts a 1 Tb (128 GB) capacity with TLC architecture, but SK Hynix refrained from revealing other details about it, such as interface speed. Meanwhile, the company mentioned that the chip features a 59% improvement in productivity compared to a 512 Gb 238-layer 3D TLC device, highlighting a significant improvement in per-wafer storage density. Whether or not the new production technology significantly reduces the cost-per-bit of 3D NAND is unclear.", "SK Hynix using a 1 Tb 3D TLC device to demonstrate the prowess of its 321-layer 3D NAND process technology may be a good sign, and the company intends to build high-capacity 3D devices on this node. The potential means reduced cost-per-bit compared to existing process nodes. This sets the stage for higher-capacity SSDs and other 3D NAND flash-bases storage devices.", "While SK Hynix has yet to reveal the specifics of building 321 active layers, it is safe to assume that the manufacturer used string stacking technology, just like the industry uses it for 200+ layer 3D NAND. However, it is unclear whether SK Hynix stacked two ~160-layer stacks on top of each other or managed to put three ~100+ stacks together.", "SK Hynix's 321-layer 3D TLC NAND device continues to use the company's CMOS-under-array architecture that puts NAND logic below memory cells to save die space, which is why SK Hynix refers to it as 4D NAND, which is essentially a marketing term.", "", " said Jungdal Choi, head of NAND development at SK Hynix, during a keynote speech. ", "", "Source: "]},
{"title": "Memory Makers on Track to Double HBM Output in 2023", "paragraph": ["TrendForce projects a remarkable 105% increase in annual bit shipments of high-bandwidth memory (HBM) this year. This boost comes in response to soaring demands from AI and high-performance computing processor developers, notably Nvidia, and cloud service providers (CSPs). To fulfill demand, Micron, Samsung, and SK Hynix are reportedly increasing their HBM capacities, but new production lines will likely start operations only in Q2 2022.", "Memory makers managed to more or less match the supply and demand of HBM in 2022, a rare occurrence in the market of DRAM. However, an unprecedented demand spike for AI servers in 2023 forced developers of appropriate processors (most notably Nvidia) and CSPs to place additional orders for HBM2E and HBM3 memory. This made DRAM makers use all of their available capacity and start placing orders for additional tools to expand their HBM production lines to meet the demand for HBM2E, HBM3, and HBM3E memory in the future.", "However, meeting this HBM demand is not something straightforward. In addition to making more DRAM devices in their cleanrooms, DRAM manufacturers need to assemble these memory devices into intricate 8-Hi or 12-Hi stacks, and here they seem to have a bottleneck since they do not have enough TSV production tools, according to TrendForce. To produce enough HBM2, HBM2E, and HBM3 memory, leading DRAM producers have to procure new equipment, which takes 9 to 12 months to be made and installed into their fabs. As a result, a substantial hike in HBM production is anticipated around Q2 2024, the analysts claim.", "A noteworthy trend pinpointed by TrendForce analysts is the shifting preference from HBM2e (Used by AMD's Instinct MI210/MI250/MI250X, Intel's Sapphire Rapids HBM and Ponte Vecchio, and Nvidia's H100/H800 cards) to HBM3 (incorporated in Nvidia's H100 SXM and GH200 supercomputer platform and AMD's forthcoming Instinct MI300-series APUs and GPUs). TrendForce believes that HBM3 will account for 50% of all HBM memory shipped in 2023, whereas HBM2E will account for 39%. In 2024, HBM3 is poised to account for 60% of all HBM shipments. This growing demand, when combined with its higher price point, promises to boost HBM revenue in the near future.", "Just yesterday, Nvidia launched ", " for AI and HPC that uses HBM3E memory instead of HBM3. The new platform consisting of a 72-core Grace CPU and GH100 compute GPU, boasts higher memory bandwidth for the GPU, and it carries 144 GB of HBM3E memory, up from 96 GB of HBM3 in the case of the original GH200. Considering the immense demand for Nvidia's offerings for AI, Micron — which will be the only supplier of HBM3E in 1H 2024 — stands a high chance to benefit significantly from the freshly released hardware that HBM3E powers.", "TrendForce also noted a consistent decline in HBM product ASPs each year. To invigorate interest and offset decreasing demand for older HBM models, prices for HBM2e and HBM2 are set to drop in 2023, according to the market tracking firm. With 2024 pricing still undecided, further reductions for HBM2 and HBM2e are expected due to increased HBM production and manufacturers' growth aspirations.", "In contrast, HBM3 prices are predicted to remain stable, perhaps because, at present, it is exclusively available from SK Hynix, and it will take some time for Samsung to catch up. Given its higher price compared to HBM2e and HBM2, HBM3 could push HBM revenue to an impressive $8.9 billion by 2024, marking a 127% YoY increase, according to TrendForce.", "SK Hynix commanded 50% of the HBM memory market in 2022, followed by Samsung with 40% and Micron with a 10% share. Between 2023 and 2024, Samsung and SK Hynix will continue to dominate the market, holding nearly identical stakes that sum up to about 95%, TrendForce projects. On the other hand, Micron's market share is expected to hover between 3% and 6%.", "Meanwhile, (for now) SK Hynix seems to have an edge over its rivals. SK Hynix is the primary producer of HBM3, the only company to supply memory for Nvidia's H100 and GH200 products. In comparison, Samsung predominantly manufactures HBM2E, catering to other chip makers and CSPs, and is gearing up to start making HBM3. Micron, which does not have HBM3 in the roadmap,  produces HBM2E (which Intel reportedly uses for its Sapphire Rapids HBM CPU) and is getting ready to ramp up production of HBM3E in 1H 2024, which will give it a significant competitive advantage over its rivals that are expected to start making HBM3E only in 2H 2024."]},
{"title": "SK Hynix Launches 24GB LPDDR5X-8500 Stacks for Smartphones, PCs, and HPC", "paragraph": ["On Friday, SK Hynix said it had started mass production of 24 GB LPDDR5X memory stacks that can be used for ultra-high-end smartphones and PCs. The company's LPDDR5X-8500 devices combine ultra-high-performance with high density, thus enabling fast systems with sufficient memory capacity. SK Hynix says such modules could be used well beyond smartphones, PCs, and even servers.", "SK Hynix's 24 GB LPDDR5X package features an 8500 MT/s data transfer rate and a wide 64-bit interface, thus offering a peak bandwidth of 68 GB/s in the ultra-low voltage range of 1.01 to 1.12V. From a typical PC perspective, this is comparable to bandwidth provided by a dual-channel DDR5-4800 memory subsystem (76.8 GB/s), but at considerably lower power and an orders of magnitude smaller footprint.", "An interesting wrinkle of the SK Hynix's announcement is that the company started to supply these 24 GB LPDDR5X modules well before the announcement as the devices are already used in Oppo's Oneplus Ace 2 Pro smartphone launched on August 10, 2023.", "Oppo is not the only maker of high-end Android smartphones out there, so I would expect more companies to follow suit in the coming months as they roll out handsets based on the Qualcomm Snapdragon 8 Gen 2 system-on-chip.", "But SK Hynix envisions its LPDDR5X devices to be used beyond smartphones, so think PCs. Apple was the first company to use LPDDR for desktops and laptops. Still, now that PC SoCs from AMD and Intel support LPDDR5X expect other leading makers of notebooks to adopt LPDDR5X in general and SK Hynix's 24 GB packages in particular.", "Meanwhile, 64-bit LPDDR5X-8500 devices look particularly compelling for the automotive industry, combining performance, capacity, and a very compact form factor. Given the fact that modern infotainment systems require high memory bandwidth, such memory devices will be pretty beneficial. SK Hynix says these memory stacks could be used for servers and even high-performance computing (HPC) applications.", "", " said Myoungsoo Park, Vice President and Head of DRAM Marketing at SK Hynix. ", "", "Source: "]},
{"title": "Cadence Delivers Technical Details on GDDR7: 36 Gbps with PAM3 Encoding", "paragraph": ["When Samsung ", " the ongoing development of GDDR7 memory last October, the company did not disclose any other technical details of the incoming specification. But Cadence recently ", " the industry's first verification solution for GDDR7 memory, and in the process has revealed a fair bit of additional details about the technology. As it turns out, GDDR7 memory will use PAM3 as well as NRZ signaling and will support a number of other features, with a goal of hitting data rates as high as 36 Gbps per pin.", "At a high level, the evolution of GDDR memory in the recent years has been rather straightforward: newer memory iterations boosted signaling rates, increased burst sizes to keep up with those signaling rates, and improved channel utilization. But none of this substantially increased the internal clocks of the memory cells. For example, GDDR5X and then GDDR6 increased their burst size to 16 bytes, and then switched to dual-channel 32-byte access granularity. While not without its challenges in each generation of technology, ultimately the industry players have been able to crank up the frequency of the memory bus with each version of GDDR to keep the performance increases coming.", "But even simple frequency increases are increasingly becoming not so simple. And this has driven the industry to look at solutions other than cranking up the clocks.", "With GDDR6X, Micron and NVIDIA replaced traditional non-return-to-zero (NRZ/PAM2) encoding with four-level pulse amplitude modulation (PAM4) encoding. PAM4 increases the effective data transmission rate to two data bits per cycle using four signal levels, thus enabling higher data transfer rates. In practice, because GDDR6X has a burst length of 8 bytes (BL8) when it operates in PAM4 mode, it is not faster than GDDR6 at the same data rate (or rather, signaling rate), but rather is designed to be able to reach higher data rates than what GDDR6 can easily accomplish.", "Four-level pulse amplitude modulation has an advantage over NRZ when it comes to signal loss. Since PAM4 requires half the baud rate of NRZ signaling for a given data rate, the signal losses incurred are significantly reduced. As higher frequency signals degrade more quickly as they travel through a wire/trace - and memory traces are relatively long distances by digital logic standards - being able to operate at what's essentially a lower frequency bus makes some of the engineering and trace routing easier, ultimately enabling higher data rates.", "The trade-off is that PAM4 signaling in general is more sensitive to random and induced noise; in exchange for a lower frequency signal, you have to be able to correctly identify twice as many states. In practice, this leads to a higher bit error rate at a given frequency. To reduce BER, equalization at the Rx end and pre-compensation at the Tx end have to be implemented, which increases power consumption. And while it's not used in GDDR6X memory, at higher frequencies (e.g. PCIe 6.0), forward-error correction (FEC) is a practical requirement as well.", "And, of course, GDDR6X memory subsystems require an all-new memory controllers, as well as a brand-new physical interface (PHY) both for processors and memory chips. These complex implementations are to a large degree the main reasons why four-level coding has, until very recently, been almost exclusively used for high-end datacenter networking, where the margins are there to support using such cutting-edge technology.", "Given the trade-offs mentioned above in going with either PAM4 signaling or NRZ signaling, it turns out that the JEDEC members behind the GDDR7 memory standard are instead taking something of a compromise position.  Rather than using PAM4, GDDR7 memory is set to use PAM3 encoding for high-speed transmissions.", "As the name suggests, PAM3 is something that sits between NRZ/PAM2 and PAM4, using three-level pulse amplitude modulation (-1, 0, +1) signaling, which allows it to transmit 1.5 bits per cycle (or rather 3 bits over two cycles). PAM3 offers higher data transmission rate per cycle than NRZ – reducing the need to move to higher memory bus frequencies and the signal loss challenges those entail – all the while requiring a laxer signal-to-noise ratio than PAM4. In general, GDDR7 promises higher performance than GDDR6 as well as lower power consumption and implementation costs than GDDR6X.", "And for those keeping score, this is actually the second major consumer technology we've seen introduced that uses PAM3. USB4 v2 (aka 80Gbps USB) is also using PAM3 for similar technical reasons. To quote from our ", ":", "So what on earth in PAM3?", "", "PAM3 is a technology where the data line can carry either a -1, a 0, or a +1. What the system does is actually combine two PAM3 transmits into a 3-bit data signal, such as 000 is an -1 followed by a -1. This gets complex, so here is a table:", "When we compare NRZ to PAM3 and PAM4, we can see the rate of data transfer for PAM3 is in the middle of NRZ and PAM4. The reason why PAM3 is being used in this case is to achieve that higher bandwidth without the extra limitations that PAM4 requires to be enabled. ", "With that said,It remains to be seen how much power a 256-bit memory subsystem with the 36 Gbps data transfer rate promised by Samsung will use. The GDDR7 spec itself has yet to be ratified, and the hardware itself is still being constructed (which is where tools like Cadence's come in). But keeping in mind how bandwidth hungry applications for AI, HPC, and graphics are, that bandwidth will always be welcome.", "In addition to increased throughput, GDDR7 is expected to feature a number of ways to optimize memory efficiency and power consumption. In particular, GDDR7 will support four different read clock (RCK) modes in a bid to enable it only when needed: ", "In addition, GDDR7 memory subsystems will be able to issue two independent commands in parallel. For example, Bank X can be refreshed by issuing a Refresh per bank command on CA[2:0], while Bank Y can be read by issuing a read command on CA[4:3] at the same time. Also, GDDR7 will support linear-feedback shift register (LFSR) data training mode to determine appropriate voltage levels and timings to ensure consistent data transfers. In this mode, the host will keep track of each individual eye (connection), which will allow it to apply appropriate voltages to better optimize power consumption.", "Finally, GDDR7 will be able to shift between PAM3 encoding and NRZ encoding modes based on bandwidth needs. In high bandwidth scenarios, PAM3 will be used, while in low bandwidth scenarios the memory and memory controllers can shift down to more energy efficient NRZ.", "While JEDEC has not formally published the GDDR7 specification, this latest technical data dump comes as Cadence has launched their verification solution for GDDR7 memory devices. Their solution fully supports PAM3 simulation by a real number representation, it supports binary bus, strength modeling, and real number modeling.", "The verification IP also supports various modes of error injection in multiple fields of transactions during array data transfer and interface trainings. Furthermore, it comes with the waveform debugger solution to visualize transactions on the waveform viewers for faster debugging and verification.", "With the first-to-market availability of the Cadence GDDR7 VIP, early adopters can start working with the latest specification immediately, ensuring compliance with the standard and achieving the fastest path to IP and SoC verification closure, a statement by Cadence reads.", "While GDDR7 promises major performance increases without major increases of power consumption, perhaps the biggest question from technical audiences is ", " the new type of memory is set to become available. Absent a hard commitment from JEDEC, there isn't a specific timeframe to expect GDDR7 to be released. But given the work involved and the release of a verification system from Cadence, it would not be unreasonable to expect GDDR7 to enter the scene along with next generation of GPUs from AMD and NVIDIA. Keeping in mind that these two companies tend to introduce new GPU architectures in a roughly two-year cadence, that would mean we start seeing GDDR7 show up on devices later on in 2024.", "Of course, given that there are so many AI and HPC companies working on bandwidth hungry products these days, it is possible that one or two of them release solutions relying on GDDR7 memory sooner. But mass adoption of GDDR7 will almost certainly coincide with the ramp of AMD's and NVIDIA's next-generation graphics boards."]},
{"title": "G.Skill Launches DDR5-8000 CL38 48GB Memory Kit For Raptor Lake CPUs", "paragraph": ["G.Skill has announced a new, high capacity DDR5 memory kit for Intel's 13th Generation Raptor Lake processors and accompanying LGA1700 platform. The Trident Z5 RGB DDR5-8000 CL38, which features a capacity of 48 GB (2 x 24 GB), comes with an Intel XMP 3.0 profile for a fast and effortless setup on high-end systems that can accomodate the high-speed hardware", "With the release of 24 Gbit DDR5 memory chips, memory manufacturers are working to fill in the gap between current 16 GB and 32 GB UDIMMs. As these new, higher capacity dies allow for larger single-rank DIMMs, this is allowing DIMM vendors such as G.Skill to launch higher capacity versions of their fastest DIMMs.", "The memory timings on the Trident Z5 RGB DDR5-8000 aren't great, but they're decent enough. G.Skill binned the memory for CL 38-48-48-127 and 1.45 volts on the DRAM side. The specifications are almost identical to the Trident Z5 RGB 32 GB (2 x 16 GB) memory kits that G.Skill announced a few months back. The principal difference is that the vendor has bumped the memory kit capacity from 32 GB to 48 GB. Unfortunately, G.Skill didn't reveal which DRAM vendor's chips they're utilizing in the Trident Z5 RGB DDR5-8000 memory kit. Considering the data rate, it's plausibly using SK hynix's latest A-die ICs, as many vendors are utilizing those for premium memory kits DDR5-7000 speeds.", "Meanwhile, it's worth noting that although the Trident Z5 RGB DDR5-8000 has XMP 3.0 support, the memory kit won't quite be plug-and-play on many LGA1700 motherboards. Consumers need to own a processor with a very strong IMC that can tolerate high-speed memory (i.e. top-tier Raptor Lake chips). An equally capable motherboard is required as well. Even then, judging from G.Skill's validation list, it sounds like 1 DPC motherboards are going to be the prime choice. G.Skill has only validated the memory kit on Asus' ROG Maximus Z790 Apex and EVGA's Z790 Dark K|NGP|N, two over-engineered motherboards tailored to extreme overclocking. Interestingly, Gigabyte's Z790 Aorus Tachyon isn't on the list, nor is MSI's MEG Z690 Unify-X.", "G.Skill's Trident Z5 RGB DDR5-8000 memory kit is scheduled to hit retail shelves globally in April of this year, going up against as-of-yet-released kits from TeamGroup, V-Color, Galax, and Netac. In the meantime, the company is keeping a tight lip on the pricing, preferring to keep the shock factor under wraps for now. Suffice it to say, given the binning required to produce this speed grade of RAM, and the premium pricing of DDR5 overall, we don't expect that the Trident Z5 DDR5-8000 kits will come cheap."]},
{"title": "Kingston Launches Fury Beast And Fury Renegade DDR5 Memory in White", "paragraph": ["Kingston Fury, the gaming and high-performance division of Kingston Technology Company, Inc., has expanded the aesthetics of the company's Fury DDR5 memory portfolio. The Fury Beast and Fury Renegade DDR5 memory lineups now arrive with a white heat spreader design. As a result, consumers of both AMD and Intel platforms can take advantage of the new memory kits when putting together a PC with a white theme.", "The Fury Beast and Fury Renegade memory kits arrive in vanilla and RGB variants. In the case of the Fury Beast, the non-RGB version measures 34.9 mm, whereas the RGB version stands at 42.23 mm. The memory sticks to a single color, either black or white. On the other hand, the Fury Renegade is slightly taller at 39.2 mm. The RGB-illuminated trim is 44 mm in height. Unlike the Fury Beast, the Fury Renegade rocks a dual-tone exterior in either black and silver or the more recent white and silver combination.", "Included within the RGB variations of the Fury Beast and Fury Renegade is Kingston's patented Infrared Sync technology, which, as the name implies, keeps the illumination on the memory module in sync. Kingston provides the company's proprietary Fury CTRL software for users to control the lighting, or they can use the included RGB software from their memory vendors.", "", "Kingston commercializes the Fury Beast and Fury Renegade as individual memory modules and dual-DIMM memory kits. Unfortunately, consumers that want a quad-DIMM memory kit are out of luck until next month. Kingston still uses standard 16 gigabit dies with the brand's DDR5 memory kits. As a result, the company cannot match other vendors who have hit 192 GB (4 x 48 GB) capacity with non-binary memory modules.", "The Fury Beast portfolio caters to mainstream consumers and offers more varieties. The speeds span from 4,800 MT/s to 6,000 MT/s, with memory kit capacities starting at 16 GB. There are Intel XMP 3.0- and AMD EXPO memory kits. The DDR5-4800 memory kit has CL 38-38-38 timings and is plug-and-play friendly. The higher-grade memory kits come with either Intel XMP 3.0 or AMD EXPO support. The Intel version of the Fury Beast DDR5-6000 memory kit sports 40-40-40 timings and requires 1.35 volts. On the contrary, the AMD version possesses better memory timings (CL 36-38-38) while using the same voltage.", "The Fury Renegade series targets gamers and enthusiasts. The memory kits start where the Fury Beast left off. The slowest Fury Renegade memory kit clock in at 6,000 MT/s, and the fastest option maxes out at 7,200 MT/s. Kingston only sells the Fury Renegade in 32 GB and 64 GB kit capacities. All Fury Renegade memory kits are Intel XMP 3.0-certified. The DDR5-7200 memory kit, available only in 32 GB (2 x 16 GB), has the memory timings configured to CL 38-44-44 and pulls 1.45 volts.", "In addition, Kingston backs its Fury Beast and Fury Renegade products with a limited lifetime warranty. The Fury Beast memory kits start at $69, $119, and $228 for the 16 GB, 32 GB, and 64 GB options, respectively. Meanwhile, the starting prices for the Fury Renegade 32 GB and 64 GB memory kits are $159 and $368, respectively."]},
{"title": "Samsung Becomes Latest Memory Fab to Cut Production Amidst Post-Pandemic Slump", "paragraph": ["Following an ongoing slump in demand that has impacted the entire memory industry over the last several months, Samsung this week has become the latest memory foundry to announce production cuts for NAND and DRAM. The meaningful cuts planned by Samsung make it the latest memory fab – and last of the big three – to undertake cuts in light of a significantly weaker market, while also marking an end to Samsung's efforts hold off on production cuts amidst the current slump to try to gain market share.", "The cuts come as Samsung Electronics has experienced a substantial drop in revenue and profits, with Q1 sales dropping 19% and operating profits plummeting 95%, according to ", ". And while a sales drop was expected (if not obligatory) in the highly cyclical commodity memory industry, this latest boom-bust cycle as been more extreme than most. The explosion in demand during the pandemic has given way to a similarly large bust that started in Q4 2022 and is expected to last for at least a couple more quarters.", "Samsung had previously planned to keep production levels largely intact in a bid to gain market share from rivals SK hynix and Micron, who have already enacted their own production cuts. However, the depth of this latest slump has finally forced Samsung to take action, as Samsung has reached the limits of what the company can weather.", "Despite these cuts, however, Samsung is also making it clear that they are very much short-term cuts, and that the company intends to continue their long-term investment plans in new fabs.", "We have cut short-term production plans, but as we project solid demand for the mid-to-long term, we will continue to invest in infrastructure to secure essential cleanrooms and to expand R&D investment to solidify tech leadership, a statement by Samsung reads.", "For the time being, Samsung is not disclosing by just how much they are reducing wafer starts and memory bit production. As a result, while Samsung's cuts should help to buoy NAND and DRAM prices – especially as the current glut in inventory slowly gets drained – it is hard to estimate just how much the company's decision will affect memory prices overall.", "Samsung is the largest global supplier of NAND and DRAM, in the fourth quarter of last year it held a ", " revenue share of the DRAM market and a ", " revenue share of the NAND market, according to TrendForce.", "It is unclear whether Samsung has managed to gain any market share in Q1 as it did not cut output like its peers, but analysts cited by Bloomberg believe that Samsung's memory business unit may have lost as much as $3 billion in Q1.", "The memory market is dominated by a few key players, including Micron, Samsung, and SK Hynix. Micron and SK Hynix lowered wafer starts on older production nodes while steadily continued ramping up production on their latest fabrication processes. Leading-edge nodes tend to cut memory chip costs and increase memory bit output per wafer, which often compensates for bit production cuts on older process technologies.", "Despite uncertainties that surround Samsung's memory production cuts, market analysts believe that the conglomerate's decision to decrease memory output will impact the market's supply-demand balance, potentially slowing the decline in memory prices in the second quarter.", "Counterpoint Research anticipates that the reduction in memory fab utilization rate will decelerate the drop in commodity memory prices, reports ", ". Still, the surplus of NAND and DRAM on the market is a result of diminishing demand and excessive inventory, so Samsung's supply-side actions are not expected to have any impact on sales. Therefore, analysts predict that the oversupply issue will persist until the third quarter, when the market begins to draw down inventory in anticipation of the fourth quarter's seasonal demand."]},
{"title": "As The Demand for HBM Explodes, SK Hynix is Expected to Benefit", "paragraph": ["The demand for high bandwidth memory is set to explode in the coming quarters and years due to the broader adoption of artificial intelligence in general and generative AI in particular. SK Hynix will likely be the primary beneficiary of the HBM rally as it leads shipments of this type of memory, holding a 50% share in 2022, according to ", ".", "Analysts from TrendForce believe that shipments of AI servers equipped with compute GPUs like Nvidia's A100 or H100 will increase by roughly 9% year-over-year in 2022. However, they do not elaborate on whether they mean unit shipments or dollar shipments. They now estimate that the rise of generative AI will catalyze demand for AI servers, and this market will grow by 15.4% in 2023 and continue growing at a compound annual growth rate of 12.2% through 2027.", "The upsurge in AI server usage will also increase demand for all types of memory, including commodity DDR5 SDRAM, HBM2e as well as HBM3 for compute GPUs, and 3D NAND memory for high-performance and high-capacity storage devices.", "TrendForce estimates that while general-purpose servers pack 500 GB – 600 GB of commodity memory, an AI server uses 1.2 TB – 1.7 TB. In addition, such machines use compute GPUs equipped with 80 GB or more of HBM2e/HBM3 memory. Since each AI machine comes with multiple compute GPUs, the total content of HBM per box is now 320 GB – 640 GB, and it is only set to grow further as accelerators like AMD's Instinct MI300 and Nvidia H100 NVL carry more HBM3 memory.", "Speaking of HBM3 adoption, it is necessary to note that SK Hynix is currently the only maker that mass produces this type of memory, according to TrendForce. As a result, as demand for this type of memory grows, it will benefit the most. Last year SK Hynix commanded 50% of HBM shipments, followed by Samsung with 40% and Micron with 10%. This year the company will solidify its positions and control 53% of HBM shipments, whereas shares of Samsung and Micron will decline to 38% and 9%, respectively, TrendForce claims.", "Nowadays, AI servers are used primarily by the leading U.S. cloud service providers, including AWS, Google, Meta, and Microsoft. As more companies launch their generative AI products, they will inevitably have to use AI servers either on-prem or at AWS or Microsoft. For example, Baidu and ByteDance plan to introduce generative AI products and services in the coming quarters.", "Source: "]},
{"title": "SK hynix Now Sampling 24GB HBM3 Stacks, Preparing for Mass Production", "paragraph": ["When SK hynix ", ", the company said it was developing both 8-Hi 16GB memory stacks as well as even more technically complex 12-Hi 24GB memory stacks. Now, almost 18 months after that initial announcement, SK hynix has finally begun sampling its 24GB HBM3 stacks to multiple customers, with an aim towards going into mass production and market availability in the second half of the year. All of which should be a very welcome development for SK hynix's downstream customers, many of whom are chomping at the bit for additional memory capacity to meet the needs of large language models and other high-end computing uses.", "Based on the same technology as SK hynix's existing 16GB HBM3 memory modules, the 24GB stacks are designed to further improve on the density of the overall HBM3 memory module by increasing the number of DRAM layers from 8 to 12 – adding 50% more layers for 50% more capacity. This is something that's been in the HBM specification for quite some time, but it's proven difficult to pull off as it requires making the extremely thin DRAM dies in a stack even thinner in order to squeeze more in.", "Standard HBM DRAM packages are typically ", " high (Samsung claims its 8-Hi and 12-Hi HBM2E are ", "), and, ideally, that height needs to be maintained in order for these denser stacks to be physically compatible with existing product designs, and to a lesser extent to avoid towering over the processors they're paired with. As a result, to pack 12 memory devices into a standard KGSD, memory producers must either shrink the thickness of each DRAM layer without compromising performance or yield, reduce the space between layers, minimize the base layer, or introduce a combination of all three measures.", "While SK hynix's latest press release offers limited details, the company has apparently gone for thinning out the DRAM dies and the space between them with an improved underfill material. For the DRAM dies themselves, SK hynix has previously stated that they've been able to shave their die thickness down to 30 microns. Meanwhile, the improved underflow material on their 12-Hi stacks is being provided via as part of the company's new ", " (MR-MUF) packing technology. This technique involves bonding the DRAM dies together all at once via the reflow process, while simultaneously filling the gaps between the dies with the underfill material.", "SK hynix calls their improved underfill material liquid Epoxy Molding Compound, or liquid EMC, which replaces the older non conductive film (NCF) used in older generations of HBM. Of particular interest here, besides the thinner layers this allows, according to SK hynix liquid EMC offers twice the thermal conductivity of NCF. Keeping the lower layers of stacked chips reasonably cool has been one of the biggest challenges with chip stacking technology of all varieties, so doubling the thermal conductivity of their fill material marks a significant improvement for SK hynix. It should go a long way towards making 12-Hi stacks more viable by better dissipating heat from the well-buried lowest-level dies.", "Assembly aside, the performance specifications for SK hynix's 24GB HBM3 stacks are identical to their existing 16GB stacks. That means a maximum data transfer speed of 6.4Gbps/pin running over a 1024-bit interface, providing a total bandwidth of 819.2 GB/s per stack.", "Ultimately, all the assembly difficulties with 12-Hi HBM3 stacks should be more than justified by the benefits that the additional memory capacity brings. SK hynix's major customers are already employing 6+ HBM3 stacks on a single product in order to deliver the total bandwidth and memory capacities they deem necessary. A 50% boost in memory capacity, in turn, will be a significant boon to products such as GPUs and other forms of AI accelerators, especially as this era of large language models has seen memory capacity become bottlenecking factor in model training. NVIDIA is already pushing the envelope on memory capacity with their ", " – a specialized, 96GB H100 SKU that enables previously-reserved memory – so it's easy to see how they would be eager to be able to provide 120GB/144GB H100 parts using 24GB HBM3 stacks.", "Source: "]},
{"title": "ASUS Issues Statement on Ryzen 7000X3D Processor Issues, Possible Voltage Issues with AMD EXPO", "paragraph": [" designed to address and alleviate potential issues with users on AM5 using AMD's Ryzen 7000X3D processors with 3D V-Cache. One of the main changes with MSI's latest UEFI firmware for AM5 included voltage restrictions when using Ryzen 7000X3D series CPUs so that these chips couldn't be overvolted as the V-Cache packaging is somewhat sensitive to additional power.", "Further to MSI's announcement, ASUS has released a statement to experienced engineer and extreme overclocker Roman 'Der8auer' Hartung, which addresses the potential issue with using AMD's EXPO memory profiles in conjunction with the Ryzen 7000X3D series chips. One of the key elements that seemingly surrounds the problem is the use of AMD's EXPO memory overclocking profiles.", "ASUS's Director of Global Product Marketing and Technical Marketing, Rajinder Gill, said in a statement to Der8auer, ", " Rajinder also said, ", "", "", "Looking at the narrative of the statement provided to Der8uaer from Rajinder, we can confirm that ASUS has indeed removed older iterations of its firmware for its AM5 motherboards. Looking at the EMEA side of things, at the time of writing, the ", ", which indicates ASUS recently updated the firmware, but the update isn't the latest one in question.", "", "The one thing these issues have in common is that AMD's EXPO memory profiles have been applied, claims Roman 'Der8auer' Hartung, and even highlighted that his Ryzen 9 7900X processor also fell foul the the 'bulging issue.' This is particularly interesting as this isn't an X3D series chip with 3D V-Cache, although we're not aware of any other reports of non-X3D Ryzen 7000 chips being affected at this time.", "Enabling EXPO memory profiles on Ryzen 7000 processors does several things to the processor that pushes it beyond the technical specification of the chip. Chief among these is raising the SoC voltage and some other primary voltages, such as VDDIO, which are used to feed the IOD. Like any ASIC, there are limits to how high voltages can be safely pushed, and this is one theory behind the cause of the recent run of damaged Ryzen reports. Though how this might be connected to the issue being centered around Ryzen X3D chips – where the voltage-sensitive V-Cache is on the CCDs and their separate voltage plane – is unclear at this time.", "In any case, this does underscore why AMD's EXPO memory overclocking profiles void the warranty on these chips, as there's more to EXPO than just ramping up memory frequencies and applying more voltage to the DRAM itself.", "Further to Rajinder's statement given to Der8auer, ASUS's Senior Technical Marketing Manager, ", " Tuesday afternoon:", "As we mentioned in our ", ", vendors are looking to address any more potential issues, following a small-but-concerning number of reports circulating on Reddit that their Ryzen 7000X3D processors are burning out and killing the motherboard in the process. ASUS's statement and the summary of the firmware on the official product page indicate that ASUS is worried about SoC voltage, and as such, the new firmware locks it down to 1.30 V. Which ASUS states is to 'protect the CPU and motherboard.' ", "", "On the Chinese product page for the ROG Crosshair X670E Extreme, the firmware has been updated as of today (at the time of writing) to 04/25/2023, and the firmware version in question (1302) does seemingly address the SoC voltage.", "Further to ASUS's and MSI's statements, ", ":", "It reads, ", "Of course, these issues of Ryzen 7000X3D series processors burning out aren't just limited to those using MSI and ASUS motherboards. Since the initial reports, users have reported additional issues on various models and brands across threads on Reddit. The potential for damage is one of the primary reasons AMD locked down the X3D series processors so that users couldn't manually overclock them. Even the first iteration, ", ", was also locked down.", "One thing remains clear: AMD and its motherboard partners are now officially investigating the matter, and users with affected Ryzen 7000 CPUs are advised to contact AMD customer support directly."]},
{"title": "Report: DDR5 RDIMM Production Impacted by PMIC Compatibility Issues", "paragraph": ["Memory module producers have been shipping unbuffered DDR5 memory modules for desktop and laptop computers running Intel's 12", " Generation Core 'Alder Lake' processors in high volumes since September, 2021, without any major issues. But DDR5 is just now entering the datacenter world, and according to a recent report, it looks like power management ICs (PMICs) for registered DIMMs have become a constraining factor due to compatibility issues.", "In a report published by ", " discussing the current state of the market for server-grade DDR5 memory, the semiconductor analyst firm noted that there is an issue with PMIC compatibility for DDR5 RDIMMs, with both DRAM suppliers and PMIC vendors are collaborating to resolve the problem. The analysts do not reveal the exact root cause of the problem, but claim that PMICs from Monolithic Power Systems (MPS) do not have any issues, leading them to expect MPS PMICs to be in high demand for the foreseeable future.", "Although DRAM makers have been distributing samples of their server grade modules to CPU and server makers since early 2022, practical issues only emerged recently when producers began to ramp up production of their machines running AMD's EPYC 9004 'Genoa' and Intel's 4", " Generation Xeon Scalable 'Sapphire Rapids' processors. As a result, the demand for PMICs from a single supplier has created a bottleneck in production, claims TrendForce. This will have a knock-on effect on the server market, which is already suffering from a demand drop.", "Neither analysts nor DRAM producers are currently disclosing the precise reason for the PMIC issue. But it is evident that, as both client and server DDR5 DIMMs require PMICs, it is turning out to be harder to make server-grade modules than client-aimed DIMMs.", "As part of the changes that came with the DDR5 specification, DDR5 memory modules now come with their own voltage regulating modules (VRMs) and PMIC. Moving these components on to DIMMs is intended to minimize voltage fluctuation ranges (DDR5's allowable range is about 3% (±0.033V) for a 1.1 volt supply), as well as decrease power consumption and improve performance. But doing so adds complexity to individual DIMMs, as well. ", "Unbuffered DDR5 DIMMs for client PCs are relatively simple since they are all single or dual-rank and carry at most 16 single-die memory chips. High-capacity Registered DDR5 memory modules for servers use more chips and those chips can pack in multiple DRAM dies each, which greatly increases complexity.", "As a result of the PMIC bottleneck as well as a slower ramping of DDR5 manufacturing capacity, TrendForce predicts that prices of server-grade 32GB DDR5 modules will drop to around $80 - $90 in April and May, due to the lower fulfillment rates of DDR5 server DRAM in the short term. As a result, DDR5 prices are expected to fall more slowly than DDR4 for the next couple of quarters, with DDR5 prices only finally catching up (or rather, down) with DDR4 once production picks up."]},
{"title": "Computex 2021: TeamGroup Goes BIG, the Xtreem DDR4-3600 256 GB Memory Kit", "paragraph": ["At the all-digital Computex 2021 trade show, TeamGroup has announced a new high-capacity memory kit designed for the high-end desktop market and workstation use. The new TeamGroup T-Force Xtreem ARGB DDR4-3600 kit boasts a combined capacity of 256 GB with 8 x 32 GB modules.", "Whether it's ridiculous amounts of Google Chrome tabs or a more realistic use case such as video editing, the Xtreem ARGB DDR4-3600 256 GB kit aims to provide a premium solution for workstation users on compatible platforms such as AMD's Threadripper 3000 series or Intel's Cascade Lake-X. The memory itself has a rectangular mirror finish on its illuminated heatsinks, designed to produce a layered effect that TeamGroup says is 'dazzling.'", "Regarding the specifications, the 256 GB kit has eight 32 GB sticks that operate at 3600 MT/s (DDR4-3600) and have primary latency timings of CL 18-22-22-42. There's no information available on the specific memory chips this kit is using, nor does TeamGroup specify the operating voltage of the kit. It has the speed to satisfy gaming demands, with AMD Threadripper using its Infinity Fabric interconnect in parallel with memory frequency.", "At present, we don't know when the TeamGroup T-Force Xtreem ARGB 256 GB (8 x 32 GB) kit will hit retail shelves, nor do we have the pricing. One thing is for certain; it's not going to be cheap as a similar kit in the Xtreem ARGB series with 64 GB (2 x 32 GB) retails for $420 at Newegg."]},
{"title": "Computex 2021: TeamGroup Announces its First DDR5-4800 Memory Module", "paragraph": ["Back in December 2020, ", " on future platforms. During Computex 2021, TeamGroup claims it has 'successfully taken the lead over competing PCB manufacturers', with the first of its announced products for DDR5, the Elite DDR5-4800 16 GB module. Back at CES 2021, ", ", but it sent us rendered images. We ultimately disapprove of this practice - don't state you have it in hand until you are ready to provide us actaul photographs of the thing. Unfortunately, TeamGroup has done the same here, providing renders. not photographs.", "Over the last year, we've highlighted certain aspects of DDR5 memory and what users can expect, including features, memory latency, and technological advancements over the current DDR4 memory. Some of which can be seen below:", "TeamGroup's announcement hasn't come as a surprise given how long DDR5 has been speculated and discussed over the last year. One of the first platforms to supposedly feature DDR5 support is Intel's Alder Lake microarchitecture, which is expected to land in Q4 2021/Q1 2022. The first series of DDR5 from TeamGroup will be based on its 'Elite' memory series, with the first kit to feature speeds of 4800 MT/s, sub-timings of CL40-40-40-77, and will feature an operating voltage of 1.1 V.", "One of the primary features of DDR5 is integrated on-die ECC, which is designed to improve overall system stability (but is actually more to do with yield). This is different to module-wide ECC, which DDR5 does not support by default (you still need a module-wide ECC module to support ECC technology). The information provided by TeamGroup say the Elite DDR5-4800 has double the banks compared to DDR4, with an all-black PCB. It is unclear whether or not the Elite DDR5-4800 will feature heatsinks, or they will operate with a bare PCB. We also know that it will feature 16 GB of capacity and will likely be sold as a dual-channel kit, and perhaps individually.", "At present, there's no information on latency timings or how much the Elite DDR5-4800 16 GB module will cost, but TeamGroup does state that it will be unveiling its 'new generation' of products in September 2021."]},
{"title": "Computex 2021: G.Skill Trident Z Royal Elite With DDR4-4000 CL14, Tight Latencies", "paragraph": ["During Computex 2021, G.Skill has announced a couple of new memory kits featuring its regal-looking Trident Z Royal Elite heatsinks. Available with super tight primary latencies of CL14, the new Trident Z Royal Elite kits will be available in DDR4-4000 and DDR4-3600, with various capacities available, including 16, 32, 64, and 128 GB kits.", "There are many different parts of a system that can add varying levels of aesthetic glamor, including the motherboard, CPU cooler, fans, anything with RGB on it, but almost everything struggles to be as bling as G.Skills Trident Z Royal Elite memory. Launched back in April, the G.Skill Trident Z Royal Elite comes available in gold and silver. Both color variants feature eight customizable RGB LED lighting zones, with a patented crystalline patterning across for that regal touch.", "Touching on the specifications, the top kit features speeds of DDR4-4000 with CL14-14-14-35, at a larger-than-expected operating voltage of 1.55 V. It will be available in two varieties, including a 16 GB (2 x 8 GB), and a 32 GB (2 x 16 GB) kit. The DDR4-3600 kits come with equally tight CL14 latencies, with a slightly lower 1.45 V operating voltage, and will be available in 16 GB (2 x 8 GB), 32 GB with the option for 2 x 16 GB or 4 x 8 GB kits. For users looking for more capacity, there are options at 64 GB with 4 x 16 GB and a large 128 GB kit with 8 x 16 GB. ", "G.Skill says the new Trident Z Royal Elite DDR4-4000 and DDR4-3600 CL14 kits will be available from June but haven't provided us with pricing at the time of writing."]},
{"title": "Micron Sells Lehi 3D XPoint Fab to Texas Instruments for $900M", "paragraph": ["Back in March of this year, Micron announced that it would be getting out of the 3D XPoint business entirely, abandoning the technology and putting its sole 3D XPoint fab up for sale. Now a short few months later, Micron has secured a buyer for the fab – and it’s not Intel. Rather it will be Texas Instruments who picks up the fab, buying it off of Micron for $900 million with plans to convert it over to analog and embedded processors.", "The sale of the Lehi fab is the latest and final chapter in Micron’s years-long efforts to unwind its non-volatile memory joint venture with Intel, IM Flash. Over the last decade Micron has acquired Intel’s share of the business in multiple stages, culminating in acquiring the crown jewel of the former partnership, the ", ", in 2018. Since then, Micron decided that it would ", ", culminating with ", ", leaving Micron with a modern fab that it didn’t have an immediate need for.", "To that end, Micron put the fab up for sale earlier this year, and has quickly found a buyer amidst the ongoing chip crunch. And while former partner (and current customer) Intel was the most likely candidate, they were not a shoe-in. As our own Billy Tallis put it at the time “Intel is not guaranteed to be the buyer of the Lehi, UT fab. They've doubtless had opportunities to do so before as Intel and Micron unwound their partnership”.", "Instead, the memory fab will be going to Texas Instruments, who is buying the building – but not all of the tools. Though designed for 3D XPoint production, the Lehi fab is otherwise a modern, 2 million square foot fab that can process 300mm wafers and is readily capable of being converted to other uses; and this is the direction TI will be taking things. The company is currently planning to equip the fab for the production of analog and embedded processors on the 65nm and 45nm nodes, with the ability to take the fab “beyond those nodes as required.” For Texas Instruments this will be their fourth 300mm fab.", "Meanwhile the remaining memory tools that TI isn’t buying will be further assets for Micron, who will be keeping some of them and selling the rest. According to the company’s press release, some of these tools are getting redeployed to other Micron fabs, some have been sold, and yet other tools are still up for sale. Micron doesn’t mention who the tool buyers are, but given the specialized nature of the equipment, it wouldn’t be too surprising if Intel were among them. Overall, Micron is valuing the tools at $600 million, bringing the total value of the transaction to a cool $1.5 billion.", "The sale is expected to close at the end of the year, at which point TI will be putting out offers to retain all of the Lehi staff as the fab gets converted over to TI’s analog and logic processes.", "Finally, for the sole company to actually use 3D XPoint memory, the sale of the Lehi fab calls into question Intel’s own 3D XPoint production plans. Having sold their share of the fab to Micron, Intel transitioned to being a customer of the world’s only 3D XPoint fab in late 2019 – an arrangement that left the fab operating in the red for Micron, as Intel’s 3D XPoint orders weren’t enough to fully utilize the fab. IM Flash jointly developed Intel’s current (", ") 3D XPoint memory technology as well, and it’s believed that the Lehi fab has been producing all of that memory for Intel.", "So it remains to be seen just how Intel will be impacted, as the sale puts a running clock on how much longer they can buy 3D XPoint memory from the third-party fab. Eventually Intel will need to setup their own fab – likely in Rio Rancho, NM, where their 3D XPoint R&D takes place – but so far the company hasn’t announced any such plans.", "Sources: ", ", "]},
{"title": "Samsung Teases 512 GB DDR5-7200 Modules", "paragraph": ["This week as part of the annual Hot Chips semiconductor conference, Samsung’s memory division has presented a poster/slides on a project it is currently working on with impressive end-point results. The company details a 512 GB module of DDR5 memory, running at DDR5-7200, designed for server and enterprise use. This is a step up from the 256 GB modules at the top end of the market today, but to get there, Samsung has been introducing some new features and functionality.", "As per standard DDR5 specifications, the modules will run at 1.1 volts with standard JEDEC DDR5-7200 timings, however ", " at this stage, choosing only to go to DDR5-6400. There are placeholders for future standards, such as DDR5-7200, and based on how the latencies increase from slower speed to higher speed, these should be in the realm of 50-50-50 to 60-60-60*.", "*", "As part of the presentation, Samsung states that the introduction of Same-Bank refresh (SBR) into its DDR5 will increase the efficiency of the DRAM bus connectivity by almost 10%, with DDR4-4800 showing the best efficiency in terms of energy from bit.", "In order to support the higher memory transfer rates of DDR5, Samsung has introduced a new DFE (Decision Feedback Equalizer) for better signal stability. It allows for a more variable data-path location, as well as per-pin calibration techniques.", "One of the big things about increasing capacity in memory is that you end up stacking more memory together. For their part, Samsung is stating that they can stack 8 DDR5 dies together and still be smaller than 4 dies of DDR4. This is achieved by thinning each die, but also new through-silicon-via connection topographies that allow for a reduced gap between dies of up to 40%. This is partnered by new cooling technologies between dies to assist with thermal performance.", "On power, we’ve known that one of the drivers for JEDEC’s newest memory specifications is lower power, and for DDR5 the major thing aside from the lower voltage is to bring the voltage regulator from the motherboard on to the memory module. This allows for the memory module manufacturer to more tightly control the power requirements and consumption of the memory, especially should the motherboard be a very cheap model that might skimp on valued components at the voltage regulation level. For this 512 GB module, Samsung is using a high-efficiency Power Management IC (PMIC) – Samsung as a company has a lot of PMIC experience through its other electronic divisions, so no doubt they can get high efficiency here. Samsung also states that its PMIC has reduced noise, allowing for lower voltage operation, and also uses a High-K Metal Gate process (introduced on CPUs at 45nm) in a first for DRAM.", "One of the talking points on DDR5 has been the on-die ECC (ODECC) functionality, built in to DDR5 to help improve yields of memory by initiating a per-die ECC topology. The confusion lies in that this is not a true ECC enablement on a DDR5 module, which still requires extra physical memory and a protected bus. But on the topic of ODECC, Samsung is showcasing an improvement on its bit-error rate of 10", ", or a factor of a million lower BER. How much of this is required by the DDR5 JEDEC specification is unclear at this point, but it’s still a good direction to have.", "At the end of the slide deck from Samsung, it states that its first 512 GB module should be ready for mass production by the end of 2021 – it’s unclear if this is a DDR5-7200 module or something else, as the slide could be interpreted differently. But one of the key aspects to this discussion is when the market expects the crossover of DDR4 and DDR5 to occur: Samsung has a big window of 2023-2024 planned for that crossover, which does align with other market analyst predictions.", "This stuff is still going to cost some serious money, which makes me wonder what this means for consumers. Right now the supply of 32 GB modules (UDIMMs) seems to be plentiful for those that want 128 GB of memory in a consumer system. The advent of these new memory packages from Samsung might suggest a path to 64 GB modules for DDR5 on the consumer platform, however you can bet your bottom dollar that they’ll stay for enterprise for a while as they will command a price premium.", "Stay tuned for ", " throughout this week."]},
{"title": "G.Skill Unveils Premium Trident Z5 and Z5 RGB DDR5 Memory, Up To DDR5-6400 CL36", "paragraph": ["With memory manufacturers clamoring over themselves to push out DDR5 in time for the upcoming launch of Intel's Alder Lake processors, G.Skill has unveiled its latest premium Trident Z5 kits. The latest Trident kits are based on Samsung's new DDR5 memory chips and range in speed from DDR5-5600 to DDR5-6400, with latencies of either CL36 or CL40. Meanwhile, G.Skill has also opted to use this opportunity to undertake a complete design overhaul from its previous DDR4 memory, with a fresh new look and plenty of integrated RGB.", "Looking at performance, the top SKU comes with fast speeds of DDR5-6400, with either a latency of CL 36-36-36-76 or CL 40-40-40-76. Both the lower-rated kits of DDR5-6000 and DDR5-5600 are available with the same latencies, while all of the six combinations will be available in 32 GB kits, with 2 x 16 GB memory modules. The new G.Skill Trident Z5 and Z5 RGB memory kits will also feature the latest Samsung memory ICs, with G.Skill hand screening the memory chips themselves to ensure maximum stability and performance.", "At the time of writing, G.Skill hasn't confirmed the operating voltages of each kit. G.Skill also hasn't unveiled its pricing at this time, but it did say that the Trident Z5 and Trident Z5 RGB kits will be available from November.", "Meanwhile in terms of aesthetics, the G.Skill Trident Z5 DDR5 memory features a new design compared with previous Trident Z series kits. The Trident Z5 comes with a new dual texture heat spreader design and is available either with a black top bar (Z5) or a new translucent RGB light bar (Z5 RGB). It's also available in black and silver, with a black brushed aluminum insert across both colors, making it stand out.", "With the RGB enabled G.Skill Trident Z5 RGB DDR5 memory kits, the lighting can be customized via its Trident Z lighting control software or synced with other third-party software supplied by vendors such as ASRock, ASUS, GIGABYTE, and MSI's own RGB software."]},
{"title": "SK Hynix Announces Its First HBM3 Memory: 24GB Stacks, Clocked at up to 6.4Gbps", "paragraph": ["Though the formal specification has yet to be ratified by JEDEC, the memory industry as a whole is already gearing up for the upcoming launch of the next generation of High Bandwidth Memory, HBM3. Following announcements earlier this summer from controller IP vendors like Synopsys and Rambus, this morning SK Hynix is announcing that it has finished development of its HBM3 memory technology – and according to the company, becoming the first memory vendor to do so. With controller IP and now the memory itself nearing or at completion, the stage is being set for formal ratification of the standard, and eventually for HBM3-equipped devices to start rolling out later in 2022.", "Overall, the relatively lightweight press release from SK Hynix is roughly equal parts technical details and boasting. While there are only 3 memory vendors producing HJBM – Samsung, SK Hynix, and Micron – it’s still a technically competitive field due to the challenges involved in making deep-stacked and TSV-connected high-speed memory work, and thus there’s a fair bit of pride in being first. At the same time, HBM commands significant price premiums even with its high production costs, so memory vendors are also eager to be first to market to cash in on their technologies.", "In any case, both IP and memory vendors have taken to announcing some of their HBM wares even before the relevant specifications have been announced. We saw both parties get an early start with HBM2E, and now once again with HBM3. This leaves some of the details of HBM3 shrouded in a bit of mystery – mainly that we don’t know what the final, official bandwidth rates are going to be – but announcements like SK Hynix’s help narrow things down. Still, these sorts of early announcements should be taken with a small grain of salt, as memory vendors are fond of quoting in-lab data rates that may be faster than what the spec itself defines (e.g. SK Hynix’s HBM2E).", "Getting into the technical details, according to SK Hynix their HBM3 memory will be able to run as fast as 6.4Gbps/pin. This would be double the data rate of today’s HBM2E, which formally tops out at 3.2Gbps/pin, or 78% faster than the company's off-spec 3.6Gbps/pin HBM2E SKUs. SK Hynix’s announcement also indirectly confirms that the basic bus widths for HBM3 remain unchanged, meaning that a single stack of memory is 1024-bits wide. At Hynix’s claimed data rates, this means a single stack of HBM3 will be able to deliver 819GB/second worth of memory bandwidth.", "SK Hynix will be offering their memory in two capacities: 16GB and 24GB. This aligns with 8-Hi and 12-Hi stacks respectively, and means that at least for SK Hynix, their first generation of HBM3 memory is still the same density as their latest-generation HBM2E memory. This means that device vendors looking to increase their total memory capacities for their next-generation parts (e.g. AMD and NVIDIA) will need to use memory with 12 dies/layers, up from the 8 layer stacks they typically use today.", "What will be interesting to see in the final version of the HBM3 specification is whether JEDEC sets any height limits for 12-Hi stacks of HBM3. The group ", ", where 8-Hi stacks had a maximum height but 12-Hi stacks did not. That in turn impeded the adoption of 12-Hi stacked HBM2E, since it wasn’t guaranteed to fit in the same space as 8-Hi stacks – or indeed any common size at all.", "On that matter, the SK Hynix press release notably calls out the efforts the company put into minimizing the size of their 12-Hi (24GB) HBM3 stacks. According to the company, the dies used in a 12-Hi stack – and apparently just the 12-Hi stack – have been ground to a thickness of just 30 micrometers, minimizing their thickness and allowing SK Hynix to properly place them within the sizable stack. Minimizing stack height is beneficial regardless of standards, but if this means that HBM3 will require 12-Hi stacks to be shorter – and ideally, the same height as 8-Hi stacks for physical compatibility purposes – then all the better for customers, who would be able to more easily offer products with multiple memory capacities.", "Past that, the press release also confirms that one of HBM’s core features, integrated ECC support, will be returning. The standard has offered ECC since the very beginning, allowing device manufacturers to get ECC memory “for free”, as opposed to having to lay down extra chips with (G)DDR or using soft-ECC methods.", "Finally, it looks like SK Hynix will be going after the same general customer base for HBM3 as they already are for HBM2E. That is to say high-end server products, where the additional bandwidth of HBM3 is essential, as is the density. HBM has of course made a name for itself in server GPUs such as NVIDIA’s A100 and AMD’s M100, but it’s also frequently tapped for high-end machine learning accelerators, and even networking gear.", "We’ll have more on this story in the near future once JEDEC formally approves the HBM3 standard. In the meantime, it’s sounding like the first HBM3 products should begin landing in customers’ hands in the later part of next year."]},
{"title": "Intel Alder Lake DDR5 Memory Scaling Analysis With G.Skill Trident Z5", "paragraph": ["In our ", ", we tested many variables that could impact performance on the new platform. This includes the performance variation when using Windows 11 versus Windows 10, performance with both DDR5 and DDR4 at official speeds, and the impact that both the new hybrid Performance and Efficient cores.", "With all of the different variables in that review, the purpose of ", "article is to evaluate and analyze the impact that DDR5 memory frequency plays on performance. While in our past memory scaling articles, we've typically stuck with just focusing on the effects of frequency, but this time we wanted to see how tighter latencies can have an impact on overall performance as well.", "", "Touching on the pricing and availability of DDR5 memory at the time of writing, the TLDR is that it's currently hard to find any in stock, and when it is in stock, it costs a lot. With a massive global chip shortage that many put down to the Coronavirus Pandemic, the drought has bumped prices above MSRP on many components. Interestingly enough, it's not the DDR5 itself causing the shortage, but the power management controllers that DDR5 uses per module to get higher bandwidth are in short supply. As a result, the increased cost can be likened to a sort of early adopters fee, where users wanting the latest and greatest will have to pay through the nose to own it.", "Another variable to consider with DDR5 memory is that a 32GB (2x16) kit of G.Skill Ripjaw DDR5-5200 can be found at retailer MemoryC for $390. In contrast, a more premium and faster kit such as G.Skill Trident Z5 DDR5-6000 has a price tag of $508, an increase of around 30%. One of the things to consider is that a price increase isn't linear to the performance increase, and that goes for pretty much every component from memory, graphics cards, and even processors. The more premium a product, the more it costs.", "In March 2021, ", ".' This was essentially an extended warranty for users planning to overclock Intel's processors, which could be purchased at an additional cost. One of the main benefits of this was that if users somehow damaged the silicon with higher than typical voltages (CPU VCore and Memory related voltages), users could effectively RMA the processors back to Intel on a like for like replacement basis. Intel stated that very few people took advantage of the plan to continue it.", "One of the variables to note when running Intel's Xtreme Memory Profiles (X.M.P 3.0) on DDR5 memory is that Intel classes this as overclocking. That means when RMA'ing a faulty processor, running the CPU at stock settings but enabling, an X.M.P 3.0 memory profile at DDR5-6000 CL36 is something they consider as an overclock. This could inherently void the warranty of the CPU. All processor manufacturers adhere to JEDEC specifications with their recommended memory settings to use with any given processor, such as DDR4-3200 for its 11th generation (Rocket Lake) and DDR5-4800/DDR4-3200 for its 12th generation (Alder Lake) processors.", "When it comes to overclocking DDR5 memory on the ASUS ROG Maximus Z690 Hero, we did all of our testing with Intel's Memory Gear at the 1:2 ratio. We did test the 1:1 and 1:4 ratio but without any great success. When enabling X.M.P on the G.Skill kit, it automatically sets the 1:2 ratio, with the memory controller running at half the speed of the memory kit.", "As we ", ", in certain software environments there can be unexpected performance behavior. When a thread starts, the operating system (Windows 10) will assign a task to a specific core. As the P-Cores (performance) and E-Cores (efficiency) on the hybrid Alder Lake design are at different performances and efficiencies, it is up to the scheduler to make sure the right task is on the right core. Intel's intended use case is that the in-focus software gets priority, and everything else is moved to background tasks. However, on Windows 10, there is an additional caveat - any software set to below normal (or lower) priority will also be considered background, and be placed on the E-cores, even if it is in focus. Some high-performance software sets itself as below normal priority in order to keep the system running it responsive, so there's a clash of ideology between the two.", "Various solutions to this exist. Intel stated to us that users could either run dual monitors or change the Windows Power Plan to High Performance. To investigate the issue during testing, all of our testing in this article was done with the Windows Power Plan set to High-Performance (as I do for motherboard reviews) and running the tests with the High-Performance Power Plan active.", "In addition to this, I also used a third-party scheduler, the ", ", to check for performance variations. I can safely and confidently say that there was around a 0.5% margin of variance between using the High-Performance Power Plan and setting the affinities and priorities to high using the Process Lasso software.", "It should also be noted that users running Windows 11 shouldn't experience any of these issues. When set correctly, we saw no difference between Windows 10 and Windows 11 in our original Core i9-12900K review, and so to keep things consistent with our previous testing for now, we're sticking with Windows 10 with our fix applied.", "As this article focuses on how well DDR5 memory scales, we have used a premium Z690 motherboard, the ASUS ROG Maximus Z690 Hero, and a premium ASUS ROG Ryujin II 360 mm AIO CPU cooler. ", "For the operating system, we've used the most widely available and latest build of Windows 10 64-bit (21H2) with all of the current updates at the time of testing. ", "Above are all of the frequencies and latencies we've tested in this article. For scaling, we selected the G.Skill Trident Z5 memory kit as it had the best overclocking ability from all of the DDR5 kits we received at launch. Out of the box it was rated the highest for frequency, and we pushed it even further. The G.Skill Trident Z5 memory was tested from DDR5-4800 CL36 up to and including DDR5-6400 CL36, but also a special case of DDR5-4800 CL32 for lower CAS latencies. Details on our overclocking exploits are later in the review.", "Read on for more information about G.Skill's Trident Z5 DDR5-6000, as well as our analysis on the scalability of DDR5 memory on Intel's Alder Lake. In this article, we cover the following:"]},
{"title": "China Develops High Capacity QLC 3D NAND: YMTC at 1.33 Tb", "paragraph": ["Yangtze Memory Technologies Co. (YMTC) has announced that it's developed its new 128-layer 1.33 Tb QLC 3D NAND memory chip, the X2-6070. The new chip is based on its Xtacking architecture which enables it to run with super high I/O while maximising the density of its memory arrays. YMTC has also unveiled its plan for a 128-layer 512 Gb TLC chip, the X2-9060, designed to meet more diverse application requirements.", "We first reported on the China-based company YMTC entering its 3D NAND memory chips into production back in 2018, when it unveiled its ", ". While it didn't disclose technical details of its announcement, it did state the Xtacking architecture has the capability to run the I/O with speeds of up to 3 Gbps. Fast forward to 2019, and it announced that it planned to start volume production of its ", ".", "Using its Xtacking architecture at the forefront of production, both the new X2-6070 and X2-9060 feature its updated 2.0 variant which YMTC claims to bring more benefits to flash memory. Both the X2-6070 and X2-9060 are claimed to deliver up to 1.6 Gb/s of I/O performance and operate with a Vccg voltage of 1.2 V. YTMC has stated that the X2-6070 QLC based chip will be first used in consumer-grade SSDs, with the aim to then deliver its capabilities into Enterprise focused drives.", "YMTC X2-6070 128-Layer QLC 3D NAND memory chip", "The QLC based X2-6070 has 128-layers and more than 366 billion effective charge-trap memory cells. Each memory cell has 4-bit of data, which equates to 1.33 Tb of storage capacity. Everything is proportionate to cost, and it seems like YMTC, which is newer than most to 3D NAND stacking, could again improve its Xtacking architecture in the future.", "We expect that YMTC, who is part of the Tsinghua Unigroup in China, is using the ", ". Tsinghua acquired XMC back in 2016, and while we haven't had it confirmed, it is likely to be producing its wafers at the ", ".", "YMTC hasn't released official specifications or data sheets about the X2-6070 QLC and X2-9060 MLC memory chips, nor has it stated when it is likely to be integrated with its controller partners (or which controllers support it)."]},
{"title": "ADATA's New 32 GB DDR4-3200 SO-DIMM, Ideal for Ryzen Mobile", "paragraph": ["ADATA, one of the leading manufacturers of DRAM and NAND products, has just unveiled its latest memory modules. The new ADATA DDR4-3200 32 GB parts are available in both UDIMM and SO-DIMM format with an operating voltage of just 1.2 V. This is just the ticket for adopters of the new Ryzen 4000 Mobile platform looking to run high-capacity memory without compromising on throughput performance. ", "Touching more on the design, we know the ADATA DDR4-2666 modules we saw at Computex were using Micron 16 Gb ICs to build its 32 GB UDIMMs. It is unlikely that ADATA has changed this, but we can't confirm this at present. The lower operating voltage over conventional DDR3 at 1.5 V according to ADATA equates to around 20% less power being drawn, which in turn generates less heat. ", "Potential use cases for DDR4-3200 32 GB memory is in platforms such as AMD's Threadripper 3000 with a total capacity of 256 GB over eight memory slots. This is more interesting when it comes to mobile platforms such as Ryzen 4000 which has seemingly raised the bar for computational performance in consumer notebooks. Being able to equip ", ".", "In terms of pricing, the new ADATA DDR4-3200 32 GB modules are set to retail with an MSRP of $160. These will filter into retail channels such as Amazon, but they will also be available to purchase from ", "."]},
{"title": "XPG Spectrix D50 Memory: A More Subtle RGB DDR4", "paragraph": ["ADATA's XPG division has unveiled its latest addition in the high-performance DRAM segment, the Spectrix D50. Starting from 8 GB DDR4-3000 modules, ", "XPG is the gaming division of ADATA, and has a broad portfolio of DRAM catering to multiple areas on the market. The latest from XPG is the Spectrix D50 which is similar to the Spectrix D60G, but with a more subtle take on RGB. Designed for enthusiasts and overclockers, it has a solid heatsink design with some interesting tweaks to make it look less aggressive than the D60G.", "The heat spreader on the Spectrix D50 memory includes a criss-cross geometric design on its 2 mm thick heatsink and a triangular RGB panel that can be controlled via the XPG RGB Sync app. XPG claims it can be used with major motherboard manufacturers own software, but it doesn't officially state which. Users can customize the look with three available RGB presets which consist of static, breathing, comet, or even synchronize the effect to the sound of music. ", "The XPG Spectrix D50 will be available in single 8 GB modules and 2 x 8 GB (16 GB) up to DDR4-4133, with single 16 GB modules and 2 x 16 GB kits ranging up to DDR4-3600. Each kit itself varies in latency from CL16 on the DDR4-3000 and DDR4-3200 kits, with CL18 on the DDR4-3600 kits, each with an operating voltage of 1.35 V.", "The higher speed DDR4-4133 kits are CL19 with a higher operating voltage of 1.4 V. ", "All the ", "kits from DDR4-3000 to DDR4-4133 will start filtering into retail channels imminently, with the higher capacity 32 GB modules and the higher speed DDR4-4600/DDR4-4800 kits coming later on in Q2. XPG hasn't unveiled any pricing information at present."]},
{"title": "GeiL Unveils 64 GB DDR4-3200 SO-DIMM Kit, 2 x 32 GB", "paragraph": ["Memory manufacturer Golden Emporer International Limited, or known generally as GeiL, has announced its new memory line with support for Intel 10th Gen and AMD Ryzen 4000 series processors. Casually calling its new 64 GB product simply 'SO-DIMM', it will be available in a 2 x 32 GB DDR4-3200 kit.", "With mobile processor architecture improving at a steady rate, memory capacity limits have increased designed to give gamers and content creators more robust memory capabilities. Designed to support Intel's 10th generation and AMD's Ryzen 4000 mobile series, the GeiL SO-DIMM offers users to upgrade its notebooks with 64 GB of memory. Not only DDR4-3200, but the GeiL SO-DIMM series also includes DDR4-2666 and DDR4-2933 variants.", "With its black and simplistic design, the DDR4-3200 64 GB (2 x 32) kit has a CAS latencies of 22-22-22-52. GeiL states every kit is tested with its DYNA 4 SLT technology but doesn't state publically what that entails. The DDR4-2666 kit has latencies of 19-19-19-43, while the DDR4-2933 has latencies of 21-21-21-48 (these sub-timings are similar to other vendors). Every 2 x 32 GB kit has an operating voltage of 1.2 V and is also backed by GeiL's limited lifetime warranty.", "While the product naming scheming is somewhat unimaginative, the SO-DIMM range of dual-channel 64 GB kits for mobile platforms is GeiL's first 64 GB SO-DIMM kit. Geil hasn't announced when the SO-DIMM 64 kits will be available, nor has it revealed pricing at this time."]},
{"title": "New ZADAK Twist DDR4 Memory, Up to DDR4-4133 and 256 GB", "paragraph": ["ZADAK has announced its latest range of DDR4 memory, the Twist series. Designed for users looking for a lower profile alternative to its previous memory brands, the Twist features aluminium heatsinks and is available in 8 GB to 32 GB modules with speeds of up to DDR4-4133, including a 256 GB of DDR4-4133.", "With a black and silver-finished aluminium heatsinks, ZADAK keeps up in the style stakes with its new Twist series. The heatsink measures in at 1.38 inches in height, which is lower profile than the vast majority of ZADAK's current range, but cannot officially considered to be low profile in terms of specification. The heatsinks themselves are constructed from anodized aluminium without RGB LED lighting and are backed by ZADAK's limited lifetime warranty.", "Available in multiple capacities ranging from 8 GB to 256 GB kits and speeds from DDR4-2666 to DDR4-4133, it offers multiple kits for many different use cases. Each kit will be available in multiple capacities from 8 GB DIMMs to kits featuring 32 GB UDIMMs, for maximum capability across multiple platforms. For reference, Intel's 10th gen Comet Lake desktop can accommodate up 128 GB, while HEDT platforms such as AMD's Threadripper 3000 series can use the 256 GB (8 x 32 GB) kits.", "As an added bonus, there's no RGB on these kits either. At present, ZADAK hasn't revealed when its Twist series will be available in retail channels, nor has it unveiled any scope on pricing. "]},
{"title": "Patriot's New 32GB Modules Available: UDIMM up to DDR4-3600, SODIMM up to DDR4-3000", "paragraph": ["Patriot has released a new series of DDR4 32GB memory modules in its VIPER GAMING STEEL series, complementing the 32GB offerings of the Blackout series as well as for the first time offering such a capacity in a 32GB SODIMM format at speeds of up to DDR-3000.", "The biggest addition to Patriot’s repertoire is the new 32GB SODIMM modules, allowing laptop and SFF PC users with corresponding memory slots to double up on the maximum configurable memory all whilst retaining high performance speeds. The small form-factor modules are available in their new 32GB size at DDR4-3000, -2666 and -2400 speeds with timings ranging from 18-20-20-43 at 1.25V for the higher frequency SKU to 15-15-15-35 at 1.2V for the lowest frequency part.", "Pricing for the new SODIMM modules land at $145 for the DDR4-3000 modules and $140 for the -2666 and -2400 variants and are available now on ", " and ", ".", "Although patriot already had 32GB modules available in its UDIMM Blackout series, it’s expanding that offering to the Steel series, which essentially includes the more stylish heat spreader.", "The new 32GB modules are available as single modules or as a 2x32GB kit up to speeds of DDR-3600 and timings of 18-22-22-42 at 1.35V. The kit is now also available on ", " and ", ", and goes for $310."]},
{"title": "GeIL Unveils Orion Series Memory, Up to DDR4-4000 with 32 GB Memory Modules", "paragraph": ["GeIL has announced its newest family of DDR4 modules, the Orion series. Available in two versions, one standard and one for AMD platforms, the Orion series offers SKUs ranging from single 8 GB sticks up to 64 GB kits with two matching 32 GB memory modules. Meanwhile the new modules will be available at memory speeds ranging from DDR4-2666 up to DDR4-4000.", "Clad in in either Racing Red or Titanium Grey for something a bit more subtle, GeIL's Orion series of DDR4 memory is offered in kits specially designed for AMD's platforms. And for hardware purists (or closed case owners) out there, the Orion range omits the use of RGB LEDs for a more clean-cut look. Meanwhile it's interesting to note that, at least going by the photos provided by GeIL, the Orion modules look surprisingly tall for otherwise simple, RGB-free memory. Unfortuantely we don't have the physical dimentions of the DIMMs, but users with low clearance coolers and the like may want to double-check that there will be sufficient room.", "Onto the technical specifications, GeIL plans to make the Orion flexible with both single and dual-channel kits  available. These range from 8 GB to 32 GB modules, with the highest spec kit topping out at 64 GB of DDR4-4000, with latencies of CL18 and an operating voltage of 1.35 V. ", "At present, GeIL hasn't unveiled pricing for any kits in its Orion series, nor has it provided details of when they will hit retail channels."]},
{"title": "SK Hynix: HBM2E Memory Now in Mass Production", "paragraph": ["Just shy of a year ago, SK Hynix threw their hat into the ring, as it were, by becoming the second company to announce memory based on the HBM2E standard. Now the company has announced that their improved high-speed, high density memory has gone into mass production, offering transfer rates up to 3.6 Gbps/pin, and capacities of up to 16GB per stack.", "As a quick refresher, ", " to improve its performance, serving as a mid-generational kicker of sorts to allow for higher clockspeeds, higher densities (up to 24GB with 12 layers), and the underlying changes that are required to make those happen. Samsung was the first memory vendor to ship HBM2E with their 16GB/stack ", ", which runs at up to 3.2 Gbps in-spec (or 4.2 Gbps out-of-spec). This in turn has led to Samsung becoming the principal memory partner for NVIDIA’s recently-launched A100 accelerator, which was launched using Samsung’s Flashbolt memory.", "Today’s announcement by SK Hynix means that the rest of the HBM2E ecosystem is taking shape, and that chipmakers will soon have access to a second supplier for the speedy memory. As per ", ", their new HBM2E memory comes in 8-Hi, 16GB stacks, which is twice the capacity of their earlier HBM2 memory. Meanwhile, the memory is able to clock at up to 3.6 Gbps/pin, which is actually faster than the “just” 3.2 Gbps/pin that the official HBM2E spec tops out at. So like Samsung’s Flashbolt memory, it would seem that the 3.6 Gbps data rate is essentially an optional out-of-spec mode for chipmakers who have HBM2E memory controllers that can keep up with the memory.", "At those top speeds, this gives a single 1024-pin stack a total of 460GB/sec of memory bandwidth, which rivals (or exceeds) most video cards today. And for more advanced devices which employ multiple stacks (e.g. server GPUs), this means a 6-stack configuration could reach as high as 2.76TB/sec of memory bandwidth, a massive amount by any measure.", "Finally, for the moment SK Hynix isn’t announcing any customers, but the company expects the new memory to be used on “next-generation AI (Artificial Intelligence) systems including Deep Learning Accelerator and High-Performance Computing.” An eventual second-source for NVIDIA’s A100 would be among the most immediate use cases for the new memory, though NVIDIA is far from the only vendor to use HBM2. If anything, SK Hynix is typically very close to AMD, who is due to launch some new server GPUs over the next year for use in supercomputers and other HPC systems. So one way or another, the era of HBM2E is quickly ramping up, as more and more high-end processors are set to be introduced using the faster memory."]},
{"title": "CES 2020: Kingston’s HyperX Adds 32 GB UDIMMs & New Fury Speed Bins to Lineup", "paragraph": ["Kingston’s HyperX division introduced a stack of new memory modules at CES 2020. Firstly, the company added 32 GB unbuffered DIMMs and SO-DIMMs to its Fury and Impact families. Secondly, the Fury and Fury RGB lineups now include DDR4-3600 as well as DDR4-3700 modules.", "Kingston’s 32 GB HyperX Fury unbuffered DIMMs as well as 32 GB Impact unbuffered SO-DIMMs are based on 16 Gb memory chips from an undisclosed supplier. According to the manufacturer, the 32 GB modules feature XMP SPD profiles for easier speed setting and are compatible with the latest platforms from AMD and Intel.", "The desktop-oriented 32 GB HyperX Fury UDIMMs are rated for DDR4-2400/CL15 at 1.2V, DDR4-2666/CL16 at 1.2 V, DDR4-3000/CL16 at 1.35 V, and at DDR4-3200/CL16 at 1.35 V operation. These modules are equipped with aluminum heat spreaders and will be available solo, in 64 GB duos, and in 128 GB quartets.", "Prices of the modules will vary from $157 for a 32 GB DDR4-2400/CL15 UDIMM to $673 for a 128 GB DDR4-3200/CL16 kit.", "The notebook-bound 32 GB HyperX Impact SO-DIMMs all feature a 1.2 V VDDQ and are rated for DDR4-2400/CL15, DDR4-2600/CL16, DDR4-2933/CL17, and DDR4-3200/CL20. In a bid to maintain compatibility with as many laptops as possible, these modules do not have metallic heat spreaders and will be available as single modules and as 64 GB kits. One 32 GB HyperX Impact DDR4-2400/CL15 module is priced at $158, whereas a 64 GB DDR4-3200/CL20 kit costs $403.", "The HyperX Fury and HyperX Fury RGB modules are not Kingston’s top-of-the-range offerings aimed at PCs where every bit of performance matters, this is a prerogative of the HyperX Predator lineup. Nonetheless, both HyperX Fury and HyperX Fury RGB families are gradually increasing performance, so from now on the company offers 8 GB and 16 GB UDIMMs rated for DDR4-3600/CL17 and DDR4-3700/CL19 at 1.35 V operation.", "Quite naturally, faster HyperX Fury and HyperX Fury RGB memory modules cost more than slower ones. The 32 GB HyperX Fury DDR4-3700/CL19 kit carries a price tag of $215, whereas the blingy 32 GB HyperX Fury DDR4-3700/CL19 kit is priced at $227.", "At press time, HyperX Gaming website did not list the new 32 GB UDIMMs nor the DDR4-3600 and DDR4-3700 offerings. But since Kingston has already published MSRPs for the new products, expect them to hit the market shortly.", "Related Reading:", "Source: Kingston/HyperX"]},
{"title": "Here's Some DDR5-4800: Hands-On First Look at Next Gen DRAM", "paragraph": ["Just like all major makers of DRAM, SK Hynix produced its first DDR5 memory chips a couple of years ago and has been experimenting with the technology since then. To that end, it is not surprising that the company displayed its DDR5 RDIMM at CES 2020, which implies that development is proceeding as planned.", "At the trade show, SK Hynix demonstrated its 64 GB DDR5 RDIMM with ECC rated for a 4800 MT/sec/pin data transfer rate. The module marked as HMCA8GR8MJR4C-EB carries 20 memory chips marked as H5CNAG4NMJ as well as IDT’s P8900-Z2 register clock driver (RCD). The memory devices are marked differently than the ones SK Hynix used for ", ", though we do not know the difference.", "The DDR5 RDIMMS feature 288 pins on a slightly curved edge connector (to reduce the insertion force on every pin), just like DDR4 modules, yet its layout and design are a bit different when compared to DDR4 to prevent installment of DDR5 modules into DDR4 slots and vice versa.", "It is unknown whether SK Hynix has already started to sample its DDR5 RDIMMs with developers of server platforms and servers, but it is obvious that all DRAM makers are aligning their DDR5 production schedules with CPU designers and other companies.", "At present, it is unclear when exactly the first DDR5 platforms are set to hit the market, but a good guess would be 2021. One of the first platforms to confirm support for DDR5 memory has been Intel's Xeon Sapphire Rapids, set for deployment in the Aurora Supercomputer. AMD support for DDR5 is unknown so far.", "Related Reading:", "Source: SK Hynix"]},
{"title": "The Corsair DDR4-5000 Vengeance LPX Review: Super-Binned, Super Exclusive", "paragraph": ["The consumer memory industry has been teasing DDR4-5000 for a few months now.  We saw one company show some DDR4-5000 modules at Computex back in July 2019, running on an MSI MPG Z390I GAMING EDGE AC with an Intel Core i7-8086K processor, but the company said at the time that it didn’t make sense to release them because (at the time) only 2% of top-end CPUs could actually keep up with such a high memory speed. Fast forward to November a few key things have changed. ", "Micron’s new 8 Gbit Revision-E DDR4 chips (Rev.E or “Micron E-die”) first gained attention in April, and now they’ve matured through rigorous testing and qualification for the high-end memory kits. Enter the Corsair Vengeance LPX DDR4-5000 memory kits, which have been QVL'ed for use with MSI's high-end X570 models to give users blazing-fast memory for Ryzen 3000 processors.", "AMD’s new Ryzen 3000 processors hit the market with a new memory controller capable of running extremely high speeds. It also helps that the CPU can now enable memory and Infinity Fabric ratios, which allow the fast memory to take advantage of the memory controller. Taking all of this into account, Corsair is now confident enough to be the first DRAM retailer to bring DDR4-5000 to market. ", "Behind the unassuming CMK16GX4M2Z5000C18 part number is a kit made with Micron 8 Gbit Revision E chips. Each of the chips have been individually tested for overclocking headroom, and are used with Corsair’s custom 8-layer PCB and cooled with anodized aluminium heat spreaders.  Corsair has stuck with the low-profile, non-RGB Vengeance LPX design and included its Vengeance Airflow fan to maximise cooling, but also to provide that unassuming look.", "The Corsair Vengeance LPX DDR4-5000 memory kit is designed for high-end Ryzen 3000 processors equipped on X570 motherboards. At present, only specific MSI motherboard models, including the MEG X570 Godlike, the MEG X570 Ace, and the MEG X570 Unify have been officially validated (or 'QVL'ed') to work with this kit. ", "The DDR4-5000 memory comes with a single XMP 2.0 profile which is rated for 5000 MT/s, with latency timings of 18-26-26-46 and has an operating voltage of 1.50 V. The Corsair Vengeance LPX DDR4-5000 kit is formed by two 8 GB memory sticks. Corsair's Vengeance LPX heatsinks are technically low profile with a height of just 31 mm. This is great for cooler compatibility as these memory sticks will fit under most CPU air tower coolers.", "The stylings are consistent with the rest of its Vengeance LPX range, with anodised aluminium low profile heatsinks. Opting for a less aggressive heatsink design allows for better compatibility with larger air coolers. The black LPX heatsinks are 31 mm tall which should allow these to fit in with any system, and the black aluminium anodizing looks subtle enough to fit into most system configurations in terms of style. The Corsair Vengeance LPX range doesn't use integrated RGB LEDs and instead opts for a more clean-cut approach to its design. ", "Although Corsair's Vengeance LPX series is usually available in white, black, blue and red colors, the DDR4-5000 kit is only available in black, at present. Bundled with the Corsair Vengeance LPX DDR4-5000 kit is a red and black four-slot memory cooler. The cooler itself includes a 3-pin fan connector which will work in both 3-pin and 4-pin fan headers.", "The Corsair Vengeance LPX DDR4-5000 kit is specifically using Micron ICs which they say are cherry-picked for maximum performance. This means Corsair is stating that it is essentially binning its memory ICs to guarantee they can deliver the 5000 MT/s speeds it advertises. ", "Interestingly Corsair is using its 8-layer PCB design which is impressive and is likely a reason why it is capable of reaching DDR4-5000 in a low profile kit. ", "Over the next page, we go into some detail about the effect high speed memory has on Ryzen 3000 processors, but it's important to note that fast memory has had a checkered past.", "Back in the days of DDR3, when systems would run DDR3-1333 as the rated memory, ", " uplift in performance moving to DDR3-1866, DDR3-2133, because at a fundamental level DDR3-1333 was ", " slow. For anything compute limited, there was little difference, but for anything that touched the memory, it was heavily advised to get the fast memory. The biggest impact with fast memory was always integrated graphics, where memory bandwidth is always king.", "For DDR4, we have seen a similar effect, but ", ". Original DDR4 systems were released with DDR4-2133 support, but over time the latest hardware now supports DDR4-2666, DDR4-2933, or DDR4-3200 as standard.", "AMD has been at the forefront of this, with the ability to rate their memory controllers at very fast standards. This means that a jump from DDR4-3200 to DDR4-3600, through buying fast memory, isn't as much of a jump as 400 MT/s used to be.", "", "For Ryzen 3000, the effect is compounded. AMD showcased its memory suggestions when the product was launched, showing that DDR4-3600 is a sweet spot, because the memory frequency and infinity fabric frequency, which manages data inside the processor, were synchronized. Going above DDR4-3600 (or to DDR4-3733) would cause the infinity fabric to be derated by half, effectively making it 1800 MT/s. There were still benefits to this, although they would require super-fast memory in order to realise them. We'll cover more detail about the infinity fabric on the next page.", "With DDR4-5000, the de-rated infinity fabric runs at 2500 MT/s, which is a lot nearer to the default running speed than most. Of course, there are still benefits running the DRAM this fast, so those are not discounted. The downside, however, is that traditionally the best recipient of fast memory has been integrated graphics. The Ryzen 3000 desktop CPUs built on Zen 2 do not have any model with integrated graphics. Not only that, but users with integrated graphics are unlikely to spend buckets of money on super-fast memory. It makes testing it in real-world a little tricky.", "For our part, we subjected the memory to a range of our workstation tests, where memory can be important. We decided to test this memory in three ways: AMD's supported maximum (DDR4-3200), as near as to AMD's recommended overclock (DDR4-3600) as is comfortable on almost every CPU, and the speed of this kit (DDR4-5000), all at the same latencies as the XMP profile of the kit (C18). As with other memory reviews, there are going to be a number of benchmarks which show no difference, however as much as this memory kit is going to be rare, the effects of the high speed are in-of themselves niche. The following pages of benchmarks will show this."]},
{"title": "Crucial’s 32 GB UDIMMs and SODIMMs Available: DDR4-2666 & DDR4-3200", "paragraph": ["In the summer of 2019, Crucial was among the first brands to demonstrate 32 GB unbuffered memory modules, which were based on Micron’s 16 Gb DDR4 chips. Now after a bit of a wait, those 32 GB UDIMMs as well as 32 GB SO-DIMMs have finally hit the retail market.", "Crucial’s 32 GB unbuffered DIMMs and SO-DIMMs are rated for DDR4-2666 with CL19 at 1.2 V and DDR4-3200 with CL22 at 1.2 V operation. The modules are not equipped with any heat spreader and since they operate in JEDEC-standard modes, they are compatible with a wide variety of PCs that can support 32 GB UDIMMs in general.", "At present, Crucial’s 32 GB UDIMMs and SO-DIMMs are available as 64 GB dual-channel memory kits priced at around $330 at the company’s ", ". Interestingly, the faster DDR4-3200 kits are only $2 more expensive than the slower DDR4-2666 kits. Meanwhile, ", " expects Crucial’s 64 GB dual-channel DDR4-2666 SO-DIMM kit to arrive on February 3, 2020.", "It is unclear why Crucial did not start selling its 32 GB UDIMMs and SO-DIMMs to general public earlier, as there are a number of brands that have been offering competing 32 GB UDIMMs using the same Micron chips for months now. In any case, Crucial’s 32 GB DIMMs are finally available.", "Related Reading:", "Sources: "]},
{"title": "SK Hynix to Cut CapEx, Accelerate Transitions, 1z nm DRAM & 128L 4D NAND in 2020", "paragraph": ["Following a massive revenue and profitability drop in 2019, SK Hynix has announced that it plans to cut down its capital expenditures. While the market has shown some signs of recovery, the company is uncertain about demand for DRAM and NAND, so its investments will get considerably more conservative and prudent. As a result, SK Hynix will focus on acceleration of technology transitions to cut costs and prepare for next-generation products.", "SK Hynix’s revenue for fiscal year 2019 came in at KRW 26.99 trillion ($22.567 billion), a 33% drop from 2018, whereas its net income totaled KRW 2.016 trillion ($1.685 billion), a whopping decrease of 87% from 2018. For the fourth quarter 2019, the company posted a revenue of KRW 6.927 trillion ($5.792 billion), a 30% YoY decline, as well as an operating profit of KRW 236 billion ($197.3 million), a 95% decline compared to the same period a year before.", "SK Hynix attributes miniscule profitability in the final quarter of the year to a 7% decline of DRAM ASP quarter over quarter amid an 8% increase in bit shipments as well as to flat NAND pricing amid 10% higher bit shipments. Meanwhile, SK Hynix’s net loss for the quarter totaled KRW 118 billion ($98.662 million) as it had to re-evaluate its investments in Kioxia.", "SK Hynix’s losses are a result of dropping DRAM and 3D NAND prices because of oversupply and overall uncertainties on the market. To that end, it has determined that it needs to concentrate on cutting costs and expenditures, which is a reason why the manufacturer is reconsidering its capital expenditure plan. Last year SK Hynix’s CapEx was cut by 25% (vs. 2018) to KRW 12.7 trillion ($10.619 billion) because of the price drops. Apparently, this year the company will cut it down even further, but at this point it does not have a number it wants to share.", "Jin-seok Cha, CFO of SK Hynix, said the following:", "Demand for 3D NAND and DRAM in terms of bits will without any surprises continue to increase this year, so no producer is likely to cut bit output. As such, SK Hynix intends to accelerate its transition to newer process technologies in a bid to cut its per bit costs. Moreover, the company plans to ensure that its next-generation products do not have ‘glitches’.", "SK Hynix says that the share of DRAM it makes using its 2", " Generation 10 nm-class fabrication process (1Y nm) will increase to 40% by the end of the year. On the NAND side of things, over half of NAND bits the company produces will be made using its 96-layer 3D NAND technology already in the first half of 2020.", "Mr. Jin-seok Cha said the following:", "More advanced process technologies promise to reduce SK Hynix’s costs, but in a bid to improve revenues and profitability, the company plans to better address high-value markets and products. In particular, the company will ‘actively respond’ to demand for LPDDR5, GDDR6, and HBM2E on the DRAM side of business, as well as increase sales of SSDs in general and datacenter drives in particular on the NAND side of things.", "Here is what the CFO said:", "Last year SK Hynix finished development of its 3", " Generation 10 nm-class process technology for DRAM (1Z nm) and also commenced sample shipments of its 128-layer ‘4D’ NAND (which is still called ‘3D NAND’ by officials) featuring the company’s charge trap flash (CTF) design, along with the peripheral under cells (PUC) architecture.", "This year, both technologies will be used in mass production, but their share is not going to be significant.", "Like other industry players, SK Hynix sees huge potential in application of emerging technologies, such as 5G and AI, which is why it is optimistic about the future in general. Meanwhile, despite some signs of recovery, not everything is back to normal, according the the company's management, and so the company is conservative both about predictions and about spending.", "Related Reading:", "Sources: ", ", ", ", "]},
{"title": "JEDEC Updates HBM2 Memory Standard To 3.2 Gbps; Samsung's Flashbolt Memory Nears Production", "paragraph": ["After a series of piecemeal announcements from different hardware vendors over the past year, the future of High Bandwidth Memory 2 (HBM2) is finally coming into focus. Continuing the industry’s ongoing momentum with HBM2 technology, late last month JEDEC published an updated revision of the HBM2 standard. The updated standard added support for even faster memory speeds of up to 3.2Gbps/pin, and in the process pushed the fastest speed for a complete stack of HBM2 memory to 410GB/sec. Meanwhile the memory manufacturers themselves have been preparing for this moment for a while, and Samsung has put out their own matching announcement regarding their Flashbolt HBM2 memory.", "First and foremost, let’s dive into the latest version of the HBM2 standard. ", ", as it’s officially called, is a relatively small update to the HBM2 standard. After introducing more sizable changes ", " with 12-Hi memory stacks, expanding both the speed and capacity of HBM2 memory, the latest revision is a more measured update focusing on performance.", "The biggest change here is that the HBM2 standard has officially added support for two higher data rates, bringing 2.8Gbps/pin and 3.2Gbps/pin into the standard. Coming from the previous standard’s maximum rate of 2.4Gbps/pin, this represents an up-to 33% increase in memory bandwidth in the case of 3.2Gbps HBM2. Or to put this in more practical numbers, a single stack of 3.2Gbps HBM2 will deliver 410GB/sec of bandwidth, up from 307GB/sec in the last standard. Which for a modern, high-end processor supporting 4 stacks (4096-bit) of memory, this brings the aggregate bandwidth available to a whopping 1.64 TB/sec.", "All told, this latest update keeps even a single stack of HBM2 quite competitive on the bandwidth front. For comparison’s sake, a 256-bit GDDR6 memory bus with 14Gbps memory can reach 448GB/sec of aggregate bandwidth; so a single stack of HBM2 only slightly trails that. And, of course, HBM2 can scale up to a larger number of stacks more easily than GDDR6 can scale up in bus width, keeping larger HBM2 topologies well ahead of discrete GDDR6 memory chips as far as bandwidth is concerned.", "The trade-off, as always, is cost and capacity. HBM2 remains a premium memory technology – due in part to the complexities involved in TSVs and die stacking, and in part to manufacturer product segmentation – and there aren’t currently any signs that this will change. Meanwhile the latest HBM2 standard does not increase memory capacities at all – either through density or larger stacks – so the maximum size of a single stack remains 24GB, allowing a 4 stack configuration to pack up to 96GB of memory.", "", "Meanwhile, it’s interesting to note that as of JESD235C, JEDEC has backed off just a bit with regards to standardizing HBM2 die stack dimensions. In the previous version of the standard, the dimensions for 12-Hi stacks were listed as “TBD”, but for the new revision the group has seemingly punted on any standardization whatsoever. As a result, there isn’t a single standard height for 12-Hi stacks, leaving it up to memory manufacturers to set their own heights, and for customers to accommodate any differences between the manufacturers.", "It is also worth noting that while the HBM2 standard doesn’t directly impose power limits on its own, the standard does specify regular operating voltages. HBM2 since its inception has operated at 1.2V, and the latest standard has not changed this. So the faster memory speeds should come with little (if any) increase in power consumption, as they won’t require higher voltages to drive them.", "Finally, it looks like JEDEC has passed on formally adopting the “HBM2E” moniker for the latest memory standard. In pre-standard technology announcements from Samsung, SK Hynix, and others, all of these groups referred to the memory as HBM2E. And indeed, Samsung still is. However this appears to be an entirely informal arrangement, as the official wording on both the JEDEC’s page as well as in the standard itself continue to refer to the memory as HBM2. So it is almost guaranteed that we’re going to see the two terms thrown around interchangeably over the next couple of years.", "Following the HBM2 standard update, Samsung this afternoon has also issued its own announcement offering an update on the status of their third-generation Flashbolt HBM2E memory. Samsung was the first company to release information on the new speeds, ", " almost a year ago during NVIDIA’s 2019 GPU Technology Conference. At the time Samsung’s announcement was still preliminary, and the company wasn’t saying when they would actually go into mass production. But now we finally have our answer: the first half of this year.", "Given that almost a year has passed since the original Flashbolt announcement, Samsung’s announcement is as much a reminder that Flashbolt exists as it is a proper update. Still, today’s announcement offers a bit more detail than Samsung’s relatively high-level reveal last year.", "Of particular note, Samsung is only announcement 16GB stacks at this time, built using 2GB dies stacked in an 8-Hi configuration. And while this doesn’t preclude Samsung eventually going to 12-Hi, 24GB stacks in the future, it isn’t where the company is going to start at. The memory dies themselves are being manufactured on Samsung’s 1y process technology.", "Meanwhile, Samsung appears to be setting some ambitious targets for data rates for Flashbolt. Along with supporting the new 3.2Gbps HBM2 standard, Samsung claims that they are able to go out of spec with Flashbolt, taking the memory to an even speedier 4.2Gbps. This would be a further 31% data rate increase over 3.2Gbps HBM2, and it would push the bandwidth available in a single stack to 538GB/sec, or better than half a terabyte a second. The key word here, of course, is “out of spec”; it’s not clear whether there are any HBM2 memory controllers that will be able to keep up with Samsung’s data rates, and of course there’s the question of power consumption. So while it’s all but guaranteed that Samsung has customers lined up to use Flashbolt at 3.2Gbps, it will be interesting to see whether we see any kind of high-volume products ship at data rates higher than that.", "Overall, this makes Samsung the second vendor to announce out of spec HBM2 memory. Last year SK Hynix announced their own HBM2E effort, which is expected to reach 3.6Gbps. So whatever happens, it would seem we’ll now have multiple vendors shipping HBM2E memory rated to go faster than the brand-new 3.2Gbps spec."]},
{"title": "Micron Shipping LPDDR5 DRAM", "paragraph": ["Micron has announced their first LPDDR5 DRAM is in mass production and now shipping to customers. The new RAM is significantly faster and more power efficient than LPDDR4x. One of the first products to use the new LPDDR5 will be the upcoming Xiaomi Mi 10 smartphone.", "Micron's LPDDR5 is available in 6GB, 8GB and 12GB packages, with speeds of 5.5Gbps and 6.4Gbps per pin. The faster speed grade is a 50% improvement over their fastest LPDDR4x products (4266Mbps per pin), and Micron also claims better than 20% reduction in power use compared to LPDDR4x. Micron will also soon be offering multi-chip packages pairing LPDDR5 with UFS-based flash storage; these products will be available sometime during the first half of the year.", "The most visible applications for LPDDR5 will be this year's crop of flagship smartphones, but Micron is also targeting automotive and networking applications with the obligatory references to 5G and AI driving demand for faster memory.", "Related Reading:"]},
{"title": "GIGABYTE Launches Designare DDR4-3200 Memory, a 64 GB Kit", "paragraph": ["GIGABYTE is a relatively new player on the memory market, yet it clearly wants to participate in the premier league. As seen at CES, this week the company introduced its Designare 32 GB memory that claims to offer both high speed and low latency. The company positions its Designare memory for high-performance systems powered by Designare motherboards.", "GIGABYTE’s dual-channel ", " kit was tested to operate in DDR4-3200 mode with CL16 18-18-38 latency at 1.35 V. The modules rated for Intel Core as well as AMD Ryzen-based PCs.", "The manufacturer does not disclose which memory chips it uses.", "The modules are a standard height and come with modest aluminum heat spreaders that do not affect compatibility with large cooling systems.", "GIGABYTE’s Designare 64 GB kit consisting of two 32 GB modules is covered by a lifetime warranty, just like other high-end memory. Expect the kit to hit the market shortly - prices will vary from region to region and will depend on the market conditions.", "Source: "]},
{"title": "G.Skill Launches 32 GB DDR4 Modules, 256 GB Kits: Up to DDR4-4000", "paragraph": ["G.Skill has now rolled out its 32 GB unbuffered DDR4 modules in dual-channel and quad-channel memory kits. The modules are offered with data transfer rates from 2666 MT/s to 4000 MT/s and various modules are compatible with AMD’s Ryzen 3000/X570 as well as Intel’s X299/Z390 platforms.", "Based on pre-binned 16 Gb memory chips and proprietary PCBs, G.Skill’s hardware boils down to sets of 32 GB DDR4 unbuffered DIMMs. Lower-end modules are set to be available as single pieces as they can be used by PC makers that need to lower their BOM cost, whereas higher-end parts will be offered as dual-channel and quad-channel kits for high-end desktops and workstations. The UDIMMs feature an XMP 2.0 SPD for setting speeds beyond JEDEC.", "As there are several platforms used by enthusiasts today, G.Skill will offer two families of products:", "For AMD Ryzen 3000-based PCs, the highest-performing kits will be 64 GB DDR4-3800 CL18 as well as 128 GB DDR4-3600 CL18 offerings. For the Intel platform, the highest end kits will be 128 GB DDR4-4000 CL18 as well as 256 GB DDR4-3200 CL16. Validation for AMD is done using the MSI MEG X570 Godlike motherboard, whereas validation for Intel is made on the ASUS ROG Rampage VI Extreme Encore motherboard. Other motherboards will be validated over time, and likely up to the motherboard manufacturers in their own QVL.", "All enthusiast-class 32 GB unbuffered DIMMs from G.Skill will be equipped with aluminum heat spreaders with an RGB lightbar with multiple lighting zones. The Trident Z Royal will come with polished silver or gold heat spreaders as well as a crystalline RGB lightbar, whereas the Trident Z Neo will use matte heat spreaders and an RGB lightbar.", "One thing to keep in mind about 32 GB UDIMMs is that they may require a BIOS update as not all motherboards support them out-of-box.", "G.Skill will start sales of its 32 GB UDIMMs as well as dual-channel and quad-channel kits that use them later this quarter. Pricing will depend on capacity as well as rated performance levels, but since these products are designed for high-end PCs, they will be priced accordingly.", " ", "", " ", "Source: G.Skill"]},
{"title": "Corsair 16GB DDR4-5000 Vengeance LPX Memory Kit: Built for AMD Ryzen 3000 and MSI", "paragraph": ["The high-tech industry loves milestones that are round numbers, be it frequency, number of cores, transistor count or something else. It is not that extra 100 MHz – 200 MHz or a couple of additional CPU cores radically improve performance or user experience these days, but because milestones symbolize an achievement, a new height from where we will go and hit the next ones. Today, the industry has reached a milestone as Corsair introduced the industry’s first commercial DDR4-5000 memory modules. We saw numerous companies 'promote' DDR4-5000 earlier this year at Computex, but none were seriously considering bringing them to retail. Corsair is the first.", "Corsair’s dual-channel ", " (CMK16GX4M2Z5000C18) memory kit comprises two 8 GB unbuffered modules featuring a CL18 26-26-46 latency and a 1.5V voltage. The memory modules use Micron’s cherry-picked memory ICs and use a custom 8-layer PCB from Corsair. The enthusiast grade modules are equipped with aluminum heat spreaders, and are compatible with Corsair’s Vengeance Airflow fan to maximize their cooling.", "Corsair says that its Vengeance LPX DDR4-5000 (CMK16GX4M2Z5000C18) memory kit was tuned to hit the desired data transfer rate on high-end platforms based on AMD’s Ryzen 3000 processor and X570 chipset. To be more precise the modules were developed and validated on MSI’s X570 Godlike, MEG X570 Ace, MEG X570 Unify, and Prestige X570 Creation motherboards. ", "It is unclear how well the modules will work in DDR4-5000 mode when used with other platforms. In any case, keep in mind that modules require 1.5 Volts, which is a whopping 25% increase over standard DDR4 voltage, so they have to be installed in an enthusiast-grade mainboard with a quality and clean memory power supply. In order to reach the DDR4-5000 mode requires some user intervention beyond just setting the XMP profile: to set up the right settings Corsair recommends to check out its ", ".", "Designed for die-hard performance enthusiasts, overclockers, and benchmarkers, Corsair’s dual-channel 16GB Vengeance LPX DDR4-5000 memory kit is certainly not cheap at all. The company sells it for a sizeable $1,224.99 in the USA ($76.56/GB) and for €1,334.99 in Europe.", "Corsair says that there are limited review samples available - if we get one in to test, what would you like to see?", "Source: Corsair"]},
{"title": "Royal Memory: G.Skill’s 32 GB DDR4-4000 CL15 Kit for AMD & Intel", "paragraph": ["Bucking the trend of ever higher clocked DDR4 memory kits, G.Skill has introduced a new high-end memory kit that is focused on lower memory latencies. Compatible with both Intel and AMD platforms, the premium memory kit offers CL15 latencies at up to DDR4-4000 speeds.", "G.Skill’s Extreme Low Latency DDR4-4000 32 GB kit consists of four 8 GB modules based on cherry-picked Samsung’s 8 Gb B-Die chips. The sticks are rated for 4000 MT/s CL15 16-16-36 at 1.5 V. The modules use G.Skill’s custom PCB, feature an XMP 2.0-enabled SPD, and come with G.Skill’s blingy Trident Royal Z heat spreaders with a crystaline RGB lightbar, or regular Trident Z with classic all-black heat spreaders.", "The Extreme Low Latency DDR4-4000 32 GB kit has been validated both on AMD’s X570/Ryzen 3000 platform (using MSI’s X570 Unify motherboard) and Intel’s Z390 platform (using MSI’s MEG Z390 Ace motherboard). Keeping in mind that we are dealing with modules that work at clocks and latencies well beyond those recommended by JEDEC at voltages that are a whopping 25% higher than spec for DDR4 DIMMs, one will clearly need a high-end motherboard with a VRM that can deliver clean and quality power to the modules.", "G.Skill will start sales of its Trident Z Royal 32 GB DDR4-4000 CL15 kit late in Q4 2019. Pricing has yet to be announced, but considering their high-end specifications, expect them to be expensive.", " ", "Related Reading:", "Source: G.Skill"]},
{"title": "Team Group Quietly Launches 32 GB DDR4 Memory Modules", "paragraph": ["Team Group has quietly added 32 GB unbuffered DDR4 memory modules to its product catalogue and plans to start sales in the near future. The modules will feature JEDEC-standard data transfer rates and will be aimed primarily at OEMs as well as high-end desktops and workstations that benefit from loads of RAM yet do not necessarily need extreme bandwidth.", "Team Group’s Team Elite UD-D4 32 GB DDR4 unbuffered DIMMs rely on 16 memory chips featuring a 16 Gb capacity from Micron. The memory modules are rated for DDR-2666 mode with CL19 19-19-43 timings at 1.2 V, which is fully compliant with JEDEC’s standards. The UDIMMs are not equipped with a heat spreader since they are not meant to be overclocked by the manufacturer.", " Team Group uses Micron's 16 Gb memory chips for its Elite 32 GB modules.", "Team Group will offer its Team Elite UD-D4 32 GB DDR4-2666 UDIMMs as single modules and as dual-channel kits. The former will be aimed primarily at computer makers that need to cut down their BOM cost, while the latter will sell to all kinds of clients that need a dual-channel 64 GB memory subsystem.", "By offering 32 GB modules with standard JEDEC speed and timings, Team Group maximizes their compatibility with systems. Meanwhile, an important thing to remember about 32 GB UDIMMs is that they may require a BIOS update as not all motherboards support them out-of-box.", "Team Group’s 32 GB UDIMMs as well as dual-channel 64 GB (2×32 GB) kits will be available in Japan starting from October 25. Pricing is unknown, but expect it to be comparable to other DDR4-2666 32 GB modules/kits.", "Sources: ", " (via ", "), "]},
{"title": "SK Hynix Develops 16 Gb DDR4 Chips for 32 GB Modules", "paragraph": ["SK Hynix announced on Monday that it has completed development of its first monolithic 16 Gb chip. This chip is to be made using its 3", " Generation 10 nm-class process technology. The new memory devices will enable the company and its partners to make more energy-efficient and higher capacity DIMMs, such as 32 GB unbuffered modules for consumers or higher capacity buffered modules for enterprise consumption.", "SK Hynix’s 16 Gb chip made using the company’s 3", " Generation 10 nm-class manufacturing technology (also known as '1Z' nm) and is rated for DDR4-3200 data transfer rates. The company states that these chips have a reduced power consumption by 40% when compared to modules of the same capacity based on 8 Gb DRAMs produced using the company’s 2", " Generation 10 nm-class (aka 1Ynm) process.", "SK Hynix’s '1Z' nm process technology uses a new substance that enables it to maximize capacitance and improve stability of DRAM devices compared to previous generation process technology. It remains to be seen whether or not usage of the new chemicals translate into additional benefits, such as clock range, or latency. Also, the new technology enables a 27% higher bits-per-wafer productivity, which will make new memory chips cheaper to produce. The manufacturer stresses that its '1Z' nm process does not use extreme ultraviolet lithography (EUVL) and is still a fully DUV process.", "In addition to its 16 Gb DDR4 chips, SK Hynix also introduced its 32 GB unbuffered DIMM and SO-DIMM modules that can be used by desktop computers. It is unclear when these modules are to be available, but it is logical to expect them to emerge after the 16 Gb DRAM devices hit mass production in 2020.", "The company plans to use its 1Znm process technology to make a variety DRAM types, including commodity DDR4 memory, LPDDR5, and HBM3.", "Related Reading:", "Source: "]},
{"title": "Samsung Launches Single-Chip uMCP Packages with LPDDR4X DRAM & UFS 3.0 Storage", "paragraph": ["Samsung has introduced a new lineup of all-in-one memory packages for smartphones that integrate both DRAM and storage. The latest generation of uMCP devices now feature up to 12 GB of LPDDR4X DRAM as well as NAND flash storage with a UFS 3.0 interface, thus providing high performance memory for mainstream handsets in a cost-effective form-factor.", "Samsung’s UFS-based multichip packages (uMCPs) integrate 10 GB or 12 GB of LPDDR4X-4266 memory (made using the company’s 2", " Generation 10nm-class process technology) as well as NAND flash storage featuring a UFS 3.0 interface. Since both new uMCP modules incorporate four DRAM devices, they will allow the latest SoCs with quad-channel LPDDR4X memory controllers to reach up to 34.1 GB/s memory bandwidth. Meanwhile on the NAND side of matters, Samsung's official announcement doesn't list what storage capacities will be available there, but the company has commented that they can provide the uMCPs in a variety of capacities.", "Meanwhile, the new uMCP devices are also mechanically compatible with Samsung's previous-generation 8GB uMCPs, utilizing the same 254FBGA package.", "Today, only high-end smartphones come equipped with 12 GB of LPDDR4X memory, but Samsung expects its new uMCPs to enable upcoming mid-range handsets to feature 10 GB or 12 GB of DRAM. The new uMCP devices are already in mass production, so expect smartphones launching in the coming months to use them.", "Samsung did not disclose pricing of its 10 GB uMCP and 12 GB uMCP chips, but expect them to cost in accordance with prices of DRAM and storage.", "Related Reading:", "Source: "]},
{"title": "GlobalFoundries Teams Up with Singapore University for ReRAM Project", "paragraph": ["GlobalFoundries has announced that the company has teamed up with Singapore’s Nanyang Technological University and the National Research Foundation to develop resistive random access memory (ReRAM). The next-generation memory technology could ultimately pave the way for use as a very fast non-volatile high-capacity embedded cache. The project will take four years and will cost S$120 million ($88 million).", "Under the terms of the agreement, the National Research Foundation will provide the necessary funding to Nanyang Technological University, which will spearhead the research. GlobalFoundries will support the project with its in-house manufacturing resources, just like it supports other universities on promising technologies, the company says.", "Right now, GlobalFoundries (and other contract makers of semiconductors) use eFlash (embedded flash) for chips that need relatively high-capacity onboard storage. This technology has numerous limitations, such as endurance and performance when manufactured using today's advanced logic technologies (i.e., sub-20nm nodes), which is something that is required of embedded memories. This is the main reason why GlobalFoundries and other chipmakers are looking at ", " in future designs as it is considered the most durable non-volatile memory technology that exists today that can be made using contemporary logic fabrication processes.", "MRAM relies on reading the magnetic anisotropy (orientation) of two ferromagnetic films separated by a thin barrier, and thus does not require an erase cycle before writing data, which makes it substantially faster than eFlash. Furthermore, its writing process requires a considerably lower amount of energy. On the flip side, MRAM’s density is relatively low, its magnetic anisotropy ", " at high temperatures and performing write operations at low temperatures requires high currents (and if anisotropy is increased in general, it will require high currents even at not-so-low temperatures), which makes it a no-option for numerous applications, but which is still very promising for the majority of use cases that do not involve low temperatures.", "This brings researchers to ReRAM, which relies on changing the resistance across a dielectric material (from ‘0’ to ‘1’ or otherwise) by electrical current. The technology also doesn't require an erase cycle, promises very high endurance, and — assuming that the right materials are used — can work at a wide range of temperatures. Meanwhile, alloys used for ReRAM should be very stable in general in a bid to survive millions of switches and retain data, even when memory cells are produced using 'thin' moden fabrication processes (e.g., GF's 12LP or 12FDX). Finding the right substances for ReRAM will be the main topic of NTU’s research, whereas GlobalFoundries will have to find a cost-efficient way to produce the new type of memory at its facilities if the research is successful.", "For years to come, GlobalFoundries (and its rivals) will use MRAM for a wide variety of applications as the technology is mature enough, fast enough, and durable enough. The company’s eMRAM implementation ‘integrates well’ with both FinFET and FD-SOI process technologies (although FinFET implementation is not yet ready), the company says, so expect it to be used widely. According to the foundry, it has multiple 22FDX eMRAM tape outs planned for 2019 and 2020.", "GlobalFoundries is not standing still and is evaluating several eNVM technologies for its roadmap beyond 2020, including ReRAM. The company does not expect the research to come to fruition before 2021, but it certainly hopes that ReRAM will become another useful embedded memory technology.", "It is noteworthy that companies like Western Digital are working on ReRAM-based storage class memory (SCM) to compete against Intel’s 3D XPoint and other SCM technologies. SCM-class ReRAM will have its differences when compared to embedded ReRAM that GlobalFoundries is particularly interested in, which once again shows that the technology could be applied very widely.", "Related Reading:", "Sources: ", ", ", ", ", ", "]},
{"title": "GIGABYTE Enhances Aorus RGB Memory with Aorus Memory Boost Capability", "paragraph": ["One of the advantages of having a highly-integrated product stack is ability to fine tune performance of your devices when they work together. On the one hand, this allows to get higher performance while ensuring maximum compatibility and thus differentiate from rivals. On the other hand, this enables to sell more products per end user, sometimes at a premium. This is exactly what GIGABYTE is doing with its Aorus motherboards and Aorus Memory Boost feature of its Aorus RGB Memory modules.", "GIGABYTE, which introduced its first DIMMs in mid-2018, is a relative newbie on the market of memory, so its DDR4 product lineup is currently limited to seven SKUs conservatively rated for DDR4-2666, DDR4-3200, and DDR4-3600 operation (whereas faster kits ", " at CES 2019 are yet to be launched commercially). Meanwhile, the company appears to have some kind of secret weapon in the form of a special SPD setting called Aorus Memory Boost (AMB) that slightly increases speed of its top-of-the-range DRAM modules.", "When used with select AMD X570 and Intel Z390-based GIGABYTE Aorus motherboards, the Aorus RGB Memory DDR4-3600 with CL18 19-19-39 16 GB dual-channel kits (", " and ", ") can automatically set themselves to DDR4-3700 or DDR4-3733 (Intel/AMD) mode when their AMB profile is activated.", "It is unclear whether such an overclock affects timings in a bid to slightly increase data transfer rates, or GIGABYTE can guarantee stable operation at higher clocks on its motherboards due to superior design of the latter, but it is evident that the company’s modules work better with its platforms. The latter would not be particularly surprising as Aorus-branded mainboards are engineered to feature an overclocking headroom for CPU and DRAM, so GIGABYTE does not really take many risks here. Meanwhile, we can only wonder whether GIGABYTE’s Aorus Memory Boost will be available on its higher-end DDR4-4000+ modules that are harder to overclock and guarantee a long-term stability.", "GIGABYTE’s Aorus RGB Memory DDR4-3600 16 GB dual-channel kits are already listed on the company’s website, so expect them to hit retail shortly. Prices are unknown, but it remains to be seen whether the manufacturer decides to capitalize on the Aorus Memory Boost and sell the modules at a slight premium.", "Related Reading:", "Sources: GIGABYTE (", ", ", "), "]},
{"title": "Samsung Starts Production of LPDDR5-5500 Devices: 12 GB of DRAM in a Smartphone", "paragraph": ["Samsung has kicked off volume production of its LPDDR5 memory devices and intends to start mass assembly of memory packages based on the new DRAMs. The company’s LPDDR5 memory will be used for upcoming flagship smartphones with up to 12 GB of memory in the coming months.", "Samsung’s 12 Gb LPDDR5 memory devices feature a 5500 MT/s data transfer rate, which is about 30% higher when compared to currently used LPDDR4X-4266 DRAM. One of the first products to use the new 12 Gb LPDDR5 devices will be Samsung’s 12 GB LPDDR5 package featuring a 44 GB/s bandwidth.", "The manufacturer produces its 12 Gb LPDDR5 chips using its 2", " Generation 10 nm-class process technology that enables it to make the new chips smaller (i.e., cheaper) and more power efficient, yet Samsung does not disclose exact voltages of these new DRAMs. What we do know is that the ICs feature a variable voltage that is up to 1.1 V. The producer claims that its LPDDR5 devices are 30% more power efficient than existing mobile memory chips because of a new circuit design with enhanced clocking, a new deep sleep mode, as well as low-power feature that guarantees stable operation at high clocks.", "Assembly of 12 GB LPDDR5-5500 packages will commence later in July, which indicates that the company expects demand for these products in the coming months. Quite naturally, Samsung does not disclose customers interested in 12 GB of LPDDR5 memory, but there are a number of new flagship smartphone launches scheduled for the coming months, so we are going to find out soon. We do expect that Samsung is starting to build inventory for new 1Q2020 device launches which will have next-generation LP5 compatible SoCs in them as well.", "Next year Samsung plans to release 16 Gb LPDDR5 devices and eventually increase data transfer rates of its LPDDR5 DRAMs all the way to 6400 MT/s. Meanwhile, as demand for LPDDR5 increases, Samsung may transfer production of this memory to its massive campus near Pyeongtaek, South Korea.", "Related Reading:", "Source: Samsung"]},
{"title": "Corsair Unveils 32 GB Vengeance LPX DDR4 DIMMs, 64 GB & 128 GB Dual-Channel Kits", "paragraph": ["Corsair has introduced its first 32 GB unbuffered DRAM modules along with 64 GB and 128 GB dual-channel memory kits for mainstream PC platforms based on AMD’s 400/500-series as well as Intel’s 300-series chipsets (and their successors). Besides, the company also unveiled its 256GB eight-channel kit for high-end desktop as well as extreme workstation processors.", "Corsair’s Vengeance LPX DDR4 unbuffered memory modules are based on 16 Gb memory chips (from an unconfirmed vendor, though Corsair historically relies on devices from Samsung) as well as the company’s custom 10-layer PCB designed to ensure quality signaling when operating at higher clocks. Traditionally for this product family, Corsair’s 32 GB Vengeance LPX UDIMMs are equipped with black anodized aluminum heat spreaders.", "Set to be available in kits containing one, two, four, or eight 32 GB unbuffered DIMMs, Corsair’s Vengeance LPX modules are rated for DDR4-2400 CL16 16-16-39 at 1.2 V, DDR4-2666 CL16 18-18-35 at 1.2 V, and DDR4-3000 CL16 20-20-38 at 1.35 V modes. It is noteworthy that the modules come with SPD programmed for DDR4-2133 CL15 mode, but since they feature XMP 2.0 profiles, setting correct speeds should be easy.", "Corsair’s 32 GB Vengeance LPX DDR4 unbuffered memory modules as well as kits on their base are available today directly from Corsair and will shortly be available from the company’s partners. One 32 GB DDR4-2400/DDR4-2666 module is priced at $149.99/$154.99; but dual, quad, and eight-channel kits are naturally more expensive.", "Related Reading:", "Source: Corsair"]},
{"title": "LG Display & SK Hynix Looking to Diversify Industrial Suppliers as Row with Japan Intensifies", "paragraph": ["South Korean electronics companies reaffirmed this week that production of computer memory and displays could be disrupted because of ongoing trade dispute between the country and Japan. Both SK Hynix and LG Display said that they were looking towards expanding the network of suppliers they use in acquiring three crucial materials required for product manufacturing.", "Having started on July 4, Japanese producers must now get approval for individual exports of polyimides (used both for LCDs and OLEDs), photoresists, and high-purity hydrogen fluoride (used to make chips, such as LSI, DRAM and NAND devices) to South Korea. These export reviews may take up to three months, whereas South Korean producers usually only keep one to two months' worth of materials in stock because they are highly toxic and uneasy to store. Meanwhile, Japanese companies — JSR, Showa Denko (SDK), and Shin-Etsu Chemical — control 70% - 90% of the global supply of these chemicals, and if they cannot supply materials to their South Korean partners on time, production of 3D NAND, DRAM, LCDs, and OLEDs at LG, Samsung, and SK Hynix will be disrupted.", "Polyimides, photoresists, and high-purity hydrogen fluoride are produced not only in Japan, but also in South Korea as well. However ramping up local production on short notice to satisfy the demand from the South Korean giants is pretty hard. Meanwhile, both LG Display and SK Hynix are looking towards other vendors simply because they have no other choice.", "Speaking about the matter yesterday to investors and financial analysts, Jin-Seok Cha, the executive vice president and head of finance and procurement at SK Hynix, stated:", "Executives from LG Display also confirmed earlier this week that the company intended to procure required chemicals from different suppliers", "Switching suppliers of chemicals is an uneasy task, and it is also hard for producers to ramp up production quickly. Considering the vast production capacities that the South Korean chaebols run in the country and their requirements for supplies, it remains to be seen whether they can get enough to keep their plants running at full capacity.", "Earlier this week South Korea failed to gain support from the World Trade Organization in its dispute with Japan. The latter plans to remove South Korea from the 'white list' of countries that have minimum trade restrictions, which will make life of Korean manufacturers even harder.", "Related Reading:", "Sources: ", ", "]},
{"title": "SK Hynix NAND Update: 3D NAND Output Cut, Slowdown Capacity Expansions", "paragraph": ["SK Hynix said that it would cut wafer starts of 3D NAND in the coming months more aggressively than it originally anticipated earlier this year. Besides, the company will reconsider plans to equip its M15 and M16 fabs, which will reduce its capital expenditures.", "Oversupply of 3D NAND memory encourages makers of flash to reduce their output in a bid to stabilize prices. Earlier this year SK Hynix said that it would reduce 3D NAND wafer starts by 10% in 2019, but this week it said it had changed its plans and now intends to reduce wafer starts by 15% when compared to its 2018 output.", "In Q2 2019, SK Hynix’s NAND flash bit shipments increased by a whopping 40% quarter-over-quarter as the company ramped up production of 72-layer 3D NAND and because overall increased demand following a traditionally slow first quarter. Meanwhile, average selling prices of 3D NAND dropped by 25%, which is reason for concern for SK Hynix.", "As SK Hynix (and other makers of NAND flash) transitions to more advanced 3D NAND designs with more layers (or more bits per cell in case of 3D QLC) and higher bit density, they increase their bit output, which to some degree create oversupply. As a result, cutting output of (usually previous-generation) wafers by 10% to 15% may not be enough to reduce bit output.", "SK Hynix currently produces 72-layer 3D NAND for datacenter and mainstream SSDs. The company’s 512 Gb 96-layer 3D TLC NAND entered production last November and the company intends to increase production of 96-layer 3D NAND shortly. In addition, SK Hynix recently started to ramp up production of 1 Tb ‘4D’ TLC NAND featuring the company’s charge trap flash (CTF) design featuring the peripheral under cells (PUC) architecture. These memory devices promise to significantly improve bit density over currently shipping 3D NAND, and further increase SK Hynix’s 3D NAND bit output.", "In addition to reduction of 3D NAND wafer starts, SK Hynix will also slow down expansion of cleanroom space at its M15 fab near Cheongju, South Korea, which can produce both DRAM and 3D NAND. In addition, it will also delay installation of equipment at its M16 fab near Icheon. While SK Hynix does not elaborate, it says that the decision would lower its 2020 CapEx “significantly” when compared to 2019, which may mean that new production capacities at the said plants may not come online next year.", "Related Reading:", "Source: SK Hynix"]},
{"title": "32 GB Unbuffered DIMMs Listed from Ten Brands: DDR4-2400 to DDR4-4000", "paragraph": ["Now that both Samsung and Micron are shipping their 16 Gb DDR4 memory chips to third parties, we're seeing wider availability of 32 GB unbuffered memory modules (UDIMMs). To date, eight brands have either introduced, or started to sell their 32 GB unbuffered DIMMs, and in the coming months more manufacturers are expected to follow.", "Before we proceed, let us recap the basics here. Because of the way memory sub-systems work, high-capacity memory modules (in our case, 32 GB and higher) for workstations and servers are built differently than regular DIMMs for client PCs (which are called unbuffered DIMMs, or UDIMMs). Registered DIMMs (RDIMMs) carry a register chip that buffers the address and command signals, whereas the Load Reduced DIMMs (LRDIMMs) replace the register with an Isolation Memory Buffer that buffers the command, address, and data signals. While both the register chip and the IMB allow hardware vendors to build high-capacity memory modules and memory subsystems, neither RDIMMs nor LRDIMMs work with regular client platforms. Therefore, if you use a contemporary desktop and need a lot of memory for some reason, you'll need 32 GB UDIMMs.", "You can read more about contemporary types DIMMs an appropriate article covering ", "At the time of writing, 32 GB UDIMMs are supported by client platforms based on AMD’s 400 and 500-series chipsets as well as Intel’s 300-series chipsets.", "Back in July, 2019, Twitter user ", ", who is from Japan, managed to get a list of 32 GB unbuffered memory modules that were either available then or were about to hit the shelves there. We took that list, added information about 32 GB UDIMMs we knew of at the time and issued the first version of the story. Several months from the initial publication we add details about recently launched 32 GB unbuddered DDR4 modules.", "Adding details about 32 GB modules from G-Skill and Team Group, clarifying official data transfer rates of Micron's 16 Gb DRAMs.", "", " Adding details about 32 GB ADATA XPG Hunter memory modules, clarifying specifications of regular 32 GB ADATA modules.", "", "Adding details about 32 GB modules from Kingston HyperX as well as low-latency modules from G.Skill.", "", "Adding details about 32 GB UDIMMs from Crucial and GIGABYTE.", "", "Adding details about G.Skill's 256 GB DDR4-3600 CL16 (8×32 GB) kit for AMD Threadripper 3000-series CPUs.", "There are a number of remarks to be made about 32 GB memory modules. Samsung’s mass-produced 16 Gb DDR4 memory chips are rated for 2133 MT/s, 2400 MT/s, and 2666 MT/s data transfer rates, yet even the company itself sells 32 GB DDR4-2933 memory modules. Meanwhile, its partners go all the way to DDR4-3000, albeit at 1.35 Volts. Micron's ", " are rated for 2933 and 3200 MT/s operation (which is within JEDEC's DDR4 specification), but many modules based on these chips are rated at 2400 or 2666 MT/s at 1.2 Volts.", "Now that we know the specs, let us talk about the modules themselves:", "", "", "ADATA was among the first companies to showcase its 32 GB DDR4-2666 CL19 at 1.2 V unbuffered DIMMs at at Computex 2019. Eventually, the manufacturer started to offer these products to its customers. Meanwhile, considering JEDEC-standard clocks and timings, it is likely that these UDIMMs are aimed mostly at OEMs.", "For channel market and PC makers who need advanced memory modules, ADATA introduced its XPG Hunter 32 GB UDIMMs and SO-DIMMs late in 2019. These modules usea  customized black PCB and come equipped with branded heat spreaders that makes them look rather stylish.", "The ADATA XPG Hunter 32 GB UDIMMs are rated for DDR4-3000 CL16 operation at 1.35 V, which makes them an interesting choice for overclockers who could increase clocks at the cost of timings. Meanwhile, the XPG Hunter 32 GB SODIMMs look special as they are rated for DDR4-3000 CL17 operation at 1.2 V, a rather unique combination of a decent speed, agressive timings, and a JEDEC-standard voltage. The latter is probably a requirement from notebook makers who would like to stay within a JEDEC-specified voltage ballpark and keep their thermals in check.", "Asgard’s Loki T2 and W2 memory modules are designed for enthusiasts, so they come with heat spreaders. The 32 GB DDR4-3000 CL16 modules need 1.35 V voltage and therefore need an enthusiast-class platform. Meanwhile, their 32 GB DDR4-2666 CL16 modules use industry-standard 1.2 V voltages.", "Corsair’s ", " come with DDR4-2400, DDR4-2666, and DDR4-3000 speeds. Depending on speed bins, these modules reportedly use memory chips from Micron or Samsung and require 1.2 V or 1.35 V. Corsair’s UDIMMs traditionally rely on the company’s custom 10-layer PCB designed to ensure quality signaling when operating at higher clocks, and are equipped with black heat spreaders.", "Micron’s Crucial brand introduced its DDR4-2666 CL19 32 GB UDIMMs back at Computex, but it too the company about half of a year to bring these modules to the market as they only became available in late January. In addition to moderate DDR4-2666 modules and kits, Crucial also offers DDR4-3200 CL22 UDIMMs and dual-channel kits for performance-demanding consumers. Furthermore, the compny also has 32 GB DDR4-2666 and DDR4-3200 SODIMMs.", "", "Crucial’s 32 GB UDIMMs do not feature any heat sinks, but use industry-standard voltage, which makes them compatible with a wide variety of PCs.", "GIGABYTE released its dual-channel 64 GB Designare memory kit tested to operate in DDR4-3200 mode with CL16 18-18-38 latency at 1.35 V in early February aiming at high-end system based on latest AMD Ryzen as well as Intel Core processors.", "The combination of high speed and low latency is designed to attract attention of enthusiasts building a PC with 64 GB (or even 128 GB) of memory and not satisfied with standard JEDEC-set specifications.", "G.Skill demonstrated its 32 GB UDIMMs at Computex and finally launched them ", ". Being one of the biggest suppliers of memory for retail and enthusiasts, G.Skill decided to address different types of customers with its high-capacty modules and for this reason introduced 32 GB memory sticks featuring six speed ratings in blingy Trident Z Royal (for Intel) and high-tech Trident Z Neo (for AMD) liveries.", "For PC makers and customers in budget, G.Skill offers DDR4-2666/CL18/CL19 and DDR4-3200/CL16 32 GB modules. For those who want something faster, DDR4-3200/CL14, DDR4-3600/CL18, DDR4-3800/CL18, DDR4-4000/CL18 are set to be available. Finally, for extreme enthusiasts with AMD's latest 64-core Ryzen Threadropper 3990X-based system G.Skill plans to offer an ", " operation somtimes in Q2 2020. The higher-end 32 GB UDIMMs require 1.35 V - 1.4 V voltage, so they will need motherboards with a DRAM VRM that can provide clean and quality power.", "As for pricing, given the unique combination of performance and capacity, expect G.Skill’s advanced 32 GB unbuffered DIMMs to cost more than competing products.", "Gloway’s 32 GB UDIMMs are rated to operate at DDR4-2400 CL17 and DDR4-3000 CL16 speed bins, according to the listing. Depending on performance, the modules need 1.2 V or 1.35 V and come with heat spreaders.", "Kingston's HyperX introduced its 32 GB memory modules in early 2020, a bit later than some of its rivals. Meanwhile, the company's family of 32 GB UDIMMs is among the broadest in the industry. For desktops, Kingston offers 32 GB HyperX Fury UDIMMs rated for DDR4-2400/CL15 at 1.2V, DDR4-2666/CL16 at 1.2 V, DDR4-3000/CL16 at 1.35 V, and at DDR4-3200/CL16 at 1.35 V operation. For laptops, there are 32 GB HyperX Impact SO-DIMMs featuring DDR4-2400/CL15, DDR4-2600/CL16, DDR4-2933/CL17, and DDR4-3200/CL20 at 1.2 V speeds.", "Samsung was first to start to producing 16 Gb DDR4 memory chips and was naturally the first to launch 32 GB UDIMMs. At present, the company offers DDR4-2666 CL19 and DDR4-2933 32 GB unbuffered DIMMs that come without any heat spreaders (based on the pictures of the modules from AVADirect).", "Team Group has decided to take a relatively cautious approach to 32 GB unbuffered DIMMs, which is why the only speed grades offered by the company this Fall will be DDR4-2400 CL16 and DDR4-2666 CL19 at 1.2 V despite the fact that Micron's 16 Gb chips (which the company uses) can go significantly higher. Meanwhile, the manufacturer offers 32 GB modules in three designs:  the ", " are not equipped with any heat spreaders and are likely aimed primarily at PC makers, whereas the Elite Plus 32 GB modules come with Gold & Black or Red & Black radiators to please the eye of the DIY crowd.", "The company is working on enthusiast-class 32 GB DDR4 UDIMMs, but these will only be available sometimes in Q1 2020, so it is too early to make assumptions about their data transfer rates and other peculiarities.", "Related Reading:", "Sources: ADATA, Corsair, Crucial, G.Skill, Samsung, Team Group, "]},
{"title": "Thermaltake’s Launches Liquid-Cooled WaterRam RGB DDR4-3600 Kits", "paragraph": ["Seemingly intent on proving that everything in a PC should in fact be liquid cooled, Thermaltake this week has expanded its ", " lineup of water-cooled RAM with DDR4-3600 kits.", "Available as a 32 GB dual-channel/quad-channel kit, Thermaltake’s WaterRAM DDR4-3600 (CL-W262-CA00SW) feature CL18 19-19-36 timings and 1.35 V operating voltage. The modules are based on tightly-screened SK Hynix’s C-die memory chips, a 10-layer PCB, and feature XMP 2.0 profiles for easier overclocking.", "The key selling feature of Thermaltake’s WaterRAM DDR4-3600 kit is its cooling system. It includes 2-mm thick aluminum heatsinks on the modules as well as a copper nickel-plated water block with a PMMA cover  that is installed on top of the DIMMs. The water block is equipped with G ¼ fittings compatible with the majority of open loop liquid cooling systems. Meanwhile, following the latest trends, the water block features 12 built-in addressable LEDs that can be controlled using Thermaltake’s hardware controller (bundled) or using software from leading motherboard makers, Razer Chroma, and Amazon Alexa.", "The manufacturer says that liquid cooling allows them to reduce RAM temperatures by 32% when compared to regular heat spreaders, a claim that has to be tested independently. Ideally, lower temperatures should enable at least some higher overclocking potential and/or improve stability.", "Thermaltake’s WaterRAM DDR4-3600 kit will be available shortly. The modules themselves are backed with a lifetime warranty, whereas the water block is covered with a two-year warranty.", "Related Reading:", "Source: ", " (via ", ")"]},
{"title": "G.Skill Reveals Trident Z Neo DDR4-3800 CL14 Kit for AMD Ryzen 3000", "paragraph": ["G.Skill has introduced its new high-end Trident Z Neo memory kits for systems based on AMD’s latest Ryzen 3000 processors. According to G.Skill, its Trident Z Neo DDR4-3800 CL14 kits reach up to 58 GB/s in measured memory bandwidth.", "AMD says — and many third-party observers confirm — that its Ryzen 3000 CPUs based on the Zen 2 microarchitecture show the highest memory subsystem performance when frequencies of Infinity Fabric (fClk), memory controller (uClk), and DRAM (mClk) are equal (i.e., the fClk to mClk ratio is set at 1:1). However, far not all Ryzen processors can support high fClk clocks, so using extremely fast DDR4 memory modules (e.g., DDR4-4000+) may be detrimental in many cases. G.Skill says that its Trident Z Neo DDR4-3800 kit, which runs at CL14-16-16-36 timings at a toasty 1.5 V, offers an optimal combination of high clocks, low latency, and fClk to mClk ratio of 1:1 for AMD’s latest CPUs.", "G.Skill’s Trident Z Neo DDR4-3800 CL14 8 GB modules (F4-3800C14-8GTZN) are based on Samsung’s 8 Gb B-die memory chips and use a custom PCB. The unbuffered DIMMs come with aluminum heat spreaders as well as RGB LEDs. To set up rather extreme clocks and low latencies, users will need to enable an XMP 2.0 profile.", "Apart from the combination of frequency and timings, a key feature of the Trident Z Neo DDR4-3800 CL14 modules is their unprecedented voltage of 1.5 Volts, a 25% increase over DDR4 specification (1.2 Volts), that is only supported properly on high-end platforms equipped with a high-quality VRM. The module maker itself has validated its new DIMMs with ASUS ROG Crosshair VIII Formula as well as MSI MEG X570 Godlike motherboards that run AMD’s Ryzen 5 3600X or Ryzen 9 3900X CPUs.", "According to G.Skill, internal tests revealed that a memory subsystem comprising of an AMD Ryzen 3000 processor as well as its Trident Z Neo DDR4-3800 CL14 modules can hit 58 GB/s, 56 GB/s, and 58 GB/s of memory bandwidth for read, write, and copy benchmarks respectively.", "G.Skill will supply its Trident Z Neo DDR4-3800 CL14 8 GB DIMMs in 16 GB or 32 GB dual-channel memory kits. The kits will hit the market shortly, their MSRPs will depend on demand and supply.", "Related Reading:", "Source: G.Skill"]},
{"title": "Western Digital: Nearly All NAND Capacities Resumed Normal Operations", "paragraph": ["Western Digital and its manufacturing partner Toshiba Memory Co. (TMC) had managed to resume normal operation of almost all of their joint production lines at their Yokkaichi Operations campus in Japan, Western Digital said on Wednesday. Damages to wafer and manufacturing tools will cost Western Digital up to $339 million in total.", "A 13-minute unexpected power outage in the Yokkaichi province in Japan on June 15 affected the manufacturing facilities jointly operated by Western Digital and TMC. The incident damaged wafers that were processed and also production equipment used by the companies. Western Digital said in late June that the accident would reduce its NAND flash wafer supply in Q3 by approximately 6 EB (exabytes), which was believed to be about a half of the company’s quarterly supply of NAND. Toshiba also confirmed that wafers and equipment was damaged, but did not elaborate.", "By now, virtually all production capacities at the Yokkaichi Operations are back online, according to Steve Milligan, chief executive of Western Digital.", "The company believes that all the lost wafers will be contained in the September quarter, but the incurred damages will be quite vast. In Q4 FY2019 (Q2 C2019) the company took a $145 million charge for impacted equipment as well as operations, and plans to take another $170 – $190 million write-off in the September quarter. As a result, the impact on Western Digital will total $315 – $339 million.", "Being a private company, Toshiba Memory does not disclose the impact of the accident, but if the company lost the equal number of wafers and has had to restore its production capacities, so its losses will be comparable to those of Western Digital. Overall, the 13-minute power outage will cost the two companies $630 to $678 million.", "Related Reading:", "Source: "]},
{"title": "Samsung to End B-Die DDR4: The Overclockers' Favorite", "paragraph": ["For many years leading DRAM module manufacturers have used Samsung’s B-die 8 Gb memory chips for their fastest and most advanced DIMMs. This quarter Samsung intends to discontinue production of B-die, forcing its partners to find a worthy replacement.", "According to Samsung’s most recent Product Guide, the company will EOL its B-die 8 Gb memory chips in Q2 2019. It is not particularly clear when exactly Samsung ceases to make its legendary memory chips, but it looks like it is time for companies like Corsair or G.Skill to stock pile B-die ICs for existing DDR4-4000 and faster kits.", "Samsung will continue to produce C-die and D-die 8 Gb memory chips using its 10 nm-class process technologies. Officially rated for DDR4-3200 and DDR4-3600 speed bins, these ICs have been in production since 2016 and 2017 respectively. By now, these memory devices have to be mature enough for high-end memory modules, but far not all makers of DIMMs use them for leading-edge products. Also their overclockability beyond those speeds pales in comparison to B-die.", "We have reached out to makers of memory modules to find out which memory chips will replace Samsung’s legendary B-die memory chips on high-end modules. We are yet to receive their responses. These products will not disappear overnight, but it looks like their days are numbered.", "Source: ", " (via ", ")"]},
{"title": "Samsung Samples 32 Gb DDR4 Memory Chips", "paragraph": ["Samsung recently began sampling of its 32 Gb capacity DDR4 memory chips. The new products will simplify production of high-capacity memory modules that use multiple DRAM packages.", "Samsung’s 32 Gb A-die DDR4-2666 chips are comprised of two stacked 16 Gb DDR4 dies produced using the company’s 10 nm-class process technology. Samsung offers two versions of 32 Gb DDR4 packages: one featuring a 2G x8 organization, another featuring a 1G x16 organization. The former is seen by memory controller as two memory devices, whereas the latter is considered as one DRAM device. The DDPs (dual die packages) come in standard 78 or 96-ball FBGA form-factor and use the industry-standard voltage of 1.2 V.", "JEDEC’s DDR4 specification only describes 4 Gb, 8Gb, and 16 Gb memory devices. As a result, DRAM makers have to use advanced packaging techniques to build chips for high-capacity memory modules for servers or workstations. DDPs are not something particularly new, but 32 Gb DDR4-2666 DDPs are unique to Samsung.", "32 Gb DDR4 memory chips will enable makers of modules and PCs to use fewer DRAM chips for building high-capacity solutions for applications that require high memory density or small form-factors. Obviously, dual-rank memory modules will still require support from memory controllers, but at least it will be easier to build high-capacity memory sub-systems using these chips.", "Samsung does not disclose pricing of its 32 Gb DDR4-2666 DDPs, but it is obvious that they will be sold at a premium given the fact that they are only available from Samsung and they are harder to build than SDPs.", "Related Reading:", "Source: ", ""]},
{"title": "KLEVV Cras X RGB: Up to DDR4-4266, Coming at Computex", "paragraph": ["KLEVV, a partner business of SK Hynix, has always been rather conservative when it comes to speed bins of its memory modules for gamers and overclockers, partly because the most popular volume models are still in the DDR4-3000 to DDR4-3600 range. This is going to change sometimes later this year when the company launches its new models of Cras X RGB modules.", "First introduced at Computex 2018, KLEVV’s Cras X RGB family of memory modules for enthusiasts included 8 GB and 16 GB DIMMs rated for DDR4-3200 CL16 18-18-38 as well as DDR4-3466 CL17 19-19-39 at 1.35V operation. At this year’s Computex later this month the company will launch faster versions of its Cras X RGB modules.", "The expanded family of Cras X RGB memory sticks will include DDR4-3600, DDR4-4000, and DDR4-4266 models. The DDR4-3600 speed bin will be compatible both with AMD Ryzen as well as Intel Core platforms, whereas the DDR4-4000 and DDR4-4200 speed bins will be aimed primarily at Intel-based PCs.", "KLEVV does not say which SK Hynix’s memory chips the new modules will use, but indicates that they will be equipped with its signature black heatsink and RGB lighting that can be controlled using software from ASUS, ASRock, GIGABYTE, and MSI.", "Launching faster DDR4 modules now makes a great sense for Klevv. On the one hand, enthusiasts today want faster memory as they upgrade to six-core or eight-core CPUs. On the other hand, faster modules are sold at higher MSRPs, which is important for DRAM makers as prices of DDR4 memory dropped significantly in the recent quarters and it is crucial for manufacturers to maintain their ASPs and profitability.", "Related Reading:", "Source: KLEVV"]},
{"title": "GeIL Launches Evo Spear Phantom Gaming Edition Memory, Designed For SFF Systems", "paragraph": ["Following on from a wide range of ASRock Phantom Gaming branded products, memory manufacturer GeIL has announced its new Evo Spear Phantom Gaming Edition memory, which is designed for use in small form factor systems. Available in frequencies ranging from DDR4-2400 to DDR4-3200, the Evo Spear Phantom Gaming memory is being pitched for use with ASRock's Phantom Gaming motherboards, with kits available specifically for both Intel and AMD models.", "Based on and designed for use with ASRock's Phantom Gaming series of motherboards, the new GeIL Evo Spear Phantom Gaming edition memory will be available in DDR4-2400, DDR4-2666, DDR4-3000 and DDR4-3200 versions with latencies ranging from CL17-19; the higher rated kits are likely to be the models that run with looser CAS latencies, with the slower rated models likely to feature tighter timings. The lower end of the Evo Spear Phantom Gaming kits come with voltages of 1.2 V, where the higher spec models will run at a higher voltage of 1.35 V. Each kit also includes an X.M.P 2.0 profile for easy and one-click overclocking capabilities.", "One of the most predominant aspects of the GeIL Evo Spear Phantom Gaming memory is the design. The low profile heat spreaders which have been designed for small form factor systems feature a stealth black aluminum frame with a silver sticker with the ASRock Phantom Gaming branding covers the right-hand side of the modules. On the flip side is primarily black with a small white GeIL sticker on the right-hand side for a simplistic, yet elegant look. The GeIL Evo Spear Phantom Gaming memory will be available for purchase as single modules and in kits up to 64 GB in capacity.", "The current availability and pricing of the GeIL Evo Spear Phantom Gaming series memory for both the Intel and AMD platforms are unknown as of yet, but we have reached out to GeIL for more information and we will update as soon as we have it.", " The GeIL Evo Spear Phantom Gaming memory kits that will be available in both 8 GB and 16 GB capacities, but the pricing will be unveiled after Computex 2019. The speed and latency configuration of the Evo Spear Phantom Gaming memory kits that will be available include the following:", "", "DDR4-2400 CL 17-17-17-39", "DDR4-2666 CL 19-19-19-43", "DDR4-3000 CL 16-18-18-36", "DDR4-3200 CL 16-18-18-36"]},
{"title": "Toshiba Memory & Western Digital Finalize Fab K1 Investment Agreement", "paragraph": ["Toshiba Memory and Western Digital on Friday announced that they had finalized a formal agreement regarding a joint investment in the K1 manufacturing facility near Kitakami, Iwate Prefecture, Japan. The fab is currently being constructed by Toshiba Memory and is expected to come online next year, as planned.", "The K1 building shell is being constructed in a single phase, while the cleanroom is being built over four similarly-sized phases. Equipment installation for a small initial production line in the Phase 1 of the cleanroom is set to begin in June 2019. When completed, the fab will be Toshiba Memory and Western Digital's largest manufacturing facility by size, and will also feature the greatest manufacturing capacity (because of the expanded cleanroom space). The first wafers – carrying 96-layer 3D NAND flash memory – will be produced at K1 in early 2020, with higher volume output expected in the second half of 2020.", "In addition to building the fab, the two companies will also extend their joint R&D activities to the new site. At present, all of their R&D activity is conducted at a special technology development center near their jointly run Yokkaichi operations.", "Under the terms of the agreement, Western Digital will fund 50% of the K1’s startup costs as well as 50% of the Phase 1 production line. The costs for the company, which include things like equipment investments, relocation costs, and startup costs will total about $660 million. Western Digital will also have to prepay around $360 million toward K1 building depreciation, which will take place over a three-year period starting in H2 2019.", "As is usually the case with fabs jointly owned by Toshiba and Western Digital, the production facility will formally belong to a separate joint venture (in this case, Flash Forward Ltd., or FFL) that will sell wafers processed by the factory to its owners at cost. As soon as Western Digital owns a certain stake in the joint venture, it will be eligible to buy a number of wafers at equal costs with Toshiba Memory. However, even if that stake falls below a threshold, Western Digital will be accountable for bearing permanent costs related to K1’s operations at that threshold.", "More details about the agreement will be published by Western Digital on Form 10-K for the fiscal year ending June 28, 2019.", "As noted above, K1 will be the largest fab operated by Toshiba Memory and Western Digital. The two companies already run five manufacturing facilities: Fab 2, Fab 5, and Fab 6 are used to make 3D NAND, whereas Fab 3 and Fab 4 serve different purposes.", "The addition of K1 to Toshiba/WD's already formidable fleet of fabs will ultimately allow the company to continue scaling up their NAND flash capacity. So even with the current weakness in flash memory pricing, it appears that the two companies remain cautiously optimistic about the prospects for the flash market.", "Related Reading:", "Sources: ", ", "]},
{"title": "Antec Unsheathes Katana: A New DDR4 Memory Series for Enthusiasts", "paragraph": ["In the market of PC components for enthusiasts and modders, Antec is trying to find a market to expand with a set of tools that it knows the best: style and design. The company’s upcoming Katana memory modules are all about style and design.", "Antec entered the market of memory modules just about a year ago with a clear aim: to sell memory modules to enthusiasts buying its stylish PC cases. The company probably has hit at least some of it its goals, which is why it is rolling out a new DDR4 product series, the Katana.", "Branded after the famous Japanese sword, the Katana memory module has an appropriate shape with RGB LEDs (Antec also shows off a regular, RGB-less version) and distinctive heatspreaders. Design of the DIMMs is actually their main selling feature", "At present Antec goes all about the volume with its Katana memory: at Computex the company demonstrated a 16 GB dual-channel DDR4-3600 CL18 20-20-44 at 1.35 V memory kit. Obviously, the company may expand the lineup if needed.", "Antec does not say when and where its Katana memory modules are set to available, but it is logical to expect them to hit the market this year at prices comparable to those of other memory modules aimed at the same market segment.", "Source: Antec"]},
{"title": "Crucial 32 GB DDR4 Modules Found in an ASRock System", "paragraph": ["In a rather unexpected turn of events, Crucial has unveiled its first 32 GB DDR4 UDIMMs, which are based on Micron's yet-to-be-announced 16 Gb memory chips. The DIMMs will be available later this year, and will allow system builders and enthusiasts to equip their PCs with a massive amount of memory without using ‘exotic’ server-class modules.", "Micron’s 16 Gb chips are built using the company’s second-generation 10 nm-class process technology (aka 1y nm), which Micron is only now starting to ramp up. Officially, the company hasn't launched its 16 Gb DDR4 memory chips quite yet – nor are they showing off any of this hardware directly at this year's Computex – however they are to the point where they're sampling the new chips to customers. These customers happen to be at Computex. ASRock is one of such clients and it is showcasing Crucial 32 GB DDR4-2666 memory modules in one of its Intel Z390-based systems featuring 128 GB of DRAM. ", "When it launches later this year, Micron’s 16 Gb DDR4 memory chip will be the industry’s second 16 Gb chip. At the moment, Samsung is the only supplier of 16 Gb DDR4 products, so Micron’s ICs will bring some welcome competition to that market.", "By and large, 16 Gb DDR4 memory chips will initially be used for products aimed at servers, as that's where where memory density matters the most and the margins are the greatest. But in time, these chips will come to more desktop-focused DIMMs as well. Eventually the new memory chips will show up in a wider variety of modules, including RDIMMs for servers and workstations.", "As for availability, Micron is not announcing a firm launch date for the new memory chips at Computex. But based on the fact that the company is showcasing them at a public trade show, I'd expect them to be available sometime this year. We even confirmed the retail packaging is already in place."]},
{"title": "ADATA Demonstrates 32 GB DDR4 Modules, Built on Micron 16 Gb", "paragraph": ["Earlier this year Intel enabled support of high-capacity 32 GB memory modules based on 16 Gb memory chips on select client platforms for enthusiasts and prosumers, but until recently 32 GB unbuffered DIMMs were only available from Samsung. This is going to change soon as a leading supplier of memory modules for enthusiasts prepping their 32 GB UDIMMs that are demonstrated at Computex.", "To build 32 GB UDIMMs, module producers need 16 Gb ICs. These DRAMs are produced using the most advanced process technologies possible: 2", "/3", " Gen 10nm-class. Up until recently such chips were only available from Samsung and the latter primarily used them to build high-end RDIMMs for servers or SO-DIMMs for laptops and mobile workstations. But now Micron is starting to ramp up production of its 16 Gb DDR4 memory chips, so later this year there will be two suppliers of high-capacity DDR4 DRAMs. Officially, the company has not launched its 16 Gb DDR4 memory chips quite yet, but ASRock is showing off Micron’s 32 GB DDR4 modules at this year's Computex, which confirms that Micron is sampling the new chips to and modules to customers and partners.", "This brings us to the subject of ADATA, who happens to be one of Micron's largest customers. Unlike Micron, ADATA ", " at this year's show, where they are demonstrating their new 32 GB UDIMMs. Officially, the company is not stating who the memory supplier is behind its 32GB DDR4-2666@1.2 V DIMMs, but given ADATA's close relationship with Micron, it is easy enough to read the unofficial subtext. Of course, this is a speculation to some degree on our side though. The company did confirm that these were not Samsung chips at any rate.", "ADATA does not disclose its launch plans concerning 32 GB unbuffered DIMMs, but it is logical to expect them to arrive sometime later this year. As for the price, we are talking about premium products, so expect a premium tag."]},
{"title": "CES 2019: GIGABYTE Aorus RGB Memory Hits DDR4-4000 with SK Hynix ICs", "paragraph": ["GIGABYTE last year entered the memory market with its Aorus RGB and GIGABYTE-branded DIMMs, designed for enthusiasts. To some degree the project was experimental with conservative DDR4-2666 and DDR4-3200 speed bins built on Samsung B-die ICs, typically known for much higher performance. At CES the company introduced faster Aorus RGB DIMMs that not only top at DDR4-4000, but do so using SK Hynix C-die ICs..", "In the near future GIGABYTE plans to add DDR4-3600 at CL18 and DDR4-4000 16 GB (2 × 8 GB) dual-channel kits to its Aorus RGB Memory lineup. The modules feature regular 1.35 V voltage for enthusiast-class DIMMs, they are also outfitted with XMP 2.0-enabled SPDs for one-click overclocking beyond JEDEC specifications, and they are equipped with aluminum heat spreaders with addressable RGB lights.", "The most interesting information about the new memory sticks is that they are based not on Samsung’s 8 Gb B-die memory chips that are traditionally used for enthusiast-class DIMMs, but on SK Hynix’s 8 Gb C-die DDR4 devices. C-Die DRAMs from SK Hynix have existed for at least a couple of years and numerous shipping DDR4-3600 (and lower) DIMMs use these chips. Meanwhile, GIGABYTE seems to be the first supplier of memory modules which has managed to overclock them to a DDR-4000 speed for a retail product.", "Overclocking potential of SK Hynix C-die-based DDR4-3600 and DDR4-4000 DIMMs beyond their stock speeds is something that remains to be seen, but with new Aorus RGB Memory modules hitting the market shortly, we will certainly learn more about it in the coming months.", "Source: GIGABYTE"]},
{"title": "ASUS Z390 Platforms Now Support 128 GB of Memory", "paragraph": ["ASUS has released a new UEFI BIOS version for its ROG Maximus XI Hero motherboard that enables support of up to 128 GB of DDR4 memory platform using 32 GB unbuffered modules featuring Samsung's newest 16 Gb memory chips. The company will release new BIOSes for other Intel Z390-based platforms shortly. Other motherboard manufacturers will likely follow as Intel has stated that this memory will be supported by its 9", " Gen Core processors.", "Last year Samsung started to mass produce ", " primarily aiming high-capacity RDIMMs for servers. These chips eventually came down to consumer grade memory as well, allowing for ", " to be added to Samsung's portfolio. Because Intel’s MRC for mainstream processors doesn't automatically support 16 Gb ICs, new firmware is required. The company has officially ", ", and so it is up to motherboard manufacturers to update their UEFI BIOSes to gain support for 32 GB UDIMMs.", "To date, ASUS has validated only SL Link's J4BGUS2G8QHBC DDR4-2667 CL19 modules with its ROG Maximus XI Hero motherboard.", "Intel is also validating various modules that use 16 Gb chips with its processors, so expect its “official” list of supported 32 GB UDIMMs to emerge in the coming weeks or months.", "It is worth pointing out that there are two competing implementations for 32GB UDIMMs. 'Double Capacity' memory modules released by G.Skill and Zadak last year are based on 32x8 Gb chips, but are essentially two modules on one PCB. This is different to the Samsung modules, which use 16x16 Gb chips.", "Source: "]},
{"title": "Double Height DDR4: 32GB Modules from G.Skill and ZADAK Reviewed", "paragraph": ["One of the disadvantages of small form factor motherboards is that they only feature two memory slots. Most consumer DDR4 modules can have a maximum capacity of 16 GB per module, which for mini-ITX would mean a maximum capacity of 32 GB. For ATX motherboards, this usually means a maximum capacity of 64 GB.  Users looking to build those small form factor systems have historically been capped to 32 GB - these new modules doubles that capacity to 64 GB.", "There are currently three motherboards on the market validated for this new double height memory:", "These are all Z390 chipset motherboards, and thus applies to Intel's 8th Gen and 9th Gen processors. In this review we used an i7-8700K, and it didn't have any issues. We tested on some other motherboards from MSI and ASRock, however those systems did not post. It would appear that the memory has been developed in conjuction with concurrent validation with ASUS.", "", "Each memory company is only offering a select number of kits, presumably due to the low catchment rate of the motherboards they are validated for, but also likely due to cost.", "G.Skill is offering three different 'TridentZ RGB DC' memory kits, each 2x32 GB:", "ZADAK by contrast is offering five 'Shield RGB DC' memory kits, each 2x32 GB:", "Using memory that is double the height of a normal module, certain other restrictions come into play: namely the CPU cooler being used has less room to exist.", "The almost universal intention in this environment, unless a low powered CPU is used, is for a liquid cooler to be in play. ", "We'll go into more detail on the specific kits over the page, but both memory modules work in a similar fashion.", "Using 8 Gb Samsung B-die chips, a normal 16 GB module would have 16 of them to make it up to capacity. For these modules, to reach 32 GB per module, there are 32 x 8 gigabit chips. These are split into two ranks of sixteen chips, and act as if there are two memory modules on the same channel. Modern mainstream processors support 'two DIMMs per channel', meaning two memory modules per channel, which is why we see motherboards for dual channel processors have a total of four slots. By putting two modules onto one PCB, only one slot is needed to hit 'two DIMMs per channel'.", "One would assume the signalling would be different, however within the same channel, a normal set of memory modules would use the same traces and either (a) daisy chain, or (b) split near the end in order to support both simulateously. There are stability advantages to the (b) method, known as T-Topology, however it is often more difficult to do. Either way, because two memory modules on the same channel do not need separate motherboard traces, that is what makes these modules possible. There are some additional fine tuning elements to the system as well, as with all memory.", "Ultimately any memory vendor's chips could have been used, but both G.Skill and ZADAK have gone with Samsung B-die, which are known for being good overclocking-focused memory. It likely also helps that the optimizations for one company's kit also helped with the second, as different ICs would have different requirements in the firmware.", "Ultimately with this review, we want to answer the following questions:", "The goal for both answers should be negative: we shouldn't expect any performance difference and no power difference. We also do some overclocking to see if they can be pushed harder even in this form factor.", " ", "Our motherboard benchmarking suite which includes our short form CPU performance tests and gaming tests were selected in conjunction with our new 2019 bench suite. Our test bench OS has been updated with drivers, newer software and as with our CPU testing updates, also includes Spectre and Meltdown patches. "]},
{"title": "GIGABYTE Adds Support for 128 GB of Memory to Z390 & C246 Motherboards", "paragraph": ["GIGABYTE has released UEFI BIOS updates for its motherboards based on Intel’s C246 and Z390 chipsets that enable support for 32 GB unbuffered memory modules from Samsung. This enables 128 GB of DDR4 on its higher-end mainstream desktop platforms. The compatibile UDIMMs are based on Samsung’s 16 Gb memory chips and are ", ".", "To date, GIGABYTE has validated 32 GB DDR4-2667 CL19 UDIMMs only with its Intel C246 and Z390-powered platforms, which is logical as owners of such motherboards are more likely to need 128 GB of memory and buy the modules. It also remains to be seen when and if support for such modules will come to other platforms.", "Intel recently updated its memory reference code (MRC) for the 9", " Gen Core processors that enables the said CPUs to work with unbuffered memory modules that use 16 Gb memory chips. Previously, only Intel’s HEDT and workstation processors could work with 32 GB RDIMM modules based on 8 Gb DRAM devices, whereas support for 16 Gb chips is still limited to select platforms.", "From now on, Intel C246 and Z390-based motherboards from GIGABYTE will work with UDIMMs featuring Samsung’s 16 Gb. Earlier, ", " to work with the said modules. In the coming weeks other makers of motherboards will also update their UEFI BIOSes with new MRCs, so UDIMMs based on 16 Gb chips will be supported more widely.", "Samsung started mass production of ", " last year initially targeting high-capacity RDIMMs for servers. These DRAMs eventually came down to consumer grade memory too, enabling for ", " to be added to Samsung's product family available primarily to OEMs. At present, such modules are still rare in retail, but over time they will be available more widely and enthusiasts who for whatever reasons need 128 GB of memory will be able to take advantage of them.", "Source: "]},
{"title": "G.Skill Unveils Trident Z Royal Hexa-Channel 192 GB DDR4-4000 Kit for Xeon W-3175X", "paragraph": ["G.Skill has released the industry’s first hexa-channel DDR4 memory kits designed specifically for Intel’s 28-core Xeon W-3175X processor for extreme workstations. The top-of-the-range kit features a 192 GB capacity and operates at 4000 MT/s data transfer rate, thus combining extreme performance and capacity. To make it even more attractive, the modules use G.Skill’s ‘blingy’ Trident Z Royal heat spreaders.", "As usual, G.Skill plans to offer a number of Trident Z Royal hexa-channel memory kits for extreme workstations powered by Intel’s Xeon W-3175X featuring capacities ranging from 48 GB to 192 GB and rated for DDR4-3200 CL14/CL16, DDR4-3600 CL17, and DDR4-4000 CL17 at 1.35 V operation. All the modules are based on Samsung’s 8 Gb B-die DRAM devices that are known for their high overclocking potential. Like the rest enthusiast-class memory modules on the market today, the Trident Z Royal feature XMP 2.0 SPD profiles for one-click setup.", "Depending on their speed bins, G.Skill’s hexa-channel Trident Z Royal DDR4 kits will offer a peak memory bandwidth of 153 GB/s, 172.8 GB/s, or 192 GB/s. Keeping in mind that the DRAM sets are designed for an unlocked 28-core CPU that operates at 3.1 – 4.5 GHz, an extreme memory sub-system is a must have feature in a bid to ensure maximum performance.", "Apart from performance, a distinctive feature of G.Skill’s hexa-channel DDR4 kits is the company’s gold or silver Trident Z Royal heat spreaders with a unique addressable RGB lighting. Usage of the premium DRAM cooling systems naturally make Intel Xeon W-3175X-based systems look very luxurious.", "G.Skill’s hexa-channel Trident Z Royal DDR4 kits will hit the market in the near future. Their MSRPs are unknown, but expect them to be on par with pricing of Intel’s Xeon W-3175X processor and ASUS’ ROG Dominus Extreme motherboard.", "Related Reading:", "Source: G.Skill"]},
{"title": "Keysight Reveals DDR5 Testing & Validation System", "paragraph": ["Keysight, an electronic measurement company, has introduced the industry’s first off-the-shelf testing and validation system for DDR5 DRAM. The N6475A DDR5 Tx compliance test software is aimed at developers of various products that will use the next-generation memory.", "Keysight’s DDR5 testing and validation system includes the company’s ", " DDR5 Tx compliance test software as well as its own ", ") and ", " hardware (though it can work with other hardware too). The application performs jitter, electrical, timing, as well as eye measurements, and is designed to test the transmitter PHY of DDR5 SDRAM, data buffer, and register chips. The program automatically compares the results with the DDR5 spec test limits and shows how closely the device passes or fails each test.", "Previously developers of various DDR5 products had to design their own testing software or perform all the measurements and analysis manually, which greatly lengthens development time. Now that Keysight’s DDR5 Tx compliance test software and hardware is available, it will be far easier for engineers to optimize transmitter, receiver, and channel designs. So this should speed up how quickly hardware vendors are able to bring DDR5-based devices to the market..", "Keysight’s N6475A DDR5 Tx compliance test software and appropriate hardware is now available. Pricing is available upon request.", "Related Reading:", "Source: "]},
{"title": "Corsair 192 GB DDR4 kits for W-3175X Listed Online: Up to $3000", "paragraph": ["Corsair has released a range of 192 GB DDR4 kits to complement the workstation-focused ", " which features 28 cores. The top kit from the new line-up Corsair Vengeance LPX 192 GB operates at DDR4-4000 with a latency of CL19 and has a price tag of $3000.", "Using its characteristic heatsink design, Corsair has equipped its 192 GB kits with the Vengeance LPX low profile heat spreaders which are constructed with anodized aluminum and feature an all-black design. Each kit comes supplied with two Vengeance Airflow cooling systems catering for both sides of the ", "; this is the only motherboard that supports the ", " at present.", "The four kits available are rated at DDR4-2666 CL16, DDR4-3200 CL16, DDR4-3600 CL18, and DDR4-4000 CL19. Each 192 GB kit consists of twelve 16 GB sticks which operate in hexa-channel mode on the Xeon W-3175X and other LGA3647 CPUs that allow for UDIMM operation. On the DDR4-2666 kit, the operating voltage is at 1.20 V, with the faster kits requiring 1.35 V to run at their rated specifications.", "The four Corsair Vengeance LPX kits are available for purchase directly from the Corsair Store, with each kit occupying a different price point. The cheapest 192 GB kit is the DDR4-2666 CL16 with a cost $1585, while the next fastest, the DDR4-3200 CL has an MSRP of $1720. Moving up to the DDR4-3600 CL18 kit, it costs $2320 and unsurprisingly, the DDR4-4000 CL19 kit is the most expensive with a mouth-watering price tag of $3000.", "All four kits on Corsair's website are currently listed as 'notify me when in stock', so it will be interesting so see when they will be in stock and how many units will be available."]},
{"title": "Advantech Unveils 32 GB SQRAM DDR4 DIMMs for HPC", "paragraph": ["Advantech, a maker of server-grade memory, storage, and other components and solutions, is introducing a new lineup of 32 GB unbuffered DDR4 memory modules. Designed for high-performance computing (HPC) applications, the SQRAM-brand DIMMs use the latest DDR4 DRAM devices from Samsung, and feature additional reinforcements to make them suitable for industrial applications.", "Advantech’s SQRAM 32 GB DDR4 modules are based on Samsung’s 16 Gb DDR4-2666 memory chips. Given their positioning, they enable system makers to easily install 64 GB of memory into machines with two memory slots or 128 GB of memory into machines with four memory slots, twice what's possible with today's common 16 GB DIMMs. Advantech's modules come in ECC Unbuffered DIMMs, Unbuffered SO-DIMM, ECC SO-DIMM, and Rugged DIMM form-factors.", "Along with class-leading capacity for an unbuffered DIMM, Advantech’s ", " memory modules are also aimed at applications that require high long-term reliability. In particular, they're rated to withstand extreme temperature ranges (between -40°C and +85°C or between 0°C and +85°C), and they feature 30u micron thick golden connectors for extra reliability. The modules also come equipped with a heatsink and are supported by the company’s SQRAM Manager utility to monitor DRAM temperature and alert about overheating.", "Advantech will start sales of its 32 GB SQRAM DDR4-2666 memory modules in the near future. The company hasn't announced any official prices at this time, but as both high-capacity and industrial-grade DIMMs, they are very much high-end parts and will undoubtedly be priced accordingly.", "Related Reading:", "Source: "]},
{"title": "Cadence & Micron DDR5 Update: 16 Gb Chips on Track for 2019", "paragraph": ["Earlier this year Cadence and Micron performed the industry’s first public demonstration of next-generation DDR5 memory. At a TSMC event earlier this month the two companies provided some updates concerning development of the new memory technology. As it appears, the spec has not been finalized at JEDEC yet, but Micron still expects to start production of DDR5 memory chips in late 2019.", ", the primary feature of DDR5 SDRAM is capacity of chips, not just a higher performance and a lower power consumption. DDR5 is expected to bring in I/O speeds of 4266 to 6400 MT/s, with a supply voltage drop to 1.1 V and an allowable fluctuation range of 3% (i.e., at ±0.033V). It is also expected to use two independent 32/40-bit channels per module (without/or with ECC). Furthermore, DDR5 will have an improved command bus efficiency (because the channels will have their own 7-bit Address (Add)/Command (Cmd) buses), better refresh schemes, and an increased bank group for additional performance. In fact, Cadence goes as far as saying that improved functionality of DDR5 will enable a 36% higher real-world bandwidth when compared to DDR4 even at 3200 MT/s (this claim will have to be put to a test) and once 4800 MT/s speed kicks in, the actual bandwidth will be 87% higher when compared to DDR4-3200. In the meantime, one of the most important features of DDR5 will be monolithic chip density beyond 16 Gb.", " ", "Leading DRAM makers already have monolithic DDR4 chips featuring a 16 Gb capacity, but those devices cannot offer extreme clocks or I/O speeds because of laws of physics. Therefore, companies like Micron have a lot of work to do in a bid to bring together high DRAM densities and performance in the DDR5 era. In particular, Micron is concerned about variable retention time, and other atomic level occurrences, once production technologies used for DRAM reach 10 – 12 nm. Meanwhile, the DDR5 Add/Cmd bus already features on-die termination to make signals cleaner and to improve stability at high data rates. Furthermore, high-end DDR5 DIMMs will have their own voltage regulators and PMICs. Long story short, while the DDR5 standard is tailored to wed performance and densities, there is still a lot of magic to be done by DRAM manufacturers.", "Micron expects to start production of 16 Gb DDR5 chips using its “sub-18nm” fabrication process late in 2019, though this does not necessarily mean that actual applications featuring this memory will be available by the end of next year. Cadence already has DDR5 IP (controller + PHY) implemented using TSMC’s N7 (7 nm DUV) and N7+ (7 nm DUV+EUV) process technologies, so chip developers have what they need to design SoCs compatible with the new type of memory. Cadence is working on DDR5 IP for more advanced process technologies. ", "Given the key advantages of DDR5, it is not surprising that Cadence forecasts servers to be the first applications to use the new type of DRAM. What is particularly interesting is that Cadence believes that client SoCs made using N7+ process will support DDR5, which essentially means chips due to hit the market in 2020. Given rather quick ramp of DDR5 production predicted by Cadence, it looks like the new DRAM will be supported by a wide range of chips.", "Related Reading:", "Source: "]},
{"title": "What Next for 3D XPoint? Micron to Buy Intel's Share in 3D XPoint Fab", "paragraph": ["Micron on Thursday announced plans to acquire Intel’s stake in IM Flash Technologies, a joint venture between the two companies. IM Flash owns a fab near Lehi, Utah, which is the only producer of 3DXPoint memory that Intel uses for its premium Optane-branded solid-state storage products. Once the transaction is completed, Intel will have to ink a supply agreement with Micron to get 3D XPoint memory after the current agreement finishes at the end of 2019. This will have important ramifications for Intel's 3D XPoint-based portfolio.", "Under the terms of the joint venture agreement between Intel and Micron signed in 2005, the latter controls 51% of company and has a right to acquire the remaining share under certain conditions. Intel already sold Micron its stakes in IM Flash fabs in Singapore and Virginia back in 2012, which left IM Flash with only one production facility near Lehi, Utah (pictured below). The fab is used exclusively to produce 3D XPoint memory right now.", "Early this year the two companies ", " to fold their NAND flash R&D partnership, which made a jointly owned production facility somewhat useless for the long term as Intel and Micron were going to develop their own process technologies and memory devices going forward. Then in July the two companies ", " plans to discontinue their joint development of non-volatile 3D XPoint memory after completing design of 2", " generation 3D XPoint, further dissolving any need in joint manufacturing operations in the mid-term future. As it turns out, Micron is set to exercise its right to call Intel's interest in IM Flash and buyout its stake for about $1.5 billion starting from January 1, 2019, the company said on Thursday.", "Under the terms of the original agreement, Intel has purchased chips from IM Flash under a special long-term supply agreement, essentially buying at manufacturing cost. Once Micron acquires Intel’s stake in IM Flash, which will take from six to twelve months after Micron exercises its right, the two companies will have to sign a new supply agreement if they need to. On the basis of previously signed contracts, Micron will still supply 3D XPoint memory wafers to Intel for up to a year after close, at pre-agreed prices. After that, Micron may continue to supply Intel with 3D XPoint memory on a foundry basis.", "Given the 6-12 month lead time required after Micron hitting the button, if Micron puts its takeover plan in motion on January 1, 2019, it will need to come to new terms to sell Intel any of the Lehi manufactured 3D XPoint memory by mid-2020 or early-2021. While this is ongoing, Micron has previously stated that it is set to introduce its own 2nd Gen 3D XPoint-based products in late calendar 2019 and then ramp them in 2020 under the QuantX brand. Around the same time Micron will start pilot production of its post-3D XPoint emerging memory products, the company indicated.", "While Intel will continue to obtain 3D XPoint from IM Flash until at least mid-2020, there is a big catch. The two companies are set to finish development of their 2", " Gen 3D XPoint only sometimes in the second or the third quarter of calendar 2019. The joint development takes place in IM Flash R&D facilities and the design is tailored for the IM Flash fab and jointly-developed process technology. Therefore, the transaction may potentially affect Intel’s ramp up plans for the 2", " Gen 3D XPoint memory. In fact, Intel can manufacture 3D XPoint memory at Fab 68 in Dalian, China, the company said earlier this year. However, since the fab is busy making 3D NAND, Intel may have to adjust its production plans for both types of memory.", "The announcement from Micron is the end of the whole IM Flash joint venture project. At this point, the two companies have very different priorities for their storage businesses in general: Intel might primarily wants to sell SSDs for client and server applications, whereas Micron’s interests also span to automotive, mobile, special-purpose use, and various emerging applications (in fact, Micron once planned to offer 3D Xpoint for mobile devices, according to a presentation).", "In order to properly address different markets, memory suppliers need different products. Intel prefers larger dies for high-capacity SSDs, while Micron needs smaller dies for other devices, it can be counterproductive for the two to work together. This can be one reason why the two decided to dissolve the partnership and focus on individual goals both for volatile (NAND) and non-volatile (post-3D XPoint) types of memory.", "What remains to be seen is how the two companies share their jointly-developed IP (actual technologies required for 3D NAND and 3D XPoint will be shared, but there are certain things beyond that). The most logical scenario would be to sign a broad cross-licensing agreement, but this is still to be determined.", "Related Reading:", "Sources: ", ", "]},
{"title": "Samsung Shows Off 256 GB DDR4 RDIMM: Coming to Servers Soon", "paragraph": ["Samsung this week demonstrated its first 256 GB memory module for upcoming servers. The new Registered DIMM (RDIMM) is based on Samsung’s 16 Gb DDR4 memory devices introduced earlier this year and takes advantage of the company’s 3DS (three-dimensional stacking) packaging. The new module will offer higher performance and lower power consumption than two 128 GB LRDIMMs used today.", "Samsung’s 256 GB DDR4 Registered DIMM with ECC carries 36 memory packages featuring 8 GB (64 Gbit) of capacity each, along with IDT’s 4RCD0229K register chip (to buffer address and command signals and increase the number of ranks supported by a memory channel). The packages are based on four single-die 16 Gb components that are interconnected using through-silicon vias (TSVs). Architecturally, the 256 GB module is octal ranked as it features two physical ranks and four logical ranks.", "On a bit more of a technical note here, it's very interesting to point out that these new DIMMs are Registered DIMMs (RDIMMs) and not ", "Normally, LRDIMMs are required for high capacity configurations, with these style DIMMs relying on additional buffering that hurts power consumption and latency versus RDIMMs. Instead, because the latest server platforms (AMD EPYC, Intel Xeon Scalable, etc.) have shifted their memory requirements to natively support support octal-ranked modules in both slots - at the cost of being limited to two slots per channel in total - LRDIMMs are not necessary to maximize the memory capacities of these new servers. As a result, simpler RDIMMs can be used instead. I suspect this is a big reason why Samsung decided to go with a 256 GB RDIMMs, as they are a natural pairing with the latest servers.", "So what can you do with 256 GB memory modules? Intel’s upcoming Xeon Scalable “Cascade Lake” processors appear to support up to ", ", so by installing 12 256 GB RDIMMs, a dual-socket server could get 6 TB of memory. AMD’s existing EPYC processors officially ", " and up to 2 TB of memory in total, which is logical as AMD has not yet validated 256 GB RDIMMs. If AMD finds 256 GB RDIMMs viable for its platform, it can support them by adjusting microcode of its existing EPYC processors, or just validating them with its upcoming 7nm EPYC Rome CPUs. In any case, 256 GB modules can enable up to 4 TB of memory per socket and up to 8 TB of RAM per 2P box in case of the AMD server platform.", "Besides capacity and lower latencies when compared to LRDIMMs, a single 256 GB RDIMM will also offer considerably lower power consumption than two 128 GB LRDIMMs used today. This is partly because Samsung uses its 16 Gb memory devices made using its 10nm-class process technology, and partly because it does not use power-hungry iMB and accompanying ICs.", "Samsung did not disclose precise specs of its 256 GB RDIMM, but do not expect its frequency to be significantly higher than the currently common DDR4-2400 & DDR4-2667 speeds. Availability of the modules will in turn depend on validation by CPU designers and server makers, which will take some time. Samsung also isn't likely to ever publish an official MSRP for the DIMMs since they're primarily aimed at a very niche market of server operators, but just to add some context, Crucial sells its 128 GB LRDIMMs for ", " today, so higher-capacity modules will be priced higher still.", "Related Reading:"]},
{"title": "Intel's Response: Micron’s Control of 3D XPoint Fab Will Not Disrupt Optane Roadmap", "paragraph": ["Intel late on Friday said that Micron’s intention to gain full control of the IMFT joint venture will not interrupt its plans concerning products based on 3D XPoint memory. The company is confident that it will have enough time to start production of 3D Xpoint memory after Micron exercises its option to buy Intel’s stake in IMFT.", "Micron currently controls 51% of IMFT, its joint venture with Intel, and has a right to buyout Intel’s share under certain conditions. After Micron proposes to buy Intel’s stake, as ", ", the deal will take up to twelve months to close and during that time the fab that exclusively makes 3D XPoint will be working as usual, and will make the memory for Intel Optane-branded products at near manufacturing cost. Furthermore, even after the deal closes, the fab may continue to produce memory for Intel on a foundry basis, which means that that Intel and Micron will have to come to an agreement (and price may increase). What is important is that Intel has the technical capability to produce 3D XPoint memory in different locations as well.", "Intel has already finalized its Optane roadmap for the coming quarters and Micron’s intentions to gain 100% control of the fab near Lehi, Utah, will not disrupt it those intentions, Intel has said.", "The full statement is presented below:"]},
{"title": "Silicon Power Enters Market of Enthusiast-Class DRAM with DDR4-4133", "paragraph": ["Silicon Power currently offers a broad range of products that span from memory cards to SSDs and from power banks to headphones. For several years the company has been offering mainstream memory modules too, but only this month it decided to enter the market of enthusiast-class DRAM.", "Silicon Power’s XPOWER DDR4 memory modules rely on custom 10-layer PCBs to ensure stability while operating at speeds beyond JEDEC standards. The current lineup includes dual-channel 16 GB (2×8 GB) and 32 GB (2×16 GB) kits aimed at the latest platforms. Silicon Power will offer DDR4-2666 CL16, DDR4-3200 CL16, DDR4-3600 CL19, and DDR4-4133 CL19 modules featuring up to 1.4 V. Like other enthusiast-class DIMMs, the XPOWER DDR4 products feature XMP 2.0 technology to simplify setting their speeds.", "Silicon Power offers two kinds of XPOWER modules: the XPOWER AirCool without any heat spreader, as well as the XPOWER Turbine with a heat spreader.", "Silicon Power does not disclose memory chips it uses for its XPOWER AirCool and XPOWER Turbine DDR4 modules, but expect different speed modules to be based on different DRAM devices. In fact, since the company requires DDR4-4133 CL19 DIMMs to use 1.4 Volts, it has a pretty wide range of chips it can use since such a high voltage pretty much guarantees stable operation at high speeds.", "All Silicon Power XPOWER AirCool DDR4 modules are backed by a lifetime warranty. Sales of these products are expected to begin in the coming weeks or months, depending on the region. Pricing is expected to in line with market trends.", "It is noteworthy that Silicon Power is one of many companies that decided to start making enthusiast-class DRAM modules this year. Alongside Silicon Power, companies such as Antec, Colorful, GIGABYTE, and Inno3D have introduced their advanced memory in the last couple of quarters.", "Source: ", " "]},
{"title": "U.S. Government Indicts Chinese DRAM Maker JHICC on Industrial Espionage; Bans Exports To Firm", "paragraph": ["The U.S. Department of Commerce this week banned U.S. exports to a China-based maker of DRAM. The DoC believes that Fujian Jinhua Integrated Circuit Company (also known as Fujian or JHICC) not only uses technologies obtained from Micron, but also threatens the latter’s long-term economic viability and therefore could also be involved in activities that are contrary to the U.S. national security interests.", "In the meantime, the U.S. Department of Justice has also filed an indictment against JHICC, United Microelectronics Corp. (UMC), and several individuals accusing them of corporate espionage and stealing IP from Micron. Between the two, the U.S. authorities essentially sided with claims that Chinese makers of memory have illegally obtained IP and technologies from DRAM makers from the U.S. and potentially other countries.", "As a result of DoC ", " against JHICC, all U.S.-based (and, actually, non-U.S.-based too) companies will require a special license for all exports, re-exports, and transfers of commodities, software and technology subject to the Export Administration Regulations (EAR). DoC makes no secret that such license applications will be “reviewed with a presumption of denial”, so it will be tremendously hard for JHICC to obtain practically everything, including Windows 7 licenses for manufacturing equipment and production tools themselves (ASML has a strong presence in the U.S., whereas Nikon Precision is based in California). Meanwhile, the whole situation is somewhat more complex.", "“When a foreign company engages in activity contrary to our national security interests, we will take strong action to protect our national security. Placing Jinhua on the Entity List will limit its ability to threaten the supply chain for essential components in our military systems,” Secretary of Commerce Ross said.", "The ", " from DoJ may also have very serious consequences for JHICC, UMC, and several individuals. If found guilty, the companies will face forfeiture and a maximum fine of more than $20 billion, which might easily destroy almost any firm. As for individual defendants, they are facing a maximum sentence of 15 years imprisonment and a $5 million fine. Besides, any products containing allegedly stolen IP will be banned from the U.S. market.", "Without any doubts, a strong new player on the DRAM market poses a threat for the whole industry when it comes to its economic viability, and the DoC is correct when it does not underestimate the DRAM effort. If Chinese companies flood its domestic market with their own memory, global businesses of Micron, Samsung, and SK Hynix might suffer. Micron will of course suffer the most as it is the only DRAM maker with no semiconductor production facilities in China. Meanwhile, for ", " the DRAM effort is part of a larger “Made in China 2025” project (which we are going to discuss below) that includes establishment of a domestic semiconductor industry, so actions of the DoC against JHICC may slow down the DRAM endeavor, but will barely affect the grand plan that the Chinese authorities have.", "Since DRAM and NAND are commodities that China has to buy from abroad in order to build hardware that is then sold worldwide, it is natural for China to want to produce them locally. It does not mean that producing DRAM is easy. Developing a competitive chip manufacturing technology from scratch is a tremendously hard task these days as leading makers of semiconductors have spent decades researching microelectronics and have both experience and IP. Building an industry that requires a variety of manufacturing processes is close to impossible. Meanwhile, this is exactly what the Chinese government is attempting to do these days with semiconductors. In the recent months Micron and some other makers of memory accused Chinese DRAM producers of illegally obtaining IP from memory makers based in South Korea and the U.S.", "It all began in May 2015, when the Chinese government announced its “Made in China 2025” initiative to broadly upgrade Chinese industry a decade later and reduce the country’s reliance on foreign goods and components. Establishing a competitive domestic semiconductor industry is a significant part of the plan and producing volatile and non-volatile memory is considered one of its crucial parts.", "At first, government-controlled Tsinghua Unigroup tried to acquire Micron and get all the technologies and IP it needed to make DRAM and NAND legally. That deal never worked out and it is widely believed that the Committee on Foreign Investment in the United States (CFIUS) would have blocked the deal. Since by 2015 only three major makers of DRAM remained on the planet, and as giants like Samsung as well as SK Hynix could not be purchased, the Chinese government turned to different tactics in a bid to get what they needed.", "In February 2016 local authorities in Fujian, China, (which are still controlled by the central government) established ", " (JHICC). In May, 2016, JHICC ", " a contract with UMC to develop a competitive DRAM manufacturing technology. According to Micron, UMC would get $300 million in R&D equipment in exchange for an advanced DRAM technology. JHICC started to construct its first 300-mm fab in July 2016 (i.e., well before it had a process technology ready). This fab costs $5.65 billion and is ", " production of chips. However there is substantial proof that UMC did not really develop a new DRAM process, but instead headhunted engineers from Micron’s operations in Taiwan in early 2016 and asked them to steal specs and peculiarities of Micron’s chips and process technologies.", "Micron accuses Stephen Chen, a former site director at Rexchip in Taiwan (Rexchip ", " a part of Micron in 2013) who was hired by UMC in the second half of 2015 and became a senior vice president, of stealing ‘trade secrets’. The company also accuses J.T. Ho and Kenny Wang, its former process integration managers, of stealing documents related to Micron’s process technologies. All three people had all the information about then-current and some upcoming memory products from Micron. Based on what is publicly known about JHICC’s process technology that will be used to make DRAM chips, it appears like that UMC and JHICC have managed to obtain and at least partially replicate one of Micron’s 20 nm-class fabrication process they now call ‘22 nm’.", "Furthermore, the U.S. DoJ has found the evidence from Micron and Taiwanese authorities viable enough to file a civil lawsuit seeking to prohibit JHICC and UMC products developed using Micron's IP from exporting to the U.S.", "Micron started to suspect that it had a leak of confidential information after JHICC and UMC demonstrated a presentation containing Micron’s code names at a recruiting event aimed at Micron staff in the U.S. In the meantime, Taiwanese authorities charged Stephen Chen of stealing trade secrets from Micron. After conducting an internal investigation, Micron filed a ", " against the said companies in Federal District Court for the Northern District of California in December, 2017.", "In response, JHICC and UMC sued Micron in Fuijan, accusing it of infringing their patents in China. All of these patents were originally issued to UMC and given the fact that this company does not produce DRAM or NAND, it is highly likely that they are related to production of semiconductors in general. Micron denies that it had infringed them because they are invalid, according to the company.", "Micron is not the only company that poses interest to Chinese makers of DRAM. Apparently, South Korean producers of memory are also targets of industrial espionage by the said companies, a report from The Korea Times said citing an “official directly involved with the issue.”", "Both Samsung and SK Hynix have production plants in China, so it remains to be seen how these companies deal with this delicate situation. Neither of them are interested in helping a potentially mighty rival, but they cannot fight government-controlled companies without a risk of ruining relationship with authorities.", "Despite controversies when it comes to DRAM-related IP, patents, process technologies, and other factors, there are at least three DRAM producers from China that either already make memory, or are about to start manufacturing operations. Besides JHICC, there are ", " and about ", ". Ironically, the latter inherited IP and process technologies originally developed by Qimonda (which assets were acquired by Elpida and which itself was taken over by Micron). Neither of these companies are under attack by foreign companies or governments (at least as of today), so the Chinese DRAM industry is developing and actual memory chips are already available. Furthermore, if you take a look at the list of ", ", you will find a lot more names from Tianxia that are not only getting ready to make DRAM or NAND, but test equipment for memory chips too.", "With the “Made in China 2025” plan in place, it is evident that China will work rigorously to develop its own semiconductor industry. The early attempts look like a mixed bag, given the DRAM controversies, CPU joint-ventures with ", " and ", " (as well as multiple developers of Arm-based SoCs), licensing of ", ", and so on. The big question is whether you can sustain an industry by either licensing or copying someone else’s work?", "Here is a quick example from the past. Having plenty of natural resources, but lacking the industry and designs, the USSR began to buy factories and blueprints from companies like ", " in the 1930s. The country needed both manufacturing technologies and actual products to develop after the devastating civil war of 1917 – 1922, so timing was crucial. The USSR did not stop there: it bought multiple designs from the U.S.-based companies after the World War II, then it bought the Fiat 124 blueprint and factory from Fiat in 1970 (i.e., a process technology + the design). The Fiat 124 small family car design branded as VAZ in the USSR and then in modern Russia had been evolving from 1973 all the way to the 2000s (because at some point the USSR/Russia was no longer able to buy technologies from the West), but it had never been truly competitive against the Western counterparts. Nowadays the automaker AutoVAZ is majority owned by the Renault-Nissan-Mitsubishi Alliance, it produces vehicles based on platforms developed by Renault/Nissan with some customization considering local realities. From a high point of view, the Russian automotive industry has never taken off and today it is a part of the international auto industry.", "Something similar might happen to the Chinese semiconductor industry. Now that Micron, (as well as Samsung and SK Hynix, but unofficially) has accused JHICC of stealing its IP, it is probably going to great length to avoid such a situation in the future. All DRAM makers are going to protect their secrets and technologies more rigorously than ever in a bid not to help their rivals. Therefore, once Micron (or any of the aforementioned memory companies) moves to, say, 4F² cell structure for DRAMs (that has been in the plans for sub-20 nm processes anyway) that will enable to them to make chips smaller and cheaper, companies with outdated fabrication processes and cell structures will not be able to compete in terms of costs. Eventually, with DDR5 and various specific DRAM products (LPDDR, HBM, Wide I/O, etc.) they will not be able to compete in terms of performance too, essentially shrinking their addressable markets.", "To make things even harder for Chinese DRAM makers in general, there is an ongoing trade feud between the U.S. and China. The actions of DoC and DoJ against JHICC may be an isolated case, or may be an element of this confrontation. Considering the background of the ongoing Micron vs. UMC legal battle and with facts already discovered by the Taiwanese authorities, it is highly likely that the plaintiff will win a cease and desist in the order barring all devices featuring the infringing memory chips from the U.S. market. In fact, the DoJ is essentially doing the same thing as Micron: barring any JHICC-made memory or products containing such chips from the U.S.", "Another move could be getting a cease and desist order in the Netherlands (the ports of Amsterdam and Rotterdam are the points of entry for virtually all the electronics made in China in the E.U.). Blocking two major markets for devices featuring DRAMs from JHICC will be a problem for this memory maker in particular and for China in general. Considering the fact that JHICC now cannot license anything or buy new equipment, it is going to be extremely hard for the company to take off and stay competitive even if it does.", "There is a reason why China wants its semiconductor industry up and ready ", ". The government wants to maintain its exports and lower its imports. China has already done a lot to build up its internal market, but it is unclear whether it is big enough for domestic designs and locally-developed process technologies. The latter may not be as advanced as those designed in the U.S. or South Korea, but remain good enough for mainstream products sold in China. Meanwhile, the U.S. DoC and DoJ just demonstrated that they have a toolset that they will not hesitate to use if they find that interests of companies like Micron are affected by infringements of IP rights by emerging rivals. If more companies join the U.S. DoC’s Entity List, then without proper access to technologies and new equipment, it will be far more difficult to develop Chinese semiconductor industry in the coming years.", "", "", ": JHICC denies it has violated Micron's IP rights (via ", ").", "Related Reading:", "Sources: ", ", ", ", ", ", ", ", ", ", ", "."]},
{"title": "Micron Kicks Off Mass Production of 12 Gb LPDDR4X DRAM Chips", "paragraph": ["Micron this week announced that it had started mass production of its first LPDDR4X memory devices using its second-generation 10 nm-class process technology. The new memory devices offer standard LPDDR4X data transfer rates of up to 4.266 Gbps per pin and consumes less power than earlier LPDDR4 chips.", "Micron’s LPDDR4X devices are made using the company’s 1Y-nm fabrication tech and feature a 12 Gb capacity. The manufacturer says that its LPDDR4X memory chips consume 10% less power when compared to its LPDDR4-4266 products; this is because they feature a lower output driver voltage (I/O VDDQ), which the LPDDR4X standard reduces by 45%, from 1.1 V to 0.6 V.", "Micron’s 12 Gb (1.5 GB) LPDDR4X devices feature a slightly lower capacity than competing 16 Gb (2 GB) LPDDR4X offerings, but they are also cheaper to manufacture. As a result, Micron can offer lower-cost quad-die 64-bit LPDDR4X-4266 packages with a 48 Gb (6 GB) capacity and a 34.1 GB/s bandwidth than some of its competitors.", "The 12 Gb LPDDR4X DRAM is Micron’s first product to be manufactured using the company’s second-generation 10 nm-class process technology, so expect Micron to launch more DRAMs that are made using the same tech and therefore feature lower power consumption and higher frequency potential when compared to existing products.", "Like other makers of DRAM, Micron usually does not announce products before it ships the first batch. Therefore, at least one customer of Micron may have already received its LPDDR4X DRAM devices.", "Related Reading:", "Source: "]},
{"title": "SK Hynix Launches 96-Layer 3D NAND and Discloses QLC Plans", "paragraph": ["SK Hynix this week officially launched its new 96-layer 3D NAND flash memory chips, which feature a new architecture and a faster interface. The NAND has already been qualified for SSDs, with first 1 TB consumer models launching shortly and enterprise-grade solutions following on later. What is noteworthy is that these drives are going to be based on SK Hynix’s own controllers. In addition, SK Hynix will eventually offer UFS 3.0-based mobile storage devices featuring the same memory.", "Initially available in a 512 Gb capacity, SK Hynix’s new 96-layer 3D TLC NAND memory devices are based on a charge trap flash (CTF) design with a peripheral circuits under cells (PUC) architecture. Officially the company has started referring to these devices as “4D NAND” (as announced back at ", " in August), though the technology is not fundamentally different from current 3D NAND architectures.", "The new 3D-V5 devices use a 1.2 Gbps Toggle 3.0 I/O interface, which is faster than SK Hynix’s 72L 3D-V4 generation products. Meanwhile the chip also features a 64 KB page size (the smallest area of the flash memory that can be written in a single operation) and an 18 MB block size (the smallest area of the flash memory that can be erased in a single operation), which will further speed up performance of the new 3D-V5 devices compared to its predecessors.", "SK Hynix says that the increased number of layers and its PUC architecture makes its 96-layer 512 Gb 3D NAND devices around 30% smaller versus their similar 72-layer 512 Gb 3D NAND devices. Furthermore, it can now produce wafers containing 49% more bits than before (assuming the same yield), albeit at the cost of extra process steps. Speaking of production, the company hopes to kick off “the early stage of mass production” this year. At least some of the new chips will be made at the company’s recently built M15 fab.", "After SK Hynix refines the mass production of its 96L 3D TLC NAND chips, the company will move on to the next stage. Sometime next year the company plans to roll out 96L 3D NAND chips with a 1 Tb (128 GB) capacity, with both TLC and QLC variants planned.", "SK Hynix has already validated its 96L 512 Gb 3D TLC NAND for SSDs. The company plans to release 1 TB client SSDs featuring the memory and its own controllers/firmware “within this year”. Meanwhile, enterprise-grade drives based on the same memory are due in the second half of 2019.", "In addition to SSDs, SK Hynix intends to release UFS 3.0-based 96L 512 Gb 3D TLC NAND chips in the first half of next year. These will be the company’s first UFS 3.0-supporting devices and will enable it to address various high-end smartphones.", "Related Reading:", "Source: "]},
{"title": "Toshiba Begins to Construct New BiCS 3D NAND Fab in Iwate Prefecture", "paragraph": ["Toshiba Memory Corp. this week held a groundbreaking ceremony for its new BiCS 3D NAND flash memory fab, which is located in Japan's Iwate prefecture. Toshiba anticipates construction to be completed by late 2019 and expects its long-term partner Western Digital to participate in the project. The latter has once confirmed its plan to join the project, but has not made any final announcements thus far.", "The new manufacturing facility near Kitakami (Iwate prefecture) will be Toshiba’s largest fab building ever and is expected to feature the highest manufacturing capacity as well, both because of expanded cleanroom space as well as a new production system that will use artificial intelligence. As usual, the building will feature protection against earthquakes that tend to happen in Japan.", "Toshiba expects that construction of the new fab will be completed in autumn, 2019. After the company moves in equipment, the fab will come online sometimes towards the end of 2020. Meanwhile between now and late 2019, Toshiba will have to make decision regarding the equipment to be used in the fab and precise manufacturing capacity of the manufacturing facility.", "The upcoming fab will complement Fabs 2 and 6 — the two contemporary fabs at the Yokkaichi Operations memory production complex in Mie Prefecture, which Toshiba jointly operates with Western Digital.", "Toshiba is about to start using its Fab 6/phase 1 fab at the Yokkaichi Operations this summer. The move will help it to increase production of BiCS 3D NAND flash memory in the coming months. Next year the company is expected to deploy the Fab 6/phase 2 fab.", "Related Reading:"]},
{"title": "Samsung Starts Production of 16 Gb LPDDR4X Chips Using 2nd Gen 10nm Tech", "paragraph": ["Samsung this week announced that it has begun manufacturing its new LPDDR4X memory chips using its second-generation 10 nm-class fabrication process (which is traditionally called 1y nm). The new technology enables the company to slightly cut down power consumption of the new memory devices as well as to reduce the thickness of actual LPDDR4X memory packages installed into smartphones.", "Samsung’s new LPDDR4X memory devices feature a 16 Gb capacity and are rated to run at 4266 MT/s. The manufacturer says that the new DRAMs consume 10% less power than their predecessors made using its first-gen 10 nm-class (1x nm manufacturing technology), but without reducing industry-standard voltages for this type of memory (VDD1=1.1V, VDD2=1.8V, VDDQ=0.6V). Meanwhile Samsung is not disclosing anything about die sizes, but if their second-generation tech is indeed a smaller process, then the resulting chips should, in time, be at least slightly cheaper to manufacture.", "Meanwhile, the company says that its new 8 GB LPDDR4X package, which consists of four new 16 Gb dies, features a 20% lower thickness compared to the company’s previous-gen 8 GB LPDDR4X-4266 package. Naturally, such packages enable makers of smartphones to make their devices slightly thinner, assuming that they can bring thickness of other components down too. In addition to the new 8 GB LPDDR4X stacks, Samsung also plans to offer LPDDR4X in 4 GB and 6 GB packages for slightly more affordable smartphones.", "Samsung started to use its 1y nm production technology for DRAM back in December, 2017. The new LPDDR4X ICs seem to be the company’s second product to use the new fabrication process. Considering the high-density nature of LPDDR4X, usage of the 2", " Gen 10nm-class fabrication process for manufacturing of such ICs may indicate that yields of the tech have improved since last year. In the coming months the company will further expand usage of its 1y nm production process.", "Large DRAM makers usually make announcements regarding mass production after they ship the first batch to a customer. Therefore, expect the new 16 Gb LPDDR4X ICs from Samsung inside actual devices in the coming months.", "Related Reading:"]},
{"title": "SK Hynix Set to Build a New Memory Fab", "paragraph": ["SK Hynix last week announced plans to build another semiconductor fab near its headquarters in Icheon, South Korea. The production facility is not going to be as big and expensive as other investments, but will contribution to the company’s revenue and bottom line.", "The new fab will be located on a 53,000 m", " site near Icheon, Gyeonggi-do province, and will cost SK Hynix around ₩3.5 trillion ($3.13 billion) to build. The company will begin construction of the fab in late 2018 and expects to complete the fab in October, 2020. The maker of memory did not say whether the plant will be operational by that timeframe, or if only the building will be completed, but given typical amount of time it takes semiconductor companies to bring up a new fab online, it is likely that the facility will process actual wafers by late 2020.", "By the 'standards' of South Korea-based makers of DRAM and NAND memory, the new fab is small and cheap. Just to put the $3.13 billion in context, Samsung’s total investments in its Pyeongtaek facility will total ₩30 trillion ($26.1 billion) by 2021 and the fab is located on a 759,000 m", " site. SK Hynix itself is operating its own M14 gigantic fab near Icheon. In fact, the addition of the new fab to SK Hynix’s family did not have any effect on its commitment to spend ₩46 trillion (~$41.16 billion) on fabs in the mid and long-term future ", ". At present SK Hynix is upgrading its M14 fab in South Korea, buidling a new DRAM/3D NAND fab near Cheongju (South Korea), and expanding its C2 fab in Wuxi, China."]},
{"title": "Yangtze Memory Unveils Xtacking Architecture for 3D NAND: Up to 3 Gbps I/O", "paragraph": ["Yangtze Memory Technologies Co. (YMTC) on Monday unveiled key details regarding its Xtacking architecture that will be used for its upcoming 3D NAND flash memory chips. The company's technology involves building NAND chips using two wafers: one wafer containing actual flash memory cells, which are based on a charge trap architecture, and another wafer featuring CMOS logic.", "Traditionally, makers of NAND flash memory produce memory array as well as NAND logic (address decoding, page buffers, etc.) on one wafer using a single process technology. By contrast, YMTC intends to make their NAND array and NAND logic on two different wafers using different process technologies, and then bond the two wafers together, connecting the memory arrays to the logic by metal vias using one additional process step.", ": YMTC clarified that its Xtacking architecture is capable of 3 Gbps I/O speed, but does not disclose specs of any actual product.", "The Xtacking architecture is designed to allow YMTC to get ultra-fast I/O while maximizing the density of their memory arrays. The manufacturer says that its Xtacking-based chips can eventually scale I/O speed of 3 Gbps, which is over two times faster when compared to Samsung’s latest V-NAND chips and about three times faster than mainstream 3D NAND. In addition, by locating the controlling logic beneath the NAND memory array, YMTC says that the Xtacking architecture allows them to maximize ttheir 3D NAND capacity and minimize dimensions of its chips.", "On paper, the high I/O performance would allow SSD vendors to make low-capacity SSDs with limited NAND channels without today's performance penalty, offsetting the low parallelism with high transfer rates.", "YMTC says that usage of two 300-mm wafers instead of one does not increase production costs significantly, as maximizing their memory density allows them to offset the cost of an additional logic wafer. Behind the scenes, the company uses XMC's fabs to produce both memory and logic. YMTC says that it uses a 180-nm process technology developed by XMC to produce the periphery logic. Meanwhile, like other makers, YMTC does not disclose lithography node it uses for 3D NAND, but typically these manufacturing technologies are pretty ‘rough’ (~ 50 nm) by today’s standards. Because both wafers are processed using mature fabrication technologies, YMTC does not need a very high mix-and-match overlay precision to bond them together and form interconnect vias.", "Makers of memory in general tend to keep their die sizes low in a bid to be more competitive and profitable. When it comes to the usual Gb-per-mm2 metrics in case of planar NAND, a smaller die wins in terms of costs because the costs of the wafer are spread out over more chips (of course, putting all complexities and yield rates aside). It gets trickier with 3D NAND as wafers spend more time in chemical vapor deposition (CVD) machines, hence the number of wafers processed by a fab as well as the costs of wafers themselves are no longer crucially important metrics. Nonetheless, they are important enough for companies like YMTC to maximize its NAND density by placing the controlling logic under the memory array.", "Related Reading:"]},
{"title": "MRAM Developer Day, Everspin Keynote: The MRAM Revolution (9:15am PT, 4:15pm UTC)", "paragraph": [" - Prior to Flash Memory Summit, the first order of business is the MRAM Developer Day. The key talks today revolve around Everspin, a leader in MRAM Technology, GlobalFoundries, and IBM. First up is Kevin Conley, CTO of Everspin, covering the latest in the 'MRAM Revolution'. The presentation starts at 9:15am PT, and Billy and I are here to cover the event.", " - Prior to the Everspin presentation, the chair of the session is going through 'Why MRAM'", " - Some talk about using MRAM in CPU caches in the future later", " - End of the day is a future outlook panel about MRAM in 2025. Unfortunately we'll miss that for another event", " - Everspin are the only commercial producer of standalone MRAM devices today", " - Kevin Conley to the stage", " - Going to talk about the potential to disrupt the industry through MRAM", " - Driving the future of the industry through innovative products", " - 'potential futures' defined for legal reasons", " - Most discussions on MRAM today is about 'emrging technologies'", " - But today's discussion is about MRAM uses today", " - Starting with MRAM History", " - 1996 MRAM DARPA Program starts", " - 2001 First Toggle MRAM demonstrated", " - 2006 First 4 Mb Toggle MRAM", " - 2008 Everspin spins out of Freescale to become independent ", " - 2010 First SPI Toggle MRAM", " - 2010 First SPI Toggle MRAM", " - 2010 First SPI Toggle MRAM", " - 2014 Spin-Transfer Torque Joint Development Alliance with GloFo", " - 2015 First demo of STT-MRAM 64Mb chip on 90nm using inhouse", " - 2018 Mass production of 256 Mb STT-MRAM chip at GloFo", " - 2018 First 1 Gb chips sampling to customers", " - Driving it into the 'slope of enlightment' with multiple suppliers", " - Showing how flash developed from 1993 to today", " - Flash started as a HDD replacement technology, but went into a variety of markets", " - The size of flash today is pretty phenomenal", " - MRAM in 2018 is moving from niche industrial to mainstream storage", " - All about the early adopters recognizing the usefulness of MRAM", " - MRAM is viewed from a latency and endurance point of view", " - MRAM is unique value prop - low latency and high endurance", " - Separating memories suited for storage (NAND) and those that are carrying memory workloads", " - The gap between the technologies are quite wide", " - Even with they hype, storage technologies aren't suited for memory ", " - This is where MRAM comes in ", " - Pace of memory has slowed significantly", " - DRAM is being challenged by the cost per bit benefits previously experienced, also power and latency", " - latency is becoming less consistent due to the strength of ECC being used", " - Excitement in how the MRAM technology will scale", " - Able to retain data at standard temperatures", " - Able to ensure reflow in industrial processes (260C)", " - It has become practical to implement MRAM in standard CMOS processes", " - Fab containment protocols in place and equipment ecosystem is being developed", " - The MRAM Universe is about the data center - ultra low latency, marhcine learning processor memory, or CPU L2 cache", " - Most accelerators today are in huge SRAM-based - MRAM focus on scaling is to help here", " - Also edge applications", " - MRAM with sensors and compute in infrastructure, security", " - Tamper resistant and incorruptible memory", " - Cars, ADAS, storage for wearables at lower power, instant on memory, etc", " - Case study: data center storage. MRAM is used to replace the write buffer", " - Replacing DRAM with caps due to MRAM", " - Fewer caps = cost savings plus higher density storage module", " - Faster time to market without power fail protection hardening - it's baked in", " - Benefits include QoS due to more data stored in buffers", " - Bandwidth is limited based on buffers - trade offs are made. These are better with MRAM with larger buffers", " - Removing caps also improves reliability", " - Power Fail Protection qualification is usually the last thing on the list - but one of the hardest. By enabling it on the drive automatically speeds up production", " - IBM will have the first STT-MRAM enabled device on the show floor this week", " - Another Case Study: an All MRAM-storage product", " - Capacity up to 1GB", " - Small packets offloaded to lower latency MRAM", " - 1GB is really good for terabyte-class NoSQL Databases", " - AI is mostly focused as MRAM replacement in the data center", " - But also applicable at the edge, eg security cameras", " - Cameras in remote installations that are battery or solar powered", " - Can be very targeted recording to save power", " - AI can identify a human vs a cat, and trigger recording appropriately", " - Traditional AI inference engines should be powered up. NVM allows all the network weights ready to execute", " - Case Study: Health Wearables", " - Extended temp operation, longer term integration of AI engines", " - Next for MRAM - broader adoption in aerospace and industrial", " - Understanding STT where data persistence at speed is required", " - TAM increases as speed, density, increases", " - Call to action: Define needs in terms of data persistence at speed", " - Consider transformational impact of MRAM", " - It's not a problem of cost per bit, it's understanding the product", " - We have a meeting with Everspin later in the week at FMS", " - That's a wrap!"]},
{"title": "MRAM Developer Day, GlobalFoundries Keynote Live Blog", "paragraph": [" - Second Keynote today is from GlobalFoundries, Everspin's MRAM partner. ", " - Michael Mendicinoj, VP on stage", " - 7% memory growth rate ", " - Growth comes from many areas - mobile computing, IoT, AI, AR/MR/VR", " - The key is to know what will drive growth and what will need it", " - GF has a dual lane roadmap to tackle high performance and low power", " - anticipating what the segments need from a total perspective", " - Today is mostly IoT and AI related", " - Potential $63B TAM in 2025", " - Connectivity is a big role in each space", " - IoT is a very broad set of applications", " - End-to-end solutions are important", " - Needing to have the right capability in the technololgy", " - Have a good overall cost of ownership", " - IoT is not a segment - it's a collection of applications spread across segments", " - Mobile Segment, Compute Segment, Automotive Segment, Aerospace segment", " - Low power in 40-130nm, Mid range in 22-28nm, High perf at 12-14nm", " - Speed and memory types vary", " - RF is important across all segments", " - 17 levels of metal at 7nm", " - The SoC Differentiator - to build value", " - Some characteristics matter more depending on the IoT device", " - Perf, Connectivity, Memory, Sensory, Storage, Battery, Security, Packaging, IP, Integration", " - MRAM offers power and area savings", " - Instant On for IoT is important", " - If you put good MRAM on a mediocre platform, that's not going to win", " - Need best in class compute and RF to get max benefit", " - AI is a key part of the semiconductor 7% CAGR", " - Break it up into two main areas : Datacenter (high-end training and inferencing)", " - These use the high end processes, big chips, mostly ASICs", " - The other side is mid-to-low end inferencing: IoT, Smartphones, Drones, ADAS", " - classic foundry and ASIC, smaller die size", " - balanced low power process", " - IN high-end, big metal stacks requiremed, high density memory", " - In edge devices, use FDX SoC platform, SoC design services", " - Datacenter is usually based on thermal limits, low end is usually power limit driven", " - How to win: IoT and ML", " - AI/ML all about the datacenter - high performance, high speed IP etc", " - IoT is all about the small chips and ultra low leakage", " - Only high-density MRAM can really connect the two", " - 22FDX is low power fully depleted SOI process", " - Can run A53 at almost 2 GHz", " - Lower dynamic and leakage", " - 22FDX is king of power", " - Uses back-biasing to help boost perf, or reduce back-bias to lower VTs and still run fast", " - Overall 80% lower power", " - Best in class mmWave perf", " - eMRAM for NVM", " - Increasing value prop by coupling eMRAM", " - Ecosystem is already quite large, and growing", " - Two versions of MRAM: -F for flash replacement, -S for SRAM replacement", " - Differences in speed, endurance, data retention, operating temperature", " - eMRAM-F is a cold storage technology, hence 15 year data retention", " - eMRAM on 22FDX beats eFlash on 40nm", " - Production of 22FDX eMRAM set for 1H 2019", " - Status of 22FDX eMRAM", " - Quarterly MPWs starting in Q1 2018", " - Risk production by end of 2018", " - JDV with Everspin in 2014", " - Succeeded in each area", " - 300 companies using production PDK", " - 32Mb eFlash and 2Mb SRAM interfaces available for use", " - Already announced $2b of design wins on 22FDX, most of which with eMRAM involved", " - Next gen is 12FDX", " - 7nm FinFET power efficiency with body bias, but still FDSOI planar process", " - 40% fewer masks than 7nm DUV", " - Four arms of technical challenges", " - Never underestimate incumbents: eFlash scaling for example", " - DRAM below 22nm is still in development - data integrity and corruption is a concern", " - eDRAM has run out of steam", " - SRAM Memory bandwidth is lagging behind CPU perf", " - MRAM could help catch up", " - IoT demand for lowest possible power memory solutions", " - Non-technical challenges - cost of manufacturing ecoysystem, market acceptance", " - making all the TAM accessible", " - A lot of people want to go with the proven solution - hard to drive adoption without a compelling product", " - MRAM is ready for GF customers"]},
{"title": "MRAM Developer Day, IBM Keynote Live Blog", "paragraph": [" - Third Keynote in this session is from IBM Research: STT-MRAM is Ready for Applications Today. ", " - In a bit, Discussing the MRAM in IBM FlashCore, a currently available product", " - Starting with data about STT-MRAM with Samsung", " - Slonczewski invented STT in 1996. He developed the magnetic tunnel junction in 1974", " - 2004 developed the MgO tunnel barrier for reading", " - 2010 Developed perpendicular CoFeB tunnel junctions to make the technology scale", " - Perpendicular is how all devices are used today", " - MRAM Applications - Standalone, Embedded, Cache", " - MRAM is unlikely to replace DRAM any time soon - DRAM is still scaling", " - Perfect applications are battery backed SRAM, or buffers for storage", " - Using MRAM to replace embedded flash in MCUs", " - eFlash doesn't scale below 20nm", " - Need a 400C process required to enable it", " - A couple of years ago, new materials were discovered to make this less of an issue", " - Using MRAM to replace L3 cache - replacement to eDRAM", " - 400C process, 4-256 megabit, 1-2ns read/write, unlimited endurance", " - Also mobile and embedded. The 'Killer' app for MRAM. Replacing low speed SRAM", " - Use co-processor when in sleep using MRAM for low power", " - Normal MRAM device today is a 2-terminal device. MRAM cell has one transistors.", " - Looking at 3-terminal devices. New physics ideas can be explored with this type of devices. Spin-Hall effects etc", " - Other ideas such as voltage control, such as anisotrophy", " - Downside is losing density, and with memory density is king", " - Curves are called write-error curves. Error probability vs voltage vias", " - bias", " - STT has inherently error rate for bit writing", " - Has to increase voltage in order to ensure that bit is written - because bias is applied in equilibrium and waiting for thermal effects to knock it out of equilibrium", " - That data was 120nm with 100ns pulse", " - Can now show 39nm with 10ns pulses", " - For MRAM, 10ns is now possible", " - Compared to 2010: 10x faster, 4x lower power, 4x denser", " - Below 5ns is tough with 2-terminal", " - On scaling, can junctions as small as 11nm", " - Current in MRAM scales with area", " - Ideas for future development include two reference layers", " - reduce current by half", " - MTJ = magnetic tunnel junction", " - A more complicated structure, but not ready for products today. Perhaps in 5 years", " - Over next 2-5 years, main gain is going to be density", " - Smaller devices, lower write current, more efficient materials", " - Faster writing as well. Current products are 30-50ns pulses, expect 10ns soon (1-2 years), maybe 5ns in 5 years", " - Can write faster than reading with 3 tunnel devices", " - Current spec for 125C operation, 150C will be coming soon. No fundamental reason why MRAM can't operate at 250C. ", " - The tradeoff is that the device has to be hardened at a level of drive currents to enable writes", " - Now talking about IBM devices using MRAM", " - FlashCore", " - Design custom size solutions with FlashSystem", " - 70mm height, 250-260mm depth", " - Recent designs (Nov 2017) shows an 18TB module in that size", " - Next question is how to embed this in other applications. The problem is the custom design though", " - E.g. the custom form factor left the power control on the system. To scale out to other use cases, need to manage it locally", " - Enabling this for a common form factor", " - Moving the long card into a 2.5-inch 15mm form factor", " - 19.2 TB in a 2.5-inch", " - Taking a 3 FPGA design from the card into one FPGA", " - Two years ago we started speaking to Everspin about MRAM", " - MRAM is a cornerstone to this new drive", " - Not having to do DRAM to NAND", " - Started with compnoent level qualification", " - It all worked - shipping drives to customers in October", " - Didn't have enough space for supercaps for the high-power FPGA to commit data", " - New design has no supercaps by using MRAM", " - Using a Xilinx FPGA", " - Design allows the write stream to be compressed into MRAM", " - Power failure allows the system to harden the MRAM to enable commit at next power on", " - FPGA has 4GiB of DDR4, 128 MiB of Persistent DDR3, and 8GiB of Flash DDR4 for the FPGA", " - 2x2 Gen 3.0 NVMe interface. Gen 4.0 capable", " - No details on IOPS or R/W data", " - Moving to the MRAM wasn't as big as a change to the architecture as expected", " - Hyper scaled - lots of low speed lanes", " - 20-lane Flash interface", " - Going forward, density of the MRAM is going to be key. 1Gb will allow some optimizations", " - On the roadmap is to create a persistent memory region for NVMe", " - Typically use DRAM today, would like to use the storage memory interface instead", " - FPGA allows us to implement this if we can sort it, lots of potential in future technology", " - FPGA is not on-the-fly reconfigurable, but firmware updates include updated RTL", " - No significant impact into BOM cost for MRAM vs DRAM", " - On the wishlist for MRAM is endurance, better error rate (the device has ECC engines to help), then capacity", " - That's a wrap!"]},
{"title": "Flash Memory Summit, Western Digital Keynote Live Blog", "paragraph": [" - Second Keynote for us: Western Digital", " - These keynotes are thick and fast", " - Unfortunately they turned the lights on which makes photos of the screens pretty bad", " - I think someone leaned on the switch and no-one is senior enough to tell someone to turn them off", " - Talk is called 'The Future of Data Infrastructure'", " - Phil Bullinger", " - SVP and GM of Datacenter Systems", " - Economy is becoming data driven", " - Moving from records, to communications, to efficiency, to currency", " - Developed in richness and value", " - Data is two main things: Big Data and Fast Data", " - Not just buzzwords, but actual workloads", " - This is driving a lot of the data processing and infrastructure", " - The final word is precision", " - Data Interaction has changed, to create, deliver, transform, and access", " - Data is pooled and shared by multiple applications", " - Dynamic workloads are increasing", " - 45% of compute resources are unused, but 70% report inefficiencies in their storage resources", " - Demands are around data infrastructure: Scalability, Efficiency, Agility, Performance", " - Critical to raise efficiency in the datacenter", " - The future is the Data Infrastructre Revolution", " - Moving from Converged infrastructure to Composable Infrastructure", " - Disaggregated compute and storage resources to scale with requirements", " - Taking the next tep is key", " - Software infrastructures allows for indepdent resources tiers", " - Erases the physicality of the barriers between resources", " - By relying on a fabric environment", " - 'A very robust solution'", " - The net takeaway, WD believes that economic advantages are very real", " - ~50% savings in CapEX, 40% lower TCO verse hyperconverged", " - WD's vision is built on four pillars: Open Standards, Scalable, Disaggregated, Extensible", " - Define and refine both software APIs and hardware", " - Opening up the hardware form factor", " - Get to a model where resources are physically separate for scalability", " - systems are composed between a data fabric and a memory fabric", " - peers come together, no discrete systems", " - The new 'fabric' device", " - Controllers speak to a network, not to a host", " - Fabric-focused systems", " - Fabric endpoints should be simple devices, and peers of each other", " - Mix and match", " - Today introducing OpenFLEX", " - ", " - A new range of fabric devices ", " - F3000 device and E3000 enclosure - high perf, low latency for fast data: AI, real time analytics, IoT", " - D3000 Fabric Device: High capacity for big data, batch analytics, machine learning, predictive modeling", " - Demonstrated on the show floor at the show", " - 'Don't think about these as a JBOD'", " - Openflex management API", " - New API called Kingfish", " - orchestrating fabric devices as fabric devices", " - Working with industry to make this an open API to create simplicity at scale", " - A critical part of the strategy", " - WD creating their own orchestration layer software", " - Creating new instances in seconds, optimizing to the unique needs of an application or workload. Built on kingfish", " - WD OpenFlex: 'committed to an open approach, positioned to accelerate market adoption'", " - Demos at booth 207", " - That's a wrap!"]},
{"title": "Toshiba Memory to Build New Fab to Produce BiCS 3D NAND", "paragraph": ["Toshiba Memory Corp., which is set to become independent from Toshiba in a few days, has announced their intention to start construction of a new BiCS 3D NAND fab in July. TMC expects Western Digital to participate in the new project. Overall, this is the latest in a number of NAND fab announcements across the industry in the last year that, at long last, signals surging interest in building additional capacity.", "The new fab will be located near Kitakami City, Iwate prefecture. By contrast, the existing NAND flash production facilities operated by TMC and Western Digital are located near Yokkaichi, Mie prefecture. Traditionally for Japan, the new fab will feature a quake absorbing structure and an environmentally friendly design, which includes materials used and energy efficient production equipment. Just like the ", ", the new production facility will use an AI-powered production system to boost productivity.", "Toshiba expects to complete the building sometimes in 2019 (most probably in summer 2019 as it takes around a year to construct a fab building) and then start with equipment move-in. This process usually takes two to three quarters, so expect the new fab to come online in 2020, if everything goes as planned.", "Until the company makes its final decision regarding the manufacturing tools to be used, the actual production capacity of the new fab is unknown. Meanwhile, decisions regarding equipment will be made based on multiple factors, including predicted demand for NAND and Western Digital’s participation in the project. Speaking of Western Digital. Late last year Western Digital announced that it would participate in building the fab in Iwate, but so far, the company has not made any announcements regarding its exact plans on the matter.", "Toshiba last week announced that it had received all the required anti-trust regulatory approvals regarding its sale of Toshiba Memory Corp. (TMC) to Pangea consortium of investors. The last regulator to approve the $18-billion transaction was China. The deal is now expected to close on June 1, as planned by the Japanese company.", "Related Reading:"]},
{"title": "Samsung Unveils 32 GB DDR4-2666 SO-DIMMs", "paragraph": ["Samsung on Wednesday introduced its first consumer products based on its 16 Gb DDR4 memory chips demonstrated earlier this year. The new SO-DIMMs are aimed at high-performance notebooks that benefit from both speed and capacity of memory modules.", "Samsung’s new 32 GB DDR4 SO-DIMMs based on 16 Gb DDR4 memory ICs (integrated circuits) are rated for a 2666 MT/s data transfer rate at 1.2 V. Because the 16 Gb memory chips are made using Samsung’s 10 nm-class process technology, the new module is claimed to be 39% more energy efficient than the company’s previous-gen 16 GB SO-DIMM based on 20 nm-class ICs. According to Samsung, a laptop equipped with 64 GB of new memory consumes 4.578 W in active mode, whereas a notebook outfitted with 64 GB of previous-gen DDR4 consumes 7.456 W in active mode.", "Samsung did not say when exactly it plans to start shipments of the 32 GB DDR4 SO-DIMMs. Meanwhile, DRAM producers usually make announcements after they ship the first batch of new products. Therefore, it is highly likely that Samsung’s customers among makers of high-end notebooks have already received the new 32 GB modules.", "Samsung is gradually expanding its portfolio of 16 Gb (2 GB) memory chips for PC applications. Earlier this year the company introduced 16 Gb GDDR6 for graphics adapters and then demonstrated its ", ". This week Samsung also mentioned 16 Gb GDDR5 chips for video cards."]},
{"title": "Intel Persistent Memory Event: Live Blog", "paragraph": ["Want to read our news about this event? Go here!", " ", " ", " - It's a Live Blog! More Optane in bound, looks like Apache Pass.", " - Time for an unexpected Live Blog. I'm in San Francisco at Intel's building discussing Persisteant Memory", " - Almost three hours of talks this morning, first up Lisa Spelman covering the Data Center market", " - Drivers revolve around latency - the ability to compute and respond as quickly as possible", " - Intel is more than a CPU company", " - A more holistic value of performance across compute, storage, acceleration and connectivity", " - Acceleration includes new instructions for DL training and FPGAs", " - Connectivity about removing bottlenecks around networking: Omni-Path, Silicon Photonics", " - $54B TAM in 2017, $73B TAM in 2022, MSS estimate at 35%", " - >Sorry, Camera trouble. No network!", " - Map services have evolved as the hardware has evolved", " - Bandwidth and latency and detail has grown", " - Also user generated data", " - Use cases will be unlocked as people start to look at data as an asset, rather than a burden", " - Data generates data, compounding the benefit", " - Intel has made progress in the industry, but huge amount of potential still there", " - As data exists today, three tiers: Cold Tier (HDD/Tape), Warm (SSD), Hot (DRAM)", " - To fundamentally think how applications are architected is difficult", " - Announcements today: Optane DC Persistent Memory", " - Sampling today, Revenue in 2018", " - 'Crystal Ridge' ?", " - Larger capacity of memory at lower cost", " - Applications developed with persistent memory in mind", " - Capability for lots of applications", " - Working with a bunch of companies for a long time", " - Microsoft, Oracle, redhat, ubuntu, SuSe, VMware", " - Announcing for developers, remote access to systems with Optane DC Persistent Memory through Intle Builders Consutrcution Zone", " - Available shortly", " - Weeks rather than months, but no exact date", " - Complimentary, but invite only. Have to submit proposal", " - Capacity sizes for developers to be covered later", " - Currently today, Intel offers Caching and Fast Storage tier, and Mainstream tier", " - Larger capacities at more affordable price points", " - Bridging the gap between the three tiers", " - Optane DC Persistent Memory below DRAM, Optane SSD above SSD", " - Intel QLC incoming", " - Alper Ilkbahar, CP/GM of DC Memory and Storage on the stage now", " - Discussing more technical details", " - 'We want you to leave today with the same level of excitement as us'", " - >As long as we leave with a sample... :)", " - Reiterating the Mind The Gaps heirarchy", " - Cold/Warm/Hot tiers are not continuous, they have their own specific reasons for being the way they are", " - DRAM is a good fit for fast latency and small granularity", " - Speed comes at the cost of implementation, and limitations on capacity", " - Storage tier is accessed through different mechanisms to memory", " - 10000 cycles, loses cache due to context switch", " - Data returns in blocks, not bytes", " - 3 orders of magnitude", " - Persistent memory bridges the gap", " - Offer a path through existing storage drivers, or allowing applications access into the hardware and bypass", " - Intel is working on the latter", " - 'It acts like a true memory'", " - Signifies compute significantly", " - DRAM-like speeds on DDR bus. Hardware accessible, byte accessible, large capacity, lower cost", " - >(sorry, pictures are SUPER slow to upload)", " - 3 SKUs product at launch - 128 GB, 256 GB, 512 GB", " - Essentially a hardware memory accessed with load/store instructions", " - DDR4 pin compatible", " - Compatible with next generation Xeon platforms", " - Does not rely on external power or capacitors", " - Uses NVM technology for persistence", " - Hardware encryption on chip and advanced ECC", " - Boot time encryption key", " - Demo time. Database restart when database is in NVM memory.", " - Scales beyond with big and affordable memory. More capacity = more containers", " - Meeting the same availability uptime", " - Helps systems where memory is a bottleneck", " - Cassandra database example", " - Optane DC Persistent Memory gives 9x more read transactions (OP/Sec), 11x more users per system", " - >The image looks like it's using less DRAM but a big Optane drive", " - > e.g. instead of 1 TB DRAM, use 256 GB DRAM + 1 TB Optane DC PM", " - Optane DC PM allows for immediate consistency compared to traditional DRAM+NVMe", " - Now a key-value test comparison", " - Every now and then, DRAM has to push data out to storage, which limits the perf", " - 99% perf loss on DRAM+Storage when relying on storage write-backs", " - 287k ops/sec on Optane PC PM, vs 3k-279k on DRAM+Storage model", " - Now Persistent Memory over Fabric (PMoF) for data replication with direct load/store access", " - Pulling data from PM on another system over the fabric", " - Current Replication from NAND to NAND across systems has high latency. Over PMoF using Optane DC PM, latency is much lower", " - On the Database Restart test, Optane DC PM took 16.9s. DRAM+Storage system took 2100 seconds", " - Moving reliability from three 9s to five 9s", " - start time goes from minutes to seconds", " - >Servers can take 10 minutes to start up", " - Andy Rudoff to the stage. Head PM software architect", " - 'Joined the project many years ago'", " - Making sure ISVs can use the technology", " - How far up the stack should the PM be visible", " - Like a fast disk, or a fast cache, or a programmable file system", " - Higher you go up the stack, the more software is needed, but the more value can be drawn from it", " - Balancing act between the barrier to adoption and increasing application value", " - SNIA NVM Programming Model. 30 members, co-chair by Intel and HPE", " - Making sure ISVs do not get locked into a proprietary API", " - Three paths - management, storage, and application", " - Use cases from generic NVDIMM driver (looks like a fast drive) up to a fully configured system", " - Memory mapping a file typically has context switching. PM allows for direct access", " - Persistent Memory Aware File System required for direct load/store", " - Intel calls this 'DAX' - Direct Access", " - Data structures are still persistent in memory, saving time", " - Most developers want to use DC PM with little hardware knowledge", " - Persistent Memory Development Kit - PMDK", " - Collection of Libraries", " - Low level programming support, transaction APIs, performance tuned, open source and product neutral", " - Not trying to make money on PMDK, trying to enable the ecosystem", " - PMoF is covered in PMDK", " - Sync replication available now, Async is a work in progress", " - Windows and Linux", " - VTune has been updated to understand Persistent Memory", " - Free downloads of PMDK available", " - Cassandra full stack example", " - Changed Cassandra to use persistent Java containers", " - The things that Cassandra provides doesn't change - the app on top using Cassandra doesn't need to know about the PM model", " - SAP Hana has already done an Optane DC PM demo", " - VMWare has done changes to Hyper-V", " - Intel has done changes for Xen and posted them for upstream review", " - Remote Developer Access is now in the early look stage", " - Submit proposals to Intel. Ready for functional testing and use case exploration", " - OK small 10-min break", " - We got some photos of the modules", " - 256 GB and 512 GB modules", " - OK here we go again", " - Bill Lizinske to the stage. Head of the NVMe group", " - Two directions = Hyperconverged and Hyperscale / Disaggregated", " - Discussing 3D NAND vs 3D XPoint", " - Optane is great for storage, and caching in particular", " - 'Optane has impressive endurance'", " - Drives moving up to 60 drive writes per day", " - Swapping NAND for Optane, might lower the cache size, but gives more perf", " - Intel will introduce new drives at 60 DWPD, rather than what the slide says about the P4800X. That stays at 30 DWPD", " - Still using first gen 3DXP", " - Intel team worked for a year with VMWare to get a significant perf increase using Optane", " - Wanting to work with all the hyper converged players", " - Lower read latencies when taking out software-based latency", " - Taking away noisy neighbor problems", " - Intel Optane SSD deployments still increasing, increase in OEMs offering VSAN Ready Nodes", " - Optane storage in MySQL mission critical cloud server database", " - tiering the data between Optane and 3D NAND", " - Always important to balance Optane/NAND ratio", " - Disaggregating storage from compute allows them to scale independently as required", " - Use Optane for random access, NAND for sequential access", " - Making sure the local data set is in the right location for the type of access", " - 'If you design the system properly'", " - Disaggregation allows for tune performance and resilience", " - Announcements about new Optane storage software stacks in the near future", " - Now for more on 3D NAND", " - NAND is all about cost", " - Replace more HDDs with SSDs", " - Moving to QLC", " - Have been using floating gate technology throughout", " - Currently shipping 64L TLC. Just gone to production of 64L QLC", " - A bit of Optane and a whole lot of 3D NAND", " - Now sampling QLC, production availability in H2 2018", " - Moving QLC NAND into the Warm storage tier", " - pushing HDDs further into the cold storage", " - Using the Ruler form factor to reinvent the data center", " - $10B+ TAM in 2021", " - 16 TB Ruler", " - Replace 256 x 4 TB HDDs with 32 ruler drives for a single 1U", " - (Also, less likely to break)", " - Ruler = EDSFF", " - Investment in Fab 2 and Fab 68", " - Fab 2 in Utah, dedicated for 3D XP. 100% converted", " - Fab 68 is doing all of Intel's 3D NAND", " - No public numbers on wafers per month from Fab 68, but much bigger than Fab 2", " - New fab space at Fab 68 coming online, which is 1.75x bigger than previous", " - QLC will be in client drives in second half of this year", " - Q&A time for a bit", " - OK Q&A over, here are the questions and results", " - Q) Do the DIMMs require next gen CPUs? A) Yes", " - Q) You mentioned Intel will be revenue shipping for 2018. Will ecosystem partners be shipping systems in 2018? A) We expect systems to be shipping in 2018, but the details of specific customers will be up to them", " - Q) What is Crystal Ridge? A) Crystal Ridge is the top level family of persistent memory parts, of which Apache Pass is a member", " - Q) It was mentioned about DDR4 pin compatibility with the DIMMs. Can users mix and match the DIMMs on individual channels, or will there be dedicated channels? A) Not disclosed at this time.", " - Q) One of the slides had a Xeon Platinum logo. Will the DIMMs only work on Xeon Platinum? A) Not disclosed at this time. We just showed pairing the best with the best", " - Q) Will there be a DIMM writes per day? A) Not disclosed at this time. But DIMMs will be operational for the lifetime of the DIMM", " - Q) What is the power draw of the Optane DIMM compared to regular DIMMs? A) Not disclosed at this time.", " - Q) Does this mean the memory limits of future Xeons are being increased? A) Not disclosed at this time.", " - Q) Will all future Xeons support the Optane DIMMs? A) Not disclosed at this time.", " - Q) Clock speeds of the DIMMs? A) Standard DDR4 speeds. Other details not disclosed.", " - Q) Will the QLC NAND adhere to JEDEC data retention. A) Not disclosed at this time.", " - That's a wrap. Some discussions and customer presentations for the rest of the day."]},
{"title": "Team Group Joins ‘Extreme SO-DIMM Club’ with T-Force Vulcan", "paragraph": ["High-performance SFF and UCFF desktops as well as gaming notebooks are getting more popular among gamers these days, so it is inevitable that makers of PC components are starting to offer high-end parts designed for such systems. One of these companies is Team Group, which will be rolling out its T-Force Vulcan SO-DIMMs at Computex next week.", "The T-Force Vulcan lineup of DDR4 SO-DIMMs will be aimed primarily at gaming laptops, as well as various Intel NUC and similar systems. The family will include dual-channel memory kits with up to 32 GB capacity (2 × 16 GB) rated for up to DDR4-3600 speeds, so while Team Group is aiming at high-performance machines, they're notable not aiming at niche high-end desktops based on ASRock’s X299E-ITX-ac, which requires quad-channel memory kits. Meanwhile, keeping in mind that we are talking about Intel NUC-compatible products, expect the new modules to support XMP 2.0 SPD profiles for easier setup of memory sub-timings", "The manufacturer also notes that it will equip its T-Force Vulcan memory modules with a graphene copper foil heat spreader that is thin and light. This is a notable inclusion, as the SO-DIMMs need to remain thin enough to fit into laptops with space constraints.", "Team Group will showcase the new T-Force Vulcan memory modules at Computex next week, so stay tuned for precise specs and more details regarding the upcoming SO-DIMMs. The biggest intrigue here is of course which memory chips are used for the Vulcan and how overclockable are they beyond DDR4-3600.", "So far, only Corsair and G.Skill have offered DDR4 SO-DIMMs rated to run at data transfer rates significantly higher than 3000 MT/s, so the addition of Team Group to the ‘extreme SO-DIMM club’ will play a positive role as it will add competition, which is always good for the consumer.", "Related Reading:"]},
{"title": "The AnandTech Podcast, Episode 47: Intel Goes Super Premium Optane", "paragraph": ["Today at Intel’s Data Center Memory Summit, the new ‘Apache Pass’ Optane memory DIMMs were announced, with capacities from 128 GB to 512 GB. This new 3D XPoint type of memory is focused on allowing persistent memory support on servers and will be available with the next generation of Xeon Scalable processors (which Intel has not announced yet). Also on the docket from Intel was some information on their high-density QLC 3D NAND solid state drives, and we have details on when they should be coming to market. Samsung also announced 32 GB SO-DIMM modules for high-end gaming laptops.", "RSS - ", ", ", "Direct Links - ", ", ", "00:00 Introduction", "00:46 Intel Announce Optane DIMMs", "24:00 Next Generation of QLC SSDs", "32:57 Samsung 32 GB SO-DIMMs Announced", "38:34 FIN"]},
{"title": "Corsair Announces Vengeance RGB Pro Memory: Up to DDR-4000, 10 RGB LEDs", "paragraph": ["Corsair on Monday introduced its latest family of memory modules designed for enthusiasts and modders. The Vengeance RGB Pro DDR4 DIMMs bring together rather high performance and style: they are rated for up to DDR4-4000 and they use brand-new heat spreader with a lightbar that features 10 RGB LEDs, the highest number of diodes that we have seen in a memory module so far.", "Corsair’s Vengeance RGB Pro family of products initially includes about a dozen of 16 GB and 32 GB kits for dual-channel and quad-channel memory sub-systems speced for operation at 2666 MT/s – 4000 MTs data transfer rates at 1.35 V (see detailed information in a table below). The modules are based on various cherry-picked DRAM chips and use Corsair’s PCB for RGB LED-equipped memory modules (featuring traces for LED controls). As with all enthusiast-class modules, the new DIMMs come with XMP 2.0 SPD profiles for easier setting up on contemporary Intel platforms. As for compatibility with AMD Ryzen platforms, the modules that run at up to DDR4-3200 will work in such systems without problems, whereas for higher speeds additional tweaking and cooling may be required.", "The Vengeance RGB Pro modules are equipped with all-new black or white aluminum heat spreaders as well as custom light bars with 10 RGB LEDs controllable using Corsair’s iCUE software. Meanwhile, the heat spreaders and lightbars are rather tall, so compatibility of the Vengeance RGB Pro with SFF systems or with PCs that use large air coolers is something that remains to be seen.", "Corsair plans to make the new modules available in the U.S. in the coming weeks or months. Exact pricing will be announced separately, but considering the fact that the Vengeance RGB Pro kits are positioned above the original Vengeance RGB, it is clear that the new memory kits will be sold at a premium.", "** Officially mentioned in the table from Corsair's pre-release", "*Disclosed during a conversation afterwards", "See more coverage of Computex below."]},
{"title": "Gigabyte Enters Memory Market with AORUS RGB LED RAM", "paragraph": ["GIGABYTE is entering the desktop memory market with a new kit of AORUS-branded RGB LED RAM. The AORUS RGB LED memory is a dual-channel 16GB (2 x 8GB) kit of DDR4-3200 with a CAS latency of 16-18-18-38 running at 1.35V. Memory compatibility is listed as cross-platform with Intel X299, Z200/Z300 as well as AMD X399 and all AM4. ", "GIGABYTE said it plans to ship the kit with two “dummy” sticks that don’t contain any memory chips, which are meant to fill your unoccupied DIMM slots for a uniformed RGB LED look without having to purchase a 4-DIMM kit. GIGABYTE also said the dummy modules are compatible with its RGB Fusion software (the same as the real memory modules), but it didn’t state whether or not the dummies will work with other motherboard RGB software. Additionally, the Fusion software features five new lighting modes that can be applied to compatible products, including the new RAM.", "GIGABYTE’s entry into the memory marketplace is a bold move for the company at a time when supply chains seem to be waning. DRAM shortages have been affecting pricing for memory and graphics cards for months, and it’s surprising (if not somewhat suspicious) that GIGABYTE was able to tap a manufacturer for Samsung b-die ICs.", "The new Aorus RGB LED DDR4-3200 memory kit is set to arrive at the end of June with an MSRP of $229."]},
{"title": "Geil Announces Super Luce RGB SYNC Series TUF Gaming Alliance Memory", "paragraph": ["Geil has announced the Super Luce RGB SYNC Series TUF Gaming Alliance memory adding to the existing RGB SYNC series SKUs. Geil’s RGB SYNC series has been around for a short while and this new partnership with ASUS and the TUF Gaming Alliance rebrands a portion of the lineup to fit into their controlled ecosystem. The TUF branded Super Luce RGB memory modules include an aesthetic RGB and heat spreader design with Geil saying there is a wide compatibility with the largest compatibility across 13 upcoming ASUS motherboards including the latest Intel platforms.", "The memory comes with a black heat spreader and as part of the TUF Gaming Alliance, uses the ASUS designed military camouflage pattern matching their TUF motherboards. Additionally, the RGB LED memory can be synchronized with ASUS AURA Sync along with 12 lighting effects and is fully customizable. The white version of these sticks did not make it over to the TUF Gaming Alliance version. ", "The Super Luce RGB SYNC TUF Gaming Alliance Gaming Memory starts at a clock speed of 2400 MHz up to 3200 MHz with operating voltage from 1.2V to 1.35V and supports Intel XMP 2.0. CAS latency will vary from CL16-CL17 depending on the frequency chosen. Modules come in 4GB/8GB/16GB sizes in single and dual-channel with capacities up to 32GB per kit according to the press release (but not the specifications from their website below). The TUF Gaming Alliance memory includes Geil's lifetime warranty which fits in with the TUF calling card of reliability. ", "Geil says the DRAM will be on display at their booth and ASUS’ during Computex. Pricing nor availability was mentioned but it is expected to be close to the not TUF Gaming Alliance branded Super Luce RGB SYNC Series DRAM and available soon.", "We will update the article as we receive more information. "]},
{"title": "HyperX at CES 2018: Predator DDR4 with IR Sensors for Better RGB Sync", "paragraph": ["HyperX announced it has designed IR communication channels into each of their new HyperX Predator DDR4 RGB modules which will allow multiple modules to sync in LED lighting. In other words, each DRAM module has an IR sensor on it in order to detect the stick next to it (during startup, the module furthest away from the CPU is determined to be the ‘master’). If the sensor is blocked, the RGB will be static.", "The reason for this method of sync, HyperX says, is because different motherboard vendors have different ways of implementing memory traces, which can affect RGB LED timing. Motherboard vendors typically use either a daisy chain or a T-Topology design rule, which both have pros and cons when it comes to timing - with this IR method, HyperX says they can ensure that no matter what layout, the modules will stay in perfect sync. ", "The sticks are powered by the DRAM slots itself so there isn’t a need for extra cables to light them up. The implementation of the IR sensor on each module syncs the LEDs with each stick negating the need for a separate controller. The HyperX Predator DDR4 RGB modules are designed to work with MSI’s Mystic Light, ASUS’ Aura Sync, and Gigabyte’s RGB Fusion for system RGB integration and support multiple lighting profiles. ", " ", "Pricing was not released yet, but HyperX did say it will add a small amount to the cost per module, but they feel it is worth it to ensure a perfect sync 'every time'. The HyperX Predator DDR4 RGB RAM is expected to be released in Q2 of this year. ", " "]},
{"title": "Micron, Rambus, & Others Team Up To Spur GDDR6 Adoption in Non-GPU Products", "paragraph": ["For regular AnandTech readers, the drums of ", " have been beating loudly for most of the last year now. The new memory standard replaces the venerable GDDR5 memory, which, to make long-time readers feel old, ", ". While GDDR5 has evolved well beyond its initially planned lifecycle to meet the needs of the industry, it’s finally begun to reach its apex, and a new memory standard has been needed to take its place. GDDR6 then promises to be a big deal, offering a significant jump in memory bandwidth over GDDR5 – and even GDDR5X – giving processors of all sorts a much-needed boost.", "And while the focus on any GDDR technology is understandably first and foremost on the ", " aspect of GDDR, the technology itself is not inherently limited to just video cards. Rather GDDR is fundamentally just a product built to the other end of the capacity/bandwidth continuum, focusing on high memory bandwidth and smaller capacities as opposed to traditional, high-density DRAM. Video cards in turn are the most obvious use case given their bandwidth requirements, but they’re not the only high-bandwidth devices out there.", "A long-term goal of the DRAM industry has been to spur the adoption of GDDR memory in non-graphics products in order to grow the overall market for the memory and provide higher bandwidth options for certain customers. GDDR IP vendors have long seen product categories such as networking gear as being the perfect ancillary market for this type of memory, given the bandwidth needs. However while this has been an ongoing effort since the GDDR5 days (if not before), any actual market penetration for non-graphics use of GDDR5 has been extremely limited, essentially setting up status quo as we know it.", "As a result, for the launch of GDDR6, Micron is taking a different, more organized path to spurring GDDR6 adoption. Being announced today, Micron, Rambus, Northwest Logic, and Avery Design are banding together to develop a complete toolkit solution for chip designers to implement GDDR6 support on their products. The development of this common ecosystem is intended to allow designers to more easily adopt GDDR6 by offering a full suite of compatible GDDR6 IP, and the means to validate all of it.", "By bringing together a group that supplies everything from the memory to the memory controller to validation tools, the group is looking to solve what Micron saw as the biggest roadblock to GDDR5 adoption: the lack of easily licensed IP. In practice if a vendor wanted to implement GDDR5, there was little in the way of prefabricated designs to work with; vendors would need to implement their own GDDR5 memory controller and all the tough work that comes with a high speed memory interface. Large players like NVIDIA and AMD could of course pull this off, but it made GDDR5 inaccessible to mid-size players. These are the kind of firms who may specialize in designing a specific aspect of a chip, and then license and integrate any remaining technology they may need.", "The group isn’t giving this collaboration a specific name, but each member supplies a difference piece of the puzzle. Micron of course supplies the GDDR6 itself, while the memory controller IP is from Northwest Logic. Meanwhile the PHY for the memory controller – an especially nasty bit since it’s a mixed analog/digital circuit – comes from Rambus. Finally, Avery Design is supplying validation tools for the effort, giving chip designers the means to validate their designs after integrating the various bits of IP. While the complete toolkit isn’t being offered in a one-stop-shopping fashion – interested firms will need to reach out to each member to license the relevant IP bits rather than licensing all of it at once – when assembled the toolkit should greatly streamline the implementation of GDDR6 in new chips.", "As for what markets the group will be targeting, this GDDR6 IP effort is at least initially focused on supporting both ASICs and FPGAs for the networking and automotive markets. The networking market is somewhat self-explanatory here – high-end switches and routers process vast amounts of data and need the memory bandwidth to keep up – and GDDR memory has always been a good potential fit here. This is where speed/capacity tradeoffs become a factor, as even a 512-bit GDDR6 implementation only offers as much memory capacity as one good RDIMM, but for products that can work in those constraints, GDDR6 would offer better bandwidth at lower energy consumption – and with fewer total components – than DDR4.", "The other big aim for the group is the rapidly expanding autonomous car market. This market has a lot in common with the graphics market in as much as it involves a lot of visual processing, though reversing the situation by making it incoming data instead of outgoing data. More advanced cars, particularly level 5 fully autonomous designs, require a massive amount of sensor data and accordingly a great deal of memory bandwidth to carry that data. In this respect the group is looking to grab a foothold in a new market, as this market is expected to boom over the coming years, and there’s ample opportunity to sell memory here.", "Ultimately driving GDDR6 adoption outside of the graphics market still remains an uphill battle, both for inertia reasons and because it’s not the only high-bandwidth memory technology vying for a piece of the market. However compared to the fledging efforts to get GDDR5 adopted in this fashion, Micron’s efforts to bring together IP providers is a lot more organized than before, thanks in large part to the fact that it significantly reduces the barrier towards adding GDDR support on the logic side of matters. Micron for their part is already sampling their GDDR6, with mass production set to begin this quarter, so if Micron’s efforts make headway, then potential customers should be able to get started very soon on integrating GDDR6 IP into their designs."]},
{"title": "Samsung Updates on GDDR6 Portfolio: 8 Gb and 16 Gb at Multiple Speeds", "paragraph": ["Samsung has issued an update to the GDDR6 announcement earlier this month. The company’s GDDR6 lineup will include chips featuring 8 Gb and 16 Gb capacities as well as speed bins not mentioned in the ", ".", "In addition to 16 Gb GDDR6 chips with 18 Gbps I/O speed, Samsung will offer GDDR6 with 12, 14 and 16 Gbps data transfer rates, thus targeting applications with different performance requirements. Also, two chip capacities (8 Gb and 16 Gb) will enable Samsung to target applications with various requirements for the amount of memory onboard.", "Assuming both capacities will be made in all the speed bins, this gives the following:", "Samsung’s 16 Gb GDDR6 chips could be used for various high-end products that benefit from large amounts of memory, including graphics cards and compute accelerators. By contrast, the company’s 8 Gb GDDR6 ICs will be handy for mainstream graphics cards that do not carry large amounts of memory.", "Samsung did not announce pricing of its GDDR6 products, but it is logical to expect 16 Gb chips with an 18 Gbps data transfer rate to cost considerably more than 8 Gb ICs with lower speed bins. Therefore, the large portfolio will enable Samsung to capitalize on the new type of memory."]},
{"title": "SK Hynix’s Product Catalog Lists 16 Gb DDR4 Chips, Opens Doors to 256 GB DIMMs", "paragraph": ["SK Hynix has recently added single-die DDR4 memory chips featuring 16 Gb capacity to its product catalog. The benefit of the increase in single-die capacity is two fold: not only will the new components enable the company to build high-capacity memory modules using fewer chips, but also it will enable SK Hynix and its partners to build 256 GB DDR4 memory modules for ultra-high-end servers.", "16 Gb DRAM chips per se are not exactly a breakthrough. Memory makers, including SK Hynix, already build high-capacity DRAM components by stacking two or four 8 Gb memory dies vertically using TSVs to get 16 Gb and 32 Gb components, then use such chips to build memory modules featuring 64 GB and 128 GB density. Stacking makes organization of DIMMs very complex: in the case of a 64 GB module we are dealing with a quad-ranked DIMM (featuring two physical and two logical ranks), whereas a 128 GB module is octal ranked (featuring two physical ranks and four logical ranks). LRDIMMs have a relatively high latency in general (because they use additional buffers), meanwhile complexity of 64 GB/128 GB LRDIMM architecture forces module makers to increase them even further (to CL20/CL22 for DDR4-2400/DDR4-2666 speed bins).", "By contrast, SK Hynix has managed to develop single-die 16 Gb DDR4 components. Such ICs enable producers to build client memory modules or subsystems with a fewer number of chips, lowering power consumption, and allows server-class DIMMs with densities of up to 256 GB. When it comes to servers, the 16 Gb DDR4 components will allow to build dual-ranked 64 GB modules, quad-ranked 128 GB LRDIMMs and octal-ranked 256 GB LRDIMMs.", "Do not expect the 256 GB modules to show up tomorrow, but the importance of ultra-high-density LRDIMMs is hard to overestimate. For example, if the microcode is adjusted to allow it, a single socket Xeon Scalable platform featuring an -M suffixed processors with 12 total memory slots could potentially support 3 TB of six-channel memory. Meanwhile, an AMD EPYC-based system can currently support 2 TB of eight-channel memory per CPU socket, and these modules could help support double that. For in-memory applications like huge databases, the more DRAM they can get the better. Undoubtedly, 128 GB and 256 GB memory modules will come at a price. For example, Crucial sells its 128 GB DDR4-LRDIMM for ", " in retail, so a 2X capacity module would cost considerably higher.", "SK Hynix’s 16 Gb DDR4 chips are organized as 1Gx16 and 2Gx8 and supplied in FBGA96 and FBGA78 packages, respectively. At present, 16 Gb memory components are rated to operate in DDR4-2133 CL15 and DDR4-2400 CL17 modes at 1.2 Volts. Sometimes in the third quarter SK Hynix plans to add DDR4-2666 CL19 to the lineup. SK Hynix does not disclose which manufacturing technology it uses to make its 16 Gb chips, but it is logical to expect that the company uses a fabrication process with minimal feature sizes ", " high yields to make large dies.", "Keep in mind that it will take quite a while for server makers to validate 16 Gb chips and 2Hi/4Hi stacks based on them, so do not expect 256 GB modules to hit today’s servers shortly from now. In the meantime, 16 Gb DDR4 chips will enable makers of SO-DIMMs to build single-sided 16 GB DDR4 SO-DIMM modules. This will also allow thin laptops (that do not use modules, but rely on commodity memory) to install 16 GB of DRAM using eight chips. For any user wondering why most 13-inch notebooks do not want to use 16 GB of DRAM in all but the high-end specification, these chips should enable a nicer ecosystem for higher memory capacity small notebooks."]},
{"title": "SK Hynix Lists GDDR6 Memory as ‘Available Now’, Publishes Final Specs", "paragraph": ["SK Hynix has updated its product catalogue and now lists its GDDR6 memory chips as “available now”. In addition, the company published final specifications of its GDDR6 product family, confirming 10, 12 and 14 Gbps transfer rates with 1.25 V as well as 1.35 V voltages.", "SK Hynix was the first DRAM maker to announce mass production of GDDR6 memory ", ". Then, the company added two GDDR6 DRAM devices into its catalogue ", ", disclosing their general specifications. The company promised to start GDDR6 shipments by the end of 2017, but did not make any formal announcements on the matter late last year. SK Hynix will likely make certain GDDR6-related comments in the coming weeks, but recently it published its Q1 2018 databook where GDDR6 chips are listed as “available now.”", "SK Hynix’s GDDR6 product portfolio includes four memory configurations, all offering 8 Gb capacities with either 10 Gbps, 12 Gbps, or14 Gbps data transfer rates. The chips feature a 256Mx32 organization and operate as two 16-bit interfaces to increase effective utilization of the bus (a speculation at this point) — a standard feature of the GDDR6 spec. It is noteworthy than in addition to GDDR6 chips with 1.35 V Vdd/Vddq, SK Hynix also lists chips that offer a below-specification 1.25 V operating voltage, presumably as a low-power option – and one that should offer lower power than even GDDR5. Based on the part numbers, the 1.35 V and 1.25 V parts are the same chips, but there may be differences when it comes to end-products. 1.25 V GDDR6 chips will be particularly useful for various low-power, Mini-ITX and mobile graphics and other memory bandwidth-hungry applications. Meanwhile, like other GDDR6 chips, SK Hynix’s ICs come in 180-ball FCBGA packages.", "Meanwhile it's worth nothing that back in January, Samsung said that it had started mass production of ", ". So it's interesting to note that just looking at each vendor's published specifications, SK Hynix’s would appear to be trailing in both density and transfer rates. With that said, however, Samsung has been known to announce memory well in advance – and indeed they were calling their 16Gb chip early production – so it's not clear whether Samsung's high density chips are actually available to manufacturers. So SK Hynix may not be as far back from Samsung as it first appears, if they're behind at all.", "With at least two major makers of DRAM ready to ship their GDDR6 chips, it is logical to assume that graphics cards based on the new type of memory are just around the corner.", "It is worth noting that SK Hynix’s Q1 2018 product catalogue no longer lists 10-Gbps GDDR5 memory chips that were added there back in May. In fact, even 9-Gbps GDDR5 ICs do not have a part number, which may indicate that high-performance GDDR5 products are not a priority for SK Hynix just now.", "Related Reading:"]},
{"title": "G.Skill Unveils 16GB DDR4-4700 Trident Z RGB DRAM Kit: Samung B-die & RGB LED", "paragraph": ["G.Skill announced today a new Trident Z RGB kit which is now the fastest DDR4 memory kit in their product stack. The new dual-channel kit is designed for Z370 platforms and Intel’s Coffee Lake CPUs. The new sticks operate at a blazing fast DDR4-4700 using 1.45V and are the first sticks to reach that speed, period, as well as the first to have RGB LEDs. ", "G.Skill’s fastest-yet DDR4 memory kit has a combined capacity of 16GB in 2x8GB sticks. Timings are set at CL19-19-19-39 at 1.45V. The voltage is a far cry from the 1.2V JEDEC specification at much lower speeds, so considerations regarding the quality of the motherboard's DRAM VRMs should be taken into account. According to G.Skill, stable performance of these sticks was captured on an MSI Z370I Gaming Pro Carbon AC motherboard running in Dual Channel mode. The Mini-ITX board uses two DRAM slots for one DIMM per channel (other boards have two DIMMs per channel) in an effort to have cleaner data pathing and stable power for maximum DRAM clocking potential. Some setups may have trouble reaching these speeds so the ability of the CPU IMC and motherboard is certainly a consideration to run this kit. ", "The new Trident Z RGB DDR4-4700 kits are based on Samsung's B-die ICs produced using 20nm process technology. These memory ICs have been used across several makers over the past couple of years now and with this maturity, know what to expect from them even with a ~20% overvoltage applied.", "The G.Skill Trident Z RGB kit comes with their brushed aluminum heat spreaders which do not stand too tall over the DRAM PCB itself. The shorter height of the heat spreaders will allow for better compatibility for CPU heatsinks. The Trident Z RGB kit uses the integrated XMP 2.0 profile for easy setup and application of the correct timings, sub-timings, and voltage. ", "G.Skill's new Trident Z RGB (2x8GB) DDR4 4700 kits will be available in 2Q 2108 and they will not be cheap. A price was not released, however, their Trident Z RGB 4266 kit is currently ", " at Newegg so we can expect it to be higher. "]},
{"title": "Gen-Z Interconnect Core Specification 1.0 Published", "paragraph": ["The first major release of the Gen-Z systems interconnect specification is ", ". The Gen-Z Consortium was publicly ", " and has been developing the technology as an open standard, with several drafts released in 2017 for public comment.", "Gen-Z is one of several standards that emerged from the long stagnation of the PCI Express standard after the PCIe 3.0 release. Technologies like Gen-Z, ", ", CCIX and ", " seek to offer higher throughput, lower latency and the option of cache coherency, in order to enable much higher performance connections between processors, co-processors/accelerators, and fast storage. Gen-Z in particular has very broad ambitions to blur the lines between a memory bus, processor interconnect, peripheral bus and even straying into networking territory.", "The Core Specification released today primarily addresses connecting processors to memory, with the goal of allowing the memory controllers in processors to be media-agnostic: the details of whether the memory is some type of DRAM (eg. DDR4, GDDR6) or a persistent memory like 3D XPoint are handled by a media controller at the memory end of a Gen-Z link, while the processor itself issues simple and generic read and write commands over the link. In this use case, Gen-Z doesn't completely remove the need for traditional on-die memory controllers or the highest-performance solutions like HBM2, but Gen-Z can enable more scalability and flexibility by allowing new memory types to be supported without altering the processor, and by providing access to more banks of memory than can be directly attached to the processor's own memory controller.", "At the lowest level, Gen-Z connections look a lot like most other modern high-speed data links: fast serial links, bonding together multiple lanes to increase throughput, and running a packet-oriented protocol. Gen-Z borrows from both PCI Express and IEEE 802.3 Ethernet physical layer (PHY) standards to offer per-lane speeds up to the 56Gb/s raw speed of 50GBASE-KR, and will track the speed increases from future versions of those underlying standards. The PCIe PHY is incorporated more or less as-is, while the Ethernet PHY standards have been modified to allow for lower power operation when used for shorter links within a single system, such as communication between dies on a multi-chip module. Gen-Z allows for asymmetric links with more links and bandwidth in one direction than the other. The Gen-Z protocol supports various connection topologies like basic point to point links, daisy-chaining, and switched fabrics, including multiple paths of connection between endpoints. Daisy-chain links are estimated to add about 5ns of latency per hop, and switch latencies are expected to be on the order of 10ns for a small 8-port switch up to 50-60ns for a 64-port switch, so using Gen-Z for memory access is reasonable, especially where the somewhat slower persistent memory technologies are concerned. The Gen-Z protocol expresses almost everything in memory terms, but with each endpoint performing its own memory mapping and translation rather than attempting to form a unified single address space across a Gen-Z fabric that could scale beyond a single rack in a data center.", "The Gen-Z Consortium launched with the support of a dozen major technology companies, but its membership has now grown to the point that it is easier to list the big hardware companies who aren't currently involved: Intel and NVidia. Gen-Z has members from every segment necessary to build a viable product ecosystem: semiconductor design and IP (Mentor, Cadence, PLDA), connectors (Molex, Foxconn, Amphenol, TE), processors and accelerators (AMD, ARM, IBM, Cavium, Xilinx), switches and controllers (IDT, Microsemi, Broadcom, Mellanox), every DRAM and NAND flash memory manufacturer except Intel, software vendors (RedHat, VMWare), system vendors (Lenovo, HPE, Dell EMC). It is clear that most of the industry is paying attention to Gen-Z, even if most of them haven't yet committed to bringing Gen-Z products to market.", "At the SuperComputing17 conference in November, Gen-Z had a multi-vendor demo of four servers sharing access to two pools of memory through a Gen-Z switch. This was implemented with heavy use of FPGAs, but with the Core Specification 1.0 release we will start seeing Gen-Z show up in ASICs. The focus for now is on datacenter use cases with products potentially hitting the market in 2019.", "In the meantime, it will be interesting to see where industry support concentrates between Gen-Z and competing standards. Many companies are members or supporters of more than one of the new interconnect standards, and there's no clear winner at this time. Nobody is abandoning PCI Express, and it isn't clear which new interconnect will offer the most compelling advantages over the existing ubiquitous standards or over proprietary interconnects. Gen-Z seems to have one of the widest membership bases and the widest target market, but it could still easily be doomed to niche status if it only receives half-hearted support from most of its members."]},
{"title": "Chinese Xi’an UniIC Semiconductors Starts to Sell DDR4 Chips and Modules", "paragraph": [", a memory producer based in China, has started to sell DDR4 DRAM chips and modules that were developed and made in-house. This is the first time when a China-based company develops its own DDR4 memory chips. In the meantime, it is completely unclear which process technology Xi’an UniIC uses to manufacture the chips and whether it was developed in-house.", "Xi’an UniIC’s DDR4 lineup includes 4 GB and 8 GB SO-DIMMs, 4 GB and 8 GB UDIMMs as well as a 4 GB UDIMM with ECC, all rated for data transfer rate of 2133 MT/s with CL15 15-15 timings at 1.2 V (according to Xi’an UniIC’s ", "). All the DIMMs are based on Xi’an UniIC’s own DDR4 memory chips featuring 4 Gb capacity. The modules and the chips are not meant to offer breakthrough performance levels and are probably aimed at various inexpensive PCs, most of which will be sold in China.", "Xi’an UniIC’s DDR4 products can hardly impress avid readers who follow DRAM innovations closely (and know that leading makers already produce DDR4-3600 ICs), but the fact that a Chinese company has developed and produced such chips is important itself. Meanwhile, Xi’an UniIC actually has history of DRAM production, so the new memory was hardly developed entirely from scratch.", "Xi’an UniIC was founded in 2003 as Infineon Xi’an Memory Division and was then renamed to Qimonda Xi’an in 2006 after Infineon spun off its DRAM business. From 2003 to 2009 the company produced DDR, DDR2, DDR3 and other memory types for the parent company (Xi’an UniIC still offers them). After Qimonda went bankrupt in 2009, Inspur Group acquired remaining assets of its Xi’an subsidiary and started to produce its own DRAM in late 2010 (using IP and process technologies originally developed by Qimonda). In 2013, the company constructed the Xi’an Memory Engineering Technology Research Center with the help from Xi’an Science & Technology Agency. This R&D center apparently worked on DDR4 memory ICs as well as a new process technology to make them. Sometime in 2015 the company was acquired by Unigroup Guoxin (which is a part of Tsinghua Holdings) and was renamed to Xi’an UniIC Semiconductor. With financial and political backing of the multi-billion dollar government-controlled conglomerate, Xi’an UniIC finished development of its 4 Gb DDR4 chips and a fabrication process to produce them.", "Xi’an UniIC reportedly started sales of its DDR4 memory modules recently. ", " notes that the company’s 8 GB UDIMM was added to the CPU-Z database in September, 2016, so they could be available to customers in China for a while now. What remains unclear is whether the DDR4 ICs from Xi’an UniIC use any IP originally owned by Infineon/Qimonda and whether the manufacturer intends to sell its chips and modules outside of China.", "Sources: ", ", "]},
{"title": "Memory Scaling on Ryzen 7 with Team Group's Night Hawk RGB", "paragraph": ["Typically overlooked by many when outlining components for a new system, memory can a key role in system operation. For the last ten years, memory performance for consumers has been generally inconseqential on memory speed: we tested this for ", " and ", ", and two major conclusions came out of that testing:", "So it is perhaps not surprising to read in forums that the general pervasive commentary is that “memory speed over DDR4-2400 does not matter and is a con by manufacturers”. This has the potential to change with AMD's Infinity Fabric, where the interconnect speed between sets of cores is directly linked with the memory speed. For any workload that transfers data between cores or out to main memory, the speed of the Infinity Fabric can potentially directly influence the performance. Despite the fact that pure speed isn’t always the ‘be all and end all’ of establishing performance gains, it has the potential to provide some gains with this new interconnect design.", "The Infinity Fabric (hereafter shortened to IF) consists of two fabric planes: the Scalable Control Fabric (SCF) and the Scalable Data Fabric (SDF). ", "The SCF is all about control: power management, remote management and security and IO. Essentially when data has to flow to different elements of the processor other than main memory, the SCF is in control.", "The SDF is where main memory access comes into play. There's still management here - being able to organize buffers and queues in order of priority assists with latency, and the organization also relies on a speedy implementaiton. The slide below is aimed more towards the IF implementation in AMD's server products, such as power control on individual memory channels, but still relevant to accelerating consumer workflow.", "AMD's goal with IF was to develop an interconnect that could scale beyond CPUs, groups of CPUs, and GPUs. In the EPYC server product line, IF connects not only cores within the same piece of silicon, but silicon within the same processor and also processor to processor. Two important factors come into the design here: power (usually measured in energy per bit transferred) and bandwidth.", "The bandwidth of the IF is designed to match the bandwidth of each channel of main memory, creating a solution that should potentially be unified without resorting to large buffers or delays.", "Discussing IF in the server context is a bit beyond the scope of what we are testing in this article, but the point we're trying to get across is that IF was built with a wide scope of products in mind. On the consumer platform, while IF isn't necessarily used to such a large degree as in server, the potential for the speed of IF to affect performance is just as high.", "At the time of the launch of Ryzen, a number of industry sources privately disclosed to us that the platform side of the product line was rushed. There was little time to do full DRAM compatibility lists, even with standard memory kits in the marketplace, and this lead to a few issues for early adopters to try and get matching kits that worked well without some tweaking. Within a few weeks this was ironed out when the memory vendors and motherboard vendors had time to test and adjust their firmware.", "Overriding this was a lower than expected level of DRAM frequency support. During the launch, AMD had promized that Ryzen would be compatible with high speed memory, however reviewers and customers were having issues with higher speed memory kits (3200 MT/s and above) . These issues have been addressed via a wave of motherboard BIOS updates built upon an updated version of the AGESA (AMD Generic Encapsulated Software Architecture), specifically up to version 1.0.0.6.", "Given that the Ryzen platform itself has matured over the last couple of months, now is the time for a quick test on the scalability on AMDs Zen architecture to see if performance can scale consistency with raw memory frequency, or if any performance gains are achieved at all. For this testing we are using Team Group's latest Night Hawk RGB memory kit at several different memory straps under our shorter CPU and CPU gaming benchmark suites."]},
{"title": "Corsair Weds RGB Lighting and White Heat Spreaders in Vengeance RGB White DDR4 DIMMs", "paragraph": ["Corsair has once again expanded its lineup of Vengeance RGB memory modules, this time with a new series of white DIMMs that incorporate RGB lighting. Dubeed the Vengeance RGB White, these sticks are aimed at modders building white systems with RGB enhancements. The new DIMMs cover a broad range of speeds and capacities, with 16, 32 and 128 GB DDR4 dual- and quad-channel kits running at 3000, 3200 and 3600 MT/s data transfer rates.", "White is becoming more popular among modders these days. Over the past several years, we have seen multiple white motherboards and computer cases, but other components like PSUs, graphics cards and memory modules came in white relatively rarely. By contrast, over the past few months, we have seen an uptick in the number of launches of products in white enclosures, including PSUs. Being one of the most prominent supporters of white components, which has offered white PC cases for more than five years, it seems only fitting that Corsair has taken the next step by offering white DIMMs.", "The Corsair Vengeance RGB White family of memory modules consists of 8 GB and 16 GB DIMMs (supposedly based on Samsung’s B-die ICs) running at DDR4-3000 CL15, DDR4-3200 CL16 and DDR4-3600 CL18 speeds. The modules require 1.35V, so an enthusiast-class motherboard that can increase DDR4 voltages is necessary. Like other Vengeance-series modules, the Vengeance RGB White DDR4 kits come with XMP 2.0 SPD profiles to make their setup easier on Intel's X99, Z170, Z270, Z370 and X299 platforms.", "Just like their brethren from the original Vengeance RGB family with black heat spreaders, the Vengeance RGB White modules plug into regular DIMM slots and do not require any additional cables for RGB lighting. The latter can be controlled using the Corsair Link software, allowing users to synchronize colors of RGB lighting of their DIMMs and specific motherboard brands. Lighting of each module can be controlled separately as well. Besides, the RGB lighting can also be tuned using appropriate programs from manufacturers of motherboards — the ASUS Aura Sync, the GIGABYTE RGB Fusion and the MSI Mystic Light.", "The Corsair Vengeance RGB White lineup is now available directly from Corsair and from its resellers worldwide. Since we are dealing with unique products for enthusiasts/modders, they come at a premium price. For example the 16 GB DDR4-3200 CL16 and the 16 GB DDR4-3600 CL18 kits cost $199.99 and $204.99, respectively. The 32 GB kits are priced from from $374.99 to $399.99, whereas the 128 GB kit is available for $1469.99.", "Related Reading:"]},
{"title": "G.Skill Launches Lineup of Trident Z Kits for Coffee Lake: DDR4 at 3733 - 4600 MT/s", "paragraph": ["G.Skill has launched a new series of memory module kits optimized for Intel’s new 8", " Generation Core processors. The new DIMMs belong to G.Skill’s Trident Z and Trident Z RGB families and are guaranteed to operate at 3733 – 4600 MT/s data transfer rates when paired with Intel's Coffee Lake processors. Some of the modules need significantly increased voltages and thus require higher-end motherboards that can deliver “clean” power.", "Getting right down to business, the fact that G.Skill even announced memory kits specifically for Coffee Lake got an eyebrow raise out of us. At first blush, it seemed like a marketing stunt, especially since they're using the same Samsung’s B-die chips that they've been using for some time now. But according to the company, Coffee Lake's memory controller behaves ever so slightly differently than Kaby Lake's when overclocked, necessitating the new modules.", "Sure enough then, if we compare G.Skill's DDR4-4200 and DDR-4600 modules for the new Coffee Lake/Z370 and the ", ", we will notice that the modules for Coffee Lake have looser tRAS sub-timings than the modules for Kaby Lake. From performance point of view, tRAS might not be a big deal, but it's an unexpected change; if anything we would have expected Coffee Lake to accept the same timings as Kaby Lake. There are a few possible reasons for this difference - not the least of which is the immature Z370 platform - however the more interesting options are that it's a product of the new manufacturing process, or possibly even a new memory controller entirely (especially seeing as how Coffee Lake doesn't support DDR3).", "Otherwise, G.Skill's tinkering only seems to have been necessary for their fastest modules, as their lower-clocked enthusiast-class memory sticks are unchanged from earlier revisions. Conversely, since G.Skill has just loosened the timings of their new high-speed DIMMs, they should continue to work fine in other platforms.", "Overall, G.Skill’s lineup of Coffee Lake-optimized DRAM kits consists of seven products featuring two or four 8 GB or 16 GB modules based on Samsung’s B-die chips. The rather broad family of Coffee Lake-optimized memory products is aimed at different classes of systems. The fastest DDR4-4400/4500/4600 DIMMs are only available in 8GB capacities and require 1.4 V, 1.45 V or even 1.5 V. G.Skill positions these modules for enthusiasts seeking maximum performance and not interested in maximizing DRAM content per box. G.Skill’s ‘mid-range’ kits for Coffee Lake run at DDR4-4000/4200, have 32 GB of capacity (16 GB DIMMs), and are designed for those who need high memory bandwidth along with a decent amount of RAM. Finally, there is a 64 GB DDR4-3733 kit for users who run memory-intensive applications.", "Traditionally, all the Trident Z modules come with XMP 2.0 SPD profiles to simplify their setup on optimized platforms. In addition, the modules are equipped with G.Skill’s proprietary aluminum heat spreaders. Meanwhile, the Coffee Lake-optimized lineup from G.Skill also includes two Trident Z RGB options with programmable LED lighting.", "G.Skill has validated its new memory kits using Intel Z370-based motherboards from ASUS — the ROG Maximus X Hero, ROG Maximus X Apex and the ROG Maximus X Formula.", "Finally, G.Skill plans to start selling the new Coffee Lake-optimized Trident Z and Trident Z RGB memory kits in November with the fastest Trident Z RGB DDR4-4266 arriving in December. The company traditionally does not touch upon MSRPs of its products in its announcements because DRAM prices tend to fluctuate. Meanwhile, since we are dealing with the latest products for a premium platform, expect appropriate prices.", "Related reading:"]},
{"title": "G.Skill Announces DDR4 SO-DIMM Kits up to DDR4-3800: Ripjaws for SFF", "paragraph": ["G.Skill has announced its new family of Ripjaws DDR4 SO-DIMM kits designed specifically for Intel’s Core X processors. The current number of consumer motherboards supporting SO-DIMMs is limited: only the ASRock X299E-ITX/ac motherboard is at retail, although there could be potential to see some high-performance notebooks also make use of the high-performance memory. The modules being launched operate from DDR4-3200 to DDR4-3800 and are currently are the fastest DDR SO-DIMMs in the industry.", "Intel’s latest processors for high-end desktops feature the company’s new-generation memory controllers that can handle very high DDR4 data transfer rates. Full-size PCs can take advantage of this capability because there is a wide choice of DDR4 modules, and we have seen modules rated for DDR-4000 and higher hit the market. By contrast, motherboards such as the ", " use SO-DIMMs, of which the choice is limited due to the low number of SO-DIMM capable motherboards and systems. At present, the fastest SO-DIMMs are rated for DDR4-3200 (the Ripjaws DDR4-3200 16 GB kit), so in a bid to offer owners better memory performance, G.Skill this week introduced a new family of its Ripjaws DDR4 SO-DIMM kits.", "The new high-speed 8 GB and 16 GB memory modules are based on Samsung’s B-die DRAM ICs used for most enthusiast-class memory hitting very high speeds. G.Skill will offer four different SO-DIMM kits, being advertised as optimized for the ASRock X299E-ITX/ac and Intel’s Skylake-X processors: three 32 GB kits rated to operate in DDR4-3200/CL16, DDR4-3600/CL16 and DDR4-3800/CL18 modes as well as one 64 GB DDR4-3200/CL16 kit. All new modules feature XMP 2.0 profiles and require 1.35 V.", "While the new SO-DIMMs are compatible with the latest laptops that use Intel’s desktop Coffee Lake CPUs (from Clevo, Eurocom and others), it is unknown whether they can work and remain stable at full speed in them. Laptops typically a different memory sub-system topology than desktops and therefore may require some additional SPD tuning. As a result, G.Skill has positioned the new Ripjaws DDR4 kits only for “SFF platforms” rather than DTR laptops.", "G.Skill says that its new quad-channel Ripjaws DDR4 SO-DIMM kits will be available from its partners in early December. The company does not disclose estimated MSRPs of the new kits, but since these are unique memory modules built for a unique platform, expect them to be priced accordingly. For example, G.Skill’s previous-generation Ripjaws DDR4-2800 32 GB SO-DIMM kit is priced between ", " and ", " in the U.S. Meanwhile, the aforementioned G-Skill’s dual-channel Ripjaws DDR4-3200 16 GB kit is priced at ", "."]},
{"title": "RGB Fan for Corsair Dominator Platinum DDR4 Launched: $70 MSRP", "paragraph": ["Corsair has introduced a new fan for its top-of-the-range Dominator Platinum memory modules that not only adds additional airflow to the memory but also adds additional RGB LEDs. The Dominator Airflow Platinum RGB cooler is compatible with DDR4 memory modules and is already available.", "Customizable RGB lighting can be installed on pretty much all types of enthusiast-class PC components these days. Virtually all high-end motherboards, graphics cards, memory modules, chassis, fans, etc. released this year are equipped with some sort of RGB LED topology. All the leading suppliers of memory modules for gamers and enthusiasts either already ship DRAM modules with customizable RGB lighting, or at least have demonstrated them. Corsair itself released its Vengeance RGB series to complement its cases and coolers this summer.", "Corsair’s top-end Dominator Platinum modules still have not received any RGB treatment. Although today's announcement is aimed to allow users to keep the design ID, add additional cooling, and add RGB. ", "Corsair's Dominator Platinum range is for Corsair's top performing modules, and the kits do not come cheap. In the effort for performance, typically the custom PCBs (and industrial design) are not intended for LEDs, especially if the delivery of “clean” power to the memory chips had an adverse effect on performance or overclocking potential. Corsair has ", " with white LED-equipped Platinum Dominator Torque DDR4-3200 special edition modules, but it looks like it does not plan to introduce LEDs to all of its highest-end parts. So instead of installing RGB LEDs on the Dominator Platinum modules, Corsair has decided to offer an optional cooler that would add lighting effects.", "The Corsair Dominator Airflow Platinum RGB cooler is equipped with two 50-mm ball bearing fans that can create 21.2 CFM airflow pressure at their maximum rotating speed of 3700 RPM. The fans are PWM controllable using Corsair Link software. The same application can customize the lighting of both fans.", "The Corsair Dominator Airflow Platinum RGB is available today directly from Corsair and its resellers. The MSRP of the product in the U.S. is $69.99, whereas in Europe the cooler is available for €74.99. Meanwhile, the device is available from Amazon for $56.54 at press time. You will need two for a high-end desktop with quad channel memory. To clarify, memory is not included."]},
{"title": "Micron Announces 32GB DDR4 NVDIMM-N Modules", "paragraph": ["Micron is announcing today their next generation of NVDIMM-N modules combining DDR4 DRAM with NAND flash memory to support persistent memory usage models. The new 32GB modules double the capacity of Micron's previous NVDIMMs and boost the speed rating to DDR4-2933 CL21, faster than what current server platforms support.", "Micron is not new to the Non-Volatile DIMM market: their first DDR3 NVDIMMs predated JEDEC standardization. The new 32GB modules were preceded by 8GB and 16GB DDR4 NVDIMMs. Micron's NVDIMMs are type N, meaning they function as ordinary ECC DRAM DIMMs but have NAND flash to backup data to in the event of a power loss. This is in contrast to the NVDIMM-F type that offers pure flash storage. During normal system operation, Micron's NVDIMMs use only the DRAM. When the system experiences a power failure or signals that one is imminent, the module's onboard FPGA-based takes over to manage saving the contents of the DRAM to the module's 64GB of SLC NAND flash. During a power failure, the module can be powered either through a cable to an external AGIGA PowerGEM capacitor module, or by battery backup supplied through the DIMM slot's 12V pins.", "Micron says the most common use cases for their NVDIMMs are for high-performance journalling and log storage for databases and filesystems. In these applications, a 2S server will typically be equipped with a total of about 64GB of NVDIMMs, so the new Micron 32GB modules allow these systems to use just a single NVDIMM per CPU, leaving more slots free for traditional RDIMMs. Both operating systems and applications need special support for persistent memory provided by NVDIMMs: the OS to handle restoring saved state after a power failure, and applications to manage what portions of their memory should be allocated from the persistent portion of the overall memory pool. This can be addressed either through applications using block storage APIs to access the NVDIMM's memory, or through direct memory mapping.", "Micron is currently sampling the new 32GB NVDIMMs but did not state when they will be available in volume.", "Conspicuously absent from Micron's announcement today is any mention of the third kind of memory they make: 3D XPoint non-volatile memory. Micron will eventually be putting 3D XPoint memory onto DIMMs and into SSDs under their QuantX brand, but so far they have been lagging far behind Intel in announcing and shipping specific products. NVDIMMs based on 3D XPoint memory may not match the performance of DRAM modules or these NVDIMM-N modules, but they will offer higher storage density at a much lower cost and without the hassle of external batteries or capacitor banks. Until those are ready, Micron is smart to nurture the NVDIMM ecosystem with their DRAM+flash solutions."]},
{"title": "Samsung Pre-Announces 16 Gbps GDDR6 Chips for Next-Gen Graphics Cards", "paragraph": ["In a surprisingly early revelation, Samsung has confirmed their plans to produce GDDR6 memory. The ", " was made as a part of Samsung’s pre-CES marketing campaign and does not disclose any dates or timeframes. Though it is worth noting that with speeds up to 16Gbps, Samsung's chips are the fastest GDDR6 chips announced to date.", "Last week Samsung issued a ", " covering its products that had been recognized as CES 2018 Innovation Awards winners. Among other things, Samsung mentioned a number of unreleased products, including the Exynos 9 Series 9810 SoC for the next Galaxy smarphone, GDDR6 memory, as well as the Gear IconX (2018) headphones. Though with a focus on the awards themselves, Samsung has released little in the way of information on the products receiving awards. And while it is clear why Samsung would decide to withhold  details about upcoming products (competition, the company does not want to spoil the actual launch, etc.), it is noteworthy that CEA does not ", " participating products to be mass-produced, or at least have a clear commercial availability timeframe.", " is a memory standard that is set to be supported by all three leading DRAM manufacturers, so Samsung's participation has been expected. Less expected was any kind of announcement or reveal before the memory is shipping, as Samsung is notoriously tight-lipped about forthcoming memory products. Consequently and unfortunately, the announcement itself contains little details about the ICs themselves as well as the whole stack of GDDR6 products that Samsung is going to offer. What we do know is that they will feature data transfer rates of up to 16 Gbps at 1.35 V.", "Ahead of full scale production, one of the big questions on our end is which process and fab(s) Samsung will be using for this cutting-edge memory, especially with the ongoing DRAM shortage. A natural suspect would be Samsung’s ", ", but the South Korean giant has not confirmed it.", "Meanwhile, it's interesting to note that while the planned capacity of Samsung's new chips wasn't mentioned in the body of their announcement itself, it was in the title. Assuming this isn't a typo on Samsung's part, it looks like the company intends to produce 16 Gb chips. Notably this is twice the capacity of their current GDDR5 chips, but also twice the capacity of Micron and SK Hynix's previously announced GDDR6 memory. Which doesn't mean that Samsung will be offering 16 Gb chips right off the bat, but for gamers looking for cards with more than 8GB of VRAM, this could prove an interesting development.", "Otherwise, it's worth noting that while Samsung's data rate goals here are welcomely aggressive, AMD and NVIDIA don't always run new-generation memory at its maximum rated speed, often due to needing to nail down their memory controllers and firmwares. So the availability of 16Gbps chips does not necessarily mean that next year’s graphics cards will use Samsung's memory at its full speed.", "Related Reading:"]},
{"title": "Corsair Builds 32 GB DDR4-4333 Kit, Only for Pre-Binned Coffee Lake CPUs", "paragraph": ["Corsair recently revealed a new 32 GB memory kit rated to run at DDR4-4333. The product consists of four modules and is the fastest set of DIMMs featuring such capacity to date. Of particular interest here are the kit's very specific compatibility requirements: due to the heavy strain on a CPU's memory controller from running so many DIMMs this far overclocked, the kit is only compatible with ", " Intel’s latest 8", " Generation Core processors, with Corsair going as far as suggesting interested buyers pickup pre-binned CPUs in order to ensure compatibility.", "Corsair’s Vengeance LPX 32 GB DDR4-4333 (CMK32GX4M4K4333C19) kit is rated to run in dual-channel modeat 4333 MT/s with CL19 26-26-46 timings and 1.5 V. Like other latest enthusiast-class DDR4 modules, the 8 GB DIMMs from the new kit are based on pre-binned Samsung B-die DRAM chips made using the company’s 20 nm process technology. The modules traditionally feature XMP 2.0 profiles with appropriate SPD settings to make their setup easier. To ensure that the 32 GB DDR4-4333 kits work stably, Corsair uses Intel’s Core i5-8600K CPU running on the ASUS ROG Maximus X Hero motherboard.", "As ", ", Intel’s Coffee Lake CPUs work a bit differently with high-end DDR4 modules and require looser tRAS sub-timings than the preceeding Kaby Lake CPUs. With this in mind, it is not entirely surprising that Corsair’s Vengeance LPX 32 GB DDR4-4333 kit is intended only for the latest Coffee Lake processors.", "As mentioned earlier, Corsair says that not all Coffee Lake CPUs can handle the kit's rated DDR4-4333 speed. This is due to a combination of the kit's already high clockspeeds, coupled with the fact that running 4 DIMMs (2 DPC) is harder on a memory controller than 2 DIMMs (1 DPC). Functionally speaking this is a facet of processor overclocking – in the form of overclocking the memory controller – and with Corsair pushing the envelope so hard, ultimately not all CPUs are going to be capable of maintaining stability this far overclocked.", "Consequently, Corsair recommends using pre-binned processors and high-quality motherboards with this 4 DIMM kit. Such CPUs are sold by select stores, such as ", " and ", ", and are more expensive than the regular parts since it takes time to find samples with a high overclocking potential. Given the very special positioning of the 32 GB DDR4-4333 Vengeance LPX kit, it remains to be seen whether Corsair will sell it only directly from its web site, or through select retailers.", "At present, Corsair’s fastest dual-channel 32 GB DDR4 kit is the Dominator Platinum 32GB (4×8 GB) DDR4-4000 C19 (CMD32GX4M4E4000C19) set of memory modules available either directly for ", " or from Newegg for ", ".", "Related Reading:"]},
{"title": "SK Hynix Advances Graphics DRAM: GDDR6 Added to Catalogue, GDDR5 Gets Faster", "paragraph": ["SK Hynix has added GDDR6 memory chips to its product catalogue, revealing their general specifications and launch timeframe sometimes in Q4 2017. As expected, the new GDDR6 ICs will be available late this year and will run at speeds not achievable by GDDR5. GDDR5 is not really going away as SK Hynix has added several new SKUs into the catalogue, targeting forthcoming applications.", "SK Hynix formally announced plans to produce GDDR6 in late April, so the addition of appropriate chips to the company’s databook does not really come as a surprise. The initial GDDR6 chips from SK Hynix will have an 8 Gb capacity and will feature 12 and 14 GT/s data transfer rates at 1.35 V. The new memory ICs will have a dual-channel 256Mx32 organization, which may indicate that GDDR6 chips will keep using 32-bit physical interface, but that I/O will operate as two 16-bit interfaces at all times to increase effective utilization of the bus (but this is a speculation at this point). The ICs will use 180-ball FCBGA packages and will thus be incompatible with existing GDDR5 and GDDR5X applications that use 170-ball and 190-ball form-factors, respectively.", "JEDEC yet has to finalize and publish specifications of GDDR6 and this is when we learn everything about peculiarities of the new memory. From SK Hynix we already know that the maximum planned data rate of the new memory will be 16 GT/s, implying a 16n prefetch and higher base clocks. We also know that one of the first graphics cards to use GDDR6 will have a 384-bit memory sub-system and assuming that it will run DRAM at 14 GT/s, it will feature 672 GB/s of bandwidth. Keep in mind that developers of GPUs and makers of graphics cards are rather conservative about memory frequencies, so, the final bandwidth could be lower, depending on yields of GPUs, DRAM ICs and graphics cards.", "Besides GDDR6 memory, SK Hynix will also release 8 Gb GDDR5 chips rated for 9 and 10 GT/s data transfer rates at 1.55 V in Q4 2017. The new chips will target mass market applications that require higher memory bandwidth as well as cost efficiency of GDDR5, so, think of mainstream graphics cards. In addition to ultra high-speed GDDR5 devices, SK Hynix will also offer 7 and 8 GT/s GDDR5 chips with reduced voltages in the fourth quarter. The insertion of the new chips into the roadmap indicates that GDDR5 will remain on the market for at least a couple of years down the road and will celebrate a decade on the market next year.", "Speaking of graphics memory in general, it is also noteworthy that SK Hynix has removed mentions about ", " from its product catalogue last quarter. As of now, the only HBM2 offering listed by the company are 4 GB 4Hi stacks with 1.6 GT/s data rate. The reasons for the move are unknown, but it is logical to assume that it is not easy to make very complex memory devices with a 512-bit I/O bus and high frequencies both from yields and from thermal points of view. Therefore, for products like AMD’s upcoming Radeon RX Vega, SK Hynix will have to offer HBM2 chips with 1.6 GT/s data rate and 204.8 GB/s bandwidth and it will be up to the buyers of such chips to implement further binning to higher frequencies.", "Related Reading:"]},
{"title": "DRAM and Motherboard Makers Demonstrate Quad-Channel DDR4-4000+ Operation", "paragraph": ["Over the course of Computex, manufacturers of memory modules and motherboards alike took to the show to showcase the latest developments in high-speed quad-channel memory configurations. Powered by Intel’s new Skylake-X CPUs, manufacturers have been able to get quad-channel data transfer rates running at 4000 MT/s and higher. This increased memory bandwidth should, in turn, help Intel’s new Core i7 and i9 processors offer significantly higher performance than predecessors in applications that heavily rely on memory transactions.", "Quad-channel memory sub-systems on Intel’s high-end desktop processors have always provided vast amounts of memory bandwidth to multi-core CPUs, even without running DRAM at high data rates. A 256-bit memory sub-system using DDR4-2400 modules has a throughput of 76.8 GB/s. To match it, a 128-bit (dual-channel) memory sub-system would have to use two DDR4-4800 modules. Meanwhile since quad-channel memory by definition provides loads of bandwidth, and due to stability/reliability concerns, Intel opted not to chase high data rates on their first-gen DDR4 controllers found in the Haswell-E and Broadwell-E CPUs, which is why such processors barely supported DDR4-3200+ memory.", "With the Skylake CPUs for consumers however, Intel introduced its second-gen DDR4 controller that could handle high data rates and several DRAM module makers quickly rolled out DDR4-4000+ DIMMs for enthusiasts. That controller has evolved with the Kaby Lake generation and ended up in Intel’s Skylake-X processors, enabling Intel’s X299 HEDT platform to support DDR4 modules at well-beyond JEDEC-specified data rates. Fittingly, at Computex, motherboard and memory manufacturers demonstrated how well their high-end X299 platforms and DDR4 DIMMs can work together at high-speeds in quad-channel mode.", "Starting things off, G.Skill displayed eight of its Trident Z RGB 8 GB DDR4 modules running in quad-channel mode with a Skylake-X CPU on the ASUS Prime X299 Deluxe at 4200 MT/s with CL19 21-21-41 timings. The CPU was cooled down using a custom liquid cooling system and the PC worked for hours during the show.", "The company also showcased its modules running at 4000 MT/s, 4400 MT/s and 4500 MT/s in dual-channel mode on Intel X299-based motherboards from ASRock and GIGABYTE, which is an important news for those planning to use Intel's Kaby Lake-X processors.", "Meanwhile GIGABYTE demonstrated its X299 AORUS Gaming 7 running 128 GB of Corsair Vengeance RGB DDR4 memory at DDR4-4133 with CL19 19-19-39 latency settings. The setup was based on the Core i7-7900X (10C/20T) processor operating at 4426 MHz under an LCS, and was running for hours in Gigabyte's air conditioned suite in the Taipei 101.", "Corsair itself was a little more conservative than GIGABYTE. In its suite, the company displayed an Intel Core i7-7800X (Skylake-X, 6C/12T) and ASUS Prime X299-Deluxe-based system running 128 GB of its Vengeance RGB memory in quad-channel mode at 3800 MT/s. The CPU was cooled down using Corsair's Hydro H110i AIO LCS, so nothing too extreme.", "In addition, the company showcased two of its Vengeance RGB DIMMs running in dual-channel mode at 4600 MT/s on a system featuring Intel's Core i7-7740X (Kaby Lake-X, 4C/8T) and ASUS' ROG Rampage VI Apex motherboard. Again, the CPU used the Hydro H110i AIO LCS and the room temperature was normal.", "Last but not least, G.Skill had on the highest frequency kit: a DDR4-4800 dual-channel set of modules, 2x8GB, running at 19-19-19 sub timings. Liquid cooling was applied to the ASRock X299 OC Formula.", "Obviously, demonstrations of overclocked systems do not necessarily reflect the formal plans of companies like G.Skill or Corsair when it comes to the Intel X299 platform in general, and for the Intel Skylake X processors in particular.", "What we do understand today is that the Skylake-X can handle DDR4-4133 and DDR4-4200 speeds in quad-channel mode, whereas the Kaby Lake-X CPUs can go even north from that and hit something like DDR4-4500~4600 in dual-channel mode. In fact, Taiwanese overclocker Toppc has managed to push a single 8 GB G.Skill Trident Z RGB module to ", " on MSI’s X299 Gaming Pro Carbon AC (MS-7A95) using Intel’s Core i7-7740K CPU under liquid nitrogen, which proves that DDR4 is gaining overclocking potential as memory controllers get better as well.", "Related Reading:"]},
{"title": "Micron Discusses GDDR: 16 Gbps GDDR5X, 16 nm GDDR6 and GDDR5 ", "paragraph": ["Micron has made a number of announcements in recent weeks regarding its GDDR memory for graphics cards, game consoles and networking applications. The company is reporting that they've been able to hit 16 Gbps data rates in the lab on their latest generation of GDDR5X devices, while also reiterating their long-term plans for GDDR6 and GDDR5, with GDDR6 memory due in a couple of quarters from now, while GDDR5 will be here to stay for a long time to come.", "Graphics DRAM has been a hot topic in the industry in the recent years as GPU demands for memory bandwidth are growing rapidly and because different companies offer different types of memory to satisfy these increasing requirements. For example, SK Hynix and Samsung rolled out HBM (Gen 1 and Gen 2) memory in 2015 and 2016 for ultra-high-end consumer and HPC applications, whereas Micron introduced its GDDR5X for high-end graphics cards last year. At present, HBM offers the greatest potential bandwidth, however the complexity of the multi-layer chips and 2.5D packaging keep costs high, so it remains to be seen which mass consumer applications adopt it. Meanwhile, conventional graphics memory in BGA packaging and proven architecture continues to evolve and hit new performance targets due to architectural improvements, which are intended to keep it competitive in the coming years.", "When Micron announced its GDDR5X memory in late 2015, it set two targets for data transfer rates: the initial target of 10 – 12 Gbps and the longer-term target of 16 Gbps. Initially, the company only supplied GDDR5X ICs validated at 10 and 11 Gbps, but this year the company also started to bin the chips for 12 Gbps. The latter are used on NVIDIA’s Titan Xp graphics card. What is noteworthy is that engineers from Micron's development center in Munich (also known as Graphics DRAM Design Center) recently managed to run the company’s mass-produced GDDR5X chips at 16 Gbps in the lab.", "While the achievement doesn't have an impact on actual products available today, it has a number of important implications. Primarily, it means that Micron has refined their process to the point where they can build graphics DRAM with 16 Gbps signaling, and this is something it is going to need going forward. But additionally, it shows that the current GDDR5X technology has potential, and that Micron’s customers might release new products with faster memory.", "Micron has been quite busy in the last couple of years working on the GDDR5X memory specification, physical implementation of such ICs, and then developing GDDR6 chips that the company plans to launch by early 2018. In fact, GDDR5X and the GDDR6 are not that different. They are both based on the 16n prefetch architecture and this is the key to their additional performance when compared to GDDR5. Meanwhile, GDDR6 also features dual-channel mode, which is meant to ensure better channel utilization and hence improve performance in cases that can take advantage of the feature.", "Meanwhile Micron will be using 16 nm fab lines to produce GDDR6 memory devices, which may add frequency potential to the upcoming chips compared to ICs made using their 20 nm fabrication process. Speaking of 16 nm, Micron also plans to use it for newer GDDR5 chips, which makes a lot of sense considering the fact that such devices are going to be used for graphics cards and game consoles for years to come.", "Summing up. Micron has GDDR5X memory chips that run at 16 Gbps in the lab using test equipment. Such chips are made using 20 nm process technology. Meanwhile Micron is using 16 nm fabrication process to produce GDDR6 and GDDR5 by 2018.", "Related Reading:"]},
{"title": "Western Digital Announce BiCS4 3D NAND: 96 Layers, TLC & QLC, Up to 1 Tb per Chip", "paragraph": ["Western Digital on Tuesday formally announced its fourth-generation 3D NAND memory, developed as part of the Western Digital/Toshiba joint venture. The fourth-generation BiCS NAND flash chips from Western Digital feature 96 layers and will include several capacity points and will use TLC and QLC architectures. The company expects to start volume production of BiCS4 chips in 2018.", "NAND dies that belong to the fourth-generation BiCS 3D NAND will use 96 word layers to minimize die size of the chips and maximize output of fabs, and at this point represents the largest layer count in the flash memory industry. Furthermore the range of BiCS4 NAND die configurations available will be considerably more diverse than BiCS3, which currently only includes 256 Gb and 512 Gb dies. Western Digital plans to offer BiCS4 components based on TLC (triple level cell) and QLC (quadruple level cell) configurations. with capacities ranging from 256 Gb to 1 Tb.", "It is noteworthy that Western Digital’s BiCS4 lineup will include QLC NAND, which has been discussed by Western Digital (and SanDisk before that) for several years, but which is about to become reality only in the coming quarters. To store four bits per cell (with 16 voltage states) Western Digital had to use a “thick” process technology alongside multi-layer 3D NAND to keep the per-bit costs down. The company is not specifying how many program/erase cycles its 3D QLC NAND will handle, but various industry predictions over the years have suggested 100 – 150 P/E cycles as a reasonable goal for QLC NAND, which is considerably lower than approximately 1000 P/E cycles supported by TLC NAND. Given such endurance, it is logical to expect 3D QLC NAND to be used for primarily removable storage as well as for ultra-high capacity datacenter drives for the so-called near-WORM (write once read many) storage applications. For example, Toshiba last year discussed a QLC-based datacenter SSD with 100 TB capacity for WORM apps.", "Western Digital plans to begin sampling of select 96-layer BiCS4 3D NAND configurations in the second half of this year, but the manufacturer does not specify which dies will sample when. As for mass production, Western Digital intends to start volume manufacturing of their 96-layer 256 Gb 3D NAND in 2018, with other dies to follow later. Based on Western Digital’s announcements made earlier, the company will gradually introduce more sophisticated BiCS4 96-layer configurations in 2018 and 2019, before moving to BiCS5 sometimes in 2020. That said, it makes sense to expect the highest capacity BiCS4 ICs to ship later rather than sooner.", "Finally, Western Digital did not disclose whether it uses NAND string stacking technology to assemble its 96-layer 3D NAND dies, but it is a likely scenario given what industrial publications have been predicting.", "Related Reading:"]},
{"title": "Micron Discontinues Lexar Business, Plans to Focus on Higher-Margin Products", "paragraph": ["Micron this week announced plans to discontinue its Lexar removable media storage business as a part of the company’s strategy to shift to higher margin NAND flash-based products. The company intends to sell all or part of its Lexar business division, but promises to support existing customers during the transition period.", "Lexar was spun off from Cirrus Logic in 1996 and then acquired by Micron in 2006 in a bid to market NAND flash media. More recently, approximately two years ago, Micron cut down the amount of NAND memory it supplied to spot market in a bid to concentrate on building its own products and thus earn higher profit margins. Last year the company ", " plans to work with its clients to build software for their software storage offerings to further improve its profit margins, this time from various SSDs. In addition, the company disclosed plans to develop special memory solutions for emerging automotive applications (which will complement its embedded portfolio). This week Micron went even further and disclosed plans to cease selling Lexar branded products to consumers and OEMs as a part of its strategy to increase “opportunities in higher value markets and channels.” The portfolio of Lexar products includes memory cards and card readers, USB flash drives and even SSDs.", "Given the competition on the market of retail removable media and storage drives, the withdrawal from such businesses may be logical for Micron, which feels increasing pressure from Samsung, Western Digital (SanDisk) and others amid lack of market growth in terms of NAND bits (at least, according to its own ", "). Meanwhile, the withdrawal also means that Micron will have to concentrate on production of SSD-grade memory, whereas any further removable storage-grade NAND that the company produces will have be sold on the open market. If someone buys the Lexar operations from Micron, the latter will likely sign some kind of exclusive supply agreement with the new owner, which means that it will keep developing the aforementioned NAND. SSD-grade memory is more expensive than chips for memory cards or USB flash drives. and for about a year Micron was the only company to sell its SSD-grade 3D NAND to third-party SSD vendors, possibly earning higher margins than by selling removable storage devices. However, NAND for the latter is typically used to test drive new production technologies and/or architectures before deploying them to make memory for SSDs.", "Otherwise, looking at the bigger picture, Micron new alignment with regards to the removable storage market is not particularly unique. SK Hynix and Intel don't produce removable storage products either (at least, not under their own trademarks), leaving Samsung, Toshiba and Western Digital as the three remaining vendors who do. That said, while it will be sad to see Micron’s Lexar gone (assuming that nobody buys it), Micron’s withdrawal from removable storage business is not exactly surprising.", "Related Reading:"]},
{"title": "G.Skill Announces Quad-Channel DDR4-4200 Kit for Intel Skylake-X CPUs", "paragraph": ["G.Skill this past week has formally announced its quad-channel memory kits designed for the latest Intel Core i7 (Skylake-X) CPUs and the Intel X299 platform. The flagship 64 GB Trident Z kit boasts a 4200 MT/s data transfer rate, a rather notable step up from the company's entry-level 3600 MT/s kit. In addition, G.Skill is also introducing its new Trident Z Black series dual-channel DDR4-4400 kit for Intel’s Kaby Lake-X processors.", "G.Skill’s lineup of memory kits for the Intel X299 platform consists of 8 GB and 16 GB Trident and Trident Z RGB DIMMs based on Samsung’s popular 20nm-fabbed 8 Gb DDR4 DRAM modules. The various kits are available at 3600 MT/s, 3733 MT/s, 3800 MT/s, 4000 MT/s, and 4200 MT/s data transfer rates, while their voltages run from 1.35 to 1.4 V. As you'd expect, the higher clocked kits also come with higher latency, with latencies starting at CL16 and reaching CL19 by DDR4-4200 speeds. Which goes to show that even though Intel's Skylake-X and Kaby Lake-X CPUs can handle very high DRAM frequencies, the tradeoff between clocks and timings has not gone anywhere.", "Meanwhile it's interesting to note that despite G.Skill's recent obsession with RGB lighting – resulting in the company offering RGB-equipped DIMMs for most of the Trident Z range – the fastest DDR4-4200 and DDR4-4400 kits are not available with RGB lighting. Keeping in mind that this kind of extreme DDR4 overclocking requires increased voltage and very “clean” power, it may not be easy to apply RGB to such DIMMs without affecting their stability. Still, keeping in mind that G.Skill itself demonstrated DDR4-4200 Trident Z RGB DIMMs in quad-channel mode at Computex, it is a matter of time before appropriate modules will hit the market.", "G.Skill traditionally announces its new memory modules a little bit ahead of their retail launch and does not set MSRPs ahead of actual availability, so pricing has not yet been disclosed on the company's newest kits.", "Related Reading:"]},
{"title": "Toshiba's 768Gb 3D QLC NAND Flash Memory: Matching TLC at 1000 P/E Cycles?", "paragraph": ["Toshiba last week announced its first 3D NAND flash memory chips featuring QLC (quadruple level cell) BiCS architecture. The new components feature 64 layers and developers of SSDs and SSD controller have already received samples of the devices, which Toshiba plans to use for various types of storage solutions.", "Toshiba’s first 3D QLC NAND chips feature 768 Gb (96 GB) capacity and uses 64 layers, just like the company’s BICS3 chips with 256 Gb and 512 Gb capacities launched in 2016 and 2017. Toshiba does not share further details about its 3D QLC NAND IC (integrated circuit), such as page size, the number of planes as well as interface data transfer rate, but expect the latter to be high enough to build competitive SSDs in late 2018 to early 2019 (that’s our assumption). Speaking of applications that Toshiba expects to use its 3D QLC NAND ICs, the maker of flash memory mentions enterprise and consumer SSDs, tablets and memory cards.", "Besides intention to produce 768 Gb 3D QLC NAND flash for the aforementioned devices, the most interesting part of Toshiba’s announcement is endurance specification for the upcoming components. According to the company, its 3D QLC NAND is targeted for ~1000 program/erase cycles, which is close to TLC NAND flash. This is considerably higher than the amount of P/E cycles (100 – 150) expected for QLC by the industry over the years. At first thought, it comes across a typo - didn't they mean 100?. But the email we received was quite clear:", "It is unclear how Toshiba managed to increase the endurance of its 3D QLC NAND by an order of magnitude versus initially predicted. What we do know is that signal processing is more challenging with QLC than it is with TLC, as each cell needs to accurately determine sixteen different voltage profiles (up from 2 in SLC, 4 in MLC, and 8 in TLC). ", "The easiest way to handle this would be to increase the cell size: by having more electrons per logic level, it is easier to maintain the data and also read from it / write to it. However, the industry is also in a density race, where bits per mm^2 is an issue. Also, to deal with read errors from QLC memory, controllers with very advanced ECC capabilities have to be used for QLC-based SSDs. Toshiba has its own QSBC (Quadruple Swing-By Codes) error correction technique, which it claims to be superior to LDPC (low-density parity-check) that is widely used today for TLC-powered drives. However, there are many LDPC implementations and it is unknown which of them Toshiba used for comparison against its QSBC. Moreover, there are more ECC methods that are often discussed at various industrial events (such as FMS), so Toshiba could be using any or none of them. The only thing that the company tells about its ECC now is that it is stronger than 120 bits/1 KB used today for TLC. In any case, if Toshiba’s statement about 1000 P/E cycles for QLC is correct, it means that that the company knows how to solve both endurance and signal processing challenges.", "The main advantage of QLC NAND is increased storage density when compared to TLC and MLC, assuming the same die size. As was perhaps expected, die size numbers were not provided. However, last year Toshiba and Facebook talked about a case study QLC-powered SSD with 100 TB of capacity for WORM (write once read many) applications and it looks like large-capacity custom drives and memory cards will be the first to use QLC for cold storage. P/E cycles and re-write endurance isn't a concern for WORM at this stage.", "Toshiba has begun to sample its 3D QLC NAND memory devices earlier this month to various parties to enable development of SSDs and SSD controllers. Taking into account development and qualification time, Toshiba plans to mass produce its BiCS3 768 Gb 3D QLC NAND chips around the same time it starts to make its the ", ". The latter is set to hit mass production in 2018, but the exact timeframe is yet to be determined.", "Related Reading:"]},
{"title": "Samsung’s Multi-Billion Fab in Pyeongtaek Starts Production of 64-Layer V-NAND", "paragraph": ["Samsung on Tuesday announced that it had started mass production of 64-layer V-NAND memory in its newly build fab in Pyeongtaek, South Korea, and the first batch had already been shipped to one of the company’s customers. The new fab was intended to ", " manufacturing, but in the light of NAND flash shortage the company adjusted its plans at some point and now the plant produces V-NAND.", "Samsung’s semiconductor manufacturing facility in Pyeongtaek will be the largest and one of the most expensive fabs in the world once it ramps up its production to full capacity. Samsung ", " plans to build it in October, 2014, and then started construction in April, 2015. Initially, Samsung announced plans to invest ₩15.6 trillion (around $13.5 billion at the current exchange rate) in the facility, but over the past couple of years, it announced further expansion plans for the fab. As a result, investments in the Pyeongtaek facility will total ₩30 trillion ($26.1 billion) by 2021, making the complex the most expensive semiconductor manufacturing facility ever.", "According to some reports, Samsung initially planned to produce DRAM in its new fab, but given its size and scale, it was doubtful that the plant would be used only for DRAM. As it appears, Samsung decided to produce fourth-generation 3D V-NAND flash memory in its Pyeongtaek facility first, possibly because there is growing demand for NAND by Samsung’s own divisions, including Samsung Mobile. It remains to be seen when the fab in Pyeongtaek starts to manufacture DRAM ICs, which are also in short supply nowadays. Keep in mind that 3D NAND and DRAM components are produced using completely different process technologies and the former requires some additional equipment. Therefore, Samsung and other memory makers cannot switch from NAND to DRAM and vice versa without some level of equipment adjustment and reconfiguration of fab space.", "At present, Samsung does not talk about the number of wafer starts at the Pyeongtaek fab because it is not operating at full capacity. That said, the plant is not going to have a substantial impact on global NAND supply in the coming weeks or months. Once fully ramped several quarters down the road, the Pyeongtaek facility will have a significant impact on both NAND and DRAM industries, as it will increase the output of both types of memory (assuming that it will be used for DRAM in the coming quarters).", "Samsung does not disclose what kind of flash memory chips it produces in terms of capacity and performance, but says that they rely on its 64-layer V-NAND design. So far, the company officially has announced only two 64-layer V-NAND ICs. First is the 512 Gb 3D TLC NAND chip with an 800 MT/s interface data rate that the company demonstrated at the Flash Memory Summit 2016. Second, the 256 Gb 3D TLC NAND IC with a 1000 MT/s interface data rate, the company launched earlier this year and began to produce in high volume in June (presumably at another facility).", "Manufacturing of 64-layer 256 Gb chips in at least two facilities indicates that Samsung is ramping up volume production of its fourth-generation V-NAND chips and therefore it is logical to expect new products based on such ICs (e.g., SSDs, memory cards, etc.) to hit the market in the coming months. Among the more interesting products will be higher-end SSDs based on 256 Gb V-NAND chips featuring a faster interface, but it remains to be seen what kind of real-world performance advantages they are going to bring given the bandwidth limitations of PCIe 3.0 x4 bus (used for NVMe M.2 drives), or for smaller capacities. So far, Samsung has only introduced the OEM-oriented PM871b SATA SSDs in 2.5 and M.2 form-factors based on its fourth-gen V-NAND memory."]},
{"title": "Hot Chips 2016: Memory Vendors Discuss Ideas for Future Memory Tech - DDR5, Cheap HBM, & More", "paragraph": ["Continuing our Hot Chips 2016 coverage for the evening, along with the requisite presentations on processors, several of the major players in the memory industry are also at the event making their own presentations. A fast chip is only as swift as the memory that is responsible for feeding it, so the development of faster processors is inexorably tied to the development of faster memory technologies and the introduction of additional layers to the computer memory hierarchy.", "Like the chip presentations themselves, I should be clear that these aren’t product announcements. But they’re a short, useful look into the challenges the memory manufacturers face and what ideas they’re floating for future generations of memory technology.", "The first memory manufacturer to present was Micron. The firm has an interesting stake in the memory industry; while producing a number of common adopted memory technologies like DDR3 and DDR4, they have also gone their own way in pioneering HBM competitor Hybrid Memory Cube (HMC) and the faster GDDR5X memory technology. The former has not seen much success so far, while the latter has been adopted by NVIDIA for their highest bandwidth configurations on consumer (non-GP100) parts.", "One interesting slide from Micron’s presentation was showing how the memory industry has been impacted by the greater difficultly in manufacturing at smaller geometries. The number of mask levels has increased over the years – especially the number of non-lithographic steps within those mask levels – and meanwhile the total amount of cleanroom space required to hold all of the necessary equipment has similarly increased as well. For an equivalent number of wafers, Micron’s 20nm tech takes more than 80% additional space compared to 30nm, which is not very far off from the 100% increase in memory density that you get from going from 30nm to 20nm in the first place.", "The lesson here being that memory manufacturers are facing many of the same constraints as logic manufacturers. Every generation the capital costs increase – and significantly at that – which squeezes margins and investors alike. The memory industry has seen a fairly regular pattern of boom and bust cycles up until now, with each bust cycle claiming a manufacturer or two. However as the number of manufacturers dwindle, I’m not sure consolidation alone is going to be able to continue to offset the higher costs.", "Meanwhile turning towards the future, the company very briefly mentioned their current plan for the memory technology that will follow DDR4, which is aptly being named DDR5. Keeping in mind that the standard has yet to be created and ratified by the JEDEC – and likely won’t be for a couple more years – Micron would essentially like to once again double the DRAM prefetch yet again, to 16n (the same as GDDR5X). Doubling the prefetch doesn’t increase the memory’s internal clock rate, but allows for a larger number of bits to be gathered per clock, and sent out over the higher frequency bus. All the while Micron would also like to get the memory voltage down to 1.1v from today’s 1.2v for standard DDR4.", "Presumably this would be using a form of QDR (like GDDR5X), with the current aim to get it into production in 2019.", "Finally, Micron also published a useful slide that helps to illustrate where they see 3D XPoint memory fitting into the computer memory hierarchy. This is essentially split between SSD-style implementations that access the memory over the PCIe bus, and RAM-style implementations that access the memory over standard memory buses in the form of DIMMs. Neither is as fast as DRAM (and 3D XPoint lacks the near-infinite endurance of DRAM), but it allows for interesting concepts such as databases stored almost entirely in 3D XPoint memory in DIMM form, allowing for relatively fast access combined with the inherent non-volatility of the memory.", "The second of the memory manufacturers to present was Samsung. Compared to Micron, Samsung has walked the more traditional path, embracing HBM and opting not to build GDDR5X. As a result, in their presentation looking at future memory technologies, we’re seeing where they want to go from today’s HBM2 and GDDR5 technologies.", "Throughout their presentation, Samsung laid out ideas for new generation memory standards for DDR, LPDDR, and GDDR5. The bulk of Samsung’s material was on the latter two, focusing their efforts on the realms of high-bandwidth memory technologies and low-power memory technologies.", "On the low-power side, Samsung is proposing a technology they are calling LP(DDR)4X. An extension of current LPDDR4, Samsung wants to enact changes that allow reducing the memory bus voltage (VDDQ) from 1.1v to 0.6v, nearly halving the voltage required. The end goal would be to further reduce the power consumption of I/O – so not the memory itself, but rather moving data around – which combined with a process node shrink Samsung estimates could reduce total DRAM power consumption by 18%.", "As for why Samsung would do this, one needs to look no further than mobile. Power is the ultimate limiting factor of computing performance these days, and that is especially the case on mobile where there is a fixed heat budget and a fixed total power budget in joules. So any reduction in power consumption can either extend battery life, or allow Samsung to further ramp up memory performance at the same power level.", "The company also floated some high-level ideas for where they’d like to go with Post LP4 (LPDDR5). Through some optimizations such as even deeper sleep states and adjustments to factors like the precharge standby current, Samsung would like to reduce power consumption per Gbps a further 20% over LP4X.", "One other idea the company is floating particularly for SoC-type designs is PIM – Processing In Memory. This would move some logic into the DRAM, allowing processing to take place closer to the memory source. The impetus behind this is that I/O power remains one of the biggest components of memory power consumption, and in theory it’s unnecessary since it’s simply moving data rather than processing it or load/storing it. The concept here then would be that by moving some processing closer to DRAM – say parts of a GPU – then less power is spent sending data to the GPU over the expensive memory bus. Instead what’s sent is the already processed data, which is a smaller amount of data, and consequently takes less power to send. The risk, of course, is that you’re now mixing logic with memory, which can be harder to implement and validate.", "Curiously, Samsung is going almost the opposite direction at the high-end of the memory market. In a proposal for low-cost HBM, Samsung laid out a plan for how to bring down the complexity of HBM, and as a result the total cost of the fast-but-expensive memory technology. The low cost proposal essentially trades off some width for frequency; moving a stack from 1024-bits to 512-bits, but increasing the per-pin frequency by 50%. The net result is still less bandwidth than HBM2, but not immensely so.", "The big savings here come from the narrower width allowing for simpler memory stacks with fewer TSVs. TSVs are the breakthrough technology that make HBM possible, but they also remain one of the most stubborn components to get correct, as thousands of vias must be wired up inside a single stack. So a die stack with fewer TSVs will be easier to manufacture.", "The other interesting aspect of this proposal is that Samsung wants to remove the base logic/buffer die. To be honest I’m not 100% sure how this would work, as one of the fundamental tenets of HBM is that it’s a logic-to-logic (processor to logic die) connection, with the HBM stack’s logic die then coordinating the relatively dumb DRAM layers. Removing the logic die would certainly bring down costs, as it means no longer meshing logic with DRAM on a single package, but it’s not clear where the HBM PHY lies on the cost-reduced memory stack.", "Finally, partially as a consequence of the narrower I/O, Samsung wants to try to get away from silicon interposers and use organic interposers instead. Silicon interposers are simple – there’s no logic, just routing – but they’re a big chunk of silicon, and that comes at a cost. If they were able to move to an organic interposer, then the interposer cost would be significantly reduced.", "Bear in mind that all of this is just a proposal – Samsung’s slide even notes that they still need client feedback to figure all of this out – but it will be interesting to see how much of this gains traction. At the same time I’m left to wonder what the resulting power cost may be; part of what makes HBM so efficient is that it’s wide and slow. The low-cost proposal here makes HBM a little more GDDR-like, and that could sacrifice some of the efficiency improvements.", "Speaking of GDDR, Samsung also pitched their idea for what Post GDDR5 (GDDR6) would look like. Fundamentally I’m not sure this is all that different from GDDR5X; the memory clock stays the same, while the data clock is doubled versus GDDR5, implying a 16n prefetch. Samsung’s target bandwidth range is from 14 to 16Gbps, which is at the very high end of Micron’s own goals for GDDR5X. I assume there’s more to this than simply a larger prefetch and a faster bus, but we’ll have to see what happens as the manufacturers eventually bring a GDDR6 standard to the market.", "As the memory manufacturer the most responsible for the development of HBM in the first place, SK Hynix’s Hot Chips presentation was all about HBM, its uses, and how technology developed from it can be used in other applications. There’s admittedly very little forward-looking about their presentation – the bulk of it was about why HBM is such a good fit for various applications and how they ensure reliability of the complex technology – but there was a brief discussion of where they want to go for HBM3.", "The goal for HBM3 is to broaden its reach from high-end applications of today to a wider range of applications for tomorrow. No specific technologies or changes are proposed in SK Hynix’s slides, but at a high level it’s not too different from Samsung’s low-cost HBM proposal. Specifically, SK Hynix wants to make ECC an optional feature, and they want to make further changes to work on the cost and density of the technology. And of course, they also want to further improve on bandwidth, making HBM even faster at the high-end for the current types of devices that are already using HBM.", "The last memory presentation I’ll be coving is from Xilinx. The firm is better known for their FPGAs and other forms of programmable logic, but they are also a major consumer of memory technologies and have their own ideas and concerns for how the memory ecosystem should advance.", "One interesting point made by Xilinx in their presentation was that, as you’d expect for stacking components, heat is an issue. The farther down the stack you go, the warmer it gets. Besides the absolute heat concerns – exceeding a safe temperate for the HBM stack – the fact that the different layers of the memory are running at different temperatures is also less than ideal (think temperature compensation and material expansion).", "Xilinx is especially concerned here for what this means for 8-Hi stacks, which double the capacity of an HBM stack by doubling the number of DRAM layers. In practice this would make the lower DRAM and logic layers even more insulated, making them even hotter. And the sheer density of HBM (even an 8-Hi stack isn’t all that tall) makes those lower layers difficult to cool with air. As a result Xilinx is pushing for HBM to be developed so that it can withstand high Tjunction (Tj) temperatures, in order to ensure that air cooling of 8-Hi stacks is viable. To that end, Xilinx would like HBM’s TjMax to be over 95C, which is not an uncommon max temperature (GPUs and CPUs often have similar rules), but none the less illustrates how hot HBM can get.", "Meanwhile their presentation also contains a handy chart of design rule comparisons for multi-die packaging. This is specifically useful for HBM, as the principles here will be useful for bringing HBM costs down. The silicon interposer is currently the only working option, but like the other presenters, Xilinx would like to have cheaper options in order to broaden the adoption of HBM. If all goes well, technologies like organic substrates and Wafer Level Fan Out may be two such solutions to the problem."]},
{"title": "G.Skill Shows Off Trident Z 8x8 GB and 8x16 DDR4-3333 Memory Kits", "paragraph": ["When Intel launched its new Core i7 Broadwell-E processors for high-end desktops earlier this year, all leading makers of motherboards released their new breed of Intel X99-based products that were supposedly 'optimized' for the new CPUs. Makers of memory modules are also beginning to roll-out their new DDR4 quad-channel kits that can operate at high frequencies with tight timings qualified for the new processors. At IDF this week, G.Skill demonstrated two new 64 GB and 128 GB kits designed for high-end workstations that require significant memory bandwidth.", "G.Skill’s upcoming quad-channel Trident Z 64 GB (8×8 GB) memory kit is rated to run at 3333 MT/s with CL13 13-13-33 latency settings at 1.35 V. Right now, the company only offers quad-channel 64 GB DDR4-3333 kits with CL16 18-18-38 timings (albeit, these are either 4×16 GB or 8×8 GB kits). Another upcoming Trident Z quad-channel kit has 128 GB (8×16 GB) capacity and can operate at 3333 MT/s with CL14 14-14-34 timings, which is considerably better when compared to CL16 18-18-38 latencies of currently available 128 GB DDR4-3333 kits from the company.", "G.Skill claims that the Trident Z kits it demonstrated at IDF are based on Samsung’s 8 Gb DDR4 chips, but does not reveal whether these are ICs made using 20 nm or sub-20 nm process technology. More advanced DDR4 ICs coupled with the new memory controller inside Intel’s Broadwell-E CPUs could allow G.Skill to build new 64 GB and 128 GB DDR4-3333 HEDT kits with tight timings. It is to be expected that the company has managed to cherry-pick the right previous-gen ICs for its new memory modules and depending on the binning of such ICs, prices will be high.", "The demonstrations at IDF were conducted using two systems equipped with Intel Core i7-6800K processors and ASUS ROG Rampage V Edition 10 or ASUS X99-Deluxe II motherboards. The PCs were running basic applications and did not require extensive cooling.", "Traditionally, all Trident Z kits come equipped with aluminum heatsinks and feature Intel XMP 2.0 SPD profiles to make it easier for end-users to run them at their data-rates with the right timings and voltage. Expect the same features from the kits that G.Skill demonstrated at IDF.", "The manufacturer did not announce when it plans to release its new Trident Z 64 GB DDR4-3333 CL13 and Trident Z 128 GB DDR4-3333 CL14 kits as well as their prices. Right now, G.Skill’s fastest 128 GB DDR4-3200 CL16 is available for ", " – ", ", depending on the retailer. Memory prices tend to be exponential at the high end, so these will cost a lot more."]},
{"title": "Samsung Introduces 8 GB LPDDR4-4266 Package for Mobile Devices", "paragraph": ["Samsung this week announced its first LPDDR4 memory chips made using its 10nm-class DRAM fabrication technology. The new DRAM ICs feature the industry’s highest density of 16 Gb, are rated to run at 4266 MT/s data rate, and open the door to more mobile devices with 8 GB of DRAM.", "Earlier this year Samsung ", " DDR4 memory using its 10nm-class DRAM manufacturing process (which is believed to be 18 nm) and recently the firm began to use it to make LPDDR4 memory devices, just as it planned. The thinner fabrication technology allowed Samsung to increase capacity of a single LPDDR4 DRAM IC to 16 Gb (up from 12 Gb at 20nm introduced in August, 2015) while retaining a 4266 MT/s transfer rate.", "The first product to use the 16 Gb ICs is Samsung’s 8 GB LPDDR4-4266 mobile DRAM package for smartphones, tablets, and other applications that can use LPDDR4. The device stacks four memory ICs and provides up to 34 GB/s of bandwidth when connected to an SoC using a 64-bit memory bus. The 8 GB DRAM package comes in a standard 15 mm x 15 mm x 1 mm form-factor, which is compatible with typical mobile devices, but Samsung can also make the package thinner than 1 mm to enable PoP stacking with a mobile application processor or a UFS NAND storage device.", "Samsung has not revealed a lot about the cost efficiency or power consumption of the 16 Gb LPDDR4 ICs, nor have they discussed those details for the 8 GB LPDDR4 package either. What little Samsung has said is that the latter consumes approximately the same amount of power as a 4 GB LPDDR4-3200 device (four 8 Gb ICs) made using its 20 nm-class process technology. Taken at face value, one can extrapolate that the switch to the 10nm-class fabrication process allowed Samsung to double the capacity and increase performance by 33% at the same power. Unfortunately, we do not know anything about the geometry scaling of the new ICs relative to Samsung's older ICs, so it's hard to even guess how much Samsung's newest DDR4 costs to fab.", "Samsung has not officially commented on when it plans to start commercial shipments of its 8 GB LPDDR4 packages, but it is reasonable to assume that the company will commence sales of such devices in the coming months, with actual products hitting the market in 2017."]},
{"title": "Transcend Introduces Extreme Temperature DDR4 SO-DIMMs", "paragraph": ["Transcend last week introduced a family of DDR4 SO-DIMMs that can operate in extreme temperature conditions. The modules are designed for industrial computers, special-purpose PCs, POS, ATM and other systems that work in rough environments for 24/7. Subsequently, the SO-DIMMs can be used safely in SFF PCs without decent cooling for prolonged amounts of time.", "Transcend’s new industrial grade memory modules use special PCBs that have industrial-grade capacitors, 30μm gold-plated contacts and are designed to withstand shock, electromagnetic disturbance and extreme temperatures from –40°C to +85°C. In theory, it means that the SO-DIMMs are rated to operate in Antarctica or in the ", ". In the real world, Transcend’s new SO-DIMMs will be used inside space-constrained industrial PCs, military systems, embedded systems and others that work 24/7 in rough conditions and/or without decent cooling.", "The new industrial-grade modules from Transcend are based on Samsung’s 8 Gb B-die DDR4 chips (marked as K4A8G08) that were hand-picked and tested to run in extreme conditions. The SO-DIMMs come in 8 GB and 16 GB configurations and are rated to operate at 2400 MT/s at 1.2V, which means that they are fully compatible with the industrial-grade, embedded and low-power CPUs that support DDR4 at JEDEC speeds. The new modules carry Transcend’s lifetime warranty.", "Pricing of Transcend’s new industrial-grade DDR4 modules is unknown as for industrial customers it typically depends on actual sales volumes. We would expect the modules will be more expensive than typical SO-DIMMs because they use special PCBs with 30μin gold plating, components with extended temperature ranges as well as cherry-picked memory ICs.", "Related Reading:"]},
{"title": "Micron Completes Acquisition of Inotera Memories", "paragraph": ["Micron this month completed acquisition of Inotera Memories, a DRAM production company it has co-owned for eight years controlled its output for three years. The acquisition is designed to help Micron to increase its profit margins and enable the company to better manage the transition of Inotera's production capacity to newer fabrication technologies. In the meantime, Nanya Technology, a former co-owner of Inotera, gets $4.1 billion and options to license Micron’s two 10 nm-class DRAM manufacturing processes.", "Inotera was established in early 2003 as a joint venture between Nanya and Infineon, with Nanya controlling two-thirds of the company. Under the terms of the agreement, Infineon developed process technologies in exchange for part of the Inotera output (technology-for-capacity deals were common in the DRAM industry back then), whereas Nanya licensed those technologies to produce memory in its own fab. Eventually, Infineon spun its DRAM operations off as an independent company called Qimonda in 2006, and Qimonda sold its stake in Inotera to Micron in 2008 (and then went bankrupt in 2009). Micron managed to amend the agreement with Nanya in early 2013 and got exclusive right to buy all of Inotera’s output at a market price that included a profit margin shared between the owners of the manufacturer.", "Inotera’s Fab 11 manufacturing facility is located in Taoyuan, Taiwan, and reportedly accounts for ", " of Micron’s total output. As a result it is an important source of DRAM for the company. Late last year Micron and Nanya finally reached an agreement under which the former would acquire the remaining stake it did not own in Inotera for $4.1 billion, comprised of cash and equity, whereas the latter would get the money along with options to license for two generations of Micron’s DRAM process technologies following the current 20 nm (at present, the technologies are known as 1X and 1Y nm). Under the ", " negotiated a year ago, in each case when Nanya licenses Micron’s processes, the U.S.-based DRAM maker will get an equity stake in Nanya as well as royalties based on revenues from products (subject to an agreed cap). The stakes would give Micron access to profits earned by Nanya in general. It is also important to note that the licenses will be limited to a specific facility footprint and subject to a quarterly cap on production, something that significantly lowers Nanya’s opportunities to compete against Micron in terms of volumes. Moreover, the licenses are non-transferrable and terminate if Nanya is acquired by a third party.", "Now that Micron assumes full control over Inotera, it will get its output at production costs, which will be immediately beneficial to the company’s profit margins and other financial metrics. Going forward, Micron will have a full control of the fab and will thus be able to manage upgrades and align them with its other DRAM manufacturing operations in Japan and Taiwan. It is interesting to note that according to DRAMeXchange/TrendForce, Inotera transited to Micron’s 20 nm process technology quicker than Micron’s own fabs, an indicator that the production facility is a good asset with an agile management team.", "In the meantime, Nanya got at least $3.1 billion in cash and access to two of Micron’s 10 nm-class fabrication technologies, which will enable it to be competitive against other DRAM makers in terms of costs, chip capacities and performance for at least four more years. It is also important that Nanya will ensure its lead over other Taiwan-based DRAM makers, Winbond and Powerchip, by using leading-edge manufacturing nodes. What happens four years down the road is hard to tell, but for some time the company will not need to collaborate with other DRAM makers to develop process technologies. At the same time, restrictions imposed by the license agreements will limit Nanya's ability to expand its market share beyond ", " of the global output it controls now.", "Related Reading:"]},
{"title": "Crucial Announces DDR4-2666 DIMMs for Upcoming Server Platforms", "paragraph": ["Crucial this week introduced an expansion of its server-grade modules lineup with DDR4-2666 offerings. The new DIMMs will be compatible with some of the current as well as upcoming server platforms featuring Intel Xeon and other processors.", "Announced by Crucial this week are the new DDR4 LRDIMMs, RDIMMs, VLP RDIMMs, ECC SODIMMs and ECC UDIMMs rated to operate at 2666 MT/s interface speed with CL19 19-19-38 timings and at 1.2 V. The modules are available in 4 GB, 8 GB and 16 GB configurations and are aimed at less memory-dense server configurations. All the new DIMMs are powered by Micron’s 8 Gb DDR4 ICs made using 20 nm process technology, just like their DDR4-2133/2400 predecessors.", "Increasing DDR4 interface speed from 2400 MT/s to 2666 MT/s amplifies theoretical peak bandwidth by 11% to 42.6 GB/s for a dual-channel memory sub-system, to 85.3 GB/s for of a quad-channel memory sub-system as well as to 127.9 GB/s for a six-channel memory sub-system. In any case, an 11% performance increase in bandwidth-hungry workloads without any rise of power consumption is a tangible benefit for many servers. On the other hand, it is noteworthy that to increase interface speeds to 2666 Mbps, the module maker also had to adhere to JEDEC specifications rise its CAS latency from CL15/CL16 and CL17 (DDR4-2133 and DDR4-2400) to CL19, which diminishes the latency performance benefits of higher clocks.", "Suppliers of server-class memory announce their products well ahead of their high-volume availability because CPU developers and makers of actual servers have to validate DIMMs before they use them in commercial machines. The situation is a bit different today. Officially, Intel’s current-generation Xeon E5 processors featuring the Broadwell-EP cores are compatible only with DDR4-2400 or slower DIMMs. However some OEMs offer Broadwell-EP machines that can officially support DDR4-2666 for lower memory density servers. Meanwhile, Intel and other manufacturers plan to introduce next-generation server platforms (such as Purley/Skylake-EP) that officially support new DDR4 configurations in 2017 and before those machines hit the market, new DIMMs need to pass a variety of validation process.", "The new server-grade DDR4-2666 memory modules from Crucial are available for purchase now. Their exact prices depend on volumes and negotiations between Crucial and its customers.", "Related Reading:"]},
{"title": "SK Hynix Updates Lineup: 8 GB LPDDR4 DRAM Packages for Mobile Devices", "paragraph": ["SK Hynix has quietly added its new 8 GB LPDDR4 package to the family of mobile DRAM offerings. The new package paves the way for single-package smartphones and tablets with 8 GB of memory and is based on the company’s yet unannounced 16 Gb LPDDR4 ICs (integrated circuits).", "The 8 GB (64 Gb) LPDDR4 package stacks four 16 Gb DRAM parts that feature a 3733 MT/s transfer rate and provide up to 29.8 GB/s of bandwidth when connected to an application processor using a 64-bit memory bus. The 8 GB DRAM package from SK Hynix comes in a standard 15 mm × 15 mm 366-ball or 376-ball form-factor which is compatible with mainstream mobile devices. The 366-ball FBGA package can be PoP stacked with a mobile SoC or a UFS NAND storage device and is available to customers of the company now. The 376-ball FBGA will be available in Q1 2017.", "SK Hynix uses its 21 nm manufacturing technology to produce the 16 Gb LPDDR4 memory devices. By contrast, Samsung, which also recently ", " an 8 GB LPDDR4 package to its own product lineup, uses its '10 nm-class' fabrication process to make 16 Gb ICs. Thinner process technology has allowed Samsung to increase interface data rate of its 8 GB LPDDR4 package to 4266 MT/s (14% higher compared to data-rate of SK Hynix’s offering).", "The 8 GB LPDDR4-3733 package from SK Hynix features industry-standard LPDDR4 voltages, but neither the company’s ", " nor the ", " reveals the expected power consumption. Since the company keeps using its 21 nm fabrication process for its 16 Gb LPDDR4 ICs, the DRAM devices will likely consume more power than their 12 Gb predecessors. Of course, SK Hynix may have refined the design of its LPDDR4 circuits to optimize their power consumption, which will be particularly important in mobile categories.", "SK Hynix did not make any formal announcements covering the new 8 GB LPDDR4-3733 packages, which may be an indicator that it has not delivered any commercial batches of the product yet. Nonetheless, the addition of the 8 GB LPDDR4 stacks to the company’s product catalog means that they are production ready and it is reasonable to expect at least select devices to use them in 2017.", "Related Reading:"]},
{"title": "G.Skill Announces Trident Z RGB Illumination to DDR4", "paragraph": ["G.Skill this week has announced a new addition to its Trident Z family of high-performance DDR4 memory modules aimed at modders. The new Trident Z RGB will feature software-controllable RGB LEDs on top of the modules. The DIMMs will require no additional connectors and will work in all DDR4-capable computers running Windows.", "The new G.Skill Trident Z RGB modules will be based on the company’s custom 10-layer PCB, will feature speed bins up to DDR4-4266 and XMP 2.0 SPD profiles to appeal to users seeking for both style and high memory performance. The DIMMs will use Trident Z’s aluminum heat spreaders, however now equipped with RGB light bars on top (as opposed to metallic bars in case of regular DIMMs). Previously the company offered Trident Z modules with different color schemes, and the addition of RGB illumination is G.Skill’s next step.", "The manufacturer says that the Trident Z RGB will display a rainbow of colors in a wave-style lighting effect by default, but users will be able to customize lighting and design their own lighting effects using a special program that controls the light bars. G.Skill does not reveal how exactly those LEDs work or controlled, but most probably the company uses one or two of the “spare” RFU (reserved for future use) pins that DDR4 modules/slots have and/or 12 V supply pins not used on consumer DIMMs to control and power the LEDs.", "G.Skill’s Trident Z RGB will not be the first DDR4 memory modules on the market to feature light bars. For example, Corsair introduced its Vengeance LED DIMMs this summer. However, G.Skill will be the first to offer software-controllable RGB light bars on its memory modules and bring additional levels of freedom of expression to modders. You can watch G.Skill’s Trident Z demo video at the company’s ", ".", "G.Skills plans to start selling the new Trident Z memory modules with RGB lighting sometimes in mid-January 2017, so chances are there might be some at CES early next month. The manufacturer does not disclose prices of the upcoming Trident Z RGB DIMMs and it is hard to predict how much will those lighting effects cost to end users. Software to configure the lighting is set to become available from February 2017.", "Related Reading:"]},
{"title": "Intel Announces Optane Storage Brand For 3D XPoint Products", "paragraph": ["At IDF 2015 this year Intel has announced that their forthcoming 3D XPoint technology based products will be sold under a new brand for the company, Optane.", "The Optane products will be available in 2016, in both standard SSD (PCIe) form factors for everything from Ultrabooks to servers, and in a DIMM form factor for Xeon systems for even greater bandwidth and lower latencies.  As expected, Intel will be providing storage controllers optimized for the 3D XPoint memory, though no further details on that subject matter were provided. This announcement is in-line with Intel and Micron’s original 3D XPoint announcement last month, which also announced that 3D XPoint would be out in 2016.", "Finally, as part of the Optane announcement, Intel also gave the world’s first live 3D XPoint demonstration. In a system with an Optane PCIe SSD, Intel ran a quick set of live IOps benchmarks comparing the Optane SSD to their high-end P3700 SSD. The Optane SSD offered better than 5x the IOps of the P3700 SSD, with that lead growing to more than 7x at a queue depth of 1, a client-like workload where massive arrays of NAND like the P3700 traditionally struggle to achieve maximum performance."]},
{"title": "G.Skill Introduces 64GB DDR4-3200 Memory Kits", "paragraph": ["Back in the days, enthusiasts of high-end personal computers had to make a choice between capacity and performance of their memory sub-systems. This year G.Skill, Corsair and a number of other makers of advanced memory modules introduced 16GB unbuffered DDR4 DIMMs capable of working at high clock-rates and thus wedding performance and capacity. G.Skill recently announced the industry’s first 64GB DDR4 memory kits that can operate at DDR4-3200 speeds.", "G.Skill’s new 16GB DDR4 memory modules are rated to function at 3200 MTs with CL14 14-14-35 or CL15 15-15-35 latency settings at 1.35V voltage, which is higher than industry-standard 1.2V. The modules are based on G.Skill’s printed circuit boards designed for high clock-rates as well as Samsung’s 8Gb memory chips made using 20nm fabrication technology. Such DRAM devices offer both high capacity as well as high frequencies. The new modules will be sold as 32GB and 64GB memory kits under Trident Z and Ripjaws V brands. Both product families come with efficient aluminum heat spreaders.", "The new 16GB DDR4 memory modules from G.Skill feature XMP 2.0 profiles in their SPD (serial presence detect) chips, hence, can automatically set maximum clock-rates on supporting platforms.", "G.Skill officially claims that the new 16GB memory modules were validated on the Intel Core i7-6700K central processing unit and the ASUS Z170 Deluxe motherboard. Nonetheless, the new quad-channel 64GB kits consisting of four modules should also be compatible with advanced Intel X99-based motherboards running multi-core Intel Core i7 “Haswell-E” processors thanks to XMP 2.0 technology.", "Earlier this year G.Skill demonstrated a 128GB DDR4 memory kit — consisting of eight 16GB modules — running at DDR4-3000 with CL14 14-14-35 timings on the Intel Core i7-5960X processor and the ASUS Rampage V Extreme motherboard.", "It is not an easy task to build high-capacity memory modules (e.g., 16GB, 32GB, etc.) capable of working at high frequencies. Server-class registered DIMMs use over 16 memory ICs (integrated circuits) or specially packaged memory chips along with buffers that enable flawless operation of such modules. RDIMMs work at default frequencies, but can barely be overclocked. Previous-generation 8Gb memory chips produced using thicker manufacturing technologies were moderate overclockers. Samsung’s 8Gb memory chips can operate at high clock-rates and are used to build high-capacity memory modules for PCs and servers.", "G.Skill’s 64GB DDR4 kit rated to operate at DDR4-3200 with CL15 15-15-35 timings will cost $499.99 in the U.S. The 64GB DDR4-3200 kit with CL14 14-14-34 latency settings will be priced at $579.99."]},
{"title": "JEDEC Publishes HBM2 Specification as Samsung Begins Mass Production of Chips", "paragraph": ["The high-bandwidth memory (HBM) technology solves two key problems related to modern DRAM: it substantially increases bandwidth available to computing devices (e.g., GPUs) and reduces power consumption. The first-generation HBM has a number of limitations when it comes to capacity and clock-rates. However, the second-gen HBM promises to eliminate them.", "JEDEC, a major semiconductor engineering trade organization that sets standards for DRAM, recently published the final specifications of the second-generation HBM (HBM2), which means that members of the organization had ratified the standard. The new memory technology builds upon the foundation of the original JESD235 standard, which describes stacked memory devices interconnected using through silicon vias (TSVs) with a very wide input/output (I/O) interface operating at moderate data-rates. The JESD235A will help engineers to further increase performance, capacity and capabilities of HBM memory chips. HBM Gen 2 will be particularly useful for the upcoming video cards by AMD and NVIDIA, which thanks to HBM2 can feature as much as 512 GB/s – 1 TB/s of memory bandwidth and 8, 16 or even 32 GB of memory onboard.", "The original JESD235 standard defines the first-generation HBM (HBM1) memory chips with a 1024-bit interface and up to 1 Gb/s data-rate, which stack two, four or eight DRAM devices with two 128-bit channels per device on a base logic die. Each HBM stack (which is also called KGSD — known good stacked die) supports up to eight 128-bit channels because its physical interface is limited to 1024 bits. Every channel is essentially a 128-bit DDR interface with 2n prefetch architecture (256 bits per memory read and write access) that has its own DRAM banks (8 or 16 banks, depending on density), command and data interface, clock-rate, timings, etc. Each channel can work independently from other channels in the stack or even within one DRAM die. HBM stacks use passive silicon interposers to connect to host processors (e.g., GPUs). For more information about HBM check out our article called “", "”.", "HBM gen 1 memory KGSDs produced by SK Hynix (the only company that makes them commercially) stack four 2 Gb memory dies and operate at 1 Gb/s data rate per pin. AMD uses these KGSDs with 1 GB capacity and 128 GB/s peak bandwidth per stack to build its Fiji GPU system-in-packages (SiPs) and the Radeon R9 Fury/R9 Nano video cards. The graphics adapters have 4 GB of VRAM onboard, not a lot for 2016. While AMD’s flagship video cards do not seem to have capacity issues right now, 4 GB of memory per graphics adapter is a limitation. AMD’s latest graphics cards sport 512 GB/s of memory bandwidth, a massive amount by today’s standards, but even that amount could be a constraint for future high-end GPUs.", "The second-generation HBM (HBM2) technology, which is outlined by the JESD235A standard, inherits physical 128-bit DDR interface with 2n prefetch architecture, internal organization, 1024-bit input/output, 1.2 V I/O and core voltages as well as all the crucial parts of the original tech. Just like the predecessor, HBM2 supports two, four or eight DRAM devices on a base logic die (2Hi, 4Hi, 8Hi stacks) per KGSD. HBM Gen 2 expands capacity of DRAM devices within a stack to 8 Gb and increases supported data-rates up to 1.6 Gb/s or even to 2 Gb/s per pin. In addition, the new technology brings an important improvement to maximize actual bandwidth.", "One of the key enhancements of HBM2 is its Pseudo Channel mode, which divides a channel into two individual sub-channels of 64 bit I/O each, providing 128-bit prefetch per memory read and write access for each one. Pseudo channels operate at the same clock-rate, they share row and column command bus as well as CK and CKE inputs. However, they have separated banks, they decode and execute commands individually. SK Hynix says that the Pseudo Channel mode optimizes memory accesses and lowers latency, which results in higher effective bandwidth.", "If, for some reason, an ASIC developer believes that Pseudo Channel mode is not optimal for their product, then HBM2 chips can also work in Legacy mode. While memory makers expect HBM2 to deliver higher effective bandwidth than predecessors, it depends on developers of memory controllers how efficient next-generation memory sub-systems will be. In any case, we will need to test actual hardware before we can confirm that HBM2 is better than HBM1 at the same clock-rate.", "Additional improvements of HBM2 over the first-gen HBM includes lane remapping modes for hard and soft repair of lanes (HBM1 supports various DRAM cell test and repair techniques to improve yields of stacks, but not lane remapping), anti-overheating protection (KGSD can alert memory controllers of unsafe temperatures) and some other.", "The second-generation HBM memory will be produced using newer manufacturing technologies than the first-gen HBM. For example, SK Hynix uses its 29nm process to make DRAM dies for its HBM1 stacks. For HBM2 memory, the company intends to use their 21nm process. Thanks to newer manufacturing technologies and higher effective bandwidth, HBM2 should have higher energy efficiency than HBM1 at its data-rates, but we do not have exact details at this point. In any case, HBM2 is likely to be more energy efficient than GDDR5 and GDDR5X, hence the odds are good that it will be the memory of choice for high-end graphics cards in the future.", ", but did not reveal too many details. Samsung's HBM2 KGSD features 4 GB capacity, 2 Gb/s data rate per pin and is based on four 8 Gb DRAM dies. The memory chips will let device manufacturers build SiPs with up to 16 GB of memory. It is noteworthy that Samsung decided to use 8 Gb DRAM dies for its HBM2 stacks. Such decision looks quite logical since with 8 Gb DRAM ICs the company can relatively easily increase or decrease capacity of its KGSDs by altering the number of DRAM layers. The DRAM maker uses its 20nm process to produce its HBM2 DRAM KGSDs. Unfortunately, Samsung did not reveal actual power consumption of the new memory stacks.", "HBM2 memory stacks are not only faster and more capacious than HBM1 KGSDs, but they are also larger. SK Hynix’s HBM1 package has dimensions of 5.48 mm × 7.29 mm (39.94 mm", "). The company’s HBM2 chip will have dimensions of 7.75 mm × 11.87 mm (91.99 mm", "). Besides, HBM2 stacks will also be higher (0.695 mm/0.72 mm/0.745 mm vs. 0.49 mm) than HBM1 KGSDs, which may require developers of ASICs (e.g., GPUs) to install a heat-spreader on their SiPs to compensate for any differences in height between the memory stacks and GPU die, to protect the DRAM, and to guarantee sufficient cooling for high bandwidth memory.", "Larger footprint of the second-gen HBM2 means that the upcoming SiPs with multiple memory stacks will require larger silicon interposers, which means that they are going to be slightly more expensive than SiPs based on the first-gen HBM. Since geometric parameters of staggered microbump pattern of HBM1 and HBM2 are the same, complexity of passive silicon interposers will remain the same for both types of memory. A good news is that to enable 512 GB/s of bandwidth, only two HBM2 stacks are needed, which implies that from bandwidth per mm", " point of view the new memory tech continues to be very efficient.", "", "Since SK Hynix’s HBM1 KGSDs are smaller than the company’s HBM2 stacks, they are going to have an advantage over the second-gen high-bandwidth memory for small form-factor SiPs. As a result, the South Korea-based DRAM maker may retain production of its HBM1 chips for some time.", "Thanks to higher capacity and data-rates, HBM2 memory stacks will be pretty flexible when it comes to configurations. For example, it will be possible to build a 2 GB KGSD with 256 GB/s of bandwidth that will use only two 8 Gb memory dies. Such memory stack could be used for graphics adapters designed for notebooks or ultra-small personal computers. Besides, it could be used as an external cache for a hybrid microprocessor with built-in graphics (in the same manner as Intel uses its eDRAM cache to boost performance of its integrated graphics processors). What remains to be seen is the cost of HBM2 stacks that deliver 256 GB/s bandwidth. If HBM2 and the necessary interposer remains as expensive as HBM1, it will likely continue to only be used for premium solutions.", "Thanks to a variety of KGSD configurations prepared by DRAM manufacturers, expect new types of devices to start using HBM2. Samsung and SK Hynix believe that in addition to graphics and HPC (high-performance computing) cards, various server, networking and other applications will utilize the new type of memory. As of September, 2015, more than 10 companies were developing system-on-chips (including ASICs, x86 processors, ASSPs and FPGAs) with HBM support, according to SK Hynix.", "The first-generation HBM memory delivers great bandwidth and energy efficiency, but it is produced by only one maker of DRAM and is not widely supported by developers of various ASICs. By contrast, Samsung Electronics and SK Hynix, two companies that control well over 50% of the global DRAM output, will make HBM2. Micron Technology yet has to confirm its plans to build HBM2, but since this is an industry-standard type of memory, the door is open if the company wishes to produce it.", "Overall, the industry support for the high bandwidth memory technology is growing. There are 10 companies working on SoCs with HBM support, leading DRAM makers are gearing up to produce HBM2. The potential of the second-gen HBM seems to be rather high, but the costs remain a major concern. Regardless, it will be extremely interesting to see next-generation graphics cards from AMD and NVIDIA featuring HBM2 DRAM and find out what they are capable of because of the new Polaris and Pascal architectures as well as the new type of memory."]},
{"title": "Corsair and G.Skill Introduce 128 GB (8x16 GB) DDR4-3000 Memory Kits", "paragraph": ["An average personal computer nowadays is equipped with 8 GB or less of DRAM, according to analysts from ", ". Due to the requirements of Microsoft Windows 10 operating system, 8 GB may be enough for general-purpose computing. But there are PCs, particularly at the high-end desktop and workstation level, which need a lot of memory either for software, computation, RAM disks or even RAM caches to the point where motherboard manufacturers are now including such software in their bundles. To fulfill demand from owners of high-end desktops, Corsair and G.Skill this month unveiled their 128 GB quad-channel DDR4 memory kits consisting of eight DRAM modules.", "Corsair and G.Skill's 128 GB DDR4 memory kits are rated to run at 3000 MT/s per pin data-rate (DDR4-3000) and are subsequently designed for Intel's X99 platform where the quad memory bus allows for up to 96 GB/s of bandwidth with 4 or 8 DIMMs.  These quad-channel kits consist of eight 16 GB unbuffered memory modules, which are based on 8 Gb DRAM chips made by Samsung using its 20 nm fabrication process. The memory sticks fully support Intel XMP 2.0 SPD profiles and can automatically set their clock-rates when installed into appropriate PCs.", "Corsair’s Black Vengeance LPX 128 GB DDR4-3000 memory kit comes in with CL16 18-18-36 latency settings as well as the higher specification 1.35 V voltage for DDR4. The modules are equipped with black aluminum heat-spreaders to aid with cooling. Corsair also supplies their Vengeance Airflow cooling system, a removable 40mm fan cooling bracket, with the kit. Corsair’s Black Vengeance LPX 128 GB DDR4-3000 kit costs $1174.99 without tax and is ", " with the official name of CMK128GX4M8B3000C16.", "Meanwhile G.Skill’s Ripjaws V 128 GB DDR4-3000 set of DRAM modules for high-end desktop features surprisingly low latencies of CL14 14-14-34, as well as the higher 1.35V voltage. G.Skill’s Ripjaws V memory come with black or red aluminum heat-spreaders, and we assume these kits also come with extra fan cooling similar to G.Skill's other high end kits. G.Skill’s Ripjaws V 128 GB DDR4 memory kit will be priced at $999.99 when it becomes available later this month under the SKU name F4-3000C16-16GVK.", "It is noteworthy that despite of more aggressive timings and potentially higher real-world performance, G.Skill’s 128 GB DDR4 memory kit costs less than Corsair’s 128 GB DDR4 set of modules. The two companies are addressing a relatively small segment of the market with their 128 GB DRAM kits, hence, the competition between Corsair and G.Skill is inevitable. The reason for the high price for both kits comes down to binning - the ICs used for these are typically sold by the IC manufacturer as a certain bin (e.g. DDR4-2400 low voltage) and then they are individually tested by the memory stick manufacturer to fit within certain frequency ranges. At DDR4-3000 C14 for example, the process of testing might only produce one memory kit per 10000 ICs tested (educated guess) - and then the modules have to be tweaked to ensure they run together. We always recommend buying a single kit for a PC, especially of high speed memory, because the modules are designed to work together, whereas two separate kits hold no guarantee, especially if the secondary and tertiary sub-timings are close to the grain (typically these are slightly loosened for larger kits).", "At present both Corsair and G.Skill market their 16 GB DDR4-3000 memory modules as solutions for overclockers because highest JEDEC data rate validated by Intel’s Haswell-E processors is 2133 MT/s. As JEDEC’s DDR4 memory standard supports data-rates up to 3200 MT/s, eventually we might see high-speed 16 GB+ memory sticks becoming normal for workstations with memory speed-limited workloads.", "Source: Corsair, G.Skill"]},
{"title": "Micron Reports on GDDR5X Dev Progress - Volume Production This Summer", "paragraph": ["Engineers from Micron Development Center in Munich (also known as Graphics DRAM Design Center) are well known around the industry for their contribution to development of multiple graphics memory standards, including GDDR4 and GDDR5. The engineers from MDC also played a key role in development of ", ", which is expected to be used on some of the upcoming video cards. Micron disclosed the first details about GDDR5X in September last year, publicizing the existance of the standard ahead of later JEDEC ratification and offering a brief summary of what to expect. Since then the company has been quiet on their progress with GDDR5X, but in ", ", the company is touting their results with their first samples and offering an outline of when they expect to go into volume production.", "The GDDR5X standard, as you might recall, is largely based on the GDDR5 technology, but it features three important improvements: considerably higher data-rates (up to 14 Gbps per pin or potentially even higher), substantially higher-capacities (up to 16 Gb), and improved energy-efficiency (bandwidth per watt) thanks to 1.35V supply and I/O voltages. To increase performance, the GDDR5X technology uses its new quad data rate (QDR) data signaling technology to increase the amount of data transferred, in turn allowing it to use a wider 16n prefetch architecture, which enables up to 512 bit (64 Bytes) per array read or write access. Consequently, GDDR5X promises to double the performance of GDDR5 while consuming similar amounts of power, which is a very ambitious goal.", "In their blog post, Micron is reporting that they already have their first samples back from their fab - this being earlier than expected - with these samples operating at data-rates higher than 13 Gbps in the lab. At present, the company is in the middle of testing its GDDR5X production line and will be sending samples to its partners this spring.", "Thanks to reduction of Vdd/Vddq by 10% as well as new features, such as per-bank self refresh, hibernate self refresh, partial array self refresh and other, Micron’s 13 Gbps GDDR5X chips do not consume more energy than GDDR5 ICs (integrated circuits) — 2–2.5W per component (i.e., 10–30W per graphics card), just like the company promised several weeks ago. Since not all applications need maximum bandwidth, in certain cases usage of GDDR5X instead of its predecessor will help to reduce power consumption.", "GDDR5X memory chips will come in new packages, which will be slightly smaller (14×10mm vs. 14×12mm) compared to GDDR5 ICs despite the increase of their ball count (190-ball BGA vs. 170-ball BGA). According to Micron, denser ball placement, reduced ball diameter (0.4mm vs. 0.47mm) and smaller ball pitch (0.65mm vs. 0.8mm) make PCB traces slightly shorter, which should ultimately improve electrical performance and system signal integrity. Keeping in mind higher data-rates of GDDR5X’s interface, improved signal integrity is just what the doctor ordered. The GDDR5X package maintains the same 1.1mm height as the predecessor.", "Micron is using its 20 nm memory manufacturing process to make the first-generation 8 Gb GDDR5X chips. The company has been using the technology to make commercial DRAM products for several quarters now. As the company refines its fabrication process and design of the ICs, their yields and data-rate potential will increase. Micron remains optimistic about hitting 16 Gbps data-rates with its GDDR5X chips eventually, but does not disclose when it expects that to happen.", "All of that said, at this time the company has not yet figured out its GDDR5X product lineup, and nobody knows for sure whether commercial chips will hit 14 Gbps this year with the first-generation GDDR5X controllers. Typically, early adopters of new memory technologies tend to be rather conservative. For example, AMD’s Radeon HD 4870 (the world’s first video card to use GDDR5) was equipped with 512 MB of memory featuring 3.6 Gbps data-rate, whereas Qimonda (the company which established Micron’s Graphics DRAM Design Center) offered chips with 4.5 Gbps data-rate at the time.", "The first-gen GDDR5X memory chips from Micron have 8 Gb capacity, hence, they will cost more than 4 Gb chips used on graphics cards today. Moreover, due to increased pin-count, implementation cost of GDDR5X could be a little higher compared to that of GDDR5 (i.e., PCBs will get more complex and more expensive). That said, we don't expect to see GDDR5X showing up in value cards right away, as this is a high-performance technology and will have a roll-out similar to GDDR5. At the higher-end however, a video card featuring a 256-bit memory bus would be able to boast with 8 GB of memory and 352 GB/s of bandwidth.", "Finally, Micron has also announced in their blog post that they intend to commence high-volume production of GDDR5X chips in mid-2016, or sometime in the summer. It is unknown precisely when the first graphics cards featuring the new type of memory are set to hit the market, but given the timing it looks like this will happen in 2016."]},
{"title": "Price Check: Price Gap Between DDR3 and DDR4 Memory Almost Gone", "paragraph": ["Around a year ago DRAM manufacturers ended up pinning a lot of their hopes on DDR4 as a way to improve their profit margins. In the cutthroat and highly cyclical DRAM industry, the launch of DDR4-capable systems was seen as encouraging new sales while also serving as an opportunity to sell DRAM with higher margins, owing to the at the time substantial price premium over DDR3. Today however, the difference between prices of DDR3 and DDR4 memory is almost negligible and soon it will likely disappear entirely. What is even more important is that DRAM in general is getting cheaper, which is good for the end-user, but is not necessarily good for companies like Micron, Samsung and SK Hynix.", "The average price of one 4 Gb DDR4-2133 memory chip was $1.814 on Taiwanese spot market in late-February, according to ", ", one of the world’s leading DRAM and NAND market trackers. This month was the first time when the spot price of one 4Gb DDR4 memory IC dropped below $2. In late December, 2015, a DDR4-2133 chip was priced at $2.221, while in late June, 2015, a similar IC cost $3.618. Overall, one DDR4-2133 chip became 18.4% cheaper in about two months and lost nearly 50% of its price in about eight months. Meanwhile the contract price of one 4 Gb DDR4 chip was $1.63 in the second half of January.", "Spot prices of DDR3 memory are also dropping. One 4 Gb DDR3-1600 chip currently costs $1.807 in Taiwan, down from $1.878 in December and $2.658 in late June, 2015. It is clear that the price of DDR3 memory ICs is decreasing slower than the price of DDR4 DRAMs - leading to the impending DDR3/DDR4 price crossover point - but the trend is obvious: memory is getting cheaper. Contract price of one 4 Gb DDR3 IC was $1.59 in the second half of January.", "Low prices of DRAM chips naturally influence the pricing of actual memory modules. The price of one 4 GB DDR4-2133 SO-DIMM dropped to $15.50 in the second half of January (down from $18 in December, 2015), whereas the price of one 4 GB DDR3-1600 SO-DIMM decreased to $15.25 (down from $16.75 in December, 2015).", "The gap between prices of 4 Gb DDR4 and DDR3 memory ICs on the spot market is now about 7 U.S. cents, leaving DDR4 just a little more expensive than its predecessor. However, if we look at the contract price of two different 4 Gb chips, we will see that one 4 Gb DDR4 IC is an even narrower, it is only 4 U.S. cents more expensive than one 4 Gb DDR3 device. Moreover, contract prices of actual DDR4 and DDR3 4 GB DIMMs, which are used today by a lot of PC makers, are nearly the same (DDR4 is about 1.63% higher, but that is insignificant).", "It is evident that despite Chinese New Year, a holiday that traditionally drives prices of computer hardware a little bit up because of increased demand and paused production in China, prices of DDR4 DRAM chips and modules are still falling. Let’s take a look how that affects actual retail prices of various DDR4 and DDR3 kits in the U.S.", "We'll start things off with Kingston’s HyperX Fury Black DDR4-2133/CL14 2x8 GB kit (HX421C14FBK2/16), a pretty typical enthusiast-class memory module set. Such modules are used by both DIYers and system integrators, hence, their prices give us a good idea about where the market is going. Right now, Kingston's kit runs for $69.94 from Amazon, according to ", ", which tracks prices of various items at Amazon and its partners. Just about two months ago the same DDR4-2133 HyperX Fury Black 2x8GB kit was priced at $108.99, which means that it has become 33.9% cheaper in a relatively short period of time.", "Since many people these days can build relatively affordable Haswell or Skylake-based PCs, it makes sense to see how much entry-level DDR3L modules cost. Kingston introduced its HyperX Fury Low Voltage 16 GB (2*8 GB) kit (HX318LC11FBK2/16) rated to run at DDR3-1866 frequency with CL11 latency back in October at MSRP of around $96. Today, this kit costs ", " at Amazon.", "If you are willing to take some risk and use DDR3 instead of DDR3L with Skylake, there is Kingston’s HyperX Fury Black 2x8 GB DDR3-1866/CL10 kit (HX318C10FBK2/16) available for ", ", down from around $80 in December, 2015. Kingston also offers HyperX Savage Red 2x8 GB kit (HX321C11SRK2/16) that works in DDR3-2133 mode with faster CL11 12-12 sub-timings. The kit is available for ", " at Amazon and its price has not significantly changed in roughly the last half-year.", "Meanwhile G.Skill’s enthusiast-class Ripjaws V DDR4-3200/CL16 2*8 GB kit (F4-3200C16D-16GVK) currently runs for ", " from an Amazon partner. The initial price of this Ripjaws V kit in the U.S. was $176.64 when it first hit the market in November, but it quickly dropped to $136.59 in December, knocking 22% off of its price.", "At the top-end of the performance spectrum, G.Skill’s blazing-fast TridentZ DDR4-4266/CL19 2*4 GB kit (F4-4266C19D-8GTZ) is available from an Amazon partner for ", " not including shipping, which is down from ", " in mid-December, 2015. Despite being a high-priced niche product, even the G.Skill Trident Z DDR-4266 8 GB kit has become around 22% cheaper in a couple of months’ time.", "High capacity kits have also come down in price as well, though perhaps by not as much as mainstream kits. The Corsair Dominator Platinum DDR4-2666/CL15 64 GB kit (CMD64GX4M8A2666C15) was among the first 8x8 GB kits from Corsair, and was specifically designed for high-end desktops running Intel Core i7 Haswell-E processors. When it was introduced in early 2015, it cost $1759.99 at Amazon, and ended the year at $679.99. Today, this kit is priced at $539.99, a further 20.5% drop.", "In fact, Corsair has quietly introduced a new version of its Dominator Platinum 64 GB DDR4-2666/C15 kit (CMD64GX4M4A2666C15) consisting of 4*16 GB modules in December. The new quad-channel kit for HEDT PCs was initially priced at ", ", but right now, it can be acquired for ", ", or 20% below its original December launch price.", "It is obvious that retail prices of advanced non-ECC unbuffered DDR4 memory modules are dropping even faster than the prices of actual DDR4 DRAM ICs. In the last several months IC costs have continued to drop and volumes increased, while demand for all compute components in the first quarter is usually pretty low, which gives retailers like Amazon and Newegg as well as manufacturers themselves good incentive to decrease prices of their modules in a bid to keep their sales on decent levels.", "What is noteworthy is that DDR3-1866 and entry-level DDR4-2133 memory modules (such as Kingston HyperX Fury) today have almost reached pricing parity. Moreover, DDR3L and higher-end DDR3-2133 kits are more expensive than DDR4-2133 kits. While DDR3 has an advantage of lower latency, it will get considerably harder and more expensive to upgrade such platforms in the future after DRAM makers reduce production of previous-generation memory.", "The miniscule difference between DDR3 and DDR4 pricing indicates that supply of the latter is ramping up and is getting on par with the former. Meanwhile, due to slow demand for PCs in general and continuing shipments of PCs featuring previous-generation CPUs, demand for DDR4 is lower than supply. Nonetheless, since DDR4 is very affordable already, PC makers will gradually shift to the new type of DRAM. As a result, just as expected by companies like IHS and Intel, DDR4 should become the dominant PC memory standard in about a year from now.", "Which is not to say that DDR3 will disappear overnight. Intel’s latest Skylake platforms for desktops and notebooks support DDR4, DDR3L and LPDDR3 memory (except Core M, which only support DDR3L and LPDDR3), hence, PC makers can choose which type to install based on their requirements and prices. The vast majority of advanced desktops and high-performance notebooks featuring Skylake CPUs already utilize DDR4 memory. However, a lot of mainstream desktops and notebooks were designed for DDR3 modules because it used to have a considerable price advantage. Even if the price of DDR4 chips drops below that of DDR3 chips in the next couple of months, it will hardly be worth the effort to redesign motherboards of those PCs to accomodate DDR4. Moreover, many Intel’s partners still sell systems based on CPUs featuring Haswell and Broadwell micro-architectures, which only support DDR3. According to analysts from DRAMeXchange, until PC makers clear-out their previous-generation inventory, they will continue to consume a lot of DDR3. As a result, many PCs will continue to feature the previous-gen DRAM for quite a while.", "“DDR3 will still account for a large share of the PC DRAM market during the first half of 2016,” ", " Avril Wu, a research director at DRAMeXchange. “DDR4’s market share will not expand rapidly until the end of the second quarter, when PC OEMs finished clearing their inventories.”", "As Intel ramps up shipments of its Skylake processors, more and more PCs will use DDR4. Since Intel’s code-named Kaby Lake processors are rumoured to arrive only in late 2016 or early 2017, we may see a number of mainstream laptops embracing Skylake CPUs and DDR4 memory this year.", "Otherwise, from the standpoint of DRAM manufacturers, DDR4 will become the dominant type of PC-class memory already this year in terms of bits shipments. The server industry started its transition to DDR4 in Q4 2014 along with the launch of Intel Xeon Haswell-EP platform. The majority of new x86 server designs nowadays already use DDR4. Servers utilize considerably higher amounts of memory than notebooks or desktops (i.e., they consume a lot more DRAM bits than PCs), so memory makers have to produce more DDR4 memory to satisfy demands of datacenters. IHS and Intel expect crossover in DDR4 and DDR3 production to happen in 2016 and it seems like they are right in their prediction.", "The impending DDR3/DDR4 crossover is being driven by softer DRAM prices overall, which in turn is a product of weaker DRAM demand and growing inventories. Worldwide PC shipments totaled ", " units in the fourth quarter of 2015, a minor 2.7% increase from the third quarter and a 10.6% decline compared to the same period in 2014, according to IDC. Sales of tablets reached ", " units in Q4 2015, an increase of 35.3% sequentially, but a 13.7% drop year-over-year, the researchers claim. Meanwhile, shipments of smartphones hit ", " units in the fourth quarter of 2015 (up 12.4% sequentially and 5.7% YoY), setting a new record.", "The vast majority of PCs and many inexpensive tablets use commodity DDR3 or DDR4 DRAM, while smartphones use more expensive LPDDR3 or LPDDR4 memory. Even though shipments of PCs and tablets in Q4 were higher than in Q3, actual DRAM industry revenue dropped by 9.1% quarter-over-quarter to ", " due to oversupply of commodity DRAM products, market analysts claim. By contrast, LPDDR revenue fell by only 1% to ", " in the fourth quarter compared to the previous quarter, according to DRAMeXchange.", "Part of this drop in demands is of course seasonal, as sales of electronics are typically down in the first half of the year. For example, shipments of notebooks are expected to decline by ", " sequentially, whereas shipments of smartphones are projected to drop by around ", " quarter-over-quarter in Q1 2016. As a result, demand for DRAM is expected to be weak, which is why DRAM prices will remain under pressure. This in turn why we're seeing actual retail prices of memory modules decline faster than the spot/contract prices of DRAM ICs.", "“We expect notebook shipments to have a quarterly decline of 20% in the first quarter of 2016 on account of seasonality,” said Mr. Wu. “Therefore, DRAM manufacturers are under pressure to lower contract prices in order to digest inventory.”", "There are only three major DRAM manufacturers on the planet, but the competition between them remains tough. Nobody wants to cut-down DRAM production because nobody wants to lose market share. Moreover, Samsung, SK Hynix and Micron are aggressively adopting smaller manufacturing technologies to cut down costs. As fabrication processes shrink, so do the sizes of memory cells, increasing bit output per wafer and essentially boosting DRAM output and causing prices to decline further.", "Samsung began to transit its DRAM production to 20 nm fabrication technology in Q1 2014 and analysts from DRAMeXchange ", " that by now their yields are very high. Meanwhile market observers anticipate Samsung will start producing memory using their 18 nm manufacturing process sometimes in the middle of 2016, which will further increase the total capacity of DRAM on the market. Smartphone manufacturers are already preparing for the jump, and DRAMeXchange claims that Xiaomi, OPPO and Vivo have already qualified Samsung’s 12Gb mono-die LPDDR4 ICs made using 18 nm technology.", "Opposing Samsung, SK Hynix is gradually increasing their DRAM production using their 21 nm manufacturing technology. While the company’s plans concerning smaller processes are unclear, SK Hynix is ramping up its M14 fab (which was ", " in August, 2015), which will eventually have a capacity of 200 thousand wafer starts per month. Even without introducing a new process technology, SK Hynix is increasing output of DRAM by deploying the fab. Moreover, the company has not yet started high volume production of monolithic 8 Gb DDR4 ICs on their 21nm process. Once the company kicks off mass production of such chips, their bit output will increase further and will add pressure on prices.", "Finally, Micron started to produce memory chips using their 20 nm fabrication process in early 2015. Late last year the company said that they remained on-track with their conversion plan and yield targets for their 20 nm technology. In fact, according to a slide that Micron demonstrated at its Winter Analyst Conference this month, their 20 nm yields are better than their existing 25 nm yields. The Boise, Idaho-based company hopes that half of their DRAM bit output will be produced at 20nm by mid-2016. The DRAM maker also plans to increase production of high-margin memory products, including 8 Gb DDR4, 8 Gb GDDR5/GDDR5X, and LPDDR4. Micron has also publicized aggressive plans for their 16 nm manufacturing technology. The company’s fabs will be ready to start production of 16nm DRAM by September, which will further increase output provided that yield rate will be high enough.", "Otherwise, as prices of commodity 4 Gb DRAM chips are declining, makers of computer memory are now pinning their hopes on LPDDR ICs, server DRAM, and graphics/specialty memory as major profit drivers. Usage of 8 Gb DRAM ICs is also growing in servers and client PCs, so there are opportunities for memory makers to earn money in the short term, however 8 Gb chips will also commoditize over time.", "Thanks to its aggressive transitions to leading-edge process technologies as well as vast manufacturing capacities, Samsung has been the world’s largest DRAM manufacturer for well over a decade. It is not surprising that the company retained its leading position in Q4 2015.", "Samsung’s DRAM revenue for the fourth quarter dropped to $4.762 billion, or by 9.7% sequentially, according to DRAMeXchange. The company commanded 46.4% of the global memory market and is considerably ahead of the world’s second largest DRAM maker, SK Hynix. DRAM sales of the latter declined by 9.3% quarter-over-quarter to $2.865 billion, whereas its market share remained nearly flat at 27.9%. Third place Micron’s DRAM shipments deteriorated by 10.5% and totaled $1.945 billion in Q4 2015. The company’s market revenue share also decreased to 18.9%, the analysts found. By contrast, smaller memory makers (Nanya, Powerchip and Winbond), who controlled 3.7% of DRAM market share in the fourth quarter, managed to slightly increase their shipments and share mostly thanks to specialty and industrial memory.", "Samsung also shipped the lion’s share of mobile DRAM in the fourth quarter. The company’s LPDDR revenue totaled $2.619 billion, up 1.3% sequentially. Samsung in turn supplies mobile DRAM to Apple; its own mobile division, the world’s top maker of handsets; as well as rapidly growing suppliers from China.", "SK Hynix remained the distant second largest manufacturer of mobile DRAM in the fourth quarter of 2015. The company’s sales of LPDDR fell to $1.175 billion from the previous quarter, whereas its revenue share dropped to 26.1%. SK Hynix is another key supplier of LPDDR4 to Apple, which is why its shipments are still very high. Finally, Micron’s mobile DRAM sales declined by 7.7% in Q4 to $642 million, its market share shrank to 14.3%, according to analysts.", "Overall, DRAMeXchange expects LPDDR4 to account for 45% of mobile DRAM shipments this year, up from 18.2% in 2015. Meanwhile usage of 8 Gb DDR4 chips is also expected to increase, and if Samsung manages to kick off 18nm DRAM production in mid-2016, as analysts expect, it may again benefit from the capacity and power advantages of a leading-edge manufacturing process. Micron, in contrast, will only be ready with its 16 nm production technology in Q4 2016, so they won't be able to capitalize on the new process until late in the year."]},
{"title": "Micron Begins to Sample GDDR5X Memory, Unveils Specs of Chips", "paragraph": ["This past week Micron has quietly added its GDDR5X memory chips to its ", " and revealed that the DRAM devices are currently sampling to partners. The company also disclosed specifications of the chips they currently ship to allies and which potentially will be mass-produced later this summer. As it appears, the first samples, though running at much higher data rates than GDDR5, will not be reaching the maximum data rates initially laid out in the GDDR5X specification.", "The first GDDR5X memory chips from Micron are marked as MT58K256M32JA, feature 8 Gb (1GB) capacity, and are rated to run at 10 Gb/s, 11 Gb/s and 12 Gb/s in quad data rate (QDR) mode with 16n prefetch. The chips use 1.35 V supply and I/O voltage as well as 1.8 V pump voltage (Vpp). Micron’s GDDR5X memory devices sport 32-bit interfaces and come in 190-ball BGA packages with 14×10 mm dimensions. As reported, the GDDR5X DRAMs are manufactured using 20 nm process technology, which Micron has been using for over a year now.", "The GDDR5X memory standard, as you might remember from ", ", is largely based on the GDDR5 specification, but has three crucial improvements: significantly higher data-rates (up to 14 Gb/s per pin with potential up to 16 Gb/s per pin), higher and more flexible chip capacities (4 Gb, 6 Gb, 8 Gb, 12 Gb and 16 Gb capacities are supported) and better energy efficiency thanks to lower supply and I/O voltage.", "The first samples of GDDR5X memory chips fully leverage key architectural enhancements of the specification, including quad data rate (QDR) data signaling technology that doubles the amount of data transferred per cycle over the memory bus (compared to GDDR5) and allows it to use a wider 16n prefetch architecture, which enables up to 512 bit (64 Bytes) per array read or write access. However, the maximum data rates of Micron's sample chips are below tose initially advertised, possibly because of a conservative approach taken by Micron and its partners.", "The addition of GDDR5X samples to Micron’s parts catalog has three important implications. First, the initial development of Micron’s GDDR5X memory chips is officially complete and the company has achieved its key goals (to increase performance of GDDR5X without increasing its power consumption). Second, one or more customers of Micron are already testing processors with GDDR5X memory controllers, which means that certain future GPUs from companies like AMD or NVIDIA do support GDDR5X and already exist in silicon. Third, the initial GDDR5X lineup from Micron will consist of moderately clocked ICs.", "Thanks to GDDR5X memory chips with 10 Gb/s – 12 Gb/s data rates, developers of graphics cards will be able to increase peak bandwidth of 256-bit memory sub-systems to 320 GB/s – 384 GB/s. Which is an impressive achievement, because this amount of bandwidth is comparable to that of AMD’s Radeon R9 290/390 or NVIDIA’s GeForce GTX 980 Ti/Titan X graphics adapters. The latter use 512-bit and 384-bit memory interfaces, respectively, which are quite expensive and intricate to implement.", "Micron originally promised to start sampling of its GDDR5X with customers in Q1 and the company has formally delivered on its promise. What now remains to be seen is when designers of GPUs plan to roll-out their GDDR5X supporting processors. Micron claims that it is set to start mass production of the new memory this summer, which hopefully means we're going to be seeing graphics cards featuring GDDR5X before the end of the year.", "More information about GDDR5X memory:"]},
{"title": "Samsung Begins To Produce DDR4 Memory Using '10nm Class' Process Tech", "paragraph": ["Samsung Electronics has started to manufacture DDR4 memory using its new '10nm class' production technology. '10nm class', by definition, implies sub-20nm but without fully disclosing the methodology, similar to the first sub-20nm NAND production that used 1x/1y terminology. By using a sub-20 nm fabrication process, this typically helps a company make ICs/DRAM cheaper, faster and more energy efficient, depending on the process complexity. In this case, Samsung continues to use ArF (argon fluoride) immersion lithography tools with quadruple patterning to make its latest memory, which indicates a very high complexity of the new process tech. What is also important is that the new DRAMs feature Samsung’s new memory cell structure.", "In the news today, Samsung’s new DDR4 memory chips are produced using 10nm-class manufacturing technology, have 8 Gb capacity, and can operate at 3200 Mbit/s data rate (DDR4-3200). In addition, the new DRAM devices are reported to consume 10 – 20% less power than equivalent DDR4 memory ICs made using a 20 nm fabrication process, based on tests conducted by the memory maker. Finally, Samsung can produce 30% more 8 Gb chips on a single 300 mm wafer thanks to the new manufacturing technology, which will lower their costs once their yields match those of current-gen chips due to having more chips per wafer.", "Samsung does not disclose many details about its production process, such as its smallest half-pitch size (which gives actual names to DRAM manufacturing technologies, such as 20 nm or 25 nm). What we do know is that the new tech stacks very narrow cylinder-shaped capacitors on top of transistors, which implies a new DRAM cell structure (4F", "?). Manufacturers of memory have historically changed the structures of DRAM cells every five or six years, and each change represents a major technology challenge as the density changes. Samsung says that it has refined the dielectric layer deposition technology and enabled substantial performance improvements, which may mean that the new memory chips can have a higher clock-rate potential than Samsung’s existing DRAMs, or more units will pass the base tests. If this is the case, if we extrapolate, this may open doors to DDR4 memory modules with unprecedented data rates (e.g., higher than DDR4-4400). Nonetheless, use of quadruple patterning significantly increases the complexity of manufacturing, which may somewhat slow down the ramp up of the new memory ICs and cause delays in increased yield refinements.", "Samsung claims that later this year it intends to use its 1x nm manufacturing technology to make LPDDR memory with increased capacity, which should help makers of smartphones, tablets and notebooks boost the amount of DRAM inside their devices or reduce pricing.", "Use of the sub-20 nm process technology to produce 8 Gb DDR4 chips should make such DRAM ICs cheaper (eventually), which will help PC and server makers to install more memory without increasing prices of their products. At press time, one 8 Gb DDR4 chip costs $4.688, according to DRAMeXchange. By contrast, a 4 Gb DDR4 IC is priced at $1.672. Therefore, using low-capacity chips is still cheaper than using high-capacity DRAM devices. Meanwhile, if you are building servers, you might not have a choice but to utilize 8 Gb chips to create high-end memory modules (i.e., with 128 GB capacities). For that reason, for server manufacturers, Samsung’s new 8 Gb DDR4 chips should be useful."]},
{"title": "Crucial DDR4 Available for Pre-Order at OverclockersUK", "paragraph": ["\tWhile browsing the internet this evening I found a news post that started quoting UK pricing for DDR4. Given the length of time between now and the official DDR4 launch, and given that DRAM manufacturers are already ", ", a quick trip to the shopping part of Google gave some interesting numbers. Several DDR4 kits had prices listed, all from one UK retailer and all from Crucial.", "\t", "\tAll the kits on offer are quad channel, with 4x8 GB and 4x4 GB kits. Notice they are all pre-order, stating a 29/8/14 ETA (or 8/29 for the US) – the end of August.", "\tThe kits at hand are offered in several speeds and price points. Note the prices above in orange are UK pricing, which includes our 20% sales tax: the black price underneath is excluding sales tax.  Here is the price comparison without tax:", "\t2133 C16: £141.66 for 4x4GB, or £8.85 / GB", "\t2133 C16: £274.99 for 4x8GB, or £8.59 / GB", "\t2400 C16: £149.99 for 4x4GB, or £9.37 / GB", "\t2400 C16: £299.99 for 4x8GB, or £9.37 / GB", "\t2666 C15: £199.99 for 4x4GB, or £12.50 / GB", "\t2666 C15: £399.99 for 4x8GB, or £12.50 / GB", "\t3000 C15: £274.99 for 4x4GB, or £17.19 / GB", "\t3000 C15: £555.55 for 4x8GB, or £17.36 / GB", "\t", "\tAside from the obvious price premium over DDR3, as is normal for a new technology, it is worth noting that 4x4 GB of the 3000 C15 is the same price as 4x8 GB of the 2133 C16. If Crucial are this early out of the gate with online listings, the other DRAM manufacturers should not be far behind.", "\tSource: ", "\t"]},
{"title": "ADATA Officially Launches XPG Z1 DDR4 Memory", "paragraph": ["\tGiven that the supposed release date of DDR4, ", " which suggests it is almost three weeks away, DRAM module manufacturers are slowly initiating press releases to tie in with which products they will be releasing. This is good news for the rest of us, as we will get to see what timings and pricings to expect when the full release happens. Today it is ADATA launching some of its higher performance kits under the XPG Z1 branding. If you followed our Computex coverage, you will notice a striking similarity to the modules we saw ", ".", "\t", "\tAside from the regular quotes about reducing the voltage from DDR3’s 1.5 volts to 1.2 volts, ADATA is stating that its XPG Z1 range will offer speeds up to 2800 MHz with timings of CL 17-17-17, all within the 1.2 volts standard. The press release would also seem to suggest that ADATA is equipping these modules with a plug and play system, by stating ‘the SPD of XPG Z1 allows direct application without changing settings in the BIOS’. I am going to follow up with ADATA to find out what they mean by this, whether it will be plug and play or they are just referring to JEDEC", "\tThe XPG Z1 design uses the angular heatsink tapering to a point, which underneath uses a 10-layer PCB with 2-oz copper layers. The heatsink is in direct contact with the ICs, and if the past serves me correctly this is mostly likely via an epoxy that is hard to remove.", "\tThe full list of kit capabilities is listed at ", ". Kits will be available in dual (2x4/2x8) and quad (4x4/4x8) channel variants, all in red to begin with, using the following speeds:", "\t", "\tNo pricing information as of yet, but given ADATA’s previous press releases, we usually get it around two weeks after the kit being announced.", "\tSource: ", "\t"]},
{"title": "Interview with ADATA's President Shalley Chen", "paragraph": ["\tAt this year’s Computex, I had the opportunity to sit down with Mrs. Shalley Chen, ADATA’s President, to discuss the current trends in the memory and SSD business, as well as get an overview of ADATA’s future plans. Mrs. Chen has been with ADATA since the company was founded in 2001 and is also the wife of the founder, Simon Chen. Before stepping in as President in April this year, Mrs. Chen served as an Executive Vice President. Mrs. Chen also holds a degree in business management from the Ming Chuan University in Taiwan.", "\tBefore we get into the actual interview, I want to provide a brief overview of ADATA. The company generates over $1 billion in yearly revenue, which makes ADATA one of the largest memory companies in the world.  Over a half of the revenue comes from the APAC (Asia-Pacific) region, which is logical given ADATA’s Taiwanese roots and the size of the Asian market. The North and Latin America region ranks as the second largest revenue source with about 15% share in total revenue, followed by Europe and other smaller regions. In the interview Mrs. Chen hinted that Asia, Europe and especially Russia are potential future growth areas for ADATA since the memory and SSD markets are still in a developing stage, whereas in the US the markets are more mature.", "\tADATA has had an office in the US since 2002 and employs 41 people across two offices in Los Angeles and Miami. These are both sales and customer support offices with the LA office in charge of North America while the Miami office is responsible for Latin America. All R&D is done in Taiwan at ADATA HQ whereas production is split between ADATA’s owned factories in China and Taiwan. While in Taiwan I took advantage of the offer to visit ADATA’s headquarters and the Taiwanese factory, as well as take some images for another article. Ever since the company was founded, ADATA has been a memory centric company. Like many companies of a similar nature, the mission, as it stood from day one, is to become the global leading brand of memory products. Although the product portfolio has grown over the years to include newer products such as USB flash drives, external hard drives, SSDs, memory cards, and, more recently, mobile power banks - fundamentally ADATA is still a memory company. Over half of ADATA’s revenue is generated by DRAM sales, and market researches rank ADATA as the Number Two DRAM module supplier in the world.", "\tGiven the high competition in the memory and SSD business, the question I always put to the manufacturers is this: what differentiates you from all the other brands? There are a dozen consumer focused DRAM companies, and there is little room for innovation or differentiation in the industry. Mrs. Chen told me that ADATA’s best weapon against the competition starts from the diversity of the product portfolio to the close relations with both chip suppliers and distributors. Mrs. Chen was keen to point out that ADATA makes products for all three major markets (client, enterprise and industrial), giving ADATA several different revenue sources, and the percentage of revenues from enterprise and industrial is getting bigger and bigger. This directly implies that the enterprise and industrial segments are substantial to ADATA.", "\tBig enterprise OEMs like Intel and Samsung are typically interested only in large enterprises that buy upwards of tens of thousands of units, which leaves the small to medium size enterprise market to OEMs like ADATA to fight for the rest of the market. For example, some of Samsung’s enterprise products are only available to large OEMs (like EMC, Dell etc.), which leaves a niche for OEMs like ADATA and other smaller OEMs to offer better support for small to medium size enterprises. This also lends a benefit to work directly with the OEM for any customization.", "\tLike other fabless DRAM and SSD manufacturers, ADATA does not manufacture the chips they use – ADATA have to buys them from the likes of Micron and Samsung. I asked if ADATA has ever thought about moving to chip fabrication, but the answer was negative. The main reason is the cost of a fab, and investing billions of dollars is a large risk. If we look at the major semiconductor fabricators, most of them have been in the industry for decades, developing new technologies as the research progresses. As a result, it would be extremely difficult for a new player to gain any significant market share without innovation or a wide product portfolio and mountains of investment (it is worth noting that innovation can come from start-ups that have new technology but get acquired). Another point ADATA raised is that it has close relations with DRAM and NAND suppliers, and thus has no need for a chip fab. In the end, the DRAM module industry is all about managing inventory against cost and potential sales, so the competitive advantage lies in forecasting the demand and managing the inventory efficiently.", "\tThe same applies to SSD controller development. Even though controllers can be fabricated by a third party, the capital required for the development and manufacturing is still a large sum. ADATA raised STEC as an example, which took the path to design its own controller platform but got into serious financial trouble due to the cost of the development.  STEC ended up being acquired by Western Digital. ADATA does, however, have its own SSD firmware development team that has been in action since 2007. ADATA believes that the firmware team will play a key role to ensure competitiveness in the future. At this point in time, the team is mainly focusing on industrial SSD firmware development but there will be a change towards more unique firmware in the consumer side as well.", "\tOne of the big topics at Computex was the state of DDR4, and ADATA was heavily presenting its DDR4 portfolio at the show. Given ADATA’s position, the company wants to be the leader in DDR4 and will aim to push the new technology quite aggressively to both consumers and enterprises. ADATA is one of Intel’s six Haswell-E/X99 launch partners (the others are Micron, Samsung, Hynix, Kingston and Crucial), so there should be plenty of ADATA DDR4 available when the X99 platform launches later this year.", "\tI asked ADATA whether the market for DDR4 will any different from current DDR3 from an OEM perspective. Mrs. Chen replied that DDR4 is different in the sense that right now DDR4 is mostly an enterprise product and will be sold through B2B marketing. The enterprise segment, due to the demand of more units per sale, also gets a greater benefit from DDR4, which is due to the lower voltage and higher frequency. The stereotypical scenario of hundreds of racks with each server equipped with eight to sixty-four DIMMs or more, lower power consumption on one module adds up and is thus always welcome. The speed should help enterprise workloads due to the tendency to be more often bound by memory performance than client workloads.", "\tFor the end-users, ADATA showed us there will be branded products at retail as well, but until the mainstream platform adopts DDR4, the enterprise segment will be the main market. In terms of production, ADATA believes that DDR4 will overtake DDR3 in H1’15 for the enterprise market, but the same will not happen in the consumer side until sometime in 2016.", "\tAll in all, there is a lot going on in both DRAM and SSD industries at the moment, so it will be interesting to see how the market reacts. We would like to thank Mrs. Chen and ADATA for their time giving us the opportunity to discuss the DRAM and SSD markets. As part of my visit to ADATA, I also met with ADATA’s DRAM and SSD directors to discuss their technology at a lower level. Keep your eyes peeled for that article in due course."]},
{"title": "G.Skill Announces Ripjaws DDR4, up to DDR4-3200", "paragraph": ["\tMuch like the recent swathe of X99 motherboard previews we have seen, memory manufacturers are getting on board with showcasing their DDR4 memory modules to use with the Haswell-E platform. Unlike the CPUs from Intel, there is no formal NDA as such, allowing the media to report the design and specifications, although because real-world performance requires the CPU, no-one is able to post benchmark numbers.", "\tThe new DDR4 from G.Skill is the next DRAM module manufacturer to come out with an official press release, and following the previous high performance Ripjaws DDR3 range G.Skill will introduce its memory under the Ripjaws 4 moniker with a new heatspreader design.", "\t", "\tG.Skill’s press release confirms the voltage ranges for DDR4, with 1.2 volts being standard on 2133 MHz to 2800 MHz kits, with the higher performance modules at ", "\t", "\tG.Skill is reporting full XMP 2.0 support, and that this new module design matches the 40mm height of previous Ripjaws designs, allowing previous CPU coolers to be matched with this generation. As the modules are launched, the three colors G.Skill is pursuing are blue, red and black. I know G.Skill monitors our news, so if you really want another color in there, make a note in the comments.", "\t", " puts these modules at:", "\tDDR4-2133 C15 4x4GB: $260", "\tDDR4-2400 C15 4x4GB: $280 / £240", "\tDDR4-2666 C15 4x4GB: $300 / £290", "\tDDR4-3000 C15 4x4GB: $400 / £380", "\tDDR4-2133 C15 4x8GB: $480", "\tDDR4-2400 C15 4x8GB: $530 / £440", "\tDDR4-2666 C15 4x8GB: $550 / £500", "\t", "\t"]},
{"title": "Corsair Launches DDR4-3300, DDR4-3200 and DDR4-3000 Memory Kits", "paragraph": ["\tWhile the JEDEC standard for DDR3 slowly creeped up from 800 MHz to 1600-1866 MHz, the new DDR4 modules will come out of the gate at DDR4-2133 CAS 15. Similarly with DDR3, the JEDEC specifications seemed a little slow for the memory manufacturers who are all keen to get more market share than anyone else. To that extent, Corsair in conjunction with ASUS is launching today the highest specification DDR4 announced to date.", "\tThe king on the plate is a DDR4-3300 Dominator Platinum kit, designed to work with all motherboards but especially with the ASUS X99 Deluxe and Rampage V Extreme motherboards. Corsair and ASUS have formed a partnership to expedite validation on ASUS’ high end motherboards along with fine tuning: I imagine we might see a specific memory profile or two on the Extreme for users wanting to overclock these particular modules.", "\t", "\tOne of the interesting things to note is that DRAM module manufacturers all bid on batches of JEDEC or near-JEDEC specification ICs. It is then up to them to bin the ICs (either automated or by hand) to place on the modules. The higher the specification of module, typically the more ICs (or the more batches) the system has to go through, which in turn puts more pricing pressure on the kits. Pricing for these modules will be higher than most, and due to their timings will initially only be available in 4x4 GB kits. We will find out the pricing and the sub-timing when Corsair puts the kits ", ".", "\t", "\tThe 3000 and 3200 MHz kits will play up against the modules from other DRAM manufacturers, but it would seem that Corsair is first to market with the 3300 MHz modules. We plan on testing a fair amount of DDR4 in the next month, especially as it forms a significant cost of a Haswell-E build.", "\t", "\tAdditional: Specifications for the 4x4GB kits have just come in, giving:", "\tDDR4-3000 at 15-17-17-35, 1.35V (CMD16GX4M4B3000C15)", "\tDDR4-3200 at 16-18-18-36, 1.35V (CMD16GX4M4B3200C16)", "\tDDR4-3300 at 16-18-18-36, 1.35V (CMD16GX4M4B3300C16)"]},
{"title": "Haswell-E Comes, ASUS and G.Skill Take Overclocking Records", "paragraph": ["\tIn our Haswell-E coverage we did some ", " suitable for the system under the desk, and there will be users with ", ". Overclocking beyond this requires a level of skill and exotic coolants not intended for the average user, akin to what drag cars are to normal runabouts. We have previously reported on ", " where the world’s best battle it out to see who can get the best results – to see who can do that quarter mile the fastest. With the launch of the new Haswell-E platform, each of the companies invested in overclocking performance products got their best in-house teams for day one results. Both ASUS and G.Skill are two of the big winners.", "\tWith a new memory system behaving differently in terms of voltage and setup, G.Skill and ASUS worked together to hit ", " using an i7-5930K and an ASUS Rampage V Extreme, with the memory at a rather tame 1.5 volts (compared to 1.2 volts standard, 1.35 volts for high performance kits). This was using a soon-to-be-announced DDR4-3300 memory kit from G.Skill. Absolute DRAM frequency records are similar to CPU frequency records: performed with a stripped out system with the aim to get that frequency number the highest. So while the record was performed under liquid nitrogen and with a single memory module, and ultimately has little real world value, both ASUS and G.Skill can claim together that they have the world’s fastest memory.", "\t", "\tASUS’ level of records go substantially deeper than just memory. After day one of Haswell-E launch, ASUS held no fewer than 37 records across CPU frequency, CPU absolute performance and popular 3D benchmarks such as 3DMark and Catzilla.", "\t", "\t26 of these records comes from the new Rampage V Extreme paired with Haswell-E CPUs, with records coming from professional overclockers such as Shamino, 8Pack, Wizerty, Hazzan, Gunsligner, Slamms and Elmor. For example, the ", " record was performed using an i7-5960X at 5.624 GHz (+87% overclock) with four ASUS Matrix R9 290X cards at 1460/1750 (+46% overclock), G.Skill memory at DDR4-3000 C12 and the whole system under liquid nitrogen.", "\t", "\tThe records are continuously evolving, for example a ", " record has been posted in the past 24 hours with an MSI motherboard and a CPU at 5930 MHz. As overclockers start to understand the platform and the motherboard manufacturers update their BIOSes to be more amenable to extreme overclocking settings, no doubt there will be more records in the future, especially for benchmarks that can use all eight threads. Ultimately one might ask the point of all this – as an overclocker myself, sometimes getting a bigger number than the other guy is just more fun! Also learning how this hardware works outside their suggested thermal window can be an interesting experience in itself. Many of these manufacturers also use their records as an advertising tool, to say they have/support the fastest on the market as a nod towards their commitment to produce the better hardware with features that help regular users get the most from their setups.", "\t", ", ", " for images"]},
{"title": "ADATA CES Suite Tour: PCIe & TLC SSDs, Power-Loss Protection Demo, 256GB SD Cards, USB 3.1 And More", "paragraph": ["I stopped by ADATA's suite last week to see what the company has been up to in the past six months. While ADATA didn't release or announce anything new at the show, there were plenty of upcoming products on display in the suite.", "The SP320 will be ADATA's first TLC NAND based SSD and will be available sometime in the first half of 2015. It's based on Silicon Motion's new SM2256 controller, which supports LDPC error correction that increases the endurance (basically, LDPC can deal with a lot higher error rate compared to traditional BCH error correction). Capacities will range from 120GB to all the way to up to 960GB, but the exact specifications are unknown at this point.", "Moving on to PCIe, ADATA was showcasing industrial SSDs based on JMicron's JMF811 and JMF810 controllers. The JMF811 is the full-fledged version with four PCIe 2.0 lanes, whereas the JMF810 is capped to two lanes. Capacities go up to 1TB in M.2 2280 form factor and I was told that the drive is already shipping to ADATA's industrial partners. Obviously, the drive is not a retail version (hence the awkward name), but I wouldn't be surprised to see a client version with the same controller showing up later.", "Similar to Computex, ADATA was also demoing the SandForce SF3700 based SR1020. To be honest, I don't really have anything new to share on the SF3700. The live demo ADATA was showing in the suite was just sequential writes, which we have already seen before for a few times. Timing wise Seagate/SandForce is now aiming for Computex 2015, so expect to see a ton of new SSD announcements and releases around June time.", "In addition to products, ADATA was showing a neat power-loss protection test platform. The platform consists of a custom PCB that plugs into a USB port along with a special software that interrupts power delivery. The purpose of the demo was to show off ADATA's enterprise SR1010 SSD with full power-loss protection, but ADATA also promised to send us the test platform for use in future reviews.", "ADATA was also showcasing a couple of USB 3.0 drives with unique security features. The first one was the UE720, which is otherwise a typical USB 3.0 drive but features a fingerprint scanner to provide an extra layer of security.", "The other one was the UC520, which uses Bluetooth 4.0 for security. I'm not sure how exactly the encryption works with Bluetooth, but I assume the drive needs to create a Bluetooth connection with a known computer/tablet/smartphone before the contents can be accessed.", "For SD cards ADATA has a new UHS-II type XPG SDXC card with capacity of up to 256GB. The card offers read speeds of up to 150MB/s and is capable of 4K2K recording. ", "ADATA was also displaying a USB 3.1 compatible SE700 external drive with dual SSDs inside. Sequential performance goes above 800MB/s and the drive will be ready to ship once USB 3.1 platforms are available later this year.", "ADATA was one of Intel's original DDR4 launch partners and since the launch ADATA has been able to up the speeds to DDR4-3333."]},
{"title": "Mushkin Releases New Striker SSD, Displays an Upcoming M.2 PCIe 3.0 x4 NVMe SSD", "paragraph": ["Mushkin had a couple of new and upcoming products in its suite during CES. The first one is a new Striker SSD, which uses Phison's S10 controller coupled with Micron's 16nm 128Gbit MLC NAND. We already took a look at the Phison S10 controller in ", " and while it didn't set any new records, it was a decent middle-class controller. My biggest criticism about the Neutron XT was the price, but I'm confident that Mushkin's Striker will be more competitive thanks to more cost efficient NAND and typically Mushkin has been one of the value players. ", "Availability will be in Q1'15, so expect to find the Striker on the shelves in the next two months or so. Pricing is to be announced.", "Mushkin also had the 1TB Reactor on display. It's an SM2246EN based drive with Micron's 16nm 128Gbit MLC NAND and what makes it truly interesting is its ", " price tag (that's $0.36 per GB!). I got a sample right before the holidays and have been testing it since I got back from CES, so stay tuned for an in-depth review within the next couple of weeks.", "Moving on to very interesting upcoming products, Mushkin showed off the Hyperion PCIe SSD. It's based on Phison's E7 controller, which is a PCIe 3.0 x4 design with NVMe support. Performance is up to 2.8GB/s for reads and 1.2GB/s for writes and random performance is also very competitive at over 300K IOPS. The controller is still in development and so far there hasn't even been a live demo yet, but I was told that the Hyperion should hit the market during the first half of this year. ", "For current generation PCIe, Mushkin was showing the XC PCIe drive. Like the most PCIe drives on the market today, the XC is simply four SandForce SF-2281 controller in RAID 0 and as you can see, the drive consists of two modules with each having two daughterboards (i.e. one PCB per controller).", "Mushkin also has a version with four SM2246EN controllers in development. The Silicon Motion controller will enable consistent performance with all data types and in addition it supports up to 1TB per controller, hence upping the maximum capacity to 4TB.", "And like everyone else, Mushkin had an SF3700 prototype on display. Mushkin will be ready to release a drive as soon as Seagate/SandForce is ready with the controller and firmware, which should be in early Q3'15 from what I have heard.", "And no lineup is complete without some DDR4. The DIMMs Mushkin had on display were DDR4-2133 and DDR4-2400, which to be honest is nothing exciting but Mushkin has always been more of a value brand instead of being the first choice of overclockers."]},
{"title": "AMD Releases New Radeon Memory SKU: RG2133 Gamer Series", "paragraph": ["\tAfter ", ", things have for the most part been quiet for AMD’s fledgling memory operations. With DDR3 enjoying a long, prosperous reign as the memory of choice for PCs, memory is not a fast-moving field that has the kind of rapid innovation and quick product turnovers as AMD’s GPU and CPU businesses do. But with that said, even as a commodity product there’s still periodic bumps in capacity and performance, and that’s what AMD is announcing today.", "\tJoining AMD’s existing 1600MHz (RE1600) and 1866MHz (RP1866) Radeon Memory products today is a new SKU, the 2133MHz (RG2133) Gamer Series. The RG2133 is a middle of the road 2133MHz part, sporting a CAS 10 latency (10-11-11-30) and a voltage of 1.65v. In keeping with AMD’s other memory products they aren’t using any flamboyant heatsinks here, so these are simple DIMMs enclosed in a heatspreader, keeping the DIMM height at a low profile of 30mm.", "\tAs with AMD’s other memory products RG2133 memory is being manufactured and sold in 16GB kit form. The DIMMs are 4GB each – unlike AMD’s other speed grades which are 8GB these days – so the full 16GB kit is 4x4GB rather than 2x8GB. Meanwhile AMD continues to contract out the actual manufacturing of their memory products, and while they haven’t named the manufacturer of the RG2133 DIMMs they’ve said that they’re keeping the same manufacturer as with their other products, which would mean it’s once again Patriot doing AMD’s manufacturing.", "\tFor AMD the primary benefit of introducing another speed grade of RAM is not only to keep themselves competitive in the memory market, but also to work the fact that AMD’s APUs greatly benefit from increased memory bandwidth. Even though the GPUs in AMD’s APUs are lower performing than AMD’s discrete GPUs they’re still memory bandwidth starved to a very large degree, and as we’ve seen even ", " most games benefit from additional memory bandwidth. So by pairing RG2133 memory with Trinity/Richland, AMD can significantly improve their GPU performance in many cases even with the same silicon.", "\t", "\tThe catch as always will be pricing. 2133MHz memory carries a distinct premium, so although faster memory will improve gaming performance it’s not a “free” upgrade. Builders and buyers will be looking at a ", ", $30 more than the RP1866 kit. However short of adding a discrete GPU, this is going to be the best way of improving AMD’s iGPU performance for the time being.", "\tOn a final note, AMD will once more be bundling licenses for their branded version of Dataram’s RAMDisk software with their memory. RG2133 kits will come with a license good for a 64GB RAM disk (note that you can’t actually get 64GB of RG2133 into a system at the moment). All other AMD memory products will continue to ship with a license for a 6GB RAM disk. The usefulness of AMD’s RAMDisk software remains questionable, but as AMD’s pricing is generally competitive it’s essentially a freebie with an otherwise solid memory package.", "\t"]},
{"title": "Memory Scaling on Haswell CPU, IGP and dGPU: DDR3-1333 to DDR3-3000 Tested with G.Skill", "paragraph": ["\t‘How much does memory speed matter?’ is a question often asked when dealing with mainstream processor lines.  Depending on the platform, the answers might very well be different.  Similar to our comparisons with Ivy Bridge, today we publish our results for 26 different memory timings across 45 benchmarks, all using a G.Skill memory kit.", "\tIn ", " with an Ivy Bridge CPU, the results of memory testing between DDR3-1333 to DDR3-2400 afforded two main results – (a) the high end memory kit offered up to a 20% improvement, but (b) this improvement was restricted to certain memory limited tests.  In order to be more thorough, our tests in this article take a single memory kit, the G.Skill 2x4GB DDR3-3000 12-14-14 1.65V kit, through 26 different combinations of memory speed and CAS latency to see if it is better to choose one set of timings over the other.  Benchmarks chosen include my standard array of real world benchmarks, some of which are memory limited, as well as several gaming titles on IGP, single GPU and multi-GPU setups, recording both average and minimum frame rates.", "\t", "\tAs mentioned in ", ", one of the main issues with reporting memory speeds is the exclusion of the CAS Latency, or tCL.  When a user purchases memory, it comes with an associated number of sticks, each stick is of a certain size, memory speed, set of subtimings and voltage.  In fact the importance of order is such that:", "\t1.      Amount of memory", "\t2.      Number of sticks of memory", "\t3.      Placement of those sticks in the motherboard", "\t4.      The MHz of the memory", "\t5.      If XMP/AMP is enabled", "\t6.      The subtimings of the memory", "\t", "\tA user can go out and buy two memory kits, both DDR3-2400, but in reality (as shown in this review), they can perform different and have different prices.  The reason for this will be in the sub-timings of each memory kit: one might be 9-11-10 (2400 C9), and the other 11-11-11 (2400 C11).  So whenever someone boasts about a particular memory speed, ask for subtimings.", "\t", "\tFor this review, G.Skill supplied us with a pair of DDR3 modules from their TridentX range, rated at DDR3-3000.  This is at the absolute high end of memory kits, with very few memory kits going faster in terms of MHz.  Of course, in this MHz race, it comes at a price premium: $690 for 8 GB.  This memory kit uses single-sided Hynix MFR ICs, known for their high MHz numbers, and while there are large heat-spreaders on each stick, these can be removed reducing the height from 5.4 cm to 3.9 cm.", "\t", "\t", "\tHynix MFR based memory kits are used by extreme overclockers to hit the high MHz numbers.  Recently YoungPro from Australia ", " (13-31-31 sub-timings) to reach #1 in the world in pure MHz.", "\t", "\t", "\t", "\tAlmost all of these combinations are available for purchase.  For any combination of MHz and CAS, we attempt that CAS for all sub-timings, e.g. 2400 9-9-9 1T at 1.65 volts.  If this setting is unstable, we move to 9-10-9, 9-10-10 then 9-11-10 and so on until the combination is stable.", "\tThere is an odd twist when dealing with DDR3-3000.  In order to reach 3000 MHz, as Haswell does not accept the DDR3-3000 memory strap, we actually have to use the DDR3-2933 strap and boost the CPU speed to 102.3 MHz.  This leads to a slight advantage in terms of CPU throughput when using DDR3-3000 which does come through in several benchmarks.  In order to keep things even, our 4.0 GHz CPU has the multiplier reduced for 3000 C12 in order to keep the overall system speed the same, albeit with a slight BCLK advantage.", "\tAt the time of testing, DDR3-3000 C12 was the highest MHz memory kit available, but since then there are now 3100 C12 memory kits on the market taking price margins even higher at $1000 for 8 GB.  The problem at this speed is the actual overclocking of the CPU aspect of the system will skew the performance results in favor of the high end kit.", "\t", "\tFor this test, we use the following real world and compute benchmarks:", "\tCPU Real World:", "\t - WinRAR 4.2", "\t - FastStone Image Viewer", "\t - Xilisoft Video Converter", "\t - x264 HD Benchmark 4.0", "\t - TrueCrypt v7.1a AES", "\t - USB 3.0 MaxCPU Copy Test", "\tCPU Compute:", "\t - 3D Particle Movement, Single Threaded and MultiThreaded", "\t - SystemCompute ‘2D Explicit’", "\t - SystemCompute ‘3D Explicit’", "\t - SystemCompute nBody", "\t - SystemCompute 2D Implicit", "\tIGP Compute:", "\t - SystemCompute ‘2D Explicit’", "\t - SystemCompute ‘3D Explicit’", "\t - SystemCompute nBody", "\t - SystemCompute MatrixMultiplication", "\t - SystemCompute 3D Particle Movement", "\tFor what should be obvious reasons, there is no point in running synthetic tests when dealing with memory.  A synthetic test will tell you if the peak speed or latency is higher or lower – that is not a number that necessarily translates into the real world unless you can detect the type and size of all the memory accesses used within a real world environment.  The real world is more complex than a simple boost in memory read/write peak speeds.", "\tFor each of the 3D benchmarks we use an ASUS HD 6950 (flashed to HD6970) for the single GPU tests, the HD 4600 in the CPU for IGP, and a HD 5970+5870 for a lopsided tri-GPU test.", "\tGaming:", "\t - Dirt 3, Avg and Min FPS, 1360x768", "\t - Bioshock Infinite, Avg and Min FPS, 1360x768", "\t - Tomb Raider, Avg and Min FPS, 1360x768", "\t - Sleeping Dogs, Avg and Min FPS, 1360x768", "\tFirstly, I want to go through enabling XMP in the BIOS of all the major vendors."]},
{"title": "ADATA XPG V2 Review: 2x8 GB at DDR3-2400 C11-13-13 1.65 V", "paragraph": ["\tMemory has an odd part to play in the desktop ecosystem.  There is plenty of it from many different manufacturers at various prices, speeds and benefits.  Most of the differentiation comes around the product, such that two sets of 8GB DDR3-1600 might differ in warranty and aesthetics alone.  With that in mind, we have several memory kits in the office tested, and the first one under analysis is a 2x8 GB DDR3-2400 C11 kit from ADATA’s XPG V2 line.", "\tADATA’s XPG (Extreme Performance Gear) V2 line is designed to showcase ADATA’s highest memory speed modules, although the range starts at 1600 C9 and extends to 3100 C12, with all speeds in 2x4 GB kits and 2x8 GB up to DDR3-2800.  Each memory kit can be found in gold, as the kit today is, or in a tungsten grey.  ADATA sent us several XPG V2 memory kits, such as this 2400 kit and a pair of 2800 kits to review.", "\tThe 2x8 2400 C11 kit sits in that spot around the sweet spot for memory tests: it escapes the basic failures that slow kits have, yet the specification precludes the price from spiraling out of control in terms of the memory MHz race that many manufacturers are keen to be a part of.  While it is debatable if memory requires heatsinks, the gold colored ones on our XPG V2 aesthetically fit well with our ASRock Z87 OC Formula test bed and any similarly colored motherboard.", "\t", "\tOverclocking performance at a boosted 1.72 volts gave a nice jump to 2666 11-13-13 stable, and a performance index of ~240 was applicable up to 2666 MHz from an original kit PI of 218.  Out of the kits we have in to test, this was actually one of the better results by comparison.", "\tThe AX3U2400W8G11-DGV 2x8 GB kit ", ", or $12.50/GB.  There are obviously cheaper kits available if you just need a 2x8GB kit without concern for the memory speed, but unfortunately for ADATA there are kits available at almost one third less, including their own ", ", which offers all the benefits just in a different color.  As memory has a tendency to go up and down in pricing, it is often best to check on the day.", "\t", "\t", "\tMemory Specifications", "\tAs this is our first proper memory review on Haswell, we have tested some other kits which are going to be the focus of future reviews, and thus as comparison points we have listed them here to give a scale of comparison.  Compared to the G.Skill DDR3-3000 12-14-14 kit that was the focus of the Haswell memory overview, the ADATA kit we are testing today seems to have looser tWR and tFAW timings.", "\t", "\tThankfully ADATA have avoided using annoying plastic packaging that can be a pain to get into – there is a simple tab on the back to help open their XPG V2 line of memory.  The packaging is simple enough, just a thin molded plastic to hold the memory in place:", "\t", "\tThe modules themselves have additional z-height, measured at 13.8mm for a total height of 44mm (1.73 inches).", "\t", "\t"]},
{"title": "Patriot Viper III Review: 2x4 GB at DDR3-2400 C10-12-12 1.65 V", "paragraph": ["\tPerhaps I am out of the loop, but in recent CPU generations of PC building, Patriot Memory has not featured much on my radar.  A quick look at their product range tells a tale: the fastest DDR3 kits are 2400 MHz, and by comparison to some other memory manufacturers, their presence at Computex was somewhat discreet.  Nevertheless, when I got in contact for our series of quick fire Haswell memory reviews, Patriot were keen to sample a couple of their 2x4 GB Viper III kits of DDR3-2400 C10 1.65V.", "\t", "\tWith mainstream computing platforms all focused on dual channel memory, we are still in the realm where two sticks of DRAM in a kit is the norm.  Modern OSes are eating varying amounts of memory, and the more computing power people have access to, the ‘lazier’ programmers and users can be with their memory allocation.  For casual desktop users on a Windows based platform, 4 GB can easily be enough: gamers and power users can look at 8 GB and be happy, while power users/enthusiasts/multi-GPU gamers will desire a 16 GB kit minimum.  Only specific niche targets will aim for more, for which there are still a numerate selection of choices to consider.", "\tBut for most builders, an 8 GB kit still hits a nice balance between ‘enough memory’ and cost.  The kit Patriot have sent us for review is not actually on Newegg right now – the nearest to the PV38G240C0K model is actually the PV38G240C1K variant, a 2400 C11 kit, which retails for $92. On Amazon.com the PV38G240C0K kit is actually $117, although on NCIX it retails for CAD$100. Because Patriot sent us two 2400 C10 kits to test, we tested a kit as it comes and both kits together, although this is not a recommended scenario (see later). ", "\tIn terms of overclocking, this memory kit starts with an initial Performance Index of 240, and with nothing more than a small bump in voltage and a memory strap adjustment, we see 2666 10-12-12, giving a PI of 267.  Adjusting through various CL values confirmed that a PI of 267 is the best result for a 24/7 stable system, valid up to 2666 C10.  Beyond C10 the system refused to be stable above 2666 MHz, thus lowering the PI.", "\t", "\t", "\tCompared to the ADATA 2400 C11 we reviewed last time, most of the secondary sub-timings are smaller (tRC, tWR, tRRD, tFAW) - some of this will be due to the lower density (2x4 GB vs 2x8GB) memory.  The amazing thing is that our XMP detection showed a command rate of 3T for the Patriot memory, although this was reported as 2T in the operating system.", "\t", "\tIn terms of the kits we have in to test, Patriot and Corsair are doing similar packaging paradigms: a cardboard outer shell that is sealed, and an easy to open plastic insert to hold the memory stable in transit.", "\t", "\tThe heatsink extends an extra 12mm (0.47 inches) above the memory PCB, giving a total heatsink height of 36mm.", "\t", "\t", "\t", "\t", "\t", "\tFor this review, we have done two sets of numbers: one with one kit of the Patriot 2400 C10 memory, and another with two kits put in the same system.  Despite this testing, it is not a recommended scenario: do not buy two memory kits, even if they are the same model, and expect them to work together.  There are ", ", many forum posts with users having two of the same memory kits in a system and it not working.  I have even been a victim at one point to this scenario.", "\tThere are several factors at work:", "\tRule of thumb: if you want 16GB/32GB/64GB of memory, buy a 16GB/32GB/64GB kit.  If it works out it costs more, that is because the kit is fully validated in that configuration.  "]},
{"title": "ADATA XPG V1.0 Low Voltage Review: 2x8 GB at DDR3L-1600 9-11-9 1.35 V", "paragraph": ["\tFor the next in our series of memory reviews on Haswell, we have another ADATA kit to test: this time a low voltage 2x8 GB kit featuring DDR3-1600 C9 timings.  Being lower down the chain on a SKU list, the heatsinks are also smaller than the ones previously tested, and come in at £125.  Previously in our big roundup of Haswell testing we suggested 1866 C9 being the minimum people should consider: would going 1600 C9 LV matter that much in results?", "\tADATA’s line away from the more extreme (2400+) memory setups is aimed more conservative.  If they were to use the same DRAM chips on board, those 2400 MHz C10 kits might hit lower voltages or lower CL numbers when we move down to 1600 MHz, so there is some potential in diversifying the product line of the same ICs as long as the market is there.", "\tThe AXDU1600GW8G9B-2G kit we are testing today is very unassuming next to those higher end modules – a simple small metallic based heatsink.  When using a large air cooler like my TRUE Copper, they were easy enough to fit in unlike some of the larger modules.", "\t", "\tThe lower voltage element of memory intrigues me, most likely for the wrong reasons.  The difference between 1.50 volt and 1.35 volt memory, in an overall system build, is not going to affect power draw in a measurable way.  If you were building a 42U rack of servers, then yes, multiply out the DRAM modules you need across all the sockets and it can make sense if they are going to be active all the time.  But at this juncture, even when a system draws sub 30W on idle and under 100W load, I cannot see a picture where moving from 1.50V to 1.35V makes a sizeable difference to a yearly electricity bill.  Others may argue this point, but finding consistent data that converts to a decent power saving is hard to produce or come by.  It would be more applicable to buy a lower TDP CPU (such as the i7-4765T, or E3-1230L V3) instead.  That leaves a bit of e-peen for being low powered and green as positives, and the kit obviously has to stand on its own two feet when we push through the benchmarks.", "\tIn our ", " for Z87 and Haswell, our cautionary tale was that slower MHz (under 1866) kits, rather than being restrictive, have a few holes in their performance on certain benchmarks, causing a 10-20% performance drop compared to the asymptotic limit hit when you go beyond 2133-2400 MHz.  This ADATA 1600 C9 Low Voltage kit hits a couple of pot holes in that regard: WinRAR could be faster, as well as some of the minimum frame rates on a few games.", "\tFor Overclocking, our kit comes out of the bag with a Performance Index (PI) of 178: we pushed this to a PI of 200 (2000 10-12-10) with very little effort.  This is a bit different from the PI of 240-260 which we see on the higher end kits.", "\tPrice wise, 2x8 GB 1600 C9 memory kits can be found for under $150 – the cheapest on Newegg today is actually a 1.35V kit for $129, followed by a 1.65V kit for $130.  ADATA do not list this kit on Newegg, but in the UK the pricing is around £125 – if you take off our 20% tax and do the conversion, that lists it as nearer $170.  ADATA’s XPG V2 and V1 normal voltage kits are at $165, with another at $150.  This is still above some of their competition, and around $150 would make it a competitive choice for this segment.", "\t", "\tAs you can imagine, this being our 1600 C9 kit for testing, the sub-timings are smaller than all the other kits we have tested.  With a PI of 178 out of the box, there should hopefully be some room to grow.", "\tThankfully ADATA have avoided using annoying plastic packaging that can be a pain to get into – there is a simple tab on the back to help open their XPG line of memory.  The packaging is simple enough, just a thin molded plastic to hold the memory in place.  Out the memory modules come, barely taller than memory without heatsinks.", "\t", "\tThere is a slight z-height addition, but it should not affect many (if any) builds:", "\t", "\t"]},
{"title": "Rambus and Micron Bury the Hatchet; All Memory Players Now License Rambus Tech", "paragraph": ["\tBringing an end to a saga that has ", " and most of the life of this site, what’s widely considered the final major legal battle between Rambus and a memory manufacturer has come to an end. Burying the hatchet, Micron and Rambus ended their fight this week with Micron finally agreeing to license Rambus’s technologies and to pay royalties for their use.", "\tAccording to the ", " Micron will be paying Rambus a 0.6% royalty rate on all impacted products, which given Rambus’s wide patent holdings essentially covers all forms of DDR SDRAM and in turn impacts vast majority of Micron’s RAM offerings. The agreement will run for 7 years, with Micron having the option to renew it at that time (as some of Rambus’s patents should still be valid even in 2020). Notably the royalty rates are capped at $10 million per quarter – adding up to $280 million over the period of the 7 year agreement – so the final price tag will depend on Micron’s DRAM revenue if they end up staying under the cap.", "\tThis agreement comes just over ", ", which saw Hynix and Micron successfully defend themselves against claims by Rambus that the two were conspiring against Rambus. That ruling meant that the two firms were not liable for treble damages to Rambus, but it left the matter of patent infringement unresolved. Since then Hynix has settled with Rambus, leaving Micron as the last man standing until now.", "\tUltimately with the settlement of the Micron fight, Rambus has now signed licensing agreements with all of the major memory manufacturers. This means that although it’s taken the better part of a decade, Rambus has ultimately proven successful in proving that SDRAM and its descendants infringe on Rambus’s patents, allowing them to collect royalties on all of the common forms of DRAM produced today. With the last memory manufacturer now licensing their technology, the only outstanding suits (that we’re aware of) all involve companies who develop memory controllers.", "\tWith that said, this does leave the question of where Rambus goes from here. In the PC space RDRAM/XDR has long been dead, and in the console space all of the current-generation consoles are using DDR3 or GDDR5, with the remaining XDR consumption tapering off alongside the last-generation Playstation 3. But there is a very real need for faster memory technologies, especially at the very high end where NVIDIA and other GDDR5 consumers are looking at more exotic solutions such as integrating/stacking DRAM on-chip as GDDR5 reaches its own apex."]},
{"title": "Corsair Vengeance Pro Review: 2x8 GB at DDR3-2400 10-12-12 1.65 V", "paragraph": ["\tCorsair is a well-known manufacturer of PC components, including DRAM, chassis, power supplies, USB storage, fans, SSDs, gaming peripherals (keyboards, mice, headsets) and cooling, among others.  Today we are looking at some of their mid-to-high range memory from their Vengeance Pro range, designed to cater for extreme system builders with DDR3-2400 CAS 10 speeds.  This also happens to be the memory we have been using for Haswell motherboard reviews.", "\tCorsair has been a long time player in the DRAM market, along with Kingston, Crucial and a few others.  Several years ago you were hard pressed to find anyone in the PC building business who would not recommend Corsair – it was very often the case that the big names make the big bucks.  Despite this, ", " pushing away from the big names to focus on the newer brands that are more adventurous with their module binning and aggressive with their pricing.  Corsair products still hold #2 and #3 spots in terms of user choice, with ~20% of users deciding to test their system with a Corsair memory kit.", "\tIn the case of memory, as reliability rates now are extremely high for anyone not overclocking, there are several main battlegrounds: warranty, price and aesthetics.  Beauty is supposedly in the eye of the beholder – some users care about the look of the memory fits into their system, whereas others will enjoy a low price to spend another $20 on something else in the system.  Corsair’s Vengeance Pro Series comes in several colors (red, blue, silver, gold), and this particular red kit is not available on Newegg (the 2400 C11 kit does, ", "), but does feature on Corsair’s website for ", ".  Unfortunately for Corsair, Newegg lists a 2x8 GB 2400 C10 kit for $150 (reduced from $170) for sale, alongside a $280 2400 C10 Dominator Platinum kit, and there are plenty of 2400 C11 kits around the $150 mark, suggesting that an $80 bump in pricing for the CMY16GX3M2A2400C10R is actually a large stretch in a system build for what are small (if any) gains at most.", "\tIn terms of our testing, Corsair supplied us with a pair of kits, and thus we tested 2x8 GB and 4x8 GB configurations.  Note that this is not a recommended scenario – memory kits, even listed as the same timings and modules, are not guaranteed to work with each other.  When you add density, timings have to be slackened to compensate, which is not taken account for when buying two kits.  Only a full on 4x8 GB kit is guaranteed to work in this context – there are plenty of posts on the ROG forums with issues relating to users attempting to put two memory kits together.  Our CPU is a good clocker and the modules we received had some headroom such that we did not experience any issues, but your mileage may vary.", "\t2400 C10 does hit a nice sweet spot in our testing, and our kit even overclocked to 2400 C9, representing a lift in Performance Index from 240 to 267 at the 2400 MHz boundary (2600 C10 was not possible though).  But for the price, Corsair are resting on their laurels with the name of the brand being what carries them through, especially with system builders.", "\t", "\t2400 C10 already comes out high on the Performance Index scale at 240, although based on the subtimings here we can see that the tRFC and tRC are actually very loose, compared to the Patriot (2x4GB) and ADATA (2x8GB C11) kits we have tested.  Typically tRFC is a timing that helps with benchmark results and needs to be low to be the best, but at 10 we are not going to set any records here.  Interestingly enough the ASRock Z87 OC Formula gives the XMP primary timings as 10-13-13 rather than the 10-12-12 listed on the modules.", "\tIn a trend that I like, memory manufacturers are making their kits easy to get in to.  Similar to one of our previous memory reviews, Corsair places their modules in an easy to open plastic clamshell, which in turn comes in a card-like packaging which shows the module details through a transparent window.", "\t", "\tThere is a sizable addition in z-height to the modules, which will impact some large coolers including my TRUE copper when mounted for airflow bottom-to-top.", "\t", "\t", "\t"]},
{"title": "ADATA XPG V2 Review: 2x8 GB at DDR3-2800 12-14-14 1.65 V", "paragraph": ["\tThe final kit in our current run of DDR3 on Intel reviews falls at the feet of a kit that blends a high rated speed with density.  When it comes to high MHz numbers, we typically see 4 GB modules as the standard, due to a higher density kit being more difficult to push in frequency.  ADATA sampled us two of their DDR3-2800 C12 kits in 2x8 GB form, representing perhaps one of the final hurdles before DDR4 reaches the market, as long as your wallets are deep enough.", "\tI like to tell the situation how it is.  Fast memory is always a thorny issue when it comes to reviewers, due to the propensity to give awards out like candy when in fact there is little to no performance gain – it all becomes about ego with regards owning the kit.  For this reason, we tested a high end memory kit earlier this year in over 25 different configurations through ", " to find out where the law of limiting returns applies.  The result of that was that 1866 C9 / 2133 C10 was the sweet spot, and anything over this had minute returns for most of our real world testing (we accepted that there are specific compute scenarios that do continually get a benefit).", "\tSo this means that the ADATA XPG V2 DDR3-2800 C12 kit we have in to review already starts off as a quest to brag about high performance memory.  Using Hynix CFR ICs to push for frequency, ADATA took a slightly different route to most and decided on 8 GB modules rather than the standard 4 GB ones we see on the market.  This means a match between high specification and high density memory: normally a very good thing in terms of developing an ecosystem, but only as far as the wallet can afford it.", "\t", "\tThe biggest drawback ADATA have with this memory kit is the price.  When I started testing for this review, the AX3U2800W8G12-DMV kit was $600 – this has since risen to $646 due to the increase in memory pricing.  That is a lot of money, no matter which way you cut it (it falls in the middle of two other kits of similar specifications): for similar pricing you could big up a 8x8GB kit of 2133 C9 of an X79 platform or save $100 and get 4x8GB of 2666 C11 for Z87.  Pricing at the high end is monumentally crazy for what are specifications improvements rather than real world improvements.  The only reason these kits cost so much is that the memory manufacturers bid on batches of CFR ICs, and the man hours required to test them – if only one memory stick in 1000 hits the required timings and voltages, that labor has to be paid for at some level.", "\tUltimately this is a 2x8GB kit with a Performance Index out of the box of 233, which was capable of ~240 when overclocked.  Being 2800 C12, the kit does not fall into any of our benchmark pits that the low end kits fall into, but in the same breath it provides no direct advantage over any 2400 C10 kit which is substantially cheaper.", "\tAn unnamed source discussed with me this week the need for memory manufacturers to produce these high end kits, regardless of actual quantities sold, merely due to the fact that ‘everyone is doing it’ and a high MHz kit offers something in terms of marketing.  But the result still stands: 2800 C12 (and up) does not benefit end users without a specific requirement for memory speed – I would perhaps even throw in 2666 to that mix as well.  This may very well change with new games like BF4 (to be part of our 2014 testing), but at this point in our testing it makes little sense to look at high end kits other than excess cash burning a hole in your bank account.", "\t", "\tWhen using higher density memory, it is expected that some sub-timings will be slackened to ensure proper performance – ultimately the nearest kit we can compare it to is the 2400 C10 from Corsair, which had loose tRC and tRFC timings to begin with, which the ADATA beats despite being higher in MHz.  Overall the ADATA 2800 C12 numbers are in line with what we expect.", "\tLike the other ADATA memory reviews we have done over the past few months, the 2800 C12 $650 kit comes the same way as the rest – a simple plastic clamshell for easy removal.  The memory kit itself is a Tungsten Silver/Grey, compared to the Gold styling we have seen previously.", "\t", "\tThe styling is exactly the same as the ADATA 2400 C11 kit we reviewed, giving an extra 13.8mm in z-height for a total height of 44mm.", "\t", "\tADATA gave us two kits to review, in a 2x8 GB and 4x8 GB configuration.  It is worth noting that memory kits are never guaranteed to work together – they often need overclocking headroom or the CPU IMC needs to be able to cope with them.  There are plenty of issues that can arise when memory kits do not work together, and the only way to ensure that four sticks of this memory run at the rated speed is to buy a four module kit.", "\t"]},
{"title": "Patriot: 16GB is the new 8GB for Sandy Bridge-E", "paragraph": ["\tPatriot gave me a preview of their new Viper Xtreme Division4 DDR3 memory due out later this year. Patriot is targeting this new line at ", ", which support up to four channels of DDR3 memory (official support for DDR3-1600, but overclocking will surely be an option).", "\t\t", "\t\t"]},
{"title": "Sandy Bridge Memory Scaling: Choosing the Best DDR3", "paragraph": ["\t", "\tIntel's Second Generation Core processors, based on the Sandy Bridge architecture, include a number of improvements over the previous generation's Nehalem architecture. We’ll be testing one specific area today: the improved memory controller. Current Sandy Bridge based processors officially support up to DDR3-1333 memory. Unfortunately, due to changes in the architecture, using faster rated memory (or overclocking memory) on Sandy Bridge via raising the base clock is extremely limited. Luckily, there are additional memory multipliers that support DDR3-1600, DDR3-1866, and DDR3-2133 memory. Some motherboards include support for even higher memory multipliers, but we’ll confine our investigations to DDR3-2133 and below.", "\tSince Sandy Bridge is rated for up to DDR3-1333 memory, we will start there and work our way up to DDR3-2133 memory. We'll also be testing a variety of common CAS latency options for these memory speeds. Our purpose is to show how higher bandwidth memory affects performance on Sandy Bridge, and how latency changes—or doesn’t change—the picture. More specifically, we’ll be looking at the impact of memory speed on application and gaming performance, with some synthetic memory tests thrown into the mix. We’ll also test some overclocked configurations. So how much difference will lowering the CAS latency make, and does memory performance scale with processor clock speed?", "\tBack when I originally envisioned this comparison, the price gap between DDR3-1333 and DDR3-2133 memory was much wider. A quick scan of Newegg reveals that a mere $34 separates those two 4GB kits. Below is a breakdown of the lowest prices (as of 7/16/2011) for various memory configurations.", "\tYou can see from the above chart that balancing memory clocks with latency results in some interesting choices, particularly on the 8GB kits where price differences are a bit larger. Is it best to go with a slower clock speed and better timings, or vice versa, or is the optimal path somewhere in between? That’s the aim of this article."]},
{"title": "AMD to Enter RAM Market with Radeon-branded DDR3", "paragraph": ["\t", " suggests that the company will be entering the RAM market soon with their own RAM modules. The modules will be branded as Radeon, just like AMD's GPUs. At first, AMD will launch three series: Entertainment, ULTRA PRO Gaming and Enterprise. All three will have the same density of 2GB and are based on the DDR3 standard, but the speeds will vary. The Entertainment series is 1333MHz and the ULTRA PRO Gaming series is 1600MHz. Timings are 9-9-9 and 11-11-11 respectively. All three series also share the voltage of 1.5V. The speeds of the Enterprise series are to be announced. Obviously, AMD claims that their memory is the most ideal for their APU and CPU systems but at least the specifications are no different from other manufacturers' RAM. ", "\tThe more interesting fact is that the actual DRAM chips are also made by AMD. ", " However, it is possible that the chips have just been rebranded and thus been manufactured by another company, but unfortunately we don't know any details at this point. ", "\t", ": Back in 2010, we did see ", " with ATI DDR2, but we never found out why. ", "\tPricing and availability are unknown, but the Entertainment series modules are already on sale in Japan (hence the pictures). ", "\t", ": ", " is selling the 2GB Entertainment series modules for 9.99CAD (~$10.11) each, which actually makes them the most inexpensive 1333MHz 2GB modules in NCIX. However, this is with 10CAD rebate so the retail price might be closer to 20CAD per 2GB. NCIXUS doesn't seem to sell these yet though, hence US availability is still uncertain. ", "\tSource: ", ", "]},
{"title": "JEDEC Reveals Key Aspects of DDR4", "paragraph": ["\tDDR3 made its debut in mid-2007 when Intel released P35 chipset with support for DDR3. Today nearly all desktop, mobile and server platforms support DDR3. ", " estimates that DDR3 will account for roughly 90% of DRAM sales this year. However, the next generation DRAM technology is already just around the corner and JEDEC is scheduled to release the full DDR4 specification next year. Yesterday, JEDEC published some of the specifications of the upcoming DDR4 technology. ", "\tFirst and foremost, DDR4 will concentrate on performance and power consumption. The latter is achieved by lowering the voltage to 1.2V, compared to DDR3's 1.5V (although there are DDR3 modules with lower or higher voltage but 1.5V is the standard for most). The performance gain is achieved by increasing the frequency and DDR4 will start from 1600MHz. It's likely that we will see 1866MHz or 2133MHz modules as the standard though, considering that DDR3 went straight for 1066MHz as well, even though a 800MHz specification existed too. The projected maximum speed for DDR4 is 3200MHz but then again, DDR3's maximum is 1600MHz, yet 2133MHz DDR3 modules are available. We will likely see even higher bandwidth DDR4 modules in the future. JEDEC lists the prefetch buffer for DDR4 as 8n, which is identical to DDR3. If this ends up being the case the bulk of the performance increase will be due to higher operating frequencies enabled through more advanced signaling.", "\tThe higher operating frequencies come at the expense of some serialization of the interface. The SDRAM memory interface remains one of the last parallel buses in modern PCs. While it doesn't look like DDR4 will change that, we have ", " ", " of the new memory standard moving to a point-to-point protocol. In other words: one DDR4 module per memory channel. Note that JEDEC hasn't confirmed this will officially make it into the DDR4 spec."]},
{"title": "Kingston Shows off Business SF-2281 SSD & 64GB Sandy Bridge E", "paragraph": ["\tI dropped by Kingston's booth at the IDF tech showcase to check out two things this evening: Kingston's SSDNow KC100 and another Sandy Bridge E demo. The KC100 is another SF-2281 SSD but aimed at business users with a 5-year warranty instead of the 3-year warranty that comes on the HyperX. Performance should be identical to the HyperX. SandForce has a new firmware revision that is in testing now (3.30) which should fix some issues users have been having, but no word on whether or not it'll address all issues at this point.", "\tKingston also populated a Sandy Bridge E motherboard with 8 x 8GB DIMMs just to show what's possible with Intel's next high-end enthusiast platform. ", "\t"]},
{"title": "Intel and Micron Develop Hybrid Memory Cube, Stacked DRAM is Coming", "paragraph": ["\tDuring the final keynote of IDF, Intel's Justin Rattner demonstrated a new stacked DRAM technology called the Hybrid Memory Cube (HMC). The need is clear: if CPU performance is to continue to scale, there can't be any bottlenecks preventing that scaling from happening. Memory bandwidth has always been a bottleneck we've been worried about as an industry. Ten years ago the worry was that parallel DRAM interfaces wouldn't be able to cut it. Thankfully through tons of innovation we're able to put down 128-bit wide DRAM paths on mainstream motherboards and use some very high speed memories attached to it. What many thought couldn't be done became commonplace and affordable. The question is where do we go from there? DRAM frequencies won't scale forever and continually widening buses isn't exactly feasible.", "\tIntel and Micron came up with an idea. Take a DRAM stack and mate it with a logic process (think CPU process, not DRAM fabs) layer for buffering and routing and you can deliver a very high bandwidth, low power DRAM. The buffer layer is actually key here because it helps solve the problem of routing pins to multiple DRAM die. By using a more advanced logic process it's likely that the problem of routing all of that data is made easier. It's this stacked DRAM + logic that's called the Hybrid Memory Cube. ", "\t ", "\t", "\tThe prototype these two companies developed is good for data rates of up to 1 terabit per second of bandwidth. Intel claims that the technology can deliver bandwidth at 7x the power efficiency of the most efficient DDR3 available today. ", "\tThe big concern here is obviously manufacturing and by extension, cost. But as with all technologies in this industry, if there's a need, they'll find a way."]},
{"title": "Rambus Loses Major Antitrust Case Against Hynix & Micron", "paragraph": ["\tThere are few companies in the tech world as infamous as Rambus, an IP-only RAM development firm. For the better part of 10 years now they have been engaged in court cases with virtually every RAM and x86 chipset manufacturer around over the violation of their patents. Through a long series of events SDRAM did end up implementing RAMBUS technologies, and the American courts have generally upheld the view that in spite of everything that happened while Rambus was a member of the JEDEC trade group that their patents and claims against other manufacturers for infringement are legitimate. At this point most companies using SDRAM have settled with Rambus on these matters.", "\tSince then Rambus has moved on to a new round of lawsuits, focusing on the aftermath of Rambus’s disastrous attempt to get RDRAM adopted as the standard RAM technology for computers. Rambus has long held that they did not fail for market reasons, but rather because of collusion and widespread price fixing by RAM manufacturers, who purposely wanted to drive Rambus out of the market in favor of their SDRAM businesses. The price fixing issue was investigated by the Department of Justice – who found the RAM manufacturers guilty – which in turn Rambus is using in their suits as further proof of collusion against Rambus.", "\tThe biggest of these suits was filed in 2004 against the quartet of Samsung, Infineon, Hynix, and Micron. In 2005 Infineon settled with Rambus for $150 million while in 2010 Samsung settled with Rambus for $900 million, leaving just Hynix and Micron to defend. That suit finally went to court in 2011, with Rambus claiming that collusion resulted in them losing $4 billion in sales, which as a result of California’s treble damage policy potentially put Hynix and Micron on the line for just shy of $12 billion in damages.", "\tToday a verdict was finally announced in the case, and it was against Rambus. A 12 member jury found in a 9-3 vote that Hynix and Micron did not conspire against Rambus, effectively refuting the idea that RAM manufacturers were responsible for Rambus’s market failure. As Rambus’s business relies primarily on litigation – their own RAM designs bring in relatively little due to the limited use of RDRAM and XDR – this is a significant blow for the company.", "\tRambus can of course file an appeal, as they have done in the past when they’ve lost cases, but the consensus is that Rambus is extremely unlikely to win such an appeal. If that’s the case this could mean that this is the beginning of a significant shift in business practices for Rambus, as while they have other outstanding cases – most notably against NVIDIA – the anti-trust suit was the largest and most important of them. Not surprising their stock also took a heavy hit as a result, as it ended the day down 60%. Rambus winning the anti-trust suit had long been factored into the stock price, so the loss significantly reduced the perceived value of the company.", "\tSource: ", "; ", "; "]},
{"title": "Introducing AMD’s Memory Brand", "paragraph": ["\tWe discussed the availability of ", " earlier this month, but today AMD is officially unveiling information on their memory platform. There are a few major questions many will have: why is AMD entering the memory market at all, and what do they hope to offer that we can’t already get from other vendors? Let’s take those in turns.", "\tThe reason for AMD’s entry into the memory market comes from two areas. First, AMD’s APUs are now shipping in large volumes and can definitely benefit from higher bandwidth memory modules. We’ve already shown the sort of ", " with higher clocked DRAM, but many people buy A-series APUs as part of a prebuilt system, and right now lots of OEMs are still cutting corners on the RAM and using DDR3-1333. That’s the second aspect of the move: AMD wants to enable a [buzzword alert!] “holistic customer platform experience”, and they may be able to help drive down costs for AMD platforms. A final element AMD mentions is a desire to drive and enable future memory product developments.", "\tThe other item to discuss is what AMD offers that we may not already have. Here the distinction between AMD branded memory and other options isn’t quite so clear, but AMD will be doing testing and validation in their labs using AMD platforms. AMD also notes that they will not be using any ETT (Effectively TesTed) or gray market RAM. The latter is used as a term to collectively group hardware that may be less desirable; as an example, Intel unboxed CPUs are “gray market” because they are intended for OEM use but can still end up being sold at retail. Basically, gray market parts would cut out some of the supply channel (in the example just cited, gray box processors typically cut out AMD/Intel and only have a short warranty from the seller). ETT parts on the other hand are a way of cutting costs by skipping branding; the RAM is still tested and is supposed to be high quality, but without branding it’s one small way to reduce costs. Generally speaking, ETT memory is destined for value RAM modules, so basically AMD is saying is that their AMD RAM will start out a step above value RAM. AMD also states that they will take end-to-end ownership of the AMD Memory ecosystem, working with module manufacturers, memory partners, IC partners, distributors, and VARs (value added resellers).", "\tWith that out of the way, let’s discuss the specifics of what AMD Memory will be available and the target markets. Here’s a slide from AMD’s presentation summarizing things:", "\t", "\t As you would expect from any memory, the AMD RAM will work with both AMD and Intel platforms; the main difference between the tiers will be the speed and packaging. Entertainment Edition memory will target the mainstream/value segment, come in single 2GB and 4GB DIMM packages, and is rated for CL9 operation at DDR3-1333 and/or DDR3-1600; Entertainment Edition memory is already available, starting in October. The Performance Edition memory should start shipping this month, and it will come in 2GB, 4GB, and 8GB capacities (these are presumably two-DIMM kits with 4GB, 8GB, and 16GB total capacities; Bulldozer could potentially use four-DIMM kits). The main difference with Performance Edition memory is that it is rated for CL8 operation at DDR3-1333/1600 speeds. Last is the Radeon Edition memory, which will come in 4GB and 8GB kits and offer DDR3-1866 and up to DDR3-2133 support with CL9 operation (and presumably CL7/8 operation at lower speeds). The Radeon Edition parts will also have support for overclocking via AMD OverDrive software; availability is expected in Jan/Feb 2012.", "\tSo what does all of this really mean? That’s the difficult part. If all AMD memory supported speeds of at least DDR3-1600, that would be a clear break from the current offerings, but the press release indicates that there will be both DDR3-1333 and DDR3-1600 parts. The upgrade to DDR3-1600 provides a significant performance increase; we linked our Llano A8-3850 article above showing some of our own results, but here are some charts of our testing along with AMD’s results:", "\t", "\tAMD shows up to a 20% performance increase in their testing by upgrading from DDR3-1333 to DDR3-1600, while our own results show an average increase in performance of around 14% across seven tested games (with a range of improvement of around 8% to 41%). Should you choose to spring for faster DDR3-1866 memory (or just overclock some decent DDR3-1600 RAM), the average performance increase is around 20% and up to 40% in some cases (or as low as 8% in Civ5). This isn’t too surprising as the AMD Fusion GPUs are significantly faster than competing solutions and the combination of shared memory bandwidth with the rest of the platform along with generally slower memory speeds (compared to dedicated GPUs) is a double-whammy. So why would AMD continue to sell anything less than DDR3-1600? Your guess is as good as mine.", "\t", "\tSeveral of us have chatted about the AMD Memory announcement, and really we’re not quite sure if this is necessary or useful. If it means systems with better quality and higher performance RAM at the same price, that would be a good thing, but the persistence of DDR3-1333 for desktop parts doesn’t jive with that goal. What’s more, RAM prices are already incredibly low, so AMD entering a commodity market doesn’t appear to be a good way to improve the bottom line.", "\tAMD’s first partners for their branded memory initiative are Patriot Memory and VisionTek, with Patriot being a familiar name to memory shoppers and VisionTek known for their graphics products. There’s nothing inherently wrong with AMD branded memory, but unless the price is lower than existing options (e.g. AMD mentions bundles as something we’re likely to see), there’s also not much that it adds to the market. For now, we’ll stick with recommending you buy RAM that will supports at least DDR3-1600 speeds if you’re buying a Llano (or future APU) system; whether that memory is AMD branded or otherwise will likely be far less important than how much the memory costs for the desired level of performance."]},
{"title": "AT News Update: AMD Sidelines DDR2 for 2004", "paragraph": ["Although we have had some strong evidence that AMD will not adopt DDR2 soon, today we received officialword that AMD will ", " adopt DDR2 in 2004, and certainly not well into 2005.", "AMD's DDR2 philosophy revolves around performance, priceand availability; that is, AMD will not implement DDR2 until all three ofthose criteria are suitable for entry.  Our sources claim this is the same strategyAMD approached to memory when it chose DDR memory over Rambus several yearsago.  ", "Perhaps the most interesting statement in AMD's newestrelease was the two key points outlined for the actual deployment of DDR2:", "Sadly, there were no sources to cite as to whether those twokey points were mutually inclusive.  Multiple sources confirm DDR2-667deployment could be here as early as Q2'05.", "Let us consider the significant negative performance issuewith DDR2 for now; latency.  If you had a chance to read our ", ", aswell as our ", " last week, you've seen that DDR2-400 and DDR1-400 have equivalent thoroughput.  Unfortunately for DDR2, we won't see timings better than 4-4-4 (while DDR1-400 can achieve 2-2-2 relatively easily).  This could in fact become ablessing in disguise for AMD.  ", "The onboard memory controller for Athlon 64 enhancesperformance more so than any other feature on the new chips (although, the64-bit addressing is pretty nice too).  Since each individual processor revisiondictates the memory clock, AMD is free release its next generation A64 with a533MHz memory bus if they wish.  Intel, on the other hand, relies on upgradingthe FSB clock on its CPUs and the memory controller in order to achieve ahigher memory clock.  DDR2 will be very easy for AMD and its partners toincorporate.  AMD upgrades the memory controller on the processor, and themotherboard manufacturers replace the 184pin DDR1 DIMM with the 240pin DIMMneeded for DDR2 - no new Northbridge."]},
{"title": "Weekly Memory & Motherboard Price Guide: March 2001 1st Edition", "paragraph": ["It's time once again for AnandTech's Memory and Motherboard price guide.", "  ", "  The basic goal is to provide you with the best deals, and follow price trends   of the listed products. We have selected a leading team of on-line vendors,   and will be tracking their progress on weekly basis. Please note that all vendors   were selected according to their best price offered. Some vendors may ask that   you place a phone-order to make sure that you receive our listed price; others   simply ask that you mention where you found the price (in this case AnandTech).   We have tried to eliminate vendors with low feedback rating, but we do encourage   you to do some research before purchasing any product from this list. ", "If you encounter any problems with a vendor on our list, please ", ", and we will take   appropriate action. Remember that we will only list vendors with positive customer   feedback. If you have any suggestions, don't hesitate to ", ". ", "Also be sure to check out ", " for even more great memory, motherboard, CPU, video card   and other technology buys. ", "AnandTech does not endorse any vendor listed in the following price guide.   AnandTech does not receive any advertising fees and/or sponsorship from the   listed vendors. All views expressed by listed vendors do not reflect the opinions   of AnandTech.", "AnandTech, nor any of the vendors mentioned guarantee that the prices listed   in this guide are accurate. ", "This week we've spiced up our Memory and Motherboard price guide with the addition   of ten VIA Apollo Pro 133A-based Socket 370/Slot-1 motherboards. As you might   recall, the Apollo Pro 133A chipset delivers PC100 and PC133 memory support   along with AGP 4X, AC97 & MC97, and 133MHz FSB features. The   flexibility of this platform as well prices of motherboards based on this chipset   are comparable to those of i815-based boards which convinced us to add Apollo   Pro 133A boards to our price guide. ", "As far as prices of the other motherboards that we list, not much has changed   since our last guide. This is especially true with KT133-based boards which   have., for the moment, stabilized in price. Both Socket-370 and Socket-423 motherboards   have remained quiet in terms of price with no significant shifts.", "In the memory arena the situation is reminiscent of our price guide dating   back to early February where we saw almost every memory module drop in price.   This week the drops are not as dramatic as before but are nonetheless present   as memory prices continue to take a nosedive."]},
{"title": "Weekly Memory & Motherboard Price Guide: April 2001 1st Edition", "paragraph": ["It's time once again for AnandTech's Memory and Motherboard price guide.", "  ", "  The basic goal is to provide you with the best deals, and follow price trends   of the listed products. We have selected a leading team of on-line vendors,   and will be tracking their progress on weekly basis. Please note that all vendors   were selected according to their best price offered. Some vendors may ask that   you place a phone-order to make sure that you receive our listed price; others   simply ask that you mention where you found the price (in this case AnandTech).   We have tried to eliminate vendors with low feedback rating, but we do encourage   you to do some research before purchasing any product from this list. ", "If you encounter any problems with a vendor on our list, please ", ", and we will take   appropriate action. Remember that we will only list vendors with positive customer   feedback. If you have any suggestions, don't hesitate to ", ". ", "Also be sure to check out ", " for even more great memory, motherboard, CPU, video card   and other technology buys. ", "AnandTech does not endorse any vendor listed in the following price guide.   AnandTech does not receive any advertising fees and/or sponsorship from the   listed vendors. All views expressed by listed vendors do not reflect the opinions   of AnandTech.", "AnandTech, nor any of the vendors mentioned guarantee that the prices listed   in this guide are accurate. "]},
{"title": "865PE & 875P Memory Guide", "paragraph": ["It's not often that we cover seventeen motherboards for just one memory article,   but ever since motherboards based on Intel's 800MHz FSB series of chipsets   were released at the end of April/beginning of May we felt the need to educate   our readers on the severe memory-related issues that have plagued these motherboards. ", "You'll remember from our ", " we encountered a number of compatibility   issues with DDR400 SDRAM and the 865PE chipset. It turns out that we weren't   the only ones; users all over the web were reporting problems. As a result we felt it was necessary to get to the bottom of these issues, and so took it upon ourselves to test five of the most   popular DDR400 memory modules and nearly all the 865PE/875P motherboards we had access   to. ", "For this review we compared five pairs of modules: Corsair LL (Low   Latency) TwinX DDR400, Crucial DDR400, OCZ EL DDR400, TwinMOS DDR400, and Kingston HyperX DDR433 (running at 400MHz DDR). ", "We requested a pair of 256MB modules be sent from every manufacturer   to be used in this review. You'll find pictures of the modules we tested below:", " All graphs on the following pages represent performance numbers from Quake 3 Arena. The /timedemo 1 benchmark was used.         "]},
{"title": "Searching for the Memory Holy Grail:  Part 1", "paragraph": ["One of the questions we are often asked is whether a particular motherboard can run with four DIMMs - or at the maximum number of memory slots for the board.  Surprisingly, the answer is often ", ", which is why AnandTech added the process of populating and testing all memory slots to the review procedures.  However, with the Intel 875/865 Dual-Channel boards, we are realizing that additional questions need to be raised.  Is there a performance difference in two DIMMs vs. four DIMMs?  Do single-sided or double-sided DIMMs perform better on Canterwood/Springdale boards?  What is the real performance difference in one DIMM, two DIMMs, and four DIMMs?", "Answers to all of these questions will lead to determining the best-performing Memory configuration for Intel 875/865 boards.  We set out to find the answer to this question, and what we discover may surprise you.", "        "]},
{"title": "Searching for the Memory Holy Grail - Part 2", "paragraph": ["When Part 1 was published a few weeks ago, the fastest memory that we had tested was a DDR466 module called OCZ 3700 Gold.  It was the first memory we tested to pass the DDR500 mark, which represents a raw bus speed of 250.  Since the Pentium 4 bus is quad-pumped, that translates to a Front Side Bus of 1000MHz or ", " — a milestone in FSB speed.    ", "Now, just a few weeks later, we have memory from five manufacturers that claim to run at DDR500.  We have even seen a recent announcement from Geil of PC4200 (DDR533) memory.  Intel legitimized DDR400 with the 875/865 chipsets, and that is now an official JEDEC standard.  These faster memories, however, are basically built to DDR400 specifications, and then tested by their manufacturers to run at the much faster DDR500 speed.  There is no official standard yet for DDR500, but all of the manufacturers seem to be using the 875/865 chipset motherboards to verify their high-speed performance.  Frankly, there is no real need for DDR500 on the current fastest AMD chipsets — the nForce2 Ultra 400 and VIA KT600 — since neither the chipsets nor the Athlon CPUs have shown any capability of reaching DDR500 performance levels.  While this may change with the introduction of Athlon64, the DDR500 and high-speed memory phenomenon is, for now, an Intel chipset playground — primarily related to the Intel 875/865 chipsets.", "Things are organized a bit differently in our Part 2 of “", "”.  We were forced to modify our testbed in order to better test the performance of the new DDR500 modules.  We also added Game performance and Number Crunching benchmarks to Sandra UNBuffered Memory Test to confirm results with real-world benchmarks. ", "Armed with the fastest memory available from Adata, Corsair, Geil, Kingston, and OCZ, our quest is to find the best performing memory for your Canterwood (875) or Springdale (865) computer.", "        "]},
{"title": "Mushkin & Adata: 2 for the Fast-Timings Lane", "paragraph": ["Mushkin has taken a different approach to the ", " question with their Level II PC3500 2-2-2 Memory modules.  Mushkin has aimed for the absolute fastest timings possible with memory more likely to be used with the 2.8 to 3.2GHz P4 processors, or AMD Bartons that will not likely see Front Side Bus Speeds greater than about DDR433.  Another unique approach is Adata DDR450, a very unusual DDR rating to be sure.  While Adata 450 could not quite reach our DDR500 cutoff in testing, it did turn in some of the most aggressive timings at DDR400 that we have seen,   Because of these different approaches to performance, we decided to take a closer look at both the Mushkin and Adata memory.    ", "Intel legitimized DDR400 with the 875/865 chipsets, and that is now an official JEDEC standard.  In fact, the fastest memory that the Intel 875/865 and AMD Athlon/Barton are designed to run is DDR400.  Anything faster than DDR400 is overclocking the memory or the system in one form or another.  So, with the Mushkin and Adata, we will try to determine which memory is the best performing memory at DDR400.  For those of you who do not overclock, this installment of our memory series was written for you.  For those who have, or plan to get, one of the higher speed P4 CPUs or an AMD Barton, this will also be good information to help you buy the best performing memory for your system.  We will also go back and pick up DDR400 performance from the 7 memories tested in Part 2 of the “", "”. ", "So we are asking the question again — what is ", " memory?  We’ve seen that raw FSB speed definitely has a tremendous impact on memory performance in games and applications.  But the other side of that coin is that memory timings can also greatly affect performance.  So which is better: DDR500 running 3-4-4-8 or DDR400 running at 2-2-2-4?", "        "]},
{"title": "AT News Update: DDR2 Memory Performance", "paragraph": ["From time to time you may see either myself, Anand, or one of the other writers post our thoughts on topics in the forums and news articles.  Today, we are going to post a bit of extended coverage on our thoughts concerning DDR2.  Hopefully, you enjoy our new approach and we encourage you to post your comments!", "Even ", " we began to first hear some of the upcoming strategies incorporatingDDR2 into upcoming Intel platforms.  Several months later, in January, wereceived confirmation on how and when these technologies were going to appearin upcoming chipsets.  ", "Today Micron, Elpida and Samsung compose of the majority ofthe DDR2 market.  Unfortunately there is a lot of confusion about the JEDECspecification.  DDR2 is nearly identical to DDR1, with a few optimizations. The major optimizations include:", "DDR2 gets the majority of its punch from the 4 bitprefetch.  DDR2 can effectively write/read four times the amount of data perclock cycle to/from the memory array.  This effectively doubles the data busspeed while keeping the internal bus speed the same from DDR1.  Both DDR1 andDDR2 use a 64-bit interface. ", "These optimizations come with the advantage of a slightlylower operating voltage, but requires 240 pins rather than the 184 pins requiredby DDR today.  ", "With the talk of different bit prefetches, it becomes difficult to tell the actual clocks of the new memory.  Briefly stated, DDR2 runs with a lower ", " clock than DDR1.  However, since the prefetch is larger than DDR1, the ", " clock is doubled.  For example, if we could run the same DDR400 on the shelves today with DDR2's 4-bit prefetch, it would essentially operate at DDR800.  Since this is not possible, the internal bus of the DDR2 modules we see now has been lowered to 100MHz for DDR2-400 and 133MHz for DDR2-533. DDR400 and DDR2-400 should perform the same.", "What does this mean for early adopters?  Essentially;nothing. ", "(or even between DDR2-533 and DDR-533).  DDR2 is the technology to enablepost-DDR533 speeds, rather than a technology to enhance it. As we start to seebenchmarks of DDR1 versus DDR2 trickle in, consider the maturity of the twotechnologies.  DDR1 is nearly 5 years old with dozens of chipset manufacturersand billions of dollars in financial backing.  DDR2 still has not even entered fullproduction yet.", "DDR2, today, is still not the DDR2 we will see in massproduction come April or May.  Not surprising, Intel has pushed its sample 925Xchipsets back another couple weeks to cope with compatibility and performanceissues on DDR2.  So, even though PC2-4300 does not perform as well as PC-4300right now, keep in mind the memory controllers still have some significantchanges to undergo.  The timings on today's PC2-4300 are also very poor; mostMicron based DDR2 is rated as 4-4-4. Regardless, we should not be looking forperformance leaps between DDR2 and DDR1 until memory gets up into the DDR2-667and DDR2-800 ranges.  According to Intel, ", " and ", " roadmaps,we might see all of these speeds this year. ", "With DDR2 memory fixed around $900 for 512MB right now, itis probably unlikely that we will see the enormous rush to Intel's 925Xchipset.  Even once prices fall to within range of the DDR prices of today, thenewer technology will not really benefit the consumer until we get into thespeeds unobtainable by DDR1.  "]},
{"title": "AT News Update: DRAM Price Fixing", "paragraph": ["Late last week various reports began to hint that the US DOJprice fixing investigations against the Big 4 memory producers; Samsung,Micron, Hynix, and Infineon.  The EU has launched a separate probe against thesame companies with regard to the extremely unusual increase in DRAM pricesthat lasted between November 2001 and May 2002.  As part of court documents inthe now dismissed FTC case against Rambus, an email sent from a Micron employeeclaiming with regard to memory suppliers Samsung and Infineon states; ", ".", "Twomonths later, we began to see memory prices increase bizarrely.  After thedisclosure of this email (and others), the US Department of Justice has launchedthis new investigation on grounds of antitrust practices.  Micron officialsclaim the email released from the FTC vs. Rambus case has nothing to do withthe recent DOJ probe.", "So what exactly happened those fateful months in 2001/2002? At the time the incident, the composition of the memory market was slightlydifferent than it is today:", "Samsung was by far the largest DRAM producer in 2001, andone of the exclusive RDRAM producers as well (along with Elpida).  Samsung andHynix are headquartered in Korea, Micron in the US, and Infineon in Germany.  Micron has a long history of complaining to the FTC about foreign memorymanufacturers dumping memory into the US below cost in order to solidifycontracts and market dominance.", "Below are snapshots of some of the bigger news items in theDRAM industry during 2001/2002:", "As we can see, when memory began to increase after falling80% since the year before, there was a clear and immediate backlash.  Micron'sCEO Steve Appleton has been documented on numerous occasions claiming it didnot withhold inventory to inflate prices, and in as many words blamed Hynix forunpredictably cutting production. ", "To convolute the period even more, Hynix and Micron weregoing through serious joint venture or merger negotiations.  Hynix (which wasmore than $6B in debt at the time) and Micron could have merged to become evenlarger than Samsung at the time.  However, the negotiations continually fellthrough and the two memory companies could not agree on a final price.  Theenormous debt of Hynix eventually leads to much of its consolidation.", "Now let us look at the PC133 128MB prices during this periodof turmoil:", "9/15/2001", "$14", "10/1/2001", "$13", "10/15/2001", "$12", "11/1/2001", "$10", "11/4/2001", "$15", "11/5/2001", "$16", "11/15/2001", "$15", "12/1/2001", "$14", "12/15/2001", "$17", "1/1/2002", "$18", "1/5/2002", "$25", "1/10/2002", "$34", "2/1/2002", "$30", "3/1/2002", "$35", "3/15/2002", "$40", "3/27/2002", "$33", "4/1/2002", "$41", "4/10/2002", "$37", "4/15/2002", "$33", "4/30/2002", "$30", "5/5/2002", "$30", "5/20/2002", "$26", "It is interesting to consider that even after memory prices correctedthemselves, memory in 2002 still cost 100% more than it did 6 months prior.  There isalso an unusual coincidence that prices began to around the same time that theHynix-Micron venture dissolved.  Intel released its i845E and i845G chipsetsaround this period. ", "From an archival point of view, it is interesting that thenumerous excuses memory manufacturers used to increase their memory prices havenever been replicated.  Incredible sales of i865/875 boards never caused amassive shortage of DDR400, even though the Big 4 blamed i845 on DDR266shortages.  It may be some time still before we get the entire story on whathappened those early months in 2002, but we can almost assure you this is onlythe beginning of a long and messy legal battle to come.", "Now that the FTC antitrust case against Rambus has beendropped, Rambus is gearing up to independently sue Infineon, Hynix and Micronwhom it claims artificially ", " prices of DRAM to corner RDRAM out ofthe market.  Samsung (Rambus's primary manufacturer of RDRAM) is absent fromthese accusations.  Obviously if the US DOJ can prove the Big 4 memorymanufacturers conspired to fix prices on the increase, it could prove verydamning in any defense against Rambus's pending lawsuits.  "]},
{"title": "In Memory Of The Law: The Memory Industry's Legal Problems", "paragraph": ["In 1890 the United States government passed the Sherman Antitrust Act, a law that formed the bedrock of the United States' policy against monopolies and other unfair forms of competition. In the many years since then, further acts have been passed to amend the law, and the Government has in time made the correction of anti-competitive actions one of its more important roles. What started with the breaking up of truly gigantic corporations like Standard Oil and AT&T has moved on to include dealing with cartels that while not of a single corporation, act at times in manners similar that result in anti-competitive actions taking place.", "If we were to take a cursory glance at the computing industry as a whole and try to pinpoint the areas where anti-competitive legal issues were likely to occur, we'd look at areas like CPUs and GPUs, where only a couple of serious competitors exist in each, or operating systems, where Microsoft has and continues to have a de facto monopoly. While these areas do in fact have issues, we would be missing an area that has shown some of the worst behavior. It turns out that the memory industry is one of the greatest offenders.", "Generally speaking, it's counter-intuitive to see the memory industry as being a hotbed of legal woes due to the highly competitive nature of the market. With the JEDEC association setting very rigorous standards for RAM, products are quite literally perfectly competitive (from a non-overclocker's point of view): a part specified to meet a certain JEDEC RAM standard should be just as good as any other part that adheres to the same specification. As a result, OEMs can and do switch RAM on a regular basis depending on who can supply it at the lowest cost, and as a result we usually see the memory market operate as it is: a highly competitive market in which multiple companies supply the same good.", "But didn't we just say that the memory market is one of the greatest antitrust offenders? Yes, for in spite of the memory market being very cutthroat, it's also an industry that is subject to highly volatile demand. It can be extremely profitable as a result when demand is far outstripping supply and it takes years to bring new fabs online to produce additional memory. It's the profitability of these periods that keeps nearly a dozen major companies in the business. With such volatility however, it also opens the window for manipulation of this volatility - if now is not a boom year, why not make it one?", "Over just the last decade, the memory industry has been through no less than three major shakeups. The first is the infamous and now settled Rambus patent case, started in 2000 when Rambus asserted that it held patents on technology used in DDR RAM and wanted royalties as such, only to be found guilty of breaking antitrust and deception laws in acquiring these patents and covertly trying to influence the memory market. The second case involves the Big 10 memory manufacturers colluding to keep RAM prices artificially high between 1998 and 2002, to which they were found guilty. Finally, a new investigation has opened up as of this year into the flash memory market, where the Justice Department is trying to figure out if there is evidence of collusion and price-fixing there too.", "Today we'll be taking a look at the latter two actions, one just wrapping up while another begins. What exactly went on in these cases? How are or potentially were consumers hurt by all of this? What has been done to punish the offenders and to correct the market? Let's find out."]},
{"title": "OCZ Flex II - Life at 1200MHz", "paragraph": [" recently released their DDR2 PC2-9200 Flex II series kit thatconsists of two 2GB modules. OCZ rates these particular modules at DDR2-1150 withtimings of 5-5-5-18 at 2.10V on higher end P35 and X38/X48 motherboards. Besidesthe impressive speed ratings, these modules feature a revised thermal managementsystem that consists of a new heatspreader with dedicated cooling channels directlyover the ICs along with two 1/4” ID barbs for attaching a liquid cooling setup.The kit contains 3/8” and 1/2” barb adapters, four-way manifold barb, and 40” ofplastic tubing for those who want to cool the memory a different way. ", "The cooling channels and manifold are made from aluminum so a user withcopper devices in their water cooling system will need to use an inhibitor to ensurethe differing metals stay at détente during operation. Due to the size of the heatspreaders,the modules cannot be placed side-by-side, thus limiting memory capacity to 4GBon most boards. ", "In practice, we found utilizing air-coolingwas just as effective for reaching our maximum clock speeds as using chilled water,even though temperatures were up to 6C lower when chilled. The primary reason forthis is the maximum voltage guaranteed by OCZ is 2.15V. The ICs are from PSC andOCZ highly bins these particular chips to ensure DDR2-1150 capability on supportedboards. As such, any voltages over 2.10V in testing did not result in any additionalspeed increase or timing decrease. In fact, our maximum voltage utilizedat DDR2-1200 was 2.08V on the ASUS P5Q Deluxe board. ", "We are going to cut to the chase with today’ssneak peak and will only be presenting our maximum stable clock results with thePC2-9200 Flex II 4GB kit on the P5Q Deluxe board sporting the new P45 chipset. Duringtesting for our 14 module, 11 different suppliers 2x2GB DDR2 roundup, wehad a couple of kits that stood out from the rest; this kit was one of them froma clocking standpoint. ", "We also had success with running thiskit at low voltages up to DDR2-900 (1.7V at 5-4-4-10), but will save those resultsand others for the roundup. Today’s preview will just answer the maximum clock questionand ensure that OCZ’s DDR2-1150 claims are indeed true. Our system setup consistsobviously of the Flex II kit, Intel E8500, ASUS P5Q Deluxe, WD 640GB HD, a coupleof optical drives from Sony, and our lab favorite ", "9800GTX AMP! Video card. Cooling our E8500 at 4.3GHz on a 24/7 basis was not goingto occur with the retail heatsink, so we employed the ", " Pure CPU cooler, which surprised us by keeping our CPU significantlycooler and quieter than our standard heatsink. ", "Let’s take aquick look at our maximum clock results today."]},
{"title": "Corsair DDR3-2133 - How high and fast will it go?", "paragraph": ["In our opinion, the current acceptance of 64-bit Vista is going to create a large demand for 4GB memory kits. For these users, buying a 2X1GB may appear as a half solution - almost an illogical purchase considering Vista's voracious appetite for memory. As such, we know our work is cut out with this preview and subsequent review of high-end DDR3 kits. Testing niche products always represents a challenge because it is impossible to justify the miniscule gains in real world testing against the premiums one has to pay for that last 1% of performance. However, for a certain group of users, that last 1% means everything - cost be dammed. There is a demand for such products; in fact, this demand sometimes shapes the course and direction of future products. Therefore, we will simply say tongue in cheek, It's a tough job, but somebody's gotta do it.", "When we first learned that Corsair was sending us this $515 kit for testing, we had just finished pushing the ASUS P5E3 Premium to its limits and found it to be a fantastic board for overclocking 1GB memory modules well in excess of 2000MHz. In order to obtain these results we used 2X1GB modules from Cell Shock that are based upon Micron's D9JNL part. These particular modules scaled all the way to 2160MHz at CAS 8 on the ASUS board, although it has to be said it took a decent amount of work getting there. Very impressive of course, but it's also no real secret that few of us really run our PCs with such a setup, simply because the voltages and time required to reach such lofty speeds is more than excessive for 24/7 operation.", "While the X48 chipset can achieve over 2100MHz with good DDR3, it does so at a real push needing more voltage to hold it'self together than most of us are prepared to use. The other logical choice for high-end DDR3 overclocking is the NVIDIA 790i chipset, but after significant testing, we realized it is no different. In fact, it's not nearly as stable when really pushed to the limit with these modules. Corsair's decision to quickly market a high-speed 2133MHz kit based on Samsung's new ICs certainly roused our curiosity. At the same time, we questioned how such kits would be qualified to run at stock specifications, never mind overclocking. Let's look at our first results."]},
{"title": "Core i7 - Is High VDimm really a Problem?", "paragraph": ["Numerous articles and forum posts have been popping uprecently about the potential of high VDimm settings damaging ordestroying the upcoming i7 processor series. Will high VDimm causedamage? The answer to that question is not so simple actually.Unfortunately, due to the current NDA status, we cannot go into detailabout this subject matter but can provide a general brief on it.", "Our answer at this time is Yes and No. It soundslike we are straddling the fence but in actuality the correct answerdepends on the available BIOS options, BIOS settings, memory selection,and final voltage settings. Intel’s stance is clear on thissubject, run VDimm higher than their 1.50V~1.65V guidelines and youwill affect the life span of the processor. ", "Exactlywhat the impact to the processor will be is dependent upon severalfactors. Put simply, if you go crazy with VDimm, let’s sayaround 2.0V~2.2V without additional tuning, then expect to greatlyreduce the processor lifespan to a few weeks or maybe days. We havealready witnessed several CPUs being damaged or destroyed at themotherboard partners with high VDimm settings, especially those thatran at 2.0V or higher with base settings. By base settings, we meanconfiguring an i7/X58 platform in the same manner a typical user nowsets up a Penryn/X48 DDR3 platform. The rules have changed completelyfor Intel, just we cannot discuss the playbook at this time (hey, it isfrustrating for us also).", "Likewise, we have seenhigh VCore/VDimm test beds operate without a problem for benchmarkingpurposes (yet still fail with long-term bench testing) provided amultitude of BIOS settings for the core, DIMM, IMC, Uncore, and QPIselections were properly set. The base secret (there are more) ismaintaining correct amplitude levels, something we will discuss atproduct launch. For now, high VDimm is not necessarily the true problem here, but it is the quickest way to damage/destroy an i7 if the rest of the system is not properly tuned. ", "However, we highlyrecommend keeping VDimm at or below Intel’s recommendationsalong with proper BIOS settings for the long-term health of the i7.Upcoming DDR3 products from the major memory suppliers will all supportlow voltage DDR3-1066~DDR3-1600 operation with fairly aggressivetimings. This is key as the retail 920/940 processors will not be memory multiplier locked. In addition, the vast majority of JDEC spec DDR3 memorycurrently on the market will operate fine on the X58, albeit atslightly higher memory timings in some cases. ", "Theextreme performance modules will also operate correctly, as we havefound in testing to date, just at higher timings in order to meet thevoltage guideline requirements. Certain performance modules thatrequire 1.8V or higher upon POST will probably not work correctly(POST) unless the board manufacturer steps outside of Intel’sguidelines. In that case, you can replace the memory, reflash the SPDif the supplier allows, or toss in a pair of JDEC spec modules (current1066 is fine), correctly set the voltages and timings that you requirein the BIOS, shutdown, and reboot with the performance modules.Realize, this does place you outside of the guidelines but most usersthat fall in this category are already outside the lines anyway.", "Personally,with the right board, cooling, and BIOS settings, 1.7V~1.8V should befine (no promises yet) and will allow the upcoming low-voltage, highclock speed DDR3 DIMMS to reach the 1866~2200MHz level. This shouldsatisfy most performance enthusiasts, but probably not the extremeclockers who will try for more. For the rest of us, this platformoffers simply amazing bandwidth and latency numbers with tri-channelDDR3 1066 or DDR3 1333. In fact, we think tri-channel DDR3-1333 at5-5-5-12 timings or DDR3-1500~DDR3-1600 6-6-5-15 settings (1.65V) willprovide optimal memory bandwidth, write speeds, and latencies for 95%of the 920/940 users at this point.  So, unlike the P45/X38/X48platforms, having low-speed rated DDR3 is not going to be a hindranceto extracting fantastic performance from a i7/X58 setup."]},
{"title": "Lab Update - Patriot Memory Viper Series DDR3-1333", "paragraph": [" ", "- an assuming thatsomething is true; a fact or statement (as a proposition, axiom, postulate, ornotion) taken for granted. A verypowerful word if we might say so and one that can generally get us in troublewhile reviewing hardware. During thecourse of testing for our upcoming DDR3 roundup, we assumed a few items to betrue about the memory we were reviewing.Turns out, our assumptions were off the mark, but for good reason. ", " Ourfirst assumption is that we should concentrate on the DDR3-1600 kits as theyprovided a wide range of flexibility for most users. Most of the performance oriented kits wouldeasily hit DDR3-1800+ at decent timings and voltages, satisfying theoverclocking needs of all but the hardcore enthusiasts while at the same timeallowing very tight timings at lower clock speeds for applications thatresponded best to a combination of bandwidth and low latencies. ", " Thereason for choosing DDR3-1600 first is that the initial DDR3-1066 and DDR3-13336GB kits we received generally clocked about 100MHz~200MHz above their ratedspeeds and latency improvements required voltages above 1.65V in most cases onour i7 platform. In addition, pricingwas not that much less on a per Gigabyte basis, which certainly justified ourhigher performing selections at the time. By chance, we werelooking at 6GB kit prices on Newegg and ", " last month and noticed a couple ofDDR3-1333 6GB kits had dropped below the $100 mark (a virtual flood of 6GB kitsare now hitting the $100 mark). ", " Thesekits were not available when we started collecting review samples a few weeksago so we ordered a new ", " Viper DDR3-1333 (PVT36G1333ELK) 6GB kit for avery reasonable price of $93.99 plus free shipping. Our reason was simple, we just wanted to seehow well the latest “budget” DDR3 product on the market clocked and if ourassumptions were still correct about the first 1066/1333 kits we received. Considering our test results with the Patriotkit, we checked the credit line and ordered several “budget” 6GB kits from ", ",Mushkin, Crucial, ", ", ", ", and ", " to feature in our roundup. ", " Webased our second assumption on test results with our DDR3-1600 to DDR3-2000kits providing the best possible performance on the i7 platform, especially forthose overclocking the 920 processors. Ourreasoning for sticking with the higher end kits was sound until recent events. The i7 platform was an expensive propositionfor most users who wanted to upgrade with decent motherboards costing $300, the“budget” 920 processor going for nearly $300, and 6GB low voltage DDR3 kitscosting a good $225 or higher for products that could keep up with the 920overclocks. This resulted in a veryniche market condition and one that if you had to ask the price then you probablywere not going to be able to afford it. ", " Afew weeks later, we have X58 motherboards selling for $170 with rebates, a new i7processor stepping (D0) coming from Intel that promises a little extra headroomin clock rates, and 6GB DDR3 kits selling for around ", ". The entry cost to get into an i7 platform hasdropped about 34% in the last six weeks if you are pinching pennies like mostof us. Guess what, the performancedifference in platform selections then and now is less than 2% at best. Only those who plan on serious overclockingneed to worry about spending more, but that is always the case. ", " Anotherfactor in dropping prices is the rise from ashes act that AMD hasaccomplished with the Phenom II product line.True, it is not in the same performance category as the i7 when it comesto crunching numbers or heavy manipulation of digital content, but the PhenomII is extremely competitive on a price/performance basis when looking at thebig picture. Pairing up the currentPhenom II X3 720BE with either a DDR2/DDR3 based 790FX/GX motherboard resultsin some of the best bang for the buck performance you are likely to experiencethis year, at least until the new X4 95x series comes out. ", " Ofcourse, Intel has the P55 platform launching later this year and we mentionthat because DDR3 will soon become the memory of choice for anyone upgrading toa new platform. The Phenom II platformlets you retain your current DDR2 based AM2+ setup until you decide to make theswitch and we will soon see that is not a bad option from an everydayperformance or cost viewpoint. However, those who need the absolute bestperformance from the Phenom II should go the DDR3 route at this point. ", " All that said, we are here today to take a first look at the Patriot Viper Series", " DDR3-1333 CAS9 6GB memory kit.Heresy, one might claim looking at the specs but this kit delivers theflexibility we have been seeking, only at a lower price point. Until we finish testing our recent budget arrivals,we thought it prudent to provide a quick look at how well this particular memorykit clocks and if it higher memory speeds actually matter at stock processor speedsor mild overclocks. "]},
{"title": "OCZ Blade DDR3-2133 - Is it Fast Enough?", "paragraph": [" shipped us their DDR3-2133 Blade 6GB kit last month and asked us to review it as part of our Core i7 975 launch. Of course, we could not refuse that offer. We received the Blade kit, our 975 ES processor, and several other premium components, but hit a huge bump in the road during testing. You see, it turns out our 975 engineering samples could not ", " their way out of a paper bag. As such, we decided to order a retail 975 and it finally arrived along with a retail ", " X58 Classified (E759) motherboard. ", " We were confident the lethal combination of a very good Core i7 975 and one of the best clocking motherboards around will allow us to take this memory kit to its limits. However, yet another speed bump presented itself as our cooling capabilities in the labs here are limited to various high-end air coolers or TEC units such as the CoolIT Systems Freezone Elite. Armed with the realization that we were going to be limited to the 4.5GHz range and resulting 2150 memory speeds we decided to pack the kit up for shipment. Raja will be the lucky recipient as he has the proper cooling equipment available and is already working on a DDR3-2000+ article at this moment for the more fanatical readers. ", " In the meantime, we ran a few numbers with a Core i7 920D0 stepping at both stock core speeds and an almost universal 4.2GHz overclock on the ASUS ", " motherboard. We also completed a couple of quick overclocks on the 920/Classified combo just to show what a couple of minutes of playing around with the BIOS can provide with this kit on high-end air cooling. As you will see shortly, there really is no reason for the typical desktop user to procure a kit like this for 24/7 use, unless you just want one for a status symbol.", "We are sure OCZ will welcome your business with open arms no matter your purpose, but their primary audience is the people who benchmark for a living. In that regard, this kit is designed to compete against the latest DDR3-2000 C7 6GB kits from ", " and ", ". As such, today's preview could be considered somewhat laughable by the hardcore enthusiast but it is perfect segue into our mainstream memory articles later this week. That is not to say this kit is completely without merit, it will easily run DDR3-2133 C7 settings at voltages we have not reached with the other two manufacturer's products and for benchmarking activities that is an important distinction. For the other 99% of us, it is fun to see the numbers but we have far better alternatives available in the market. ", " ", " ", " This is OCZ's top rated Blade series kit. Of course looking at the specifications it is the top rated kit available, period. Whether it is the top performing kit is something we will answer shortly. OCZ designed this kit to operate at DDR3-2133 (1067MHz) at timings of 8-9-8-24 on the X58 platform with 1.65v, preferably with the Core i7 975. The reason being, IMC load, the lower the Bclk, the lower the load and voltage requirements on the platform when using the unlocked multiplier on the 975 to gain CPU speed compared to a locked processor like the 920 or W3540 that requires high Bclks to reach like processor speeds. It is a little more complicated than that, but that is the 10,000ft overview. ", " The OCZ Blade OCZ3B2133LV6GK features the top (1%) binned Elpida Hyper J1108BASE-MNH-E IC or the Hyper for short. These IC's are already rated for the upcoming ultra low 1.2V/1.35V voltage specification as well as the current JEDEC standard of 1.5V. One of the primary differences between these IC's and all others is that they use copper interconnects as opposed to aluminum, resulting in higher clock speeds at lower voltages. I wonder where we have heard that use of technology before. Anyway, it is obvious by now that we are not dealing with your mass produced ", " kits and as such we expect a heavy price premium when these kits launch in the coming weeks. ", " In the meantime, let's take a quick look at these unique modules being subjected to clock rates that probably had them screaming, not from pain, but rather embarrassment. "]},
{"title": "Memory Scaling on Core i7 - Is DDR3-1066 Really the Best Choice?", "paragraph": ["And we begin, with a graph:", "The graph above represents the cost, from Newegg.com, of 11 different 6GB DDR3 memory kits (1066 C7/C5 are the same kit). The only variables are the manufacturer and speed of the DDR3 memory included in the kit.", " The least expensive DDR3-1066 6GB kit we purchased sells for $80, the mostexpensive 6GB kit? $289. That’s over a $200 difference; that andsome pocket change is enough to pay for a sweet new video ", ",a nice 22” ", ", or even a iPhone ", ". ", "All of that extra money is going somewhere: frequency and latency. The lowest end kit has a data rate of 1066MHz and a CAS latency of 7 cycles. The most expensive kit has a 1866MHz data rate at the same CAS latency; that’s a 75% increase in data rate. ", "A 10% increase in CPU speed rarely yields more than a 4 or 5% increase in performance, but what about a 75% increase in memory speed? We don’t have a single page on AnandTech to point you to that would answer that question. At least we didn’t, until today.", "We first met ", " alongside Intel’s P35 chipset. It’s performance at the time was at best equal to or usually worse than DDR2 while carrying a significant price premium. It wasn’t until the release of the Intel X48 and NVIDIA 790i chipsets that Socket 775 users could even see an advantage to using DDR3 and even then, it was primarily for benchmarking contests - hooray, because we all know how important those are.", "There were some tangible advantages to DDR3 from the start, the biggest being it’s lower operating voltage. DDR2 memory required 1.8V while DDR3 could run at 1.5V, this made DDR3 particularly attractive for notebooks but on the desktop the advantage was sort of abused.", "In order to take advantage of DDR3’s higher memory speed, benchmarking enthusiasts often had to use DDR3-1866/2000 kits that required voltages in the 1.8V~2.0V range to reach these clock speeds. Performance improvements in certain benchmarks were available through brute force use of voltages and ICs that allowed high memory speeds at decent latencies. In the end, improvements in actual applications were just not worth the cost or trouble of using DDR3 compared to DDR2. ", "Intel made no secret of its plans to move the vast majority of their processor lineups to DDR3 memory a few years ago. They truly wanted/desired that DDR3 would be the standard memory of choice by the time P45/X48 launched, but DDR3’s limited availability, middling performance, and a price premium that was truly prohibitive for the mainstream crowd, let alone the enthusiast market space made this desire impossible. As such, this left users with memory controllers not truly optimized for either memory technology that resulted in performance not significantly different from earlier Core 2 supporting S775 chipsets. ", "AMD recently released the AM3 platform and their AM3 based Phenom II processors support both DDR2 and DDR3 allowing users to either upgrade to AM3 boards or keep using their DDR2 based AM2+ boards, a simple if not elegant solution. With the recent release of new boards, BIOS optimizations, and near cost parity with DDR2, we now think DDR3 is a viable option for AMD users. ", "That said, DDR3 started coming into its prime last fall as the release of second and third generation DDR3 devices along with Intel’s Core i7. Core i7 and the X58 platform introduced Intel’s first on-die memory controller. Aside from other architectural improvements, Core i7 supports three DDR3 memory channels compared to the standard two channel setup, yielding some impressive bandwidth numbers.", "There was one problem with this new design, a real fly in the ointment actually for the memory suppliers. Current JDEC specifications list 1.50V as the official voltage specification for DDR3 with a move to 1.35V in the near future and eventually to 1.20V. However, most of the performance oriented DDR3 modules released for the Core 2 platforms generally operated at 1.8V~2.0V in order to hit high speeds with decent latencies. In essence, the memory kits were already overclocked to hit clock speeds that made DDR3 a performance consideration on S775. The memory controllers on the Core 2 based Northbridge products could easily handle these voltages and surprisingly enough, so could the ICs. ", "Well, Intel officially released their recommended memory voltages for the Core i7 several months before launch with 1.50V as the recommended base voltage and 1.65V as the suggested maximum along with 1.35V for VTT (QPI) maximum. This left the memory suppliers in a bind as true high-speed low-voltage ICs were not going to appear until after the Core i7 launch. Intel extended official support to DDR3-800/1066 speeds only, although most current X58 motherboards support speeds up to DDR3-2133 or higher. ", "At the Core i7 launch, the market ended up with a bevy of DDR3-1066/1333 low-voltage kits with a sprinkling of higher speed DDR3-1600 and DDR3-1866 kits based on highly binned ICs that met the 1.65V recommendation. One other twist was that the memory suppliers had to package low-voltage higher-speed 3-DIMM kits instead of the normal 2-DIMM configuration in order to satisfy triple channel owners. ", "Fast forward to today and we see the wide availability of high-speed low-voltage DDR3 products with more choices coming on a daily basis. In fact, the availability of DDR3 products almost matches that of DDR2 with similar price points. By the end of this year, DDR3 products will outnumber DDR2 offerings although it will be a couple of years before DDR3 usage overtakes DDR2. "]},
{"title": "DDR3-2000+ Memory Kits - Fast but Flawed", "paragraph": ["\tWe just looked at i7 memory scaling performance and now it is time to chill a few processors to see what those DDR3-2000+ kits are capable of for the serious overclocker. As it turns out that was the opening to our original article, which we planned to launch in conjunction with the DDR3 ", " article.", "\tHowever, the best plans of mice and men sometimes go awry. Unfortunately, we met delay after delay as every one of our Elpida “Hyper” based kits failed on us in some form or fashion over the past few weeks. At times, a single module would fail and eventually the whole kit in certain instances. Eventually our patience wore thin as even warranty replacements started failing and we knew this was not an isolated problem.", "\tIn fact, this problem has become widespread in the extreme overclocking community. Admittedly, widespread in this particular group means a few hundred users. Nevertheless, this audience purchases these extreme memory kits with prices tags reaching the $500+ level at times and expects like performance and quality in return. Certainly, the performance is there, quality we are not so sure about right now.", "\tWe could attribute the demise of our modules to the elevated voltage levels we have used for this article and normally we would go that direction and stop for the day. However, we had modules die on us using no more 1.50V VDimm and stock VTT settings in a variety of boards. We are not the only ones, as it seems a number of users have also been through the RMA process (a few more than once) regardless of voltage settings.", "\tThe “official” cause of death is unknown at present, while the usual suspects, such as manufacturing errors, motherboard voltage/ user over voltage issues and temperature related deterioration are the obvious perpetrators. The “unofficial” cause of death is simply a quality problem with the Elpida “Hyper” based ICs according to various sources we have spoken with the past couple of weeks. Granted, the other factors can and probably do account for a certain failure rate, but the randomness of our failures along with others, especially at first POST or during stock benchmarking lead us to believe that the quality of the IC is the primary factor at this point.", "\t", "\tWe have contacted Elpida about the problem but do not have an “official” response from their engineering group yet. However, the problem is serious enough that Corsair informed us earlier today that they ", " their retailers to return any kits in the channel. They will not be selling kits based on the Elpida Hyper ICs until an enhanced manufacturing and testing process is in place to ensure the quality of this particular product before shipment. We applaud Corsair for being aggressive in regards to this problem and we expect/hope other suppliers to follow suit.", "\tMost of the suppliers have reported that a relatively small percentage of kits appear to be affected. Just how small is unknown. Based on our own numbers and those of other users it appears to us it is significantly more serious than we were lead to believe a few weeks ago. We are now at the point of just saying that you are better off avoiding Elpida Hyper kits due to the ‘frequently random’ level of failures with modules. However, at least for now, all of the suppliers are fully backing their warranties. If you need the available benchmarking performance generated by these kits then it is worth the risk. Just make sure of the warranty terms before purchase, or simply put, buyer beware.", "\tWhen we speak of failures, there are two types, a catastrophic failure where the module dies instantly and one of deterioration. One or more of the modules failing to map fully to the operating system usually marks the first sign of deterioration. Moving the modules around between the slots can work around some of this, although from our experience this is a primary sign that things are beginning to go downhill fast. This phenomenon is not to be confused with the i7 memory controller skipping to map a module because of insufficient voltages for the applied clocks.", "\tThe next step is when the module no longer clocks up at stock voltages or given voltage limits like 1.65V VDimm. We have witnessed modules not clocking above 1900MHz or so regardless of voltages and slowly dropping to 1200MHz before total failure.", "\tWith all that said, we decided to complete the article as there are users out there that have not experienced any of the issues at all or those still wishing to take a chance on these kits. Two of the kits we have been pushing for raw bandwidth over the past few weeks are Corsair’s Dominator GT 7-8-7-20 6GB kit and OCZ’s ", " 8-9-8-24 6GB kit. We have tested other kits, but these are the last two standing in the labs although both of them are now showing signs of deterioration.", "\tCorsair chose to stick with the tried and tested ", " CAS 7-8-7-20 formula while OCZ gives up the tighter CAS rating in a bid to woo the market with a ", " kit at 8-9-8-24 timings. On the face of it, we would say that both kits should be capable of similar results assuming that SPD and PCB differences between the two are not massive. OCZ and Corsair tell us their respective top end kits represent the top 1% of the Elpida Hyper yield.", "\tWe’re keeping it simple today, running a few of the preferred benchmarking programs in a bid to find maximum frequency limits for the modules along with a small comparison of scores at the same CPU frequency. We have already shown that these kits are not really needed by the general enthusiast and typically do not improve application performance significantly enough to warrant the increased cost. However, they do provide a certain degree of flexibility when overclocking and allow for very tight latencies at a variety of memory speeds."]},
{"title": "This Just In: G.Skill Giveaway Goodies", "paragraph": ["\tBefore the new site launched I demoed a new feature I'd been toying with called ", ". The idea is to give you guys a quick glance at what I'm working on (and eventually what the entire team is working on) as soon as something new arrives at our doorsteps.", "\tI'll admit that there have been a few things that have arrived since my last post, however all of them are under NDA at this point. I do have good news though, more giveaways are coming.", "\tI asked our ad reps to see if any of their clients wanted to provide any giveaways to commemorate the new site launch. G.Skill was eager to show their appreciation for you all and dropped off a big box of goodies to give away.", "\t", "\tI haven't inventoried it all yet, nor have I decided how we're going to give it away but expect more details next week :) And congrats to our ", " winner Scott T. from Syracuse, NY. Scott and I have already been in communication and AMD is working hard to get him his brand new ThinkPad X100e asap!"]},
{"title": "Fastest Memory Race Heats Up - Corsair Announces 2533MHz DDR3 ", "paragraph": ["\tThe whole 'fastest memory' halo product race is a bit of a farce.  In terms of DDR3, Corsair started the race back in 2007 with their first set of Dominator modules, running at 1600Mhz, 10-8-8-24.  This has been followed and bested, mainly by Corsair, but with sneak appearances by Kingston, G.Skill and Patriot (see below).", "\t", "\tAvailable as single sticks from the Corsair website, these new GTX4 modules will set you back $325 for each 2GB stick.  With rather slack timings of 9-11-10-30 at 1.65V, each module is handtested using a Core i7 Lynnfield CPU on a Gigabyte P55 motherboard.  Michal Nowicki, Corsair's inhouse overclocker, advises that 'most CPUs will require sub-ambient cooling to run [these modules] at their maximum speed'.", "\tDespite the lifetime warranty and the ability to boast about a 'halo' product, I can't see a point in these sticks - even for overclockers.  With such slack timings to begin with, I wonder just how much headroom is available, when other 2400+ kits with better timings are available.  At $325 a stick, you really are shooting yourself in the foot.", "\tBut alas, these modules will sell, and Corsair know they will.", "\tA brief (and abridged) history on the latest and greatest memory is summarised below:", "\t\t\t\t\t", "\t\t\t\t\t", "\t\t\t\t\t", "\t\t\t\t\t", "\t\t\t\t\t", "\t\t\t\t\t Jun '07", "\t\t\t\t\t Corsair", "\t\t\t\t\t Dominator", "\t\t\t\t\t DDR3-1600Mhz", "\t\t\t\t\t 10-8-8-24", "\t\t\t\t\t Jun '08", "\t\t\t\t\t Corsair", "\t\t\t\t\t Dominator", "\t\t\t\t\t DDR3-2000Mhz", "\t\t\t\t\t8-8-8-24", "\t\t\t\t\t Dec '09", "\t\t\t\t\t Corsair", "\t\t\t\t\t Dominator GTX", "\t\t\t\t\t DDR3-2250Mhz", "\t\t\t\t\t8-8-8-24", "\t\t\t\t\t Jan '10", "\t\t\t\t\t Corsair", "\t\t\t\t\t Dominator GTX1", "\t\t\t\t\t DDR3-2333Mhz", "\t\t\t\t\t9-11-9-27", "\t\t\t\t\t Mar '10", "\t\t\t\t\t Kingston", "\t\t\t\t\t HyperX", "\t\t\t\t\t DDR3-2400Mhz", "\t\t\t\t\t9-11-9-25", "\t\t\t\t\t Apr '10", "\t\t\t\t\t G.Skill", "\t\t\t\t\t Trident", "\t\t\t\t\t DDR3-2500Mhz", "\t\t\t\t\t9-11-9-28", "\t\t\t\t\t Apr '10", "\t\t\t\t\t Patriot", "\t\t\t\t\t Viper II", "\t\t\t\t\t DDR3-2500Mhz", "\t\t\t\t\t9-11-9-27", "\t\t\t\t\t May '10", "\t\t\t\t\t Corsair", "\t\t\t\t\t Dominator GTX4", "\t\t\t\t\t DDR3-2533Mhz", "\t\t\t\t\t9-11-10-30"]},
{"title": "Everything You Always Wanted to Know About SDRAM (Memory): But Were Afraid to Ask", "paragraph": ["\tIt’s coming up on a year since we published our last memory review; possibly the longest hiatus this section of the site has ever seen. To be honest, the reason we’ve refrained from posting much of anything is because things haven’t changed all that much over the last year – barring a necessary shift towards low-voltage oriented ICs (~1.30V to ~1.50V) from the likes of Elpida and PSC. Parts of these types will eventually become the norm as memory controllers based on smaller and smaller process technology, like Intel’s 32nm ", ", gain traction in the market.", "\tWhile voltage requirements have changed for the better, factors relating to important memory timings like CL and tRCD haven’t seen an improvement; we’re almost at the same point we were a year ago. Back then Elpida provided a glimpse of promise with their Hyper-series of ICs. The Hyper part was capable of high-speed, low-latency operation in tandem. Unfortunately, due to problems with long-term reliability, Hyper is now defunct. Corsair and perhaps Mushkin still have enough stock to sell for a while, but once it's gone, that’s it.", "\t", "\tThe superseding Elpida BBSE variant ICs and a spread of chips from PSC now dominate the memory scene, ranging from mainstream DDR3-1333 speeds all the way to insanely-rated premium DDR3-2500 kits. Some of these parts are capable of keeping up with Hyper when it comes to CL, but do so by adding a few nanoseconds of random access latency due to a looser tRCD. Given that read and write access operations make up a significant portion of memory power consumption, this step backwards in performance may be a requisite factor for reliability – perhaps something was found by Elpida during the production lifetime of Hyper ICs that prompted a re-examination, leading to a more conservative recipe for data transfer/retrieval.", "\t", "\tToday’s memory section comeback was fuelled by the arrival of a number of mainstream memory kits at our test labs – many of the kits we were using for motherboard reviews are no longer for sale so we needed to update our inventory of modules anyway. Corsair, Crucial and GSkill kindly sent memory from their mainstream line-ups. The original intent was to look at a few of those kits.", "\tHowever, during the course of testing these kits, our focus shifted from writing a memory review (showing the same old boring graphs) to compiling something far more meaningful: a guide to memory optimization and addressing, including a detailed look at important memory timings, and an accounting of some of Intel’s lesser-known memory controller features. As such, this article should make a very compelling read for those of you interested in learning more about some of the design and engineering that goes into making memory work, and how a little understanding can go a long way when looking for creative ways to improve memory performance…"]},
{"title": "Patriot SSDs, Flash, and Large Memory Applications", "paragraph": ["\tPatriot has been supplying memory products for some time now, and they had the usual assortment of SSDs, RAM, USB, and other Flash products on display in their suite. We’ve tested many of their SSDs already—or at least similar products with the same controller—and besides the numerous SandForce equipped SSDs they also had an SSD with a Phison controller. The Phison-based products will constitute the Magma line, with 64/128/256GB capacities available and SATA 6Gbps support. We’ll be interested in testing their Magma solutions and seeing how the controller competes with other solutions; Patriot’s goal is to deliver performance that’s competitive with other midrange SSD solutions, with the intention of delivering such SSDs at more affordable price points. With a new controller and firmware to develop and debug (relative to existing solutions), the launch target is currently Q2’2012.", "\tPatriot also had a couple SNB-E systems running to demonstrate large memory applications. With quad-channel memory and eight DIMM slots, Patriot had two systems available, one with 32GB (8x4GB) and one with 64GB (8x8GB). This is obviously a solution targeted more at workstation users, and as a demo of what sort of work would require that much system RAM Patriot had a Photoshop plug-in that stitched together 90 500-600MB TIF images into a single huge panoramic video. The final output of the tool is a 26Kx9K 1.80GB image, and the amount of system RAM has a dramatic impact on performance. The project loads in around 21 seconds with 16GB, 32GB, or 64GB of RAM (largely bottlenecked by the SSD storage performance), but it requires over twice as long (54 seconds) with 8GB RAM. The entire process takes under one minute with 64GB, just under 3 minutes with 32GB RAM, 6.5 minutes with 16GB RAM, and 8.5 minutes with 8GB RAM.", "\t"]},
{"title": "Micron CEO Steve Appleton Dies in a Plane Crash", "paragraph": ["\tMicron's long time CEO, Steve Appleton, has died in a plane crash at the age of 51 at the Boise Airport on Friday morning. He was reportedly flying a single-engine Lancair plane, which stalled and then nosedived shortly after take-off. Appleton was the only person onboard and died immediately upon impact.", "\tAppleton started working at Micron in 1983 and became the CEO eleven years later in 1994. Micron is most known for storage solutions, such as NAND flash. Intel's and Micron's joint NAND venture, IMFT, is one of the leading NAND manufacturers, and consumers may also be familiar with Micron's subdiary Crucial, a well known SSD and RAM brand. Flying was always Appleton's passion and he owned over 20 airplanes. He leaves behind a wife and four children.", "\tR.I.P. Steve Appleton, 1960-2012"]},
{"title": "Rambus And NVIDIA Bury The Hatchet, Sign 5 Year Agreement", "paragraph": ["\tWhile Rambus has settled in one form or another with most of the major players in the computing industry, one of the remaining holdouts has been NVIDIA. NVIDIA has already lost to Rambus in court over some infringement cases, while cases over other products and patents have been ongoing. As a chipset, SoC, and GPU provider, NVIDIA has a particularly wide exposure to memory-related suits as virtually all of their products contain a memory controller of some kind, giving them ample reason to continue fighting Rambus.", "\tBut that fight has finally come to an end. Yesterday Rambus and NVIDIA signed a 5 year licensing agreement, under which NVIDIA gets rights to Rambus's patented technologies, and at the same time both companies drop all outstanding suits aimed at each other. As with other Rambus licensing agreements the specific terms of the deal are private, so how much NVIDIA is paying per the agreement and whether there is a per-product royalty rate attached is unknown.", "\tIt's interesting to note though that this comes so soon after two major Rambus losses. In November ", ", meanwhile in January of this year the United States Patent and Trademark Office ruled that 3 of Rambus's major patents (the Barth patents) were invalid. The Barth patents have been Rambus's biggest weapons, and they were the patents that defeated NVIDIA in the infringement suit that NVIDIA previously lost. Given the timing of this latest settlement, it stands to reason that a weakened Rambus was willing to settle with NVIDIA on far more favorable terms - to the point where it would be cheaper than continuing the suit - but as the terms of the deal are not public we'll never know for sure.", "\tIn any case, with NVIDIA finally settling there are now only a few smaller holdouts remaining. The Wall Street Journal names the remaining parties as LSI Corp (storage controllers, including SandForce), MediaTek (SoCs), and STMicro (everything from SoCs to ICs).", "\tSource: "]},
{"title": "Micron To Acquire Elpida For $2.5 Billion", "paragraph": ["\tAnd then there were 5.", "\tFor the better part of a year now the DRAM industry has been in a lurch due to low prices. As a result of soft demand exacerbated by the hard drive shortage and a corresponding glut in supply, DRAM prices have become severely depressed, to the point where even 16GB of PC DRAM can regularly be found for under $90 and 8GB of RAM for as little as $40. And though Moore’s Law puts constant downward pressure on DRAM prices, on a historical basis healthy DRAM pricing shouldn’t drop this quickly this fast.", "\tBecause of this extremely weak pricing all of the major players in the DRAM industry have been struggling to stay afloat – just breaking even is a big deal – which has led to a series of cutbacks and delays in future build outs. However even that hasn’t been quite enough, and as we’ve seen time and time again in during major slumps in commodity technology industry, the rising tide of red ink has come to claim another.", "\tThe victim this time is Elpida, one of the smaller DRAM manufacturers. After filing for bankruptcy earlier this year the company has finally accepted a buy-out offer from Micron, who has been looking to take advantage of this slump to purchase more capacity and increase their competitiveness with the other major players in the DRAM market. As a result of the deal Micron will pay Elpida shareholders a total of nearly 2.5 billion dollars, paid out as $750M upfront and then annual installments through 2019. In turn Micron will acquire Elpida and its assets, allowing the company to expand their DRAM production by nearly 50% for a fraction of the price of building new facilities of their own.", "\tThis acquisition is primarily about jockeying for position among the remaining DRAM manufacturers – Samsung, Micron, Hynix, Winbond, and Nanya – ahead of a cyclical recovery in the highly volatile DRAM market. The acquisition will boost Micron to the 2", " largest DRAM manufacturer (between Samsung and Hynix), while putting Winbond and Nanya in competition for 4", "and 5", " place. At the same time Elpida has a strong presence in the mobile DRAM market with memory types such as ", " and DDR3L, which in turn will give Micron a much stronger position in those markets as opposed to the more cutthroat PC DRAM market.", "\tUltimately major slumps in the DRAM market are usually followed by major booms, and this should be no different. A typical recovery pattern means that once demand recovers the current lack of investment in new facilities will bottleneck supply, which is where these acquisitions typically pay for themselves. At the same time five players is still a larger number than what we see in most other commodity component industries (e.g. hard drives), so there’s no guarantee that the next slump won’t also consume a DRAM manufacturer.", "\tSource: ", "\t", ": In our attempt to count the remaining DRAM manufacturers we forgot about Nanya. Sorry about that, guys."]},
{"title": "Samsung Introduces 64GB UHS-I microSD and SD Cards", "paragraph": ["\tSamsung has ", ", both capable of storing 64GB of data. One is a full sized SD card, suitable for devices such as cameras and camcorders, while the other is a microSD card, perfect for use inside a smartphone or tablet. Said cards are UHS-I certified, with the full sized card being able to deliver 80MB/second read speeds and 40MB/second write speeds. The smaller microSD card is said to deliver 70MB/second read speeds and 20MB/second write speeds.", "\tBoth cards use 20 nanometer 64 gigbit NAND chips and they're expected to hit the market in October. Pricing information hasn't been announced, though it's safe to say that they're not going to be cheap."]},
{"title": "Micron Announces 30nm DDR3L-RS Products", "paragraph": ["\tMicron recently announced the availability of their 30nm DDR3L-RS (formerly DDR3Lm) memory, which could prove particularly beneficial for Ultrabooks and other ultrathin computing devices. Just what is DDR3L-RS memory? It’s a new type of memory that improves overall system power consumption by reducing self refresh power (IDD6). That may not matter much for desktops where an extra watt of power draw is hardly noticeable, but when you’re using an Ultrabook that idles at well under 10W even a 250mW reduction in power draw can yield a significant improvement in battery life. Micron also notes that the new 2Gb and 4Gb solutions will reduce standby power requirements, allowing a laptop to remain in suspension for much longer. Perhaps more importantly, DDR3L should be able to do all of this while providing the same high performance of traditional DDR3 memory, and pricing will be “competitive”.", "\tMicron is also the first vendor with DDR3L-RS products to be validated by Intel, giving them a leg up on the competition. In addition to the current 2Gb and 4Gb devices, Micron has also begun sampling 8Gb x 32 DDR3L-RS and is delivering 8Gb x 16 DDR3L-RS. Production for both is slated for December 2012. These products should help reduce board space by increasing density, which is again particularly beneficial for the new wave of ultrathin computing devices—and hopefully it spells the end of 4GB non-upgradeable Ultrabooks. Finally, Micron expects additional power and footprint savings with the launch of DDR4-RS in early 2013. "]},
{"title": "Additional Details on Micron’s DDR3L-RS, DDR4-RS, and Other Memory", "paragraph": ["\tEarlier this week we posted a short write-up about ", ". We didn’t have a lot of technical detail to go on at the time, but Micron offered us a chance to chat with them on the phone and we were able to get more information about DDR3L-RS as well as their other memory products. Memory is something many of us take for granted in our PCs and other computing devices, but there’s a lot more going on in the market than you might expect.", "\tIf you need the least expensive memory possible, DDR3 is currently the way to go. On the other hand, if you’re making a mobile device, finding memory that uses less power even if it costs more might be the best option. Naturally, there are plenty of other options that fall somewhere in between those extremes; Micron provided us with the following chart showing where the various memory types fall in terms of price vs. power requirements.", "\t", "\tStarting at the top with LPDDR3 and other LPDDR products, their specialized nature is what gives them both their low power usage as well as their higher cost—consider how most tablets and smartphones only ship with 1GB LPDDR or less right now. Chiefly this comes because of the complexity of the devices; for example, the memory might be integrated into an SoC, or placed in a PoP package. The result is that while you can get the best power characteristics out of LPDDR, the volume is much lower as it’s generally not used in high volume markets like laptops and PCs with 8GB or more RAM. We haven’t seen any laptops that use LPDDR so far (at least, not that I’m aware of), but Intel reportedly has LPDDR3 support on their Ultrabook roadmaps, which would allow for improved battery life as well as smaller/thinner designs.", "\tAt the other end of the spectrum we have DDR3, a commodity memory where low price is generally the primary consideration. These devices are mass produced so economies of scale along with less difficult targets (e.g. 1.5V and DDR3-1600 speed) allow them to reach lower price points. Right now, for example, you can find a kit of 8GB DDR3-1600 CL9 SO-DIMMs for around $40 (and under $35 for DDR3-1333 and/or CL11).", "\tOne step up from DDR3 in terms of power efficiency is DDR3L, which targets 1.35V instead of 1.5V. Power scales linearly with voltage and current (P = V * I), and reducing the voltage typically reduces the current required for the chip as well, resulting in a substantial reduction in power draw. Getting chips that will run at a lower voltage is mainly a matter of binning, along with improvements in process technology, so the costs are very similar to regular DDR3. Sticking with the previous example, the same DDR3-1600 CL9 kits cost about 10% more if you get 1.35V DDR3L. Note that most DDR3L laptop kits will also run fine at 1.5V, but if you want to run at 1.35V you’ll generally need a laptop specifically designed to utilize the lower voltage—Apple’s MacBook Pros for instance use 1.35V CL11 memory.", "\tStraddling the line between LPDDR3 and DDR3L, we have Micron’s new DDR3L-RS memory. The RS suffix stands for “Reduced Standby”, and through a process of binning along with a few extra features, Micron is able to cut standby power use for a system by around 25%. DDR3L-RS is also backwards compatible with the DDR3 standard, so there’s no change necessary at the controller level—all the extra work happens in the memory devices. Micron couldn’t discuss specific prices of their various memory types, but they did suggest that at the component level DDR3L-RS should cost around 20% more than DDR3L. In terms of power efficiency, Micron provided the following information showing their expected power savings:", "\t", "\tOne of Micron’s key features in reducing the amount of power used in standby mode is TCSR: Temperature Controlled Self Refresh. Most systems are specified to run the RAM at up to 85C when active, but in sleep mode the temperatures drop substantially and open the door for some additional power savings. In the case of Micron’s DDR3L-RS, once the temperature hits 45C or less, they can reduce how frequently RAM needs to be refreshed and thereby reduce the power draw. It's also important to remember that DDR3L-RS won't perform any better than DDR3L in active use; its benefits as the name implies are only when the memory/system is in standby.", "\tWe should note that while we’re talking about Micron’s specific memory, DDR3L-RS, it is expected that the other major memory manufacturers (e.g. Hynix, Elpida, Samsung, etc.) will have similar RAM technologies, though the specifics of how they save power may vary among the suppliers.", "\tWhat about future memory technologies like DDR4? Micron also discussed some of their upcoming designs that leverage DDR4 with us, and like the switch from DDR2 to DDR3, the change from DDR3 to DDR4 will necessitate new memory controllers and will not be backwards compatible. One of the biggest changes with DDR4 is that the standard voltage drops from 1.5V (DDR3) down to 1.2V, enabling power savings over even DDR3L. Micron will also have DDR4-RS memory available, and we’ll likely see products start to use that (e.g. some tablets) as soon as late 2012/early 2013. While Intel hasn’t officially made any statements in regards to Haswell’s memory technology, the emphasis on reducing power use would make that an ideal time for Intel to switch from a DDR3 controller to DDR4—we should know more sometime in the coming months.", "\tWrapping up, obviously there’s no single “silver bullet” memory technology that works best for all markets. Paying a price premium for DDR3L or DDR3L-RS on a desktop just to save a couple watts of power doesn’t really make sense, while on laptops and in particular Ultrabooks the power savings could definitely be worthwhile. Like other DRAM manufacturers, Micron looks to offer a broad selection of DRAM devices for the whole array of options. The end result is that customers can choose based on cost, form factor, power, etc. and find the best balance of features and pricing for their product. Margins on memory products have become razor thin over the years, so anything that can help companies like Micron find a way to improve their bottom line is obviously something they will pursue; currently, the ultrathin computing initiative—tablets, Ultrabooks, sleekbooks, etc.—is really pushing for improvements in memory technology.", "\t"]},
{"title": "Memory Performance: 16GB DDR3-1333 to DDR3-2400 on Ivy Bridge IGP with G.Skill", "paragraph": ["\tMemory reviews are, in my opinion, actually quite hard to do.  There are plenty of memory kits available that are nice and cheap, and the easy way to differentiate between them in a review is usually though synthetics – without too much effort we can find memory comparison articles online that deal solely in synthetics.  The downside of synthetics is that they rarely emulate real-world performance.  When the requests came in for a comparison of memory kits available on the market, I was stumped to find real-world examples where memory truly matters by significant margins, and benchmarks to match.  Fast forward a month or so, and we have compiled a series of tests taking advantage of some of the most memory limited examples common to most users – IGP performance using memory from DDR3-1333 to DDR3-2400.  Inside this review we have also mixed in some encoding, compression, and you may be surprised to hear that USB 3.0 performance is also affected by memory speed.  In this article we also look at and review the memory kits that G.Skill has gracefully provided from their Ares, Sniper, RipjawsX, RipjawsZ and TridentX brands.", "\t", "\tGraphical performance is all about vector calculations - moving data from memory to the compute units for calculation then placing it back out again where required.  High end graphics cards do this quite well, with the high end NVIDIA GTX680 video cards achieving a rated bandwidth of ~192 GB/s.  In comparison, integrated graphics have a tough time.  Their main memory store is the system memory, which can vary from 10 GB/s to 50 GB/s depending on the platform.  There are architectural decisions made in both circumstances (discrete and IGP) to reduce the importance of memory bandwidth, and software can be written to hide the memory bandwidth or memory latency issues.  But the fact still remains that memory bandwidth is key and vital for a good number of real-world applications and usage scenarios.", "\tThe future of memory is a little mysterious to say the least.  Current modern systems run DDR3 SDRAM that can vary in speed from 800 MHz to 3000 MHz, which also varies in price, performance, power usage, and if the memory controller can handle such a speed.  Those 3000 MHz modules cost a pretty penny, and are reputed to only work with 1 in 10 Ivy Bridge processors.  The immediate future for memory still lies in DDR3 – the next iteration, DDR4, is still several years away.  We are told that on the Intel side of things, Haswell is DDR3, as will be Broadwell, the Haswell replacement.  Reports expect DDR4 to be less than 10% of the market in late 2014 (early adoption in the high end space), but 50%+ across 2015.  DDR4 is expected to have a base speed of 2133 MHz up to 3200 MHz for initial enthusiast applications – though given the rise in enthusiast speeds this could seemingly be pushed to 4266 MHz+ over the course of the development cycle.  DDR4 is also expected to be a single module per channel, paving the way for up-to-quad channel in the mainstream arena.", "\tThere are also exciting technologies being developed in the memory space, for both NAND and DRAM – memristors, ReRAM, stacked memory, spintronics et al. If history is anything to go by, as long as these technologies are not hindered by patents, trolls or physics, each could lead to interesting products coming to market.  Though we may have to wait several years, and chances are that only one or two will come through for their respective markets, and the rest will go the way of Betamax and HD-DVD.", "\tBack to our DDR3 memory, G.Skill was kind enough to provide us several kits for this overview of memory performance.  Most DDR3 kits on sale for the vast majority of users come in speeds from 1333 MHz to 2133 MHz.  Anything above DDR3-2133 is definitely in the enthusiast range, and as such G.Skill also sent us a DDR3-2400 kit to test for this overview.  In due course we also have a DDR3-2666 kit to test, so stay tuned for that review.", "\t", "\tBut memory is not all about the MHz, just as computer speed is not all about the MHz and cores.  Deciding when memory should be accessed, what delays to be put in place between read and write cycles are the sub-timings.  These sub-timings are arguably more important than the MHz number, as we will see in the review.  The main timings on display to the public are the following:", "\tCAS Latency (CL)", "\tRAS to CAS (tRCD)", "\tRAS Precharge (tRP)", "\tRow Active Time (tRAS)", "\tRow Cycle Time (tRC)", "\tCommand Rate (CR)", "\tFor a very extensive look into memory, our last big memory article went into obscene depth of how memory works.  Please read it ", ", and I will confess that I do not understand it after just reading it, but need a pen and paper when going through it thoroughly.  One of the most important images of that memory article is the following:", "\t", "\t", "\tUsing this image, from left to write, we can explain what the timings mean to a certain degree:", "\ttRAS determines the length of time between initialization and the requirement for the memory row to recharge.  Within this tRAS we need a tRCD to initialize the column of the row from which we would like to read. After the tRCD is the CL, which provides a read latency.  There are also other features which allow for reads across multiple columns within the tRAS, however in order to move to the next row the tRAS needs to end and the tRP allows the next row to precharge.", "\tAll this means that:", "\tIf tRAS is a low number, it is quick to read from different rows.  If it is a high number, reading from different columns is easier.", "\tIf CL is a low number, reading from within a row (and the columns) is quicker.", "\tIf tRCD is low, more CLs can be initialized inside the tRAS.", "\tIf tRP is low, then the overall time (tRAS+tRP) to jump between row reads is quicker.", "\tWhen we buy a memory kit, we usually get a SKU number and a description of the modules at hand.  Let us look at the first kit we will be testing today:", "\tF3-1333C9Q-16GAO", "\t4x4 GB DDR3-1333 9-9-9-24 1.50V", "\tThe first line describes the module in the form of a SKU, which allows for stock checking.  In this case, G.Skill’s naming scheme makes it simple – F3 means DDR3; 1333C9 means 1333 MHz with CL9; Q means quad module kit; 16G means it is a 16GB kit; A means the Ares branding; and O means our kit is colored orange.", "\t", "\tThe second line is a little more readable.  First we get the size of the kit (4x4 GB) then the speed (DDR3-1333).  Next are the sub-timings, which will always appear in the order of CL-tRCD-tRP-tRAS.  This means that our three main sub-timings are 9-9-9, and the tRAS is 24.  The last bit of information is the voltage of the kit.", "\t", "\tAs a general rule, lower is better.  Memory kits on the market will vary in their subtimings – you can purchase DDR3-1333 9-9-9, DDR3-1600 11-11-11 all the way up to DDR3-3000 12-14-14.  The question then becomes whether you want to decide between two similar kits.  Imagine the following kits:", "\tDDR3-1333 9-9-9", "\tDDR3-1600 10-10-10", "\tDDR3-1866 11-11-11", "\tIn a lot of scenarios, an enthusiast may take one look at these numbers and tell a user that these kits are equivalent – boosting the memory speed but increasing the sub-timing latencies causes similar performance.  There is one way to determine whether a kit might be better than another, and that is to look at the calculable latency of the kit.", "\tCalculating this value is a simple enough formula:", "\t2000 x (CL / Speed ) = Latency in nanoseconds (ns)", "\tThus for the three kits above:", "\tDDR3-1333 9-9-9 has a latency of 13.5 ns", "\tDDR3-1600 10-10-10 has a latency of 12.5 ns", "\tDDR3-1866 11-11-11 has a latency of 11.79 ns", "\tThis latency essentially tells us which kit is fastest at non-sequential reads.  Non-sequential reads are important in a lot of variable scenarios, such as video games whereby the user could perform one of a billion different actions and as such different elements of the memory have to be loaded. ", "\tThe downside of this test is that it does not take into account consecutive reads.  When dealing with conversion, video editing, or anything that requires a large dataset to be read sequentially, we have to look at how long reads are processed.", "\tThe way to check this with DDR3 is as follows:", "\tCycle time in ns = 1000 / (Memory Speed / 2)", "\tBit time in ns = 1000 / Memory Speed", "\tThe time to read a single word of data (word is a technical term meaning 64 bits) is given by the Cycle Time multiplied by the CL.  The time to read eight words is the Cycle Time multiplied by the CL then add seven lots of Bit Time.  Let us go through the memory kits above with this method.", "\tDDR3-1333 9-9-9 has a Cycle Time of 1.5 ns and a Bit Time of 0.75 ns", "\tThe time to read one word is 1.5*9 = 13.5 ns", "\tThe time to read eight words is 13.5 + 7 * 0.75 = 18.75 ns", "\tDDR3-1600 10-10-10 has a Cycle Time of 1.25 ns and a Bit Time of 0.625 ns", "\tThe time to read one word is 1.25 * 10 = 12.5 ns", "\tThe time to read eight words is 12.5 + 7 * 0.625 = 16.875 ns", "\tDDR3-1866 11-11-11 has a Cycle Time of 1.07 ns and a Bit Time of 0.536 ns", "\tThe time to read one word is 1.08 * 11 = 11.79 ns", "\tThe time to read eight words is 11.79 + 7 * 0.536 = 15.54 ns", "\tIn both the sort reads and long reads, DDR3-1866 11-11-11 wins out of the three kits.  But what if it was not so clear cut?", "\tThe following kits have the following timings and results:", "\tDDR3-2000 at 9-9-9 reads one word in 9 ns and eight words in 12.5 ns", "\tDDR3-1666 at 7-7-7 reads one word in 8.75 ns and eight words in 13.125 ns", "\tThis means that the DDR3-2000 kit should be better for longer reading workloads, whereas the DDR3-1666 kit should be better for random reads.", "\tI should stress (and add a disclaimer) that this comparison is all at the high level, as we are only talking about memory speed and CAS Latency – everything else plays its part, and I highly suggest reading Rajinder’s memory article to get a deeper look as to how this all works.", "\tPersonally, I use these formulas when overclocking competitively – if I have two kits, one of which can do DDR3-2000 6-7-7 and the other is DDR3-2666 11-13-13, I can decide which one is more appropriate for the benchmark in question.", "\t", "\tThis funny little number at the end is often quoted as 1T or 2T depending on the memory kit, how many modules are installed, and the motherboard settings.  The command rate is the address and command decode latency, essentially the delay between accessing and decoding data - this delay allows the memory time to be accessed without errors. ", "\tIn an ideal world there should be no latency, but in performance tests using a setting of 1T is shown to be quicker than 2T for synthetic benchmarks.  Whether a user can feel the difference (in essence it adjusts peak bandwidth as well) is debatable, but the slower the kit as standard, the more of a difference will be felt between the two options.  The argument also exists that a setting of 2T will allow the kit to be overclocked higher. ", "\tBy default 2T is usually selected for memory kits that contain more modules - on the off chance that one module of the kit cannot perform at the stated speed using 1T timings, defaulting to 2T will make sure more modules pass the binning process.", "\t", "\tContrary to the most popular of beliefs, memory kits do not work as stated out of the box.  The number of times I have walked through a large LAN event and found people playing games on $2000+ water cooled systems, only to find that their kit of DDR3-2400 is actually running at DDR3-1333 astounds me.  It is a lot more common than you think, and there is probably someone you know that is a culprit of this.  Making sure memory is set at its rated speed is an important part of the process, and as an enthusiast we have a job to make sure that is the case.", "\tRant aside, this is an important point – when we buy a processor, it always runs at the stated speed.  When we plug it into the system, there is no fiddling required.  If every time I installed a processor I had to go into the BIOS and adjust it so it runs above 1.2 GHz or 1.6 GHz, I would be annoyed.  So why is there this discontinuity on the memory side?  Why do we have to go into the BIOS to adjust the memory speed to what it says on the box?", "\tThe issue is largely down to compatibility.  When a processor is installed into the board, the processor knows that it will go into a board that has the right socket, it knows that there will be pins for a certain number of PCIe lanes or for data transfer to the chipset.  It also knows that there will be memory on the end of some pins that runs at a designated multiplier as dictated by the BIOS.  The issue with memory is that the memory does not know where it will be plugged into.", "\tA DDR3 module or kit could be plugged into any DDR3 compatible motherboard, and paired with AMD, Intel, or any other processor capable of DDR3, such as server parts.  As processor design is now putting the memory controller onto the CPU itself, the capabilities of that memory controller can vary wildly.  On a Xeon processor, the system may only accept 1600 MHz maximum due to the capable multipliers, so it would be foolish to try and boot the system with a 2133 MHz kit attempting to apply full speed.  We could plug at DDR3-2666 kit into a Sandy Bridge system, but the memory controller would refuse to run at 2666 MHz.  However, take the same motherboard and an Ivy Bridge processor, and the memory should be able to work.  Then at the high end, remember I mentioned that there are DDR3-3000 memory kits that only work with 10% of Ivy Bridge i7-3770K processors?  There is that too.  I could plug in a four module DDR3-kit into a 990FX board, a P67 motherboard, a B75 motherboard, or something nice and obscure.  The memory does not know what processor or memory controller it is going to get, but the processor does know that it will get DDR3 when it is plugged in.  There are a lot more variables on the memory side which are unpredictable.", "\tWith that being said, we have seen some ", " with plug-and-play capabilities.  This memory was limited in speed, availability, and did not catch on in the way that it should.  Speaking with memory vendors, the main barrier to this being applied globally are the motherboards themselves – the motherboard should be able to recognize a plug-and-play kit then adjust accordingly.  There are already standards set in place (JEDEC, XMP – more later on these), so if the plug-and-play does not work, then the speed will be reduced down to the one that works.  It sounds simple, but then again how do we confirm that the memory works?  If it boots into an operating system, or if it survives 72 hours of MemTest86 or Linpack?  Do people want to wait 3 days to get the system at the speed the kit is rated?  The answer is almost certainly no, hence why we are limited to adjusting a BIOS setting to get the speed we want.", "\tI have floated the idea of having software with the memory kit to enable XMP through the operating system, but the main barrier to that is the need for the software to work with every motherboard available.  The next thought was to whether the motherboard manufacturers could create the software, to enable a JEDEC or XMP setting on the next boot through software.  As expected, the answer was the complication of so many modules and so many motherboards.  The answer to this new problem would be to include standards to the memory and the motherboards so this all works – but there are already standards.  For this to work, it would require a deep partnership between a motherboard manufacturer and a memory vendor, potentially aiding sales from both sides.  We will see.", "\tIn the meantime, make sure your friends and family are running their memory at rated speed!", "\t", "\tThis review takes into account five kits from DDR3-1333 to DDR3-2400.  Many thanks to G.Skill for providing us with these memory kits, one of each from their Ares, RipjawsX, Sniper, RipjawsZ and TridentX series.  Specifically, we have the following kits:", "\t4 x 4 GB DDR3-1333 9-9-9-24 1.50 V : F3-1333C9Q-16GAO (Ares)", "\t4 x 4 GB DDR3-1600 9-9-9-24 1.50 V : F3-12800CL9Q-16GBXL (RipjawsX)", "\t4 x 4 GB DDR3-1866 9-10-9-28 1.50 V : F3-14900CL9Q-16GBSR (Sniper)", "\t4 x 4 GB DDR3-2133 9-11-10-28 1.65 V : F3-17000CL9Q-16GBZH (RipjawsZ)", "\t4 x 4 GB DDR3-2400 10-12-12-31 1.65 V : F3-2400C10Q-16GTX (TridentX)", "\t", "\tOver the next few pages, we take the run down of all these kits."]},
{"title": "GeIL Evo Veloce Review: 2x8GB at DDR3-2400 C11-12-12 1.65 V", "paragraph": ["\tAs part of a series of memory reviews, the next kit to enter our test beds is a limited edition enthusiast kit from GeIL.  Attached with what is called a ‘Frost White’ colored heatsink, this is a two module dual channel kit with a total of 16 GB running at DDR3-2400 MHz at 11-12-12-30 sub-timings that retails for ~$150.", "\t", "\tGeIL is short for Golden Emperor International Limited, and in the world of memory, have been a main player in the consumer memory space since the late 1990s.  Today their product range consists of product names typically reserved for cars – Corsa, Leggera, and in this case Evo Veloce.  This could imply that GeIL want to advertise themselves at the forefront of memory production, and this is shown by their catalogue on Newegg showcasing mostly kits with 8GB modules. ", "\tThe bulk of their memory sales comes from their Corsa range, featuring yellow colored heatsinks in a range of capacities (8GB modules to 8x8GB kits) and speeds (1333 to 2133 MHz). ", "\t", "\tThe Leggera range has similar speeds (up to 2400 MHz) and capacities (up to 4x8GB kits), but smaller blue heatsinks.", "\t", "\tIn contrast their Black Dragon range is heatsinkless, and comes in at only 1333 and 1600 MHz:", "\t", "\tToday we are looking at one of GeIL’s Evo Veloce kits, kitted out in a ‘limited edition’ frost white.  The heatsinks are large, and with two 8 GB modules, there leaves room for upgrades in the future.", "\t", "\tBack in the", "overview, superlatives were not forthcoming with our DDR3-2400 C10 kit under scrutiny.  It offered little performance gain over the DDR3-2133 C9 kit, but asked for another $15 for the privelege to exceed in peak synthetic results only.  The GeIL Evo Veloce DDR3-2400 11-12-12 2x8GB kit then has a tough act to follow, coming in at $150 (more than the 2400 C10 kit) and having the timings reduced.  The upshot of all this is more capacity per module, leaving the door open for future upgrades, or maximising the memory in a dual module system.", "\tWhen making the jump from 4GB modules to 8GB modules, compromises have to be made.  It could be construed that as everything is smaller, accesses should be quicker – but with double the density we can accrue additional latencies by reading larger rows in our memory module.  Whether that actually makes a difference in normal day to day tasks is another matter – everything to do with memory and memory speed borders on the debatable when it comes to actually affecting everyday use.", "\tIn terms of the competition, solely looking at 2x8 GB kits means on Newegg we have two competitors – the G.Skill TridentX 2400 C10 kit ($155) and the Corsair Dominator Platinum 2400 C10 kit ($255).  Going on solely XMP profiles, the G.Skill is the main competition, and being C10 is an advantage.  However, a set of 2x8 GB from the Crucial Ballistix range at 1866 C9 ($150) could also give the 2400 kit a run for the money.  Based on the calculation methods described in our original Ivy Bridge DDR3 overview, we having the following:", "\t2x8GB DDR3-2400 C10 has a latency of 8.33ns, and will read 8 words in 11.25ns", "\t2x8GB DDR3-2400 C11 has a latency of 9.16ns, and will read 8 words in 12.08ns", "\t2x8GB DDR3-1866 C9 has a latency of 9.65ns, and will read 8 words in 13.40ns", "\tWhenever we look for a memory kit, having something extra to talk about always helps – aesthetics or overclocking usually works well.  While the Evo Veloce frost white modules look nice, they overclocked relatively well, hitting 1T with no issues, as well as overclocking to DDR3-2600 11-12-12 and DDR3-2400 10-11-11 at stock voltages.", "\t", "\t", "\t", "\t", "\tUsually the first thing we notice about the high end memory kits is the size of the heatsink.  With the Evo Veloce 2400 C11 kit, the heatsink extends 17 mm above the module itself providing some but not an optimal amount of surface area to dissipate heat… if that was the primary purpose.  Heatsinks on memory kits in the year 2012 tend to be on the kit for two reasons – the first is aesthetics, and as such if a user is producing a colored build then having memory the right color is a step in the right direction.  The other reason is one of secrecy – more often than not memory vendors no longer disclose what type of memory is underneath and where they buy it from.  We know that GeIL does its binning of the ICs, but they do not want other manufacturers to know which ICs are being used unless the manufacturer buys a kit and then rips it apart.  These heatsinks are sufficiently bonded to the ICs that attempts to remove them will damage the module.  Nevertheless, here are what the modules look like:", "\t", "\t", "\tIn comparison to other kits we have tested, we can see the extent of the heatsink.  In the case of the G.Skill Ares, which is a standard height memory module:", "\t", "\tIn terms of the G.Skill RipjawsZ:", "\t", "\tAnd against the tallest kits we have in, the G.Skill TridentX:", "\t", "\tWhen placing such large modules into a motherboard, we must be aware of how large air coolers can affect the placement.  Typically a large air cooler will encroach on the nearest memory slot, and thus choosing the right memory can be important.  Following on from our previous memory testing, here is the attempt to get a GeIL kit into a Gigabyte H77N-WiFi which has a Copper TRUE mounted so the PCIe slot is not blocked:", "\t", "\tThe result is not good – I could not even get the module in.  In contrast, here is the second slot:", "\t", "\tWhile the module is in the slot, we are right up against the cooler and there is some pressure there against the module forcing it at an angle.  Users with these modules may want to invest in some form of all-in-one liquid cooling as a result.  In our actual testing we use an ASUS P8Z77-V Premium and a stock Intel cooler, meaning spacing is not an issue.", "\t"]},
{"title": "G.Skill TridentX Review: 2x4GB at DDR3-2666 C11-13-13 1.65V", "paragraph": ["\tNext in our line of memory reviews is a kit I have actually had at my work desk for a while.  In the land of overclockers, synthetics are everything – if it can get a higher number on a screen, and that number can be pushed, then it is worth it.  Thus in steps comes G.Skill with their high end TridentX range, pushing the boat from DDR3-2400 (both 4GB and 8GB modules) all the way up to DDR3-2800 (4GB modules only).  The kit we are testing today falls right in the middle of all of this, being a 2x4 GB kit of DDR3-2666 11-13-13.  This is an 8 GB kit that retails at $170, and for that money we could easily pick up a 2x8 GB 2400 C10 kit.  Proof will be in the pudding as we put this kit through the testing suite – let us see if it is actually relevant for day-to-day use.", "\t", "\tBack in our initial memory overview, I gave a couple of formula in order to calculate (at a high level) how a memory kit should act in sequential and random reads.  The formulas were:", "\tTime to read one word: CL * 2000/MHz", "\tTime to read eight words: CL * 2000/MHz + (7*1000/MHz)", "\tApplying this to the G.Skill kit we have in today gives us 8.25ns for a one word read, and 10.88ns for reading eight words.  For comparison, the following memory speeds offer similar scores:", "\tDDR3-2000 C8: 8.00ns/11.50ns", "\tDDR3-2133 C9: 8.44ns/11.72ns", "\tDDR3-2133 C10: 9.38ns/12.66ns", "\tDDR3-2400 C10: 8.33ns/11.25ns", "\tDDR3-2400 C11: 9.17ns/12.08ns", "\tDDR3-2600 C10: 7.69ns/10.38ns", "\tDDR3-2600 C11: 8.46ns/11.15ns", "\tDDR3-2666 C10: 7.50ns/10.13ns", "\t", "\tDDR3-2800 C11: 7.86ns/10.36ns", "\tDDR3-2800 C12: 8.57ns/11.07ns", "\tMost of these kits should be available for sale around the same price, but purely by these numbers the 2666 C11 has an advantage over both the 2400 C10 and the 2800 C12.  Moving up to 2666 C10 obviously has the advantages of the lower command rate.", "\tWith the G.Skill 2666 C11 kit we are testing today, as it is the highest rated kit we have tested, it clearly gets top marks across almost all of our benchmarks.  Obviously there are some benchmarks that enjoy the MHz (Batman:AA, WinRAR), but others either tend towards a limit (Portal 2 on IGP) due to other factors becoming limiting, or some would prefer more memory as a whole (Thunderbolt copying, more on that later), or others need a nicer balance between MHz and Command Rate (catia in SPECviewperf).", "\tThe kit is also great at overclocking.  Like I said, I have had this kit for a while, and part of playing around with the kit was an attempt to push the MHz as far as it would go.  In that respect the kit easily pushed 2800 C11 at stock volts, and 2950 C12 with a bit more juice.  Given that plenty of kits on the market will not move an inch above XMP at stock volts, this is nice to see.", "\tThe downsides to this kit are predominantly two-fold.  The cost per GB is astronomical, especially compared to the other kits we have tested.  In our memory overview, the 1866 C9 4x4GB kit performed at almost the same level as this 2666 C11 2x4GB kit for double the capacity and $75 less.  That is a shocking statement – the only way to show that the 2666 C11 kit is a mountain and a half better than the 1866 C9 kit is through synthetics, which rarely have a real-world influence, especially in memory.", "\tAs a result, this kit is purely for the extreme overclockers out there – those that need and can feel the difference between 2666 C11 and 2400 C11 by virtue of the number they get on a screen.  It will be some time before a kit of this high specifications comes down to a reasonable price (sub $100) for the rest of the userbase to be interested.", "\t", "\t", "\t", "\tThe big change over previous kits is the tRFC, the Row Refresh Cycle time.  tRFC is defined as the minimum wait in cycles required following a refresh to an idle bank before it can be again activated for access.  This should mean that reads from subsequent rows requiring a refresh will be faster compared to the 2400 C10/C11 kits we have tested.", "\t", "\tThis TridentX kit is essentially the same as the previous TridentX 2400 C10 kit we reviewed - TridentX is one notch above RipjawsZ, and spans kits from DDR3-2400 C9 to DDR3-2800 C11.  The main features on the kit (aside from the speeds) are the heatsinks, to which G.Skill have added a detachable fin.  Without the fin, the module is approximately 9mm above the module, and with the fin the total height is 22mm above the PCB.  That is a lot of height for a memory module that in 99% of circumstances would not produce enough temperature to trouble any build.", "\t", "\t", "\t", "\t", "\t", "\tIn order to remove the fin there is a screw at each end of the module, and the fin slides off effortlessly.  The fins fit very well, but upon attempting to reattach a fin I was unable to get it on as securely as it came out of the box, leaving a little wobble in the fin.  There is no cause for alarm if you get a module with a wobbly fin – nothing is wrong, and it will not affect the heat dissipation as much as most users may think.  Most modules output a few watts at best, so dissipation of several watts of energy without a fin is simple enough.", "\tOne thing I should point out with the TridentX modules is the fins are actually very sharp – if you are trying to put these modules into a motherboard where the range of movement to apply pressure is small, wear some gloves.  I actually did take some skin off my hand doing exactly this, trying to use my fingers and palm to push the modules down.", "\tAs with the previous TridentX 2400C10 kit, putting such a large module in our TRUE Copper scenario was a recipe for disaster:", "\t", "\tEven putting the module in the second slot faired no better:", "\t", "\tAll the testing for this review was done on an ASUS P8Z77-V Premium motherboard with the Intel stock cooler, so module movement is not much an issue in that case, but big air coolers still get a lot of usage (and is more often than not an investment over several updates), so there are things to consider when purchasing memory.", "\t"]},
{"title": "Crucial Demonstrates DDR4-2133 Modules", "paragraph": ["\tWe’re not likely to be running DDR4 any time soon on desktops, and even most laptops are probably over a year away from getting the upgrade, but now is the time to prepare for the shift. To that end, Micron (Crucial) has a DDR4 demonstration running at CES 2013. The system is an Intel test platform with undisclosed internal hardware, affectionately (or perhaps not) referred to as the Frankenstein Box. My guess is that there might be an Ivy Bridge, Sandy Bridge-E, or current-gen Xeon running in the box with a converter board of some sort to allow the DDR4 to talk to the DDR3 on-die controller (similar to the RDRAM to SDRAM converters we saw back in the Pentium 4 Rambus days), but how they’re running it right now isn’t particularly important so much as the fact that they are able to run Windows. It’s just as possible that the box has an unannounced next generation Xeon with a DDR4 controller. But I digress….", "\tThe systems wasn’t open for inspection, but Crucial had an oscilloscope showing the signals on the test unit and a bootable Windows 7 platform running a bouncing balls simulation, which is what we usually see with early/prototype/Frankenstein systems. The memory was running at 2133MHz, apparently with similar timings to what we currently see with DDR3-2133, so at launch the base DDR4 speeds are going to be around twice as fast as what we saw with DDR3. The test platform unfortunately is limited to 2133MHz as the maximum clock; Crucial said they’re seeing 2400-2800MHz without any trouble, and the JEDEC DDR4 specifications currently go up to DDR4-3200. Worth note is that DDR4 makes some changes to help reduce power use, including dropping the standard voltage to 1.2V (down from 1.5V with DDR3), and we’ll likely see low voltage and ultra low voltage DDR4 in the 1.0-1.1V range.", "\tThe standard memory chips are now 4Gb compared to 2Gb for most DDR3, which makes 4GB single-sided and 8GB double-sided DIMMs the starting capacity. The initial target devices will be servers where the improved memory density and power savings are needed most, effectively doubling the amount of RAM we’re likely to see at similar price points/configurations to the current generation DDR RAM. Crucial will be releasing a full portfolio of products based off the memory chips, including RDIMMs, LRDIMMs, SO-DIMMs, and UDIMMs (standard and ECC). Mobile and desktop adoption of DDR4 is expected to occur in 2014. One change Crucial pointed out with their UDIMMs can be seen in the photo above: the edge with the 284 pins is no longer perfectly straight. The idea is that when you insert a DDR4 DIMM, it will require less pressure as you’ll only be pushing in about half of the pins at a time.", "\t", "\tBesides the DDR4 demonstration, Crucial had a display showing their various memory modules over time, from DDR through DDR4. It’s always fun to see how far we’ve come over the past eight or so years. At the top we have a DDR DIMM with 184 pins—state-of-the-art circa 2001/2002. Launch speeds were DDR-200 (PC1600), with capacities of 128MB to 1GB being typical over the life of the product. DDR2 moved to 240 pins around 2003, launching at DDR2-400 and moving up to DDR2-1066 by the end of its life cycle; typical capacities ranged from 256MB to 2GB. 2007 brought about the advent of DDR3, and while there are technically DDR3-800 parts, for the mainstream market DDR3 started at 1066 and has officially moved up to DDR3-2133; capacities are generally in the 512MB to 4GB range, with 8GB being the maximum. And last we have DDR4, launching by the end of the year. If the pattern continues, we should see DDR4-4266 by the time DDR5 memory is ready for mainstream use and capacities will start at 2GB and likely top out at 16GB (possibly more) per module.", "\t"]},
{"title": "Micron and TE Connectivity Offer New Ultrathin DRAM Solutions", "paragraph": ["\tThe push for smaller and thinner laptops, Ultrabooks, and tablets of late has come with some potentially undesirable side effects, namely the loss of flexibility. Of the Ultrabooks we’ve reviewed, I’m not sure any supported more than a single SO-DIMM slot for memory expansion, and many of them have all the DRAM components mounted directly onto the motherboard, all in the pursuit of reducing the z-height of the systems. In an effort to provide something of a middle ground, both Micron and TE Connectivity are offering alternatives that provide some reduction in z-height compared to standard SO-DIMMs while still maintaining the flexibility of an SO-DIMM slot.", "\tThe solution is quite simple and maintains full backwards compatibility with standard SO-DIMM slots, but to fully realize the z-height savings a modified SO-DIMM socket is required. In short, Micron is offering single-sided SO-DIMMs (with a standard 4GB capacity); since there are no components on one side of the SO-DIMM, it can lie flat against the motherboard. This is where the new SO-DIMM socket comes into play: it would have the module sit nearly flush against the motherboard so the connector would be the same but the housing would be slightly different.", "\tTo put things in perspective, a standard SO-DIMM is around 4mm thick; the new single-sided SO-DIMMs are able to reduce the z-height to 2.6mm. That’s not to say that they’re able to match surface mounted DRAM (around 1.2mm), but users and manufacturers would be able to choose between several memory configurations (generally speaking, 4GB or 8GB) and still maintain a thin profile. With surface mounted DRAM, you get the thinnest profile but completely lose out on upgradeability and if a company wants to offer two SKUs (e.g. 4GB and 8GB) it requires more effort in the manufacturing and assembly process. There’s also the potential for DRAM failures, which are simple to fix if you have a module but require a new board if you have surface mounted components.", "\tFrom a high level, I’d just as soon see all modern laptops ship with 8GB standard, particularly the Ultrabooks with surface mounted DRAM, but manufacturers are always looking for ways to reduce cost and that has led to the existing crop of 4GB non-upgradeable Ultrabooks (ASUS UX21A/UX31A, Acer S7, etc.) One other item of note is that all of the reduced z-height modules from Micron will be ", " (", "). At least initially, the modules will only be shipping in 4GB capacities (currently, 8GB SO-DIMMs require dual-sided modules). Future higher density modules with monolithic devices (8x8Gb) should show up eventually, and of course all of the design elements are applicable to DDR4 when we see a shift to that some time likely next year.", "\tThis particular approach is only one of several that are apparently being tossed around in the industry, but thanks to the backwards compatibility with existing SO-DIMM slots it appears to have a better chance of succeeding. Other approaches that are being looked at right now include non-standard modules, which would require new connectors and modules and likely limited production compared to existing solutions. It’s expected other companies will also support the new connector, and availability of the new package (connector and single-sided SO-DIMMs) is expected this spring.", "\t"]},
{"title": "Server Buying Decisions: Memory", "paragraph": ["\tWe reviewed several types of server memory ", ". You still have the same three choices—LRDIMMs, RDIMMs, and UDIMMs—but the situation has significantly changed now. The introduction of the ", " is one of those changes. The latest Intel Xeon has better support for LR-DIMMs and supports higher memory speeds (up to 1866 MHz).", "\tBut the biggest change is that the pricing difference between LRDIMMs and RDIMMs has shrunk a lot. Just a year ago, a 32GB LRDIMM cost $2000 and more, while a more sensible 16GB RDIMM costs around $300-$400. You paid about three times more per GB to get the highest capacity DIMMs in your servers. Many servers could benefit from more memory, but that kind of pricing made LRDIMMs only an option for IT projects where hardware costs were dwarfed by other costs like consulting and software licenses. Fifteen months in IT is like half a decade in other industries; just look at the table below.", "\t", "\tIf you need a refesher on UDIMMs, RDIMMs and LRDIMMs, check out ", ". The price per GB of LRDIMMs is only 60% higher than that of the best RDIMMs. Quadrank 32GB RDIMMs used to be a lot cheaper than their load reduced competition and that difference is now negligible."]},
{"title": "Crucial Showing DDR4 Modules and Sport VLP DDR3", "paragraph": ["\tI’m nearly finished with my CES coverage (thanks to a relapse as well as a household of sick family members), with just a few final visits to discuss. My meeting with Crucial/Micron/Lexar had a couple interesting tidbits, perhaps the most noteworthy being their apparently production ready DDR4 modules for both desktops and laptops. It’s pretty clear now that the transition to DDR4 is going to happen with one of Intel’s upcoming CPU/platform launches, though the exact details of the rollout of DDR4 RAM are still a bit hazy – will we see it first on servers, then desktops, then laptops, or maybe desktops first, or given the potential for power savings, why not laptops first? You can also see the slightly curved insertion edge of the DDR4 desktop DIMMs that’s designed to aid in installation.", "\tThe other cool thing Crucial had to show is their half-height Ballistix Sport VLP DIMM. These have been available for a little while, but they have several features that make them attractive. For one, instead of the usual gigantic heat spreaders – which can sometimes interfere with the installation of CPU coolers or other items – the Sport VLP has a very low profile (that’s the VLP part of the name) and ends up being about half the height of a standard DIMM. They’re also 1.35V DDR3-1600 modules, so they use less power and generate less heat – never a bad thing in my book. These are literally the polar opposite of some of ", ", with capacities up to ", " and pricing that’s somewhat higher than standard DDR3 DIMMs. Note that you may need to spend some time in the motherboard BIOS in order to get these DIMMs to work, and raw performance isn’t likely to be as high as some other DDR3 DIMMs, but for mini-ITX builds I could see these being very handy alternatives to regular size DIMMs."]},
{"title": "I'M Intelligent Memory to release 16GB Unregistered DDR3 Modules", "paragraph": ["\tAfter talking about Avoton and Bay Trail on Twitter, I was approached by the company heading up the marketing and PR for I’M Intelligent Memory regarding a few new products in the pipeline different to what we had seen in the market previously.  The big one in my book is that they are currently sampling ", " ready for ramping up production.", "\tCurrently in the consumer space we have 8GB unregistered modules, usually paired together for a 16GB kit.  These use sixteen 4 Gb memory packages on board to total up to the 8 GB number, and are packaged in speeds up to 2933+ MT/s.  Intelligent Memory are a company (or series of smaller individual companies) that have new IP in the market to tie two of these 4 Gb dies together into a 8 Gb die, and are thus able to double the capacity of memory available in the market.", "\tI have been speaking with Thorsten Wronski, President of Sales and Technology at Memphis AG, the company heading up the business end of the Intelligent Memory plan.  We went into detail regarding how the new IP works (as much as I could be told without breaking NDA):", "\tDRAM stacking is unlike NAND stacking.  We have seen ", " onto a single package, but DRAM requires precise (picosecond level) timing to allow the two 4 Gb dies to act as a single 8 Gb package.  This is the new IP to the table, which can apply to both unregistered and registered memory, as well as ECC memory.", "\tThe ", " do account for the use of 8 Gbit packages (either one 8 Gbit die or two 4 Gbit dies per package), should these be available.  However I am told that currently there is a fundamental non-fixable issue on all Intel processors (except Avoton and Rangeley, other Silvermont (BayTrail) is affected) that means that these dies are not recognised.  In their specifications for Ivy Bridge-E, Intel do state that 8Gb packages are supported (", ", page 10), however this apparently has not been the case so far and I'M is working with motherboard manufacturers to further pin down this issue.", "\tTypically the access of a memory chip requires a column and a row, both of which are multiplexed across a set of 16 connects.  With a 4 Gbit package, to access the row, all 16 are used (A0 to A15), whereas a column uses 10 (A0 to A9).  In the 8 Gbit package, the column also requires A11, all part of the JEDEC spec.  This works on Avoton/Rangeley, but not on any other Intel processor, according to Intelligent Memory, and the exact nature of the issue is down to Intel’s implementation of the specification.  I suspect that Intel did not predict 8 Gbit packages coming to market at this time, and have found an efficiency improvement somewhere along the line.  Perhaps needless to say, Intel should be supporting the larger dies going forward.", "\tThe dies that I’M are using are 30nm, and according to them the reason why Hynix/Samsung et al have not released an 8 Gbit DRAM die up until this point is that they are waiting until 25nm in order to do so – this is why I’M is very excited about their product.  It could also mean that users wanting HSA implementations under Kaveri could have access to 64GB of DRAM to play with.  But it also means that when 8 Gbit 25nm DRAM dies become available, I’M will perhaps try for a 16 Gbit package for 32GB modules - all aimed for DDR4 I would imagine.", "\tI’M Intelligent Memory is currently a couple of weeks out from sampling our server guru Johan with some of these modules, so hopefully we will get an insight from him as to how they are looking.  They are intending to go down two routes with their product – selling the combined die packages and selling modules.  I have been told that one of the normal end-user manufacturers has already expressed interest in the packages (rated at DDR3-1600), which they would place onto their own DRAM sticks and perhaps bin the ICs for higher speed.  The modules will be sold also via a third-party that often deals in bulk sales.", "\tMass production is set to begin in March and April, with initial pricing per 16GB module in the $320-$350 range for both DIMM and SO-DIMM, ECC being on the higher end of that range.  To put that into perspective, most DRAM modules on sale today for end-users are in the $8-$14/GB range, making the modules have a small premium which is understandable to get the higher density. ", "\tIf this IP holds up to the standard, I would not be surprised if it is purchased (or at the very least observed) by the big DRAM manufacturers.  I expect these modules will first see the light of day in servers (Avoton based most likely), and I will keep an eye out if any end-user manufacturers get a hold of some.  I’M have verified the modules on AMD FX processors (FX-6300 and FX-8320 on 990FX/AM3+) as well as AMD's 760G and A75 (FM2 socket) chipsets.  I was forwarded the following screenshot of two of these modules in an ", " motherboard, which is a dual DRAM module motherboard using the FM2 socket for Trinity APUs:", "\t", "\tHere each of the 16GB modules (shown in the SPD tab of CPU-Z) are running at DDR3-1600 11-11-11, giving the two DRAM slot motherboard a total of 32GB of addressable space.", "\tAside from unregistered modules, I’M are also planning ", " versions as well, such as 16GB very-low-profile RDIMMs and 16GB ECC SO-DIMMs.  Non ECC SO-DIMMs are also being planned.  A lot of their focus will be the supply of DRAM components for the direct integration onto automated systems where memory counts are fixed, for systems that use Marvell, TI, Freescale, Xilinx, Altera, Renesas and so on."]},
{"title": "G.Skill takes Ripjaws SO-DIMM to DDR3-2600MHz on ASRock M8", "paragraph": ["\tOne of the many issues presented with a SO-DIMM capable system, whether laptop or desktop, is one of performance.  In our recent ", " using regular sized DIMMs, the high-performance sweet spot for memory was around the 2133 MHz CAS 9 or 2400 MHz CAS 10 marks.  The issue with SO-DIMM systems is that memory often starts at 1333 CAS 9 or 1600 CAS 11, but in recent months companies like ", ", ", " and ", " have released higher specification SO-DIMM kits, up to 2133 CAS 11.  This is still a little way off our sweet spot, but on the road.  The main barrier to this incidentally is the lack of XMP support on laptops and mobile devices, firmly shutting the door on speeds above 1600 MHz without a modified BIOS.", "\tWhile we are doing some in-house memory scaling testing regarding SO-DIMM, G.Skill went ahead with some testing using the main overclockable motherboard for SO-DIMMs: the ", ".  We reviewed the ", " as a Steam Box alternative last year capable of handling an i7-4770 CPU and a 250W GPU and gave it a Silver Award for industrial design. ", "\t", "\tFor the overclocking test, G.Skill use their", " and boost the final speed to DDR3-2600 12-14-14.  Back in our memory scaling article we introduced the concept of a memory Performance Index as a rough guide to performance, and this memory kit started at a PI of 193 and ended on 217, or a 12.4% increase in potential performance.", "\t", "\tWhile G.Skill have jumped us in terms of showing that these speeds are possible, it remains to see if memory manufacturers will go ahead and make SO-DIMM modules at this speed. Or ultimately what matters more is that the platforms that use them (especially laptops and SFF) will actually adhere to XMP and allow us to enable it without any fuss.  There are speed gains to be had by moving up from the industry default of 1600 MHz CAS 11 as we showed in our Haswell memory scaling article, but there needs to be a paradigm shift from the manufacturers that implement SO-DIMM.  If the SO-DIMM modules come up to par with regular DIMMs, there might be a future where motherboard memory makes the transition. ", "\t "]},
{"title": "G.Skill Launches 32GB DDR3L-2133 1.35V SO-DIMM Memory Kit", "paragraph": ["\tThe topic of SO-DIMM memory is an interesting one.  As it currently stands, almost all laptops with interchangeable memory slots have SO-DIMM slots, as well as a few motherboards at the low end and systems such as the ", ".  The main issue with SO-DIMM is that it is often limited in frequency – manufacturers who equip their laptops/motherboards with SO-DIMM slots typically do not worry about XMP, and as such SO-DIMM rarely sees more than 1600 MHz at a CAS latency of 11.  However in recent quarters a couple of the memory manufacturers are bucking the trend, announcing that they have DDR3L memory in the smaller form factor that can support higher speeds.  The newest release to this segment is G.Skill’s attempt to provide some of the fastest and dense modules available.", "\tThis week G.Skill is releasing a 4x8GB SO-DIMM kit, under their Ripjaws branding, capable of 2133 MHz at CL11 (while remaining within the 1.35V specification of DDR3L).  The aim for this kit is mostly in the high end gaming laptops that support XMP, such as ", ".", "\t", "\tThe combination of having four free SO-DIMM slots, and an XMP enabled laptop, puts this memory kit into those extreme niche markets.  The ultimate irony here is that during our memory scaling articles, such as ", ", the biggest increase achieved with faster memory was with integrated graphics.  Laptops at this price range that can equip this memory kit tend to rely on discrete graphics modules, and thus the faster memory (and high density) might be more appealing to workstation laptop type environments or those that pursue compute tasks.  In our memory scaling testing, we saw an ideal medium around 2133 MHz CL9 memory, however anything that puts a laptop above 1600MHz CL11 is more than welcome in my view.", "\tG.Skill is not stating an MSRP, however it should be roughly double the price of the ", " version, making the 32GB kit around $360. ", "\tAs we have mentioned in previous articles, buying all the modules you need in a single kit ensures they will work with each other.  Buying two identical kits (e.g. two 2x8 kits) does not guarantee compatibility due to the strain on some memory controllers with the tighter secondary and tertiary sub-timings on kits with fewer modules."]},
{"title": "Computex 2014: Crucial Shows Ballistix Elite DDR4", "paragraph": ["\tObviously one of the biggest topics of Computex this year is DDR4. Crucial will be bringing their DDR4 to the consumer market under the Ballistix Elite brand with speeds of 2666MHz and 3000MHz in the beginning. The modules themselves will be 4GB or 8GB at first, although kits will range all the way to up to 32GB (4x8GB). The latencies are still up in the air as the product isn't finalized yet but from what I have heard the latencies will be about CL15 at first, although it's certainly possible that there will be different models with different latencies available. Availability is slated for August but pricing has yet to be announced. ", "\tThe big thing about DDR4 is that it comes with a lower voltage of 1.2V compared to 1.5V that DDR3 uses by standard. That will result in lower power consumption, which ultimately means longer battery life for mobile devices. In addition, DDR4 is also bringing higher speeds because right at the beginning we are going to see products at 3000MHz, although Crucial told me that they have been able to get the modules to run at up to 3200MHz, so we might see even faster modules pretty soon. DDR4 will also bring support for higher densities (4Gb vs 1Gb), which will allow bigger for higher capacity DIMMs. While Crucial's offerings will be limited to 8GB at launch, they (well, Micron) has quad rank server DIMMs that go to up to 32GB but only at 2133MHz. ", "\tIn addition to DDR4, Crucial also had the MX100 at their suite. ", " when it officially launched, so there isn't really anything new to share, but Crucial was able to tell me that they are working on an SSD toolbox that should be available within a few months (I was told around September). This has been one of the only things missing from Crucial's SSDs, so it's great to see that they are responding to the public demand. The supply of MX100 should also be a lot better than the M500 when it launched, meaning that you shouldn't see any sold out tags at every retailer. ", "\t "]},
{"title": "Computex 2014: Transcend Shows SSD370 with Custom Firmware, SSD & RAM Upgrade Kits for Macs", "paragraph": ["\tTranscend has lately been shifting their focus and the company's strategy now is to concentrate on providing upgrade kits to Mac users. That was evident at their Computex booth since nearly half of the booth was dedicated to products designed for Macs and their demos. ", "\t", "\tFirst up is the JetDrive, which consists of four models: 420, 500, 520 and 720. All these drives are similar in terms of hardware and performance and the only difference is simply the form factor and connector. The controller is labeled as Transcend but the actual silicon is from Silicon Motion (or SMI as often called within the industry) but Transcend has designed the firmware themselves. The NAND is Micron's 128Gbit 20nm MLC, which allows capacities of up to 960GB. ", "\tThe 420 is a standard 2.5 drive but it's designed for Macs in the sense that it includes a toolbox for OS X that can enable TRIM along with an aluminum USB 3.0 enclosure for the old hard drive. The 500, 520 and 720 are for MacBook Airs and Retina MacBook Pros that use a unique form factor and connector (supported models can be found ", "). There is also a USB 3.0 adapter included for the old SSD like the one in the picture above. All models are available at up to 960GB and come with a 5-year warranty", "\t", "\tNext up is the JetDrive Lite. It's also designed for Macs and offers an alternative way to increase the internal storage by utilizing the SD card slot. The JetDrive Lite is designed so that it doesn't stick out of the SD card slot like normal SD cards do, so it can comfortably be used as permanent storage. Performance is also fairly good at least for sequential IO but I wouldn't hold my breath for SSD-like IOPS. Once again four different models are available: 130, 330, 350 and 360 with the difference being the Mac model that the card is designed for. The supported models can be found ", " and all models except the 330 are available in both 64GB and 128GB capacities (the 330 is limited to just 64GB).  ", "\t", "\tTranscend also offers RAM for nearly all Macs made within the last decade or so, including some rarer models such as the eMac.", "\t", "\tThe SSD370 is based on the same custom Transcend-SMI controller and firmware with Micron’s 128Gbit 20nm NAND but it is aimed for the PC market as the retail package doesn’t include any enclosures or other accessories that the JetDrive 420 does. I’m trying to get a sample of the drive as I’m eagerly looking forward to seeing what Transcend’s firmware team has been able to add to the drive compared to the stock SMI solution.", "\t", "\tSome of Transcend’s OEM customers are already employing the SSD370 in server environments. While the drive is mostly designed for the mainstream market, Transcend believes that it’s also suitable as an entry-level enterprise drive.", "\t", "\tThe SSD370 (or equivalent to it) is also available in M.2 form factor in various lengths. Maximum capacities range from 256GB to 512GB depending on the length and the controller is the same Transcend-SMI solution.", "\t", "\tThe CFast 2.0 memory cards are designed for high-end video cameras and DSLRs that are capable of recording 4K video. Good quality 4K video, especially uncompressed one, may easily require hundreds of megabytes of throughput per second, so the cards utilize SATA 6Gbps bus to ensure SSD-class performance.", "\t", "\tThis year a visit to a memory OEM almost guaranteed a sneak peak of DDR4. While Transcend isn’t one of Intel’s official launch partners, they have a full lineup of DDR4 ready, although it’s mainly geared towards the enterprise market."]},
{"title": "G.Skill Overclocking World Cup at Computex 2014: $10,000 for #1", "paragraph": ["\tExtreme overclocking using LN2 (Liquid Nitrogen) to get the best scores possible has", "\tFor the past two years, G.Skill has run their World Record Stage, inviting the employed or sponsored motherboard manufacturer overclockers to break records using G.Skill’s memory live at Computex.  For 2014, G.Skill added in another element: the First Annual Overclocking World Cup.", "\t", "\tThrough a pre-qualifier on overclocking record website HWBot, six of the top memory overclockers were invited to compete in Taipei for a $10,000 prize.  For those in the extreme overclocking community, the names above will be fairly familiar, particularly 8 Pack as the current world #1, and Splave as an ASRock sponsored memory specialist.  All six overclockers that qualified are also guaranteed G.Skill DDR4 sponsorship when it comes to market.", "\t", "\tEach of the six finalists were given stage time from Tuesday to Thursday in order to qualify for the 1 vs 1 final.  Competitors had to bring their own core hardware (CPU, motherboard, GPU, specialist G.Skill DRAM) while G.Skill provided the essentials and the liquid nitrogen.  It might be odd that the competitors had to bring their own core hardware, but these are individuals who will test 50+ CPUs to find the best one and get the best score possible.", "\tBenchmarks chosen for the on-stage live qualifier were SuperPi 32M at 5 GHz, Aquamark3, Maximum Memory Frequency and Catzilla 720P with a GTX750 Ti.  These are all well-known benchmarks in the extreme overclocking community, and from these results Splave and 8 Pack both made it through to the final.", "\t", "\tThese two were then put on stage on the Friday, which is the day I happened to be visiting the G.Skill booth.  As I visited in the morning, they were both still in the setting up stage:", "\t", "\tBenchmarks for the final were SuperPi 32M 5G and Maximum Memory Frequency again, but the other two benchmarks were replaced with 3DMark Fire Strike.  The benchmarks were weighted in favor of the more memory oriented section of the contest.", "\t", " ", "\tNormally when users think extreme overclocking, it might involve liquid nitrogen on the CPU, or the CPU and GPU.  Due to the push of G.Skill and others in recent years, we now develop special pots for cooling memory as well:", "\t", "\tThe colder the memory is, the more voltage can be pushed through and hopefully, the higher the frequency can be sustained. ", "\t", "\tWhile the pre-event qualification and live qualification was a fast and furious blow-by-blow intense competition, the 1-on-1 final was a little subdued.  In the first benchmark, 3DMark Firestrike, 8 Pack pushed out a strong score almost 50% more than what Splave was capable of.  8 Pack often gets his world records on GPU based benchmarks, so perhaps that was no surprise.  However, the tables turned and 8 Pack’s system started to behave abnormally.  This left him without a score in SuperPi 32M at 5 GHz, making the contest all hinge on the Memory Clock result.  In the live qualifier, 8 Pack had the better memory clock score, but was unable to match it in the final.  Splave was able to surpass 8 Pack’s original score and claim the title as well as the prize money.", "\t", "\tCongratulations to both competitors, as well as Xtreme Addict from Poland who came in third.", "\tOn the OC World Record Stage, the Friday happened to be the day that GIGABYTE’s team of overclockers were trying to take other records.  On stage were ViVi, Hiwa and Pro from G.Skill as well as Sofos, Dinos22 and HiCookie from GIGABYTE.  The GIGABYTE team already had some success mid-week at the Intel overclocking event, but at the G.Skill booth there was no specific benchmark to run and a more relaxed atmosphere.", "\t", "\tBy far one of my most favorite images to come out of Computex is this one:", "\t", "\tHere Dino is warming up the pot with two torches, while I have no idea what HiCookie and Sofos find funny.  Being loosely associated with the extreme overclocking community myself, I know most of these people and have had social events with them in years past.", "\t", "\t", "\tUnfortunately I could not stay for the whole day at the booth (many thanks to G.Skill for some of these post-competition images), but the last I had heard another world record had fallen by the end of the day.  Here are some of my favorite images taken by G.Skill during the week:", "\t", "\t", "\t", "\t", "\t", "\t", "\t", "\t"]},
{"title": "Computex 2014: GeIL Shows DDR4, with Suggested CAS Latencies", "paragraph": ["\tOne of the big launches this year will be the Haswell-E platform.  It is pretty much common knowledge in hardware discussions that this means Haswell-E, X99 and DDR4 will effectively launch to the consumer on the same day.  One element of that link that we have the fewest leaks and information from is the DRAM side.  I explicitly asked the DRAM manufacturers I have most contact with if they would be showing any DDR4 – either modules, specifications or in action.  Many of them obliged – it helps that a fair number also make SSDs and so Kristian was able to get a few snapshots.  But talking to GeIL at Computex also revealed something a little more interesting: CAS Latencies.", "\t", "\tMemory, as I attempt to convey in reviews, is more than just the frequency stated.  There are several sets of subtimings associated with the memory, often divided up into primary subtimings, secondary and tertiary.  The primary ones are the most important, and arguably one of the most important of those is called the CAS Latency, or CL for short.  Memory is usually quoted as a combination of frequency and CL, and in the past it has been easy to compare kits by comparing the results of Frequency divided by CL, such that the kit with the higher result is often the better performing.", "\tMoving from DDR3 to DDR4 means a move from 280-pin to 288-pin connections.  The layout of the modules is slightly different, with the pins being different lengths (notice in the image above how the pins in the middle are longer than those at the edge) in order to help installing memory.  Voltage moves down from 1.5 V to 1.2 V, and processors are expected to support DDR4-2133 by default.", "\tMost manufacturers on the Computex show floor were coy with what sub-timings they will aim for their modules, whereas GeIL had a handy list:", "\t", "\tSo when GeIL offers below 2133 MHz, I am a little taken aback, because their answer is ‘because some people will use it’.  I hope that the reason they will use it is because the processor will not support above 1600 MHz.  But this list gives that clear indication of CAS Latency between 1600 Mhz and 2400 MHz, with indications that 2666 MHz and 3200 MHz might be more common than we think.", "\tCAS Latency for DDR4 does seem a little down compared to DDR3, though this might be due to the initial batches of ICs coming through.  I remember 2133 C11 being the first 2133 MHz DRAM off of the shelf, but now we can buy 2133 C8 very easily.", "\t"]},
{"title": "ADATA Launches XPG V3 DDR3 Range", "paragraph": ["\tDespite the talk surrounding the introduction of DDR4 to the market, the volume product for the foreseeable future is still DDR3. We have done a number of memory scaling articles in the past [", ",", ",", "], but due to the resurgence of growth in the gaming segments over the last several quarters, there is still a demand for high speed DRAM, especially those that match the style of the build if the user or gamer wants to show it off at an event. This has caused some of the enthusiast DRAM manufacturers to re-launch their high end modules under new names and new skins, with the option of customization. This lies at the heart of ADATA’s new XPG V3 DDR3 range.", "\t", "\tThe finned array for the heatsinks can be removed, similar to other high end ranges, and replaced with a custom color. ADATA is saying that the first batches of these modules for retail will include a second set of fins, so users can select between gold and red. There are plans to launch other colors in the future.", "\t", "\tLaunched SKUs will first be available in gold/red, in either 2x4 GB or 2x8 GB kits, with the following speeds:", "\tDDR3-1600 9-9-9-24 1.50V", "\tDDR3-1866 10-11-11-30 1.50V", "\tDDR3-2133 10-11-11-30 1.65V", "\tDDR3-2400 11-13-13-35 1.65V", "\tDDR3-2600 11-13-13-35 1.65V", "\tDDR3-2800 12-14-14-36 1.65V", "\tDDR3-2933 12-14-14-36 1.65V", "\tDDR3-3100 12-14-14-36 1.65V", "\t", "\tAll kits will support XMP 1.3, use 8-layer PCBs with 2oz copper to improve signalling, and Thermal Conductive Technology (TCT), which is a fancy way of saying that the DRAM chips themselves are in contact with the heatsink, so the heatsink may be hard to remove depending on the bonding.", "\tWith the high frequency modules, it is always worth noting that these are designed for use with Ivy Bridge and Haswell CPUs, and the quality of the memory controller will determine the maximum speed possible. All the Ivy Bridge and Haswell CPUs I have tested, at stock, will easily do DDR3-2933, and should find DDR3-3100 OK as well with a small base frequency overclock. Overclocking the CPU may reduce the peak memory frequency possible, and thus if running an overclocked system, a balance may be needed as well as the expertise/guide to manage that balance. This is true with any high speed memory, not just the ones here, such as our reviews of ", "\tADATA has offered us a review sample which should arrive shortly. Stay tuned for the review. I am currently awaiting a full list of MSRPs and will update the news when it arrives.", "\tSource: "]},
{"title": "ADATA Formally Announces DDR4-2133 CL15 UDIMMs", "paragraph": ["\tOne of the hot topics in computer upgrades for the next couple of years is going to be the move to DDR4.  Intel ", " that the Haswell-E / X99 platform will be based on DDR4, and we can only assume that other future platforms will use it as well.  The shift from DDR3 to DDR4 is a the big jump for DRAM manufacturers as well, shifting gears to the new product and maintaining stocks of both for the meantime.  ADATA is one of the first to officially launch their consumer memory, their Premier line of DDR4.", "\tJEDEC specifications have the DDR4 base frequency at 2133 MHz with sub-timing latencies of 15-15-15 at 1.2 volts.  This is where ADATA will be positioning their first DDR4 modules in the market, and we can assume that others will as well until higher frequency parts are binned.  Compare this to the rate of DDR3-2133, which is often at 10-12-12 timings or similar, but uses 1.65 volts, and typically comes with heatsinks.", "\tBecause we are far from the launch of a consumer platform for DDR4, as one might expect this comes across more as a paper launch.  ADATA in the past typically publishes a PR about new memory about two weeks before it goes on the market, and I am asking about pricing which was not mentioned.  Given the pictures we received with the modules, it would seem that 4GB and 8GB modules will be first to market for DDR4 unless another DRAM manufacturer has something up its sleeve.", "\tSource: ", "\t", "\t"]},
{"title": "Combo SDIMM: Apacer adds SATA M.2 Storage to DRAM Modules", "paragraph": ["\tOne focus of PC design is towards the smaller form factor. While mini-ITX is the standard ‘small’ form factor, Apacer is starting to sample their Combo SDIMMs that add storage functionality to the DRAM module (Storage + DIMM = SDIMM in this case, or so it would seem). The idea is to remove a bulky storage device attached via a cable and migrate it to another PCB – in this case, the DRAM module.  Note this means this is not extra DRAM, just two different devices on the same PCB drawing from the same power source.", "\tThese modules come with either an M.2 slot, supporting 2242/2260/2280, or a CFast memory card. Both options are still connected to the SATA interface, although they draw power from the DRAM slot rather than the motherboard directly. Apacer is thinking that users who want M.2 or CFast capabilities can purchase these combo modules and connect them without having to upgrade. Or alternatively, in order to reduce bulk in the system.", "\tWhile reducing bulk in ATX might not count for much as there is plenty of space to play with, it makes more sense on mini-ITX.  Only one mini-ITX motherboard supports 2280 M.2 drives, the ASUS Z97I-Plus, but at the expense of extra routing and PCB layers to place it on the rear.  Apacer is also quoting potential use in embedded devices, with M.2 support up to 256GB and CFast to 128GB.", "\tIf an embedded device manufacturer goes custom then soldering on DRAM and adding an M.2 slot negates this new technology. The main application for Apacer, as quoted in their press release, would seem to be towards the Internet of Things and also the suspected wave of upgrades to appear now that Windows XP has officially stopped patching security flaws for regular license holders.", "\tThis Combo SDIMM adopts the DDR3 standard (I would assume DDR4 might be around the corner as well), and takes advantage of the VLP DIMM PCB design (0.748-inch in z-height) for the memory chips. Size or speed of the actual DRAM on the module is not quoted, although given the image we have access to, it would look like there will be at least 8 GB modules running at DDR3-1600 CL11. One could argue that 4x8GB of DRAM with four M.2 drives saving space could be a good thing, or even more in an X79 system. Note in the image above there is an SLI-like connector between the modules - this is presumably the SATA connector.  For the motherboard in the image, it would seem that the smart orientation would be the other way.", "\t", "\tApacer is now sampling customers for evaluation, which would point to an OEM only release for workstations or SFF systems."]},
{"title": "Corsair Show DDR4-3400, also mentions 16GB UDIMMs?", "paragraph": ["Aside from the formal press releases from Corsair already announcing the new ", ", the ", ", the ", " and their ", ", at their suite there was a couple of interesting things worth discussing regarding DRAM. A small portion of the suite had the recently released GIGABYTE X99-SOC Champion (which ", "), but plugged in to this was a set of orange DDR4-3400 memory.", "Up until this point, Corsair had released ", " (we have a kit of this in to test) at $740 for 4x4GB to ", " at $910, but DDR4-3400 pushes the margin out a bit more. With most DRAM, binning for higher speed hits the law of diminishing returns – you have to bin more ICs to get the high speed. As a result, these modules will be pretty expensive, and because it is X99 which needs four modules to reach quad channel bandwidth, a user has to buy all four. At the suite, they even had them running with a small overclock to DDR4-3500:", "This sets them up to be very expensive. They are currently on ", " for a 4x4GB kit. To put that into context, two sets of ", " will run at just over $1000 combined, making these modules almost 4x the cost per GB than the base JEDEC frequency memory. These DDR4-3400 modules are set at 16-18-18, which is looser than JEDEC at 2133, but indicates that both primary sub-timings and frequency are tight compared to each other. Compatibility for this kit is so far only listed as with the X99-SOC Champion.", "While the kit was impressive and did catch my eye, the following wall image caught my attention more:", "Here it explicitly states that a module size of 16GB is coming to DDR4 in 2015. Unfortunately no other information could be crowbarred out of Corsair regarding time frame or pricing, but we were able to speak with a memory manufacturer who said it should be coming in the near future. We will be working hard with Corsair to secure some testing kits if they pop up, but it means that soon we should (hopefully) start to see 128GB UDIMM arrangements on X99. It might also mean another round of BIOS updates to help support a full 8x16GB configuration. These would most likely start at DDR4-2133, as this would have the highest yields."]},
{"title": "More DDR4-3400: G.Skill’s 4x4GB CL 16 Kit Released", "paragraph": ["When we look at the history of DDR3, a number of key advertising points were consistent across most of the memory manufacturers. First was high speed in terms of out of the box, and the other was high speed from overclocking. The big names all went for these records, and after we posted about Corsair’s DDR4-3400 kit a couple of days ago, G.Skill is also jumping onto the bandwagon. However, the kit is very slightly different – G.Skill is supporting 16-16-16-36 timings, compared to Corsair’s 16-18-18-40. Whether that means much in real-world usage is hard to say, but I would imagine G.Skill, given the history between the two, will also compete on price. So perhaps under $1000, which would be a big hit in anyone's build.", "This 4x4 GB kit will also be flanked by a new DDR4-3200 4x4 GB kit, available at 15-15-15-35 timings, which also undercuts the competition. Both of the new kits from G.Skill are validated on the GIGABYTE X99-SOC Champion and the ASUS Rampage V Extreme.", "The kits will also come with G.Skill’s Turbulence III fans to provide extra cooling. There is no date currently mentioned by G.Skill, but 'released' often means 'heading to distributors'. Given the high specifications of the kit, I would imagine only a handful are actually going on sale.", "We still have a round-up of DDR4 memory kits planned in the works, from 2133 to 3200 (perhaps 3400 if we can get them), so stay tuned for that.", "Source: G.Skill"]},
{"title": "New Challenger: KLEVV DRAM Modules, Linked to SK Hynix", "paragraph": ["The DRAM market, especially at the consumer level, is a cut and thrust business. Margins are small on a per-module basis, but with the right volume it can make several companies earn a tidy profit. If they move into the server market, there is even more potential. But for now, the three main DRAM IC manufacturers are Micron, Samsung and SK Hynix.", "Each reseller of DRAM modules buys or bids on batches of ICs from these companies, does internal binning to see which speeds it can reach, and arranges the modules for the market.  Certain batches of ICs, such as Hynix MFR, are expensive due to their high overclocking capability for example. On the open market, it can be a free for all. But some companies have additional leverage.", "Samsung use their own ICs and sell DRAM modules under their own name. Micron also sells their own DRAM in modules for the bulk customers, and their Crucial brand which gets the pick of the components in the consumer business. The only player without a ‘house brand’ so to speak is SK Hynix. This is where the name ‘KLEVV’ comes in.", "SK Hynix is owned by SK Group (SK C&C), which acts as an umbrella firm over many individual companies. SK Group created a new firm, Essencore, to help bring to market some of the DRAM and NAND capabilities directly to the end-user rather than through their ICs being sold on the open market. Essencore thus created KLEVV to cover the DRAM side of the equation, kind of making KLEVV a customer/vertical integration partner of SK Hynix, although the two are separate entities under the same umbrella, SK Group. This allows SK Hynix to have more control over their better components coming out of the fabs and sell direct. KLEVV is, on paper at least, another Crucial-like player in the space, and another soon-to-be important DRAM module manufacturer.", "This marks a few interesting dynamics. As I mentioned previously, a lot of the high end memory modules use Hynix MFR ICs which are historically known as good clocking components. If KLEVV ends up having first pick of those modules, without a serious high bid from people like G.Skill and Corsair, there is potential for market share to adjust somewhat quickly. This could lead to rapid growth from KLEVV and Essencore if their distribution is set up as well as any other memory module manufacturer. KLEVV could very easily start to price some of the more established DRAM brands who do have their own fabs out of business, or offer a more unique range of products.", "At this point in time, at PAX South, Essencore is launching KLEVV into the market with a full array of DDR4 and DDR3 products, at least on paper. We have been told that Newegg will be their initial partner in North America, but we are waiting for information on how they are going to attack other markets such as Europe and Asia. Distribution, without previous contacts, can be difficult to penetrate – but with the right execution, it could go well. KLEVV is targeting the gaming market hard with this launch.", "The halo line will be called the KLEVV Cras DDR4, featuring very tall heatsinks with LED lighting effects. KLEVV has not said which combinations of speed will match what capacities, but kits will be offered from 2x4GB to 4x8GB, in 2133 MHz to 3200 MHz configurations.", "When I first got this slide, there was one standout kit that took me by surprise - a 2133 10-12-12 kit. Subtimings of 10-12-12 are crazy low for DDR4 at this frequency, and most kits we see are 15-15-15. This would have a direct impact in performance, moving the MHz/CL rating from 142 to 213. When KLEVV begin sampling, this is the kit we have requested for our DDR4 coverage. Unfortunately it looks like it was a copy paste error from DDR3, and the kit is listed as 15-15-15 in the final press materials we were emailed.", "The DDR3 lines are essentially three big Venn diagram circles covering almost the same areas. At the top is KLEVV Genuine, from 1600 C9 to 3200 C13, followed by KLEVV Urbane in similar scope, and KLEVV Neo on the more budget oriented scale.", "While Genuine and Urbane cover the same speeds and densities, the Genuine line will be fitted with LEDs, hence the different branding.", "For budget builds, KLEVV will also start to sell DDR3 and DDR4 in JEDEC specifications as single modules.", "While KLEVV is being controlled by Essencore rather than directly from SK Hynix, there is still an element of vertical integration which could benefit both sides and hopefully benefit end users. As mentioned, Essencore is dealing with both DRAM and NAND, so while the plan today is to launch memory modules, over the course of 2015 we will see MicroSD cards and eventually SSDs reaching the market under the SK Group heading, with all the advantages that entails. We are not sure yet if the SSDs will also be called KLEVV, or if Essencore will use a different brand for that direction, but both Kristian and I are in contact for when products enter the market. As the SSD side is still a number of quarters away, no specifications or predictions can be made at this time.", " went live in the last 24 hours, with details about each of the product areas. I cannot find the products up for sale at the time of writing, but I understand ", " should be listing them soon.", "Source: Essencore", ": We have just been told that t", ": After posting this news, it seems to have create a fuss regarding the relationship between Essencore/KLEVV and SK Hynix. Both companies are under the SK C&C banner, with Essencore stating they have a strong partnership with SK Hynix. However, SK Hynix is stating that they want to make it very clear. I recieved two emails from different parts of the SK Group with roughly the same information.", "This additional information is slightly confusing. Both Essencore and SK Hynix are under the same umbrella company - if there was not any synergy in place, then Essencore are diving head first into a very competitive market with very little margins. Given Essencore's marketing materials we received, it indicated that there was a strong partnership with SK Hynix (as indicated above), and that being part of the SK Group in itself would be a big benefit to both sides of the equation. If that is no longer the case (and several of my predictions and 'if' statements above are not due to come to fruition), then Essencore has their work cut out for them and it seems a missed opportunity/"]},
{"title": "DDR4 Haswell-E Scaling Review: 2133 to 3200 with G.Skill, Corsair, ADATA and Crucial", "paragraph": ["For any user interested in performance, memory speed is an important part of the equation when it comes to building your next system. This can apply to any user, from integrated graphics throughput to gaming and prosumer environments such as finance or oil and gas. Individuals with an opinion on memory speed fall into two broad camps, from saying faster memory has no effect, to the ‘make sure you get at least XYZ’. Following on from our previous Haswell DDR3 scaling coverage, we have now secured enough memory kits to perform a thorough test of the effect of memory speed on DDR4 and Haswell-E.", "On the face of it, direct comparisons between DDR4 and DDR3 are difficult to make. With the switch over from DDR2 to DDR3, there were some platforms that could use both types of memory and we could perform tests on both in the same environment. The current situation with DDR4 limits users to the extreme platform only, where DDR3 is not welcome (except for a ", " which are rarer than hens teeth). The platform dictates the memory compatibility, and the main characteristics of DDR4 are straightforward.", "DDR4 brings to the table a lower operating voltage, down from 1.5 volts to 1.2 volts. This is the main characteristic touted by the memory manufacturers and those that use DDR4. It does not sound like a lot, especially when we can be dealing with systems from 300W to 1200W quite easily under Haswell-E. The quoted numbers are a 1-2W saving per module per system, which for a fully laden home-user desktop might approach 15W at the high end of savings over DDR3, but for a server farm with 1000 CPUs, this means a 15kW saving which adds up. The low voltage specification for DDR4L comes down from DDR3L as well, from 1.35 volts to 1.05 volts.", "The lower voltage is also enhanced by voltage reference ICs before each memory chip in order to ensure that a consistent voltage is applied across each of them individually rather than the whole module at once. With DDR3, a single voltage source was applied across the whole module which can cause a more significant voltage drop, affecting stability. With this new design any voltage drop is IC dependent and can be corrected.", "The other main adjustment to make from DDR3 to DDR4 is the rated speed. DDR3 JEDEC specifications started at 800 MTs and moved through to 1600 MTs, while some of the latest Intel DDR3 processors moved up to 1866 and AMD up to 2133. DDR4’s initial JEDEC for most consumer and server platforms is set at 2133 MHz, coupled with an increase in latency, but is designed to ensure that persistent transfers are quicker but overall latency is comparable to that of DDR2 and DDR3. Technically there is a DDR4-1600 specification for scenarios that want the bargain basement memory and are unfazed by actual performance.", "As a result of this increase in speed, overall bandwidth is increased as well.", "Latency moves from DDR3-1600 at CL 11 to DDR4-2133 at CL 15, which was an expected jump as JEDEC tends to increase CL by 2 for a jump in frequency. While having a latency of 15 clocks might come across as worse, the fact that the clocks are at 2133 MTs ensures that the overall performance is still comparable. At DDR3-1600 and CL11, time to initiate a read is 13.75 nanoseconds, compared to 14.06 nanoseconds for DDR4-2133 at CL15, which is a 2% jump.", "One of the things that will offset the increase in latency is that CL15 seems to be a common standard no matter what frequency the memory is. Currently on the market we are seeing modules range from DDR4-2133 CL15 up to ", ", marking a read latency down to 9.375 nanoseconds. With DDR3, we saw kits of ", " for 8.33 nanoseconds, showing how aggressive memory manufacturing over the lifetime of the product can increase the efficiency.", "Another noticeable difference from DDR3 to DDR4 is the design of the module itself.", "As with most technology updates notches are shifted in order to ensure that the right product fits in the right hole, but DDR4 changes a bit more than that. DDR4 is now a 288-pin package, moving up from 240-pin in DDR3. As the modules are the same length, this means a reduction in pin-to-pin distance from 1.00 mm to 0.85 mm (with a ±0.13 tolerance), decreasing the overall per-pin contact.", "The other big design change is the sticky-out bits in the middle. Moving from pin 35 to pin 47, and back from pin 105 to pin 117, the pin contacts get longer as well as the PCB by 0.5 mm.", "This is a gradient change rather than a full quick change:", "Initially when dealing with these modules, I had the issue of not actually placing them in the slot correctly when using a motherboard with single sided latches. Over the past couple of weeks it has started to make more sense to place both ends in at the same time due to this protruding design, despite the fact it can be harder to do when on your hands and knees in a case.", "Along with the pin size and arrangement, the modules are ever so slightly taller than DDR3 (31.25 mm rather than 30.35mm) to make routing easier, and the PCB is thicker (1.2 mm from 1.0 mm) to allow for more signal layers. This has implications for future designs, which we will mention later in the review.", "There are other non-obvious benefits and considerations baked into the DDR4 design to mention.", "DDR4 supports a low-power auto self-refresh (listed in the documentation as LPASR) which does the standard thing of refreshing the contents of memory but uses an adaptive algorithm based on temperature in order to avoid signal drift. The refreshing modes of each module will also adjust each array independently as the controller must support a fine-grained optimization routine to also coincide which parts of the memory are being used. This has power as well as stability implications for the long term future of DDR4 design.", "Module training when the system boots is also a key feature of DDR4. During the start-up routine, the system must sweep through reference voltages to find a maximum passing window for the speeds selected rather than just apply the voltage in the options. The training will go through the voltage reference in steps from 0.5% of the VDDQ (typically 1.2V) to 0.8% and the set tolerance of the module must be within 1.625%. Calibration errors are plausible at one step size (9.6 mV at 1.2V) but also the slew margin loss due to calibration error must also be considered. This is due to the greater implication of losses due to margins and tolerances and ensures stable operation during use. The downside to the user is that the number of modules in the system effects the boot time of the device. A fully laden quad-channel Haswell-E system adds another 5-8 seconds to perform this procedure, and it is something that cannot be circumvented through a different routine without disregarding part of the specifications.", "Source: ", "DDR4 is also designed with the future in mind. Current memory on the market, except what we saw with ", ", is a monolithic die solution. The base JEDEC specification will allow for 3D stacking of dies with through-silicon-vias (TSVs) should any memory manufacturer wish to go down this route to increase module density. To support this adjustment there are 3 chip select signals, bringing the total of bank select bits to 7 for a total of 128 possible banks. At current UDIMM specifications, there is provision for up to 8 stacked dies, however DDR4 is listed only to support x4/x8/x16 ICs with capacities of 2, 4, 8 and 16 Gibit (gibibit). This would suggest that the stacked die configuration is more suited to devices where x-y dimensions are a premium, or in the server markets. When it comes to higher capacity modules, we have already reported that ", ", representing an 8*16Gb dual rank arrangement. We are working to make sure we can report on these as soon as they land, however when it comes to higher density UDIMM parts (i.e. not RDIMM or LRDIMM) we might have to start looking at newer technologies.", "There are a significant number of other differences between DDR4 and DDR3, but most of these lie in the electronic engineer/design role for the memory and motherboard manufacturers, such as signal termination, extra programmable latencies and internal register adjustment. For a more in-depth read into these, a good ", " can yield results, although a thorough understanding of Rajinder Gill’s AnandTech piece about ‘", "’ is a great place to start about general memory operation. I still go back and refer to that piece more frequently than I admit, and end up scratching my head until I reach bone."]},
{"title": "Corsair Releases Orange Dominator Platinum DDR4-3400 for GIGABYTE X99-SOC Champion", "paragraph": ["During CES earlier this year we spent some time at the Corsair booth and saw a beta system demoing an orange kit of DDR4-3400 modules on the X99-SOC Champion. It would seem that now those modules are finally coming to market, with the X99-SOC Champion being the lead platform due to the styling. Both Corsair and GIGABYTE are pushing both the speed of the modules (at 16-18-18 sub-timings) and the motherboard which is designed to take care of the faster speeds.", " when it was released at CES, and agreed that it had the chance to take the place for X99 overclockers on a budget. However, these DDR4-3400 modules will not come cheap with an MSRP of $999.99 for a 4x4GB kit, but will come with a lifetime warranty. Users of the X99-SOC Champion will have to update to BIOS F4d, which should be available online shortly, in order to enable XMP appropriately.", "We actually have these modules in to test already, and applying XMP in our test system put the CPU into the 167 MHz strap at 160 MHz, resulting in a 22x multiplier on the CPU in order to keep the CPU frequency relatively consistent.", "The reason it goes for this strap is because at the 100 MHz strap it would require a higher DRAM multiplier which may not be possible. In actual fact, our testing CPU would not allow the 100 MHz with a 34x DRAM multiplier, but neither would it allow 160 Mhz on the 167 MHz strap either due to a mediocre processor.", "We were able to get the kit running at DDR4-3400 using the 125 MHz strap with a small overclock, which kind of confuses comparisons because it means the CPU is lower/higher in frequency, depending on the CPU multiplier (127.5 x 27 = 3440 MHz / 127.5 x 28 = 3570 MHz). One of the benefits of these high end memory kits with a processor at XMP will be that they require a CPU overclock to work properly, promoting performance (albeit indirectly). We tuned the CPU to stock speeds which reduced the kit to DDR4-3333 (still 16-18-18), and the biggest jumps from our quick testing showed WinRAR on Windows and Redis on Linux both getting improvements over 2133 MHz, similar to our ", ".", "We’ll roll out a full review, with new GPU benchmarks as well, at a later date. I would imagine that in time these modules will also be validated on other systems, however it would seem that GIGABYTE and Corsair have done a deal to focus on the X99-SOC Champion first. The modules will initially be available from ", "."]},
{"title": "G.Skill Announces 16GB Unbuffered Modules: 128GB Kit at DDR4-2800", "paragraph": ["One of the more important announcements this year in the world of DRAM has been the march towards 16GB un-buffered modules. We saw last year Intelligent Memory launch some for DDR3, but due to other issues they only worked out-of-the-box on AMD and Atom platforms and were not widely available. At CES we saw Corsair place an interesting image on one of their displays, indicating that DDR4 modules at 16GB a piece were coming. Today, G.Skill formalises this with the announcement of a 128GB memory kit for X99.", "G.Skill has worked with Samsung in order to produce modules rated for DDR4-2800 at 16-16-16. These 8Gb ICs are produced at 20nm, and while the average user has little need for 128GB, X99 is aimed more at the prosumer market which can have exorbitant memory requirements – previously the only way to hit 128GB on a single socket was with RDIMMs and Xeon processors which have a substantial cost.", "At this point in time, G.Skill is showing that DDR4-2800 with 128GB works with the ASUS X99 Rampage V Extreme, although the XMP profile should allow use on other motherboards. Personally I would suggest that X99 users ensure they have the latest BIOS update before installing these modules, should they have any additional sub-timing parameters needed. I would also expect that as other manufacturers get these modules in to test, validation lists and QVL will be updated.", "As this is an announcement rather than a launch, G.Skill hasn’t released pricing or a date yet. Based on previous experience this usually means we will have to wait between 2-6 weeks before they go on sale. It is worth noting that Computex is in early June, and thus a launch around that time might be expected. A current 8x8GB DDR4-2800 kit costs $790, so I wouldn't be surprised if this kit easily doubles that. We should start seeing slower kits at DDR4-2133 for less over the summer, if this announcement is anything to go by."]},
{"title": "GeIL Launches the ‘Super Luce’ DDR4 Line with Heartbeat LEDs", "paragraph": ["An inescapable part of the world of self-building a personal computer is customization and aesthetics. For most users, and even some gamers, the box under the desk is built for function. But there’s a sizeable crowd of chassis/system modders, LAN gamers and forum users that like to show off what they have. For these users, we have styled motherboards, graphics cards, coolers and even power supplies in order to build the design. Chassis can come with side windows, be fully open or custom built to how the user wants. One area in the customization route that has been a hard one to innovate has been what to do with DRAM.", "Corsair and ADATA provides colored tops for some of their ranges, G.Skill has themed heatsinks but also bundle the high end kits with additional fans with LEDs, but currently Avexir have stood out with different colored modules with LEDs along the top. Now GeIL is joining the crowd with the Super Luce line.", "The principle behind these kits is that the top of the module can beat at five different rates, based on the temperature of a thermal sensor on the module. Under 40ºC, the LED will pulse at 13 beats per minute, or one per 4.6 seconds. Then as the temperature rises in sets of 5ºC, it will move up to 60, 80, 120 and 200 beats per minute, reaching the peak frequency over 55ºC.", "Judging by the way that GeIL is describing their implementation, each module is independent of the others. This might indicate that depending on the heat movement around the socket, one side of the modules might be at a different heartbeat frequency than the others.", "The Super Luce family of products will be available in white, red or blue, from DDR4-2666 MHz to DDR4-3400 MHz and up to 64GB capacity. Currently on the website we are seeing each of the colors at DDR4-3000 and DDR4-3400, but exact combinations of colors, frequencies and capacities have not been announced yet. GeIL is indicating availability by the end of April.", "Source: "]},
{"title": "Corsair Now Retailing 128GB UDIMM DDR4 Kits, Starting at $1755", "paragraph": ["Not much exciting happens in the land of DRAM I know – usually the most exciting things occur when we get a standards change, or when capacities increase. Luckily for DRAM manufacturers we got the first taste of consumer grade DDR4 back in 2014, and almost a year later in 2015 we are now seeing capacities double per module from 8GB to 16GB. We reported on one company promoting their 16GB modules, specifically an 8x16GB kit for 128GB, and now it is the turn of Corsair who is guaranteeing US availability as this press release went live direct from the ", " website.", "Corsair is launching three kits as follows:", "Aside from the price, the timings are naturally quite interesting. JEDEC specifications for DDR4 come in at DDR4-2133 15-15-15, and most of the modules we saw at the release of DDR4 were on those lines, moving up to DDR4-3200 with a slow rise in subtimings. The first two kits from Corsair, the Vengeance LPX and Dominator Platinum, arrive at DDR4-2400 14-16-16, indicating a rise in frequency and a decrease in CAS latency, all while retaining the nominal 1.2 volt specification from JEDEC rather than jumping up to 1.35 volts. Nice.", "The other kit in the stack is at DDR4-2666 15-17-17, also at 1.2 volts, which is somewhat in-line with the 8GB module kits we have seen so far. Using our Performance Index rating, ", ", puts each of the kits as the following:", "Vengeance LPX 128GB DDR4-2400 C14 = 2400/14 = 171", "Dominator Platinum 128GB DDR4-2400 C14 = 2400/14 = 171", "Dominator Platinum 128GB DDR4-2666 C15 = 2666/15 = 177", "This is around the Performance Index of the midrange kits for both DDR4 and DDR3, indicating a level of performance in that area.", "The pricing on the other hand commands a distinct premium. The Vengeance LPX kit starts at $1755, with the Dominator Platinum 2400 C14 kit moving to $1980. At the top sits the 2666 C15 kit, by virtue of the higher frequency, at $2120. This means per GB:", "Vengeance LPX 128GB DDR4-2400 C14 = $1755/128GB = $13.71 per GB", "Dominator Platinum 128GB DDR4-2400 C14 = $1980/128GB = $15.47 per GB", "Dominator Platinum 128GB DDR4-2666 C15 = $2120/128GB = $16.56 per GB", "Compare that to a standard DDR4-2400 8x8GB kit on Newegg retailing at $720, which comes out at $11.25 per GB, or a DDR4-2400 4x8GB kit retailing at $330, giving $10.31, then you are commanding a 30%+ premium in order to get the best unbuffered DRAM density available on X99. Of course, whether you need all that is dependent on your workload. ", "All kits are available on the Corsair website now, and come with a lifetime warranty.", "Source: ", "We have about a dozen DDR4 memory kits in-house that have been sat on my desk for far too long. Keep an eye out for some quick reviews of those in due course."]},
{"title": "ASRock Rack Announces EP2C612D24 and 4L: Dual Socket Haswell-EP with 24 DDR4 Slots", "paragraph": ["Two things jumped out at me when I received this press release. Firstly the name, which comes out as a mouthful – it isn’t something you could casually mention in conversation, even if you worked closely with the motherboard. The second is the amount of DRAM slots, which is ultimately what the ", "and ", " are catering for.", "The Haswell-EP/Xeon E5 v3 DDR4 memory controllers are designed for up to three DIMMs per channel, similarly to Ivy Bridge-EP (E5 v2) and Sandy Bridge-EP (E5), although in all cases it is usually reserved for more niche systems. With 16GB UDIMMs, this allows for a maximum of 384GB, although moving up to RDIMM, LRDIMMs or 64GB NVDIMMs pushes the max to 1.5TB in a dual socket motherboard. Only those with deep pockets, big budgets or stringent requirements need apply, as the major cost here will be the DRAM.", "The motherboard uses a staggered processor arrangement with narrow ILM versions of the LGA2011-3 socket. Combined with the 24 DRAM slots means there is little room for anything else. We get three PCIe 3.0 x8 slots which are open ended, allowing for x16 sized cards to come in, although one slot will be limited to reduced width cards as some of the DRAM slots would encroach a super long co-processor. The ten onboard SATA ports are supported by an M.2 PCIe 3.0 x4 slot and an onboard USB 3.0 Type-A port for in-chassis licensing dongles or Live-USB OSes. One downside to mention, according to the specifications for Haswell-EP, is that when fully populated, the memory should reduce down in speed, from 2133 to 1600 MHz.", "Network connectivity is provided by an Intel i350 which gives ", ", but ", ", but we also get another network port for the AST2400 which provides IPMI 2.0 network management. ASRock Rack is targeting the usual suspects when it comes to large DRAM packages – intensive compute tasks, big data analysis, Hadoop and cloud computing.", "Source: ASRock"]},
{"title": "G.Skill Announces DDR4-4000 and DRAM in Dual Channel Kits", "paragraph": ["At this point in time, the only commercial platform that runs DDR4 is the Haswell-E processor combined with the X99 chipset. For that platform, the processor has a quad-channel memory controller and in order to extract the best performance, four memory modules are needed – ", " speed on this platform earlier in the year.", "Despite this, G.Skill is today announcing its upcoming memory kits – specifically ‘designed for 6", " Gen Intel Core Processors and Z170 motherboards’, or what the rest of us calls ‘Skylake’. These new kits fall into two series called ‘Trident Z’ and ‘Ripjaws V’, with the Trident line being typically faster than Ripjaws although there will be crossover. Memory companies usually do this in order to enable users who prefer one style over the other but still want a certain speed.", "These new kits, not only being announced seemingly early, also seem to break DRAM speed barriers for kits in the market. The new Skylake platform is expected to have a memory rating equivalent for the JEDEC specifications for DDR4, which is DDR4-2133 at subtimings of 15-15-15. One of the new kits pushes through to DDR4-4000, almost doubling the frequency of the JEDEC standard, although with a slightly slower sub-timings of 19-25-25.", "These will be available only in 2x4 GB form, with pricing not announced. All Trident Z modules will run at the higher DDR4 voltage standard of 1.35 volts except this DDR4-4000 kit, which will require 1.35-1.40 volts. It would seem that the ICs used here are hand picked and tested, and thus each kit might have slightly different voltage requirements and thus uniquely programmed.", "The other design is the Ripjaws V, which will cover most frequencies from DDR4-2133 but also in the higher capacity configurations. I am told that G.Skill is ready to deploy a number of kits with 16GB modules, affording 2x16 and 4x16 kits giving 32GB and 64GB of DRAM respectively.", "Ripjaws V will be available in red, blue, silver, gray and black. The 16GB modules are specifically using Samsung ICs, and will be available up to DDR4-3200.", "The Trident Z line is a lot less spiky than the previous Trident modules for good reason - personally I obtained injuries using it over the years because ", ". The new line avoids this, but also enables G.Skill to add its name to the top of the module, allowing modders to indicate exactly what modules are being used.", "Given this press release today, and what we’ve heard on the grapevine, it seems that Skylake is promising to be a super platform for DRAM in terms of both capacity and speed. Needless to say, pricing and specific release dates were not provided. I suspect other companies will follow with their dual channel kit announcements soon given this release today.", "Source: ", " "]},
{"title": "Analyzing Intel-Micron 3D XPoint: The Next Generation Non-Volatile Memory", "paragraph": ["The current mainstream memory technologies, namely DRAM (quick memory accessed by the processor) and NAND (solid-state storage), have been around for decades. While the cell designs have evolved over the years to allow scaling to 20nm and below, the fundamental physics behind DRAM and NAND operation haven't changed a bit and both technologies have their unique technological limitations. DRAM offers nanosecond-level latency and unlimited endurance, but this comes at the cost of large cell size, cell volatility, and power consumption. Since DRAM cells need to be constantly refreshed, the cells don't retain data in an off state, requiring quite a bit of power and making DRAM unsuitable for permanent storage. NAND, on the other hand, has much higher latency (especially write operations) and has a limited number of write cycles, but the cells are non-volatile and the structure is much more efficient, enabling low cost and suitability for storage.", "Combining DRAM and NAND at the system-level architecture provides the best of both worlds, which is why modern computers use DRAM as a memory/cache and NAND for storage. However, there's still a latency and capacity gap between DRAM and NAND, so the question arises: what if you were to combine the best of DRAM and NAND at the silicon level? The mission of next generation memory technology across the industry has been to develop a new type of memory that provides low latency and high endurance while offering a small and scalable cell size.", "We have seen numerous startups, such as Crossbar and Nantero, discuss and demonstrate their next generation memory technologies, but we have yet to see the established DRAM and NAND vendors come out with their solutions. Intel and Micron are here to change that with the announcement of their new 3D XPoint (Cross Point) non-volatile memory technology this week.", "First and foremost, Intel and Micron are making it clear that they are not positioning 3D XPoint as a replacement technology for either NAND or DRAM, and in that scale it has been talked about more in its applications nearer NAND than DRAM. It's supposed to complement both and provide a technology that sits in between the two by filling the latency and cost gap exists between DRAM and NAND. Basically, 3D XPoint is a new tier in the computer architecture because it can be used as either slower, non-volitile memory or much faster storage.", "Intel and Micron are claiming that 3D XPoint provides up to a thousand times higher endurance than NAND. Assuming that the numbers are relative to modern (15-20nm) MLC NAND, the endurance should be in the order of a few million P/E cycles; though the marketing materials are claiming up to tens of millions of write cycles. If we assume 3 million write cycles (1000x of what modern MLC has), a 256GB 3D XPoint based drive would have a total write endurance of 768 petabytes. That's equivalent to 420TB per day for five years, or 4.9GB per second. For storage applications that currently rely on NAND, 3D XPoint will eliminate any potential endurance concerns, but it's not durable enough to challenge DRAM in that front since DRAM endurance is essentially infinite. Whether 3D XPoint provides enough endurance to replace DRAM ultimately depends on the application, but especially in certain enterprise workloads there's a need for DRAM.", "3D XPoint latency should be in the order of 10s of nanoseconds, but the companies didn't specify whether this is read or write latency. Judging by the graphs provided by Intel, it seems to be read latency because NAND write latency would measured in milliseconds (typically 1-2ms for a full page write), whereas the graph puts NAND latency at tens of microseconds that is in line with NAND read latency. Write latency is likely higher than that, probably at least 100s of nanoseconds or even a few microseconds given Intel and Micron's claims of up to 1000x faster than NAND, but what complicates things is that 3D XPoint is accessible at the bit-level whereas NAND is page-level, so comparing the latency of the two without extended context is quite difficult. In any case, 3D XPoint performance should be closer to DRAM than NAND, but since Intel and Micron aren't discussing any specific latencies yet it's too early to make any final conclusions.", "Meanwhile unlike many next generation memory technologies out there at the moment, 3D XPoint is the furthest along and doesn't only exist on paper or in a lab. Intel and Micron are currently sampling the first generation die that is being produced at the companies' jointly owned fab in Lehi, Utah. The die is 128Gbit (16GB) in capacity, whereas the products that startup memory companies have in production are in the order of dozens of megabytes. The die is built on a 20nm node and consists of two layers, and in the future scaling will happen through both lithography shrinks and by increasing the number of layers.", "The Utah fab has been producing 20nm NAND for now since Intel didn't invest on the 16nm shrink and all initial 3D NAND production will take place in Micron's Singapore fab, but it's unclear whether the full fab with its 20,000 wafers per month capacity will be dedicated to 3D XPoint from now on. My guess would be that 3D XPoint will gradually take over the full wafer capacity in Utah depending on how the market reacts to the new technology and how high demand Intel and Micron are seeing. 3D XPoint does require some new equipment for manufacturing since 3D XPoint deals with a whole new set of materials, but Intel and Micron said that the transition is quite similar to a new NAND node and allows some of the existing equipment to be used. ", "The companies aren't quoting any price per gigabyte yet, but since the whole function of 3D XPoint is to fill the gap between DRAM and NAND, it will also be priced accordingly. A quick look at NewEgg puts DRAM pricing at approximately $5-6 per gigabyte, whereas the high-end enterprise SSDs are in the range of $2-3. While client SSDs can be had for as low as $0.35, they aren't really a fair comparison because at least initially 3D XPoint will be aimed for enterprise applications. My educated guess is that the first 3D XPoint based products will be priced at about $4 per gigabyte, possibly even slightly lower depending on how DRAM and NAND pricess fall within a year."]},
{"title": "Rambus To Go Into Fabless Chip Production, Announces RB26 DDR4 DIMM Chipset", "paragraph": ["Since its inception in 1990, DRAM technology company Rambus’s business model has been an unusual one, focused on the creation and licensing of technology as opposed to selling finished chips. It’s this emphasis on technology design and licensing that has led to Rambus holding a number of major DRAM patents, and also their resulting ", " over DDR technology. That said, with their legal battles settled earlier this decade we haven’t heard much from Rambus in the DRAM space as of late; after a run in the PC space with RDRAM and a design win in the Playstation 3 for XDR DRAM, the company has seen little success licensing further DRAM designs.", "Meanwhile with the DRAM market having unified behind JEDEC standards – DDR4, GDDR5, and HBM – Rambus’s influence has been limited to that of a smaller player, though one still holding a selection of major DRAM patents. As a result there has been some speculation over just what the future would hold for a company whose newer DRAM designs have been ignored. With the 2015 Intel Developer Forum kicking off this week we finally have the answer to that question: Rambus will be making the transition from an IP licensing business to a true fabless semiconductor firm, designing and selling their own products.", "For their entry into the world of chip design and sales, at this week’s IDF Rambus is announcing that they will be designing and selling DDR4 DIMM chipsets. The chips, which will trade under the R+ chipset family, will be for Registered DIMMs (RDIMMs) and Load Reduced DIMMs (LRDIMMs) for server usage, with Rambus producing both the Register Clock Driver (RCD) chip for RDIMM/LRDIMM, and the data buffer chips for LRDIMMs.", "As we have covered in the past, ", ". By interfacing with an RDIMM’s RCD to better organize address and command signals, a CPU memory controller can handle more DIMMs and more memory per DIMM than standard unbuffered memory. LRDIMMs in turn take this one step further by attaching buffers to the data bus of each RAM chip on a DIMM – essentially changing DIMM bus operation to a type of serial mode – yet again increasing the amount of memory servers can address and the speeds they can work at. The tradeoff is of course DIMM cost due to extra chips, ", ", but in return servers can accept far more memory than what a standard unbuffered bus would allow.", "Rambus for their part sees a place for themselves in the current DIMM market for supplying the register and buffer chips used for DDR4 RDIMM/LRDIMMs, as DDR4 imposes further limitations in order to reach its greater speeds. This in turn is where Rambus is looking to capitalize on their experience with high speed memory, as they believe it gives them a leg up in producing DDR4 chipsets for both speed and reliability. The company’s first chipset, the RB26, will be compliant with DDR4-2666 specifications, and eventually Rambus wants to take it to DDR4-2933.", "Meanwhile, although Rambus is producing their own DIMM chipsets, they will not be producing their own DIMMs or DRAM. Rather the company will be offering their chipsets for sale to the DIMM vendors – Hynix, Micron, Samsung, etc – for those companies to use in building their respective RDIMMs and LPDIMMs. Ultimately such DIMMs would end up in the hands of server manufacturers and operators for their respective systems, with Intel’s latest Xeon processors being the catalyst.", "Going forward, Rambus is aiming to turn this into a regular business for the company. Besides the RB26 chipset, which is sampling low and will be in production in Q4, the company is also already in the process of developing future generations of chipsets to further boost performance and reduce power consumption.", "Finally, as for Rambus’s foray into fabless manufacturing, given the difficulties the company has seen in getting their DRAM technology adopted, the move into making chipsets for DDR4 is an interesting and somewhat unexpected one for a company who has traditionally only licensed IP, but also a logical one in their current situation. Though the company officially hasn’t thrown in the towel on their own DRAM standards, embracing the JEDEC standards rather than competing with them is the safer move given the momentum behind DDR4 and other standards. Meanwhile transitioning from pure licensing to selling their own chips is going to be a big – and undeniably risky – step for Rambus, but again owing to their background and history, it’s the move that makes the most sense as it means they aren’t wholly reliant on licensing to other companies to bring their designs to life, for all of the benefits and challenges that entails."]},
{"title": "Micron Confirms Mass Production of GDDR5X Memory", "paragraph": ["Micron Technology this week confirmed that it had begun mass production of ", " memory. As revealed last week, the first graphics card to use the new type of graphics DRAM will be NVIDIA’s upcoming ", " graphics adapter powered by the company’s new high-performance GPU based on its Pascal architecture.", "Micron’s first production GDDR5X chips (or, how NVIDIA calls them, G5X) will operate at 10 Gbps and will enable memory bandwidth of up to 320 GB/s for the GeForce GTX 1080, which is only a little less than the memory bandwidth of NVIDIA’s much wider memory bus equipped (and current-gen flagship)  GeForce GTX Titan X/980 Ti. NVIDIA’s GeForce GTX 1080 video cards are expected to hit the market on May 27, 2016, and presumably Micron has been helping NVIDIA stockpile memory chips for a launch for some time now.", "Earlier this year Micron began to ", " rated to operate at 10 Gb/s, 11 Gb/s and 12 Gb/s in quad data rate (QDR) mode with 16n prefetch. However, it looks like NVIDIA decided to be conservative and only run the chips at the minimum frequency.", "As reported, Micron’s first GDDR5X memory ICs (integrated circuits) feature 8 Gb (1 GB) capacity, sport 32-bit interface, use 1.35 V supply and I/O voltage as well as 1.8 V pump voltage (Vpp). The chips come in 190-ball BGA packages with 14×10 mm dimensions, so, they will take a little less space on graphics cards than GDDR5 ICs.", "The announcement by Micron indicates that the company will be the only supplier of GDDR5X memory for NVIDIA’s GeForce GTX 1080 graphics adapters, at least initially. Another important thing is that GDDR5X is real, it is mass produced now and it can indeed replace GDDR5 as a cost-efficient solution for gaming graphics cards. How affordable is GDDR5X? It should not be too expensive - particularly as it's designed as an alternative to more complex technologies such as HBM - but this early in the game it's definitely a premium product over tried and true (and widely available) GDDR5."]},
{"title": "G.Skill Unveils New Trident Z DDR4: Five New Colors", "paragraph": ["G.Skill has introduced new additions to its Trident Z family of DDR4 memory modules, which are designed to simplify the lives of anyone who wants to color-coordinate their PC. The new Trident Z lineup includes memory sticks with five new color schemes which are designed to match the aesthetics of overclocking and gaming motherboards.", "Just 10 to 15 years ago, PC modding used to be reserved for hardcore enthusiasts, who were willing to spend time and money to build beautifully looking PCs using custom-made components. PC cases with built-in LEDs or even transparent windows were in the minority, with only fully custom liquid cooling systems as a deviation, and the vast majority of motherboards were either slowly implementing color schemes or remained green/brown. Memory modules with heat spreaders were considered stylish. Fast forward to 2016, we have plenty of mass-produced components with PC modding features and almost everyone with moderate knowledge of PC hardware can build a PC with matching color scheme as well as lighting. The new Trident Z memory modules further simplify building of computers with unique designs, something that gamers and enthusiasts want to do.", "The G.Skill Trident Z series comes with two vectors: the main body and the top bar. The main body is either black or silver, and the top bar can come in orange, yellow, white or black. The original Trident Z modules featuring a silver body and black brushed aluminum heat spreader with a red top-bar highlight will remain on the market. Meanwhile, new color schemes (such as those with orange and yellow bars) will come in handy for those building new PCs based on the latest ASUS ROG, GIGABYTE Super Overclock or MSI XPower/MPower motherboards.", "The new G.Skill Trident Z memory modules have 8 GB or 16 GB capacities and are based on Samsung’s 8 Gb DDR4 ICs. The Trident Z will be available in dual-channel and quad-channel kits with 16, 32, 64 and 128 GB capacities, targeting everything from gaming desktops to higher-end workstations. Initially, G.Skill will offer colorful Trident Z kits with DDR4-3200, DDR4-3300, DDR4-3333, DDR4-3400 and DDR4-3466 speed-bins, CL14, CL16 or CL16 latencies as well as the higher DDR4 standard voltage (which is normal for high speed DDR4). The Trident Z Color are aimed at a good price/performance ratio for the majority of PC enthusiasts. Offering too many DDR4-4000+ SKUs with different color schemes could make lives of retailers uneasy since such modules are not too popular because of their high price. Therefore, if you want to go DDR4-4000 and higher, you will have to stick to “classic” Trident Z color scheme: black and silver heat spreader with red top-bar highlight.", "I know Ian has taken a delivery of some of these modules for future testing, in the silver body and white bar design. As shown below, these are 16GB modules at DDR4-3200 and 14-14-14-34 sub-timings, installed in the GIGABYTE X170-Extreme ECC.", "G.Skill intends to make the new Trident Z modules available this month. Since such modules only feature new heat spreaders, but continue to use the company’s own design PCBs as well as Samsung’s mass-produced 8 Gb DDR4 chips, they should not cost significantly more than existing Trident Z solutions."]},
{"title": "Crucial Announces 16GB Ballistix Sport LT DDR4-2400 SO-DIMMs", "paragraph": ["This week Crucial is introducing its first DDR4 SO-DIMMs for enthusiasts, designed for high-performance notebooks and small form-factor PCs. The Crucial Ballistix Sport LT PC4-19200 SO-DIMMs are available in 4 GB, 8 GB and 16 GB capacities and can operate at DDR4-2400 with 16 16-16 timings with 1.2 volts. The modules feature SPD with XMP 2.0 profiles for devices that support XMP.", "PC makers focusing on Intel enthusiast mobile parts usually ship their computers with DDR4-2133 memory modules, as per the JEDEC standard and the supported standard on the chips, and provides a peak 34.1 GB/s bandwidth when operating in dual-channel mode. By contrast, a pair of DDR4-2400 SO-DIMMs enables 38.4 GB/s of bandwidth, or 12.6% higher, which could provide a noteworthy performance improvement in applications that demand memory bandwidth (e.g., graphics applications). At the same time, the binned 2400 MT/s data rate and 1.2 volts modules with additional heatsinks are geared to maintain temperature equilibrium similar to the base frequency modules. In short, it should be relatively safe to use such modules even in highly-integrated systems with moderate cooling.", "The Ballistix Sport LT DDR4 SO-DIMMs will be available for purchase globally from retailers shortly and are currently available from the Crucial website. ", " date "]},
{"title": "G.Skill Reveals 2x8GB DDR4-4266 C19 and 4x16GB DDR4-3466 C14 Kits", "paragraph": ["Until recently enthusiasts who would like to use the fastest DDR4 memory with their Skylake-S processors had to use 4 GB DIMMs based on 4 Gb chips, typically sold in pairs for a 8 GB total memory. This week G.Skill has introduced three new sets of Trident Z memory modules that come with either an extremely high clock rate, or very aggressive timings. ", "The new G.Skill Trident Z memory modules based on Samsung’s 8 Gb DDR4 ICs and are available in 8 GB and 16 GB versions. The 8 GB DRAM sticks are rated to run at 3200 (CL13 13-13-33), 3466 (CL14 14-14-34) or 4266 (CL19 23-23-43) MT/s data rates, whereas 16 GB modules can work at 3200 and 3466 MT/s data rates at the aforementioned timings, with all kits running at the recommended DDR4 enthusiast setting of 1.35 volts. Like the rest of the Trident Z modules, the new sticks feature aluminum heat spreaders and custom black PCBs developed by G.Skill.", "The new Trident Z modules are designed for Intel’s Skylake-S processors when used in Intel’s Z170-based motherboards which support XMP 2.0 technology (to automatically set their clock rates when they are installed into appropriate PCs). Using the 'performance index' metric from our memory reviews as a rough indication of general performance (rough in the sense that some workloads are frequency dependent, others are latency driven), the 3200 C13 modules come in at a PI of 246, the 3466 C14 modules have a PI of 248, and the 4299 C19 are at 225. Historically a higher frequency is harder to validate for reliability than a lower CAS Latency, and represents the main challenge when producing high-performance modules.", "Because high-speed memory often needs to be validated with specific motherboards, so far G.Skill has validated its DDR4-4266 modules featuring 8 Gb chips on the ASUS ROG Maximus VIII Impact mainboard, but we expect that to expand over time. Meanwhile, the 8 GB and 16 GB DDR4-3200 and DDR4-3466 should work on many other motherboards as well. It is important to keep in mind that Intel’s HEDT platforms (Haswell-E) are more limited for extreme memory frequencies, which is why G.Skill officially has not validated the aforementioned modules on the Intel X99.", "Exact prices of the new Trident Z memory modules from G.Skill are unknown, but do not expect them to be cheap: DDR4-4266 modules at this time have only been announced by a few companies, and we believe G.Skill is the first to offer 8 GB modules. Moreover, DDR4-3200 and DDR4-3466 modules with aggressive timings like CL13 or CL14 are also pretty rare.", "Availability of memory modules with high clock rates will depend on the availability and binning of chips capable of operating at appropriate frequencies. Typically it is up to the memory companies to find which ICs are capable of these speeds, and companies compete in bidding for certain batches that have high hit rates for fast memory. Nonetheless, if the share of Samsung’s 8 Gb DDR4 chips that can operate in DDR4-4266 mode or with aggressive timings is significant, we may see competing solutions from other companies in the coming weeks or months."]}
]
