[
{"title": " Investigating NVIDIA’s Defective GPUs: RTX 5080 Missing ROPs Benchmarks", "paragraph": ["Investigating NVIDIA’s Defective GPUs: RTX 5080 Missing ROPs Benchmarks", "Last Updated: ", "The Highlights", "Today we’re looking at a deficient ", " Founders Edition (read ", ") that’s missing ROPs, meaning it came straight from NVIDIA and that NVIDIA had complete and total end-to-end control over the entire process, just like they want, and they still somehow f***ed it up. The normal ", " is as much as 10-11% better than this deficient one. Sometimes it’s 0%, often it’s 3-8%, but the swings can be large. This is a huge problem because most users won’t ever notice if their GPUs are missing ROPs. Unfortunately, the masses probably won’t even know about this problem to begin with.", "Here’s what’s going on:", "Steve Burke", "Jimmy Thang", "We traded a functional ", " (read ", ") to our viewer, Mason, for his defective 5080. Thanks for the trade, Mason.", "We have confirmed and validated that this GPU is missing 8 of its ROPs, down at 104 ROPs from the expected 112 ROPs. That means the proper card has nearly 8% more ROPs than the defect. ", "This is a huge problem. There are no obvious signs that this issue is present without knowing to look for it, which screws mainstream owners. There will absolutely be defective units out there without people knowing, and we don’t think NVIDIA has done enough to draw attention to this issue. You’d have to know to launch GPU-Z, then know to check the ROPs, then recognize that the count is wrong. That knowledge and skill will be way more common for this audience than most, but even then, most people aren’t going to feel a need to validate the GPU they bought has each individual fixed function unit present.", "NVIDIA needs to do better about notifying customers. NVIDIA may claim 0.5%, but from first-hand experience in our inbox alone, we have a hard time believing the count is that low -- especially since it didn’t name the 5080. Either NVIDIA didn’t know about the 5080, in which case it’s wrong about the defect rate, or it did know and it was disingenuous at best by leaving it out. We’re not sure which is worse. We’ve received dozens of emails and messages about units deficient in ROPs count, which seems awfully high for a focused audience with seemingly low distribution of the card so far.", "That’s the backstory. Let’s get into the testing.", "A “ROP” is a raster operations pipeline (or render output unit) and is a core part of the GPU. ", "We already explained this in-depth in a ", ". Here’s the basics: The NVIDIA Blackwell architecture for gaming GPUs looks like this block diagram at most. ", "Each GPC has 8 TPCs, with two groups of 8 ROPs assigned separately to groupings of 4 TPCs. In some ", ", ", ", and now 5080s, one of these banks of 8 ROPs appears to be disabled, or at least not functioning.", "As we said before, the weird thing is that this shouldn’t have been possible on the 5080. The 5080 should be a full GB203 die, and so there are no disabled SMs on a GB203 RTX 5080 unlike a ", " or a ", " where some of the stuff is turned off and there could be collateral damage under traditional understanding. ", "Maybe some poor TSMC or NVIDIA employee knocked over a coffee mug and hit the KILLROPS.EXE key on the 5080 production run or something. Whatever the case is, it has an impact.", "Over the years, we’ve seen GPUs with a ROPs advantage and iso other conditions typically show their benefit in higher resolution scenarios or in heavily anti-aliased testing. ROPs perform some of the final stages in the rendering pipeline. Of the 3 resolutions we test, 4K will show the biggest impact, but scenes with a lot of blending or some types of anti-aliasing will also reflect the change.", "NVIDIA acknowledged this issue shortly after it emerged, but only for the 5070 Ti (read ", ") and 5090 (read ", "). It almost immediately somehow knew exactly how many units were affected, which further reinforces our belief that NVIDIA would have known about this, with the company pinning it to 0.5% of units. The company did not name the 5080 -- it also didn’t really apologize and we felt it downplayed the performance impact to the lowest number, which would be 4% on the 5090. It didn’t mention that the 5070 Ti and 5080 impact would be greater.", "After Mason’s card showed up on Reddit, NVIDIA issued a second statement that we’re going to call their “oopsies” statement, where they confirmed the 5080 was also affected.", "Let’s get into some simple performance numbers. We only really need two basics:", "1 - The impact to performance against the normal 5080, which can be done in a simple A/B chart", "2 - The change in relative positioning versus nearby alternatives", "We’re going to keep the charts really focused and simple because we don’t need much to show the evidence of performance impact.", "This chart shows the head-to-head in average FPS for the two 5080 cards. Some games are almost exactly identical: Baldur’s Gate 3 predictably is CPU-bound, but it’s nice to know that a CPU-bound scenario didn’t force a gap. Black Myth: Wukong was remarkably consistent and Final Fantasy 14 was within 1 FPS for this testing, but there are some differences.", "Total War: Warhammer 3 is the most concerning of these. This one has always rooted-out the most erratic behaviors in testing and that’s why we keep it around. Across all 3 resolutions, we saw major swings. At 4K, we observed an 11% improvement with the actual RTX 5080 rather than the deficient one. That is a difference as big as the gap between some of NVIDIA’s models entirely.", "Dying Light 2 also consistently showed a gap: The full 5080 ran 8.7% higher framerate for average FPS than the deficient one. F1 24 showed a 3.3% improvement with all ROPs, with Resident Evil 4 at 1.6%, which is outside our run-to-run variance and makes it a real result, and Starfield at 2.3%. ", "At 1440p, we saw an 8.8% improvement with all ROPs in Dying Light 2, which matches our 4K results. Final Fantasy is at about 2%, Dragon’s Dogma 2 is at 2.5%, and F1 24 is at 0.8%. ", "Let’s look at how this impacts the relative ranking versus other cards. We’ll look at only the games with the largest impact for a worst-case scenario.", "Here’s Total Warhammer III result at 4K. The 5080 “Reduction of Performance” variant ran at 82 FPS AVG, a significant reduction from the correct result of 91 FPS AVG. Before, the 5080 was tied with the ", " and within error. Now, the ", " outperforms the 5080 by 12%. That is a huge swing and makes the 7900 XTX significantly better value. Sure, the partners might help you replace a defective model; however, that’d require noticing it.", "The gap over the not-ROPs-deficient 5070 Ti is also reduced to nothing. This particular title and the way we test it is highly reactive to this defect.", "In Dragon’s Dogma 2, the 5080 Special Edition landed between the stock model and the 7900 XTX, cutting the gap in half. This significantly harms the value of the RTX 5080. The lead is reduced from 10% to 5%. Literally halved. The lead over the 5070 Ti is also cut, now 9.4% from 15%.", "1080p shows the 5080 Regression of Performance edition at 157.1 FPS AVG from 165, which reduces it to equal the 4080 (watch ", "). Before, they were functionally equal. Now, they’re literally equal. The 5080’s lead over the 5070 Ti was 9%. Now it’s 3.8%. It was cut into a third of the benefit, basically. The 7900 XTX now is nearly within run-to-run variance of the 5080 defect.", "We’ll just look at one more. In Dying Light 2 at 4K, the RTX 5080 normal card ran at 81 FPS AVG, with the 5080 ROPs defect card at 74.5 FPS AVG. The 5080 was 11.7% ahead of the 7900 XTX, but is now only 2.8% ahead. ", "If you had bought the ", " instead of the ", " because of the expectation and ended up with a defect, this is a big problem because now the ranking shuffles. If you don’t notice and you keep using the defective device, you’re going to get screwed. You’ll be stuck with something worse than you thought. ", "Checking for this is really easy. When you buy a 50 series card, the first thing you should do is check for all of the ROPs to make sure that your card is not affected. ", "You have to do a clean install of the drivers. If you check ", " without the drivers installed, it will reference a look-up table and tell you the correct amount even if they’re not present. So you need to install the drivers first and then install the latest version of GPU-Z and look for ROPs. ", "Then look at the image above to see how many ROPs should be present. ", "If what you have differs from what it should be, you absolutely need to seek a refund or replacement, but we’d encourage a refund as it’s the fastest path. ", "There is absolutely a performance impact and NVIDIA’s approach of “just reach out and we’ll make it right” is completely unacceptable. They also left out the ", ". The company deserves to get raked over the coals for this. Most users will not notice this.", "NVIDIA originally said the problem was with 1 ROP instead of 8 ROPs.", "We did take apart the card and observed no physical difference to the die with the text looking the same. It also has the same branding. ", "This puts a cap on what has been an utter disaster of a launch for NVIDIA. One or two mistakes is understandable, but the totality of these mistakes is insane, especially for the prices they are going for."]},
{"title": " NVIDIA is Selling Lies | RTX 5070 Founders Edition Review & Benchmarks", "paragraph": ["NVIDIA is Selling Lies | RTX 5070 Founders Edition Review & Benchmarks", "Last Updated: ", "The Highlights", "NVIDIA is selling lies and reviewers shouldn’t be afraid to mince words. That is precisely what the ", " is. It was marketed on the back of lies considering NVIDIA stated that the card, which has 12GB of VRAM, would offer ", ", which has 24GB of VRAM, performance for $549 with the help of AI. ", "Here’s an NVIDIA-compliant comparison of the RTX 5070 with MFG against the RTX ", " without any frame generation at all.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "These are really abusive settings, stressing both cards heavily. But NVIDIA said the ", " would be equal to the 4090 (watch ", "), and we’re not even close. The 5070’s spiky behavior is exceeding 200 ms in this like-for-like comparison except that it has MFG. The 4090 isn’t perfect, but WITHOUT any frame generation at all, it’s hitting at worst about 50-60 ms, with an average closer to 26. ", "Here’s what that actually ", ". Using NVIDIA’s own FrameView tool, we also get a glimpse into another problem: Latency. The PC Latency on the 4090 was around 51 ms during a like-for-like comparison. 51 is a lot better than what we saw in the 5070 with MFG 4X after 5 minutes of being in the game. That was 500-720 ms. Now, to be fair, if you only played Cyberpunk with these settings for about 15-20 seconds at a time, things look a lot better… ", "The 5070 is getting absolutely clobbered for VRAM, which is just 12GB to the 4090’s 24GB. To call these the same is an absolute, flat-out lie. These cards are not the same. In situations where the card runs out of VRAM in particular, it can never dream to be a 4090. It is simply impossible. ", "Here’s a quick chart showing passes 1 through 3 of the 5070 as it gets progressively worse with each benchmark pass as the framebuffer fills. The 4090, meanwhile, maintains its performance the entire time.", "NVIDIA has got to stop lying. This isn’t just marketing, this is an actual, verifiable lie. But let’s just pretend MFG 4X is somehow a fair comparison against the 4090 in a scenario that’s maybe not VRAM constrained. It’s an OK technology, but it is not a like-for-like comparison because the images themselves are not the same. When you turn it on, it’s like Clive here has 6 feet. ", "NVIDIA could have launched its RTX 5070 to mediocre or lukewarm reviews. Instead, it decided to openly lie on stage and manipulate its performance numbers to mislead consumers into thinking an otherwise lukewarm card is equal to the flagship of last generation. NVIDIA, this was avoidable. You are making all of the unforced errors right now. This was a completely unnecessary fumble. We could have just listed all the numbers and called it a day, but now have to start by writing about NVIDIA’s lies and marketing.", ". It’s hard to say what it’ll actually be for street pricing. But basing only off of MSRP, that makes this card ", " at its launch in 2020 and $50 ", ". ", "This looks like the patterned NVIDIA stutter-stepping of price slowly upwards, where they overshoot, then bring it back down. We saw this from 10 to 20 to 30 series.", "The ", " has an advertised 6144 CUDA cores, a 192-bit bus, and 12GB of GDDR7 memory. It might even have all of its ROPs. The ", " has an MSRP at $750 and carries 16 GB of GDDR7 memory on a 256-bit bus, so there’s more bandwidth, a little more capacity, and an increase to 8960 CUDA cores, and it may even have all of the ROPs that you’re paying for.", "Clocks on the 5070 are advertised at 2.51 GHz boost.", "A quick glance at pricing breaks it down like this: ", "There are 5 MSRP models of the 5070 Ti (read ", ") on Newegg, which is just enough to technically claim the MSRP exists. The rest of them are higher, often $900 and over. Board partners have now directly repriced their cards, with ", " just before the 5070 launch. ", "As we write this review, following the VideoCardz news post, ", ", dropping from $820 and $840 to $750. NVIDIA has historically applied pressure to partners to make MSRP units available, so it wouldn’t surprise us if the VideoCardz story triggered a reaction to keep two models available. They can also achieve this with rebates.", "As for things available right now, we found the ", " for $530 and... that’s it. When we sorted Newegg to $450 to $650 for “in stock” and “sold by Newegg,” meaning no third-party sellers and no unavailable models, all we got were a bunch of refurbished units and the 7800 XT Pulse.", "It really is crazy right now.", "We’re going to get into the benchmarks next. This review contains most of the games that we benchmark since we’re preparing for the ", " and ", " launch. We currently have around 50-60 GPUs tested in our lineup, so to fit the charts, we need to remove a few from the chart.", "Here’s what we’ve added and removed:", "Final Fantasy 14: Dawntrail is up first for a traditional raster title at 4K, without any bulls*** to artificially inflate numbers.", "This game is actually playable on most modern hardware at this resolution. The RTX 5070 ran at 78 FPS AVG, landing it right between the 4070 Ti (watch ", ") and the ", ". Maybe we should call it the 4070 Ti V3 instead. The ", " outperforms the 5070 by 25% here, the ", " is ahead by 11%, and the ", " by 6%.", "Going by name only, the generational lead over the ", " (watch ", ") is 30%, or 48% over the 3070 (watch ", ") and 118% over the 2070 (watch ", "), followed by 244% over the 1070. ", "Unfortunately, the 5070 is not better than the 4090 -- but if we were to be artificially intelligent and actually intellectually dishonest, it might be!", "At 1440p, the RTX 5070 Ti’s lead over the RTX 5070 is reduced to 22% from 25% at 4K. The 5070 is also reduced in its advantage over the 4070 Ti, now just 1% from around 6% at 4K. From 150 FPS to 172 FPS, we now have 3 GPUs from NVIDIA. If you want to make NVIDIA look as ridiculous as possible, you could maximize the size of the clown car by drawing a box from the ", " at 202 FPS to the 4070 FE at 117 FPS. The result is 7 modern NVIDIA GPUs spanning an 85 FPS range. Divided evenly, that would be one GPU for every 12 FPS. In this situation though, 4 of them land within a 36 FPS range: The 5070 Ti, 4070 Ti Super (read ", "), 5070, and 4070 Ti mean you can dial it into the individual decimals if you were so picky about your performance.", "The 7900 XT (read ", ") lands in the middle of all of these and has a 12% lead over the RTX 5070, assuming all ROPs are present on the 5070.", "The 5070 is, again, not better than the 4090. ", "Remarkably, we still have OK scaling at 1080p for most of these GPUs. The fact that the 9800X3D allows the ", " (read ", ") and 4090 to still have a slight gap at 1080p really speaks to how exciting AMD’s 9800X3D is.", "Anyway, the 5070 ran this workload at 225 FPS AVG and fell below the 4070 Ti. No wonder NVIDIA wants everyone using MFG. The 4090, predictably, outperforms the 5070 massively. It’s a 67% gap here.", "The 7900 XT now has a reduced lead of 9%.", "Black Myth: Wukong at 4K and rasterized had the 5070 at 40 FPS AVG, giving the 5070 Ti a 27% lead. The 5070 really struggled in this one and ended up tied with the 4070 Ti and, to its benefit, the 7900 XT. We’ll be curious to see how the 9070 does in this one… Surely we don’t already know as we’re writing this and definitely haven’t looked at the results and in no way would we ever encourage you to just wait and see what the results are…", "If we were to randomly multiply the frames, it’d be better than the 4090 -- until you randomly multiplied the 4090 with lossless scaling. Jensen’s claim is like a schoolyard argument: The 5070 is infinity times better.", "At 1440p, we re-introduce other 70-class cards of the past. The 5070 FE ran at 72 FPS AVG, with frametime pacing unremarkable. The 5070 is tied with the 4070 Ti and 7900 XT. Generationally by name only, the 5070 improves on the 4070 by 22%, the 3070 by 58%, and the 2070 non-Super by 137%.", "The 5070 Ti leads the 5070 by 21% here.", "1080p has the RTX 5070 down at 98 FPS AVG, allowing the 4070 Ti to gain a slight 2% lead. The 5070 Ti is ahead by 17.6% here, assuming all ROPs are present. ", "Against the prior cards containing 70 naming, the 5070 is ahead of the 4070 by 18%, the 3070’s 63 FPS AVG by 56%, and the 2070’s 43 FPS by 126%.", "Starfield at 4K is up now. The RTX 5070 ran at 54 FPS AVG here, giving the 4070 Ti’s 59 FPS a 9% lead. It’d be interesting if AMD’s 9070 performed similarly to the 7900 XT here since the Hellhound is 20% ahead of the 5070. We’ll find out tomorrow.", "The 5070 Ti has a larger lead over the 5070 in this test than the last 1080p benchmark, running a 68 FPS AVG for a 27% advantage over the 5070 FE. Performance of the 5070 over the 2070’s 22 FPS is about 145% ahead.", "1440p significantly reduces the 5070 Ti’s uplift over the 5070, bringing it down to 22% from the prior 27%. The 7900 XT, which is an important comparison in this test for... reasons, runs at 98 FPS AVG with comparable lows to its neighbors. That has it 18% ahead of the RTX 5070’s 83 FPS AVG. ", "As for the RTX 4070, the 5070 leads by a paltry 10.6%, then 48% over the 3070’s 56 FPS.", "At 1080p, the 5070’s 104 FPS AVG planted it between the 4070 and 4070 Ti again, with an unimpressive 9% improvement on the 4070. The gap shrinks as the resolution decreases in this game. The 5070 Ti is now ahead by only 19%, down from 27% at 4K. As for AMD, its RX 7900 XT is 15% ahead here, down slightly from the 1440p advantage.", "Dragon’s Dogma 2 at 4K is next. This game is relatively heavy on the GPU in our test area, but is unique for its ability to also produce a heavy CPU load in cities.", "The RTX 5070 ran at 56 FPS AVG here and had good frametime pacing represented in the lows, but then again, so did everything around it. It’s proportional.", "The 5070 very slightly leads the 4070 Ti. ", "As for the 4090: We’re still somehow not matching the RTX 4090, which is up at 98 FPS. We must have mistyped the =5070*4 formula that Jensen prescribed reviewers. ", "The 5070 Ti leads the 5070 by a much larger 31% in this benchmark, producing one of the most notable jumps yet. The 3090 Ti ran at 64 FPS for a 14% lead over the 5070, which might seem totally non-sequitur and unrelated, but it isn’t.", "Anyway, the 7900 XT held a 61 FPS AVG in this one, with the ", " just past the 5070 Ti. ", "At 1440p, the RTX 5070 basically ties the RTX 4070 Ti again. The 7900 XT’s 104 FPS AVG is just a 9% lead here, with the 4070 Ti Super a slight step above that. The 5070 Ti has a 25% lead over the 5070 here, posting one of its better 1440p comparative results.", "Somehow, and we don’t know how this happened, the RTX 4090 just seems to be better than the RTX 5070. That’s just so weird. Maybe we should run NVIDIA Multi-Fraction Generation to divide the 4090 down to a 5070.", "At 1080p, the 5070’s 126 FPS AVG has it just behind the 4070 Ti. The 7900 XT leads by only 7% here, with the 5070 Ti knocked down to a 21% lead from 25% at 1440p. The 5070 Ti’s 151 FPS AVG is also about the same as the ", ", which has its own slight advantage.", "As for the 4090, well, ours really must be broken since it’s not making the 5070 look good enough.", "Cyberpunk is up now. We have a more limited data set with this since we updated the game to v2.21 and have been working on re-running everything.", "At 4K, the 5070 ran at 41 FPS AVG. That put it 6% ahead of the 4070 Ti and 144% ahead of the 2070, or 68% ahead of the 24 FPS result of the 3070. As for the 5070 Ti, its 50 FPS AVG gives it a 22% lead here, with the 7900 XTX (watch ", ") ahead of that at 57 FPS AVG. The 7900 XT has a noteworthy 13% lead against the 5070 here.", "At 1440p, the 5070 ran at 89 FPS AVG and had lows at 75 FPS 1% and 71 FPS 0.1%. The 5070 Ti at 108 FPS is about 21% ahead, not changing much from 4K. The 7900 XT is ahead of the 5070 in AVG, 1%, and 0.1%, holding a 12% lead in average framerate.", "Once again, the 4070 Ti basically ties the 5070, with the latter slightly ahead this time.", "1080p reintroduces other 70-class cards: The 5070 Ti ran at 167 FPS AVG, with the 5070 at 138. That’s still 21%. The 4070 hasn’t been rerun here yet, but the 3070 is present at 85 FPS, yielding a 62% lead to the 5070, followed by the 2070 at 60 FPS for 130%, then the GTX 1070 at 35 FPS AVG. That’s about a 293% improvement to the 5070.", "AMD’s RX 7900 XT seems like it’ll be particularly relevant soon. This one ran at 150 FPS AVG, with lows expected at 116 and 104. That’s an 8.8% improvement over the 5070.", "Dying Light 2 is up now. This is another of the heavier games, especially with RT later.", "At 4K, the 5070 ran at 56 FPS AVG and struggled in this title, allowing the 5070 Ti an advantage of 25%. The 7900 XT doesn’t look great by comparison here, at 55 FPS AVG itself.", "As for the 4070 Ti, it’s again roughly equal. ", "1440p has the 5070 at 106 FPS AVG, now trading places with the 7900 XT. The 5070 Ti’s lead is reduced to 22%, with the 4070 Ti now falling slightly behind the 5070.", "By generational naming, the 4070 ran at 78 FPS AVG (so the 5070 is 36% better) and the 3070 was at 67 FPS AVG (or 60% better on the 5070).", "Resident Evil 4 is up last for raster testing. We’re almost through these.", "At 4K, the 5070’s 78 FPS AVG has it just behind the 4070 Ti that we’ve been tracking. It’s also about 6 FPS ahead of the ", ", so measurably different but functionally equal. The 5070 Ti’s 107 FPS AVG positions it 36% ahead in this one, which is a huge gain and among the largest we’ve seen. The 7900 XT seems like a good AMD comparison, landing at 100 FPS AVG and leading the 5070 by 28%.", "At 1440p, the 5070 held a 152 FPS AVG and trailed the 4070 Ti by 8 FPS. The 5070 Ti is 30% higher framerate here, down from 36% at 4K. As we’ve seen, the gap tends to close at lower resolutions, although it’s still a huge gap in this game.", "The 7900 XT is now up at 186 FPS AVG, with a reduction in the percentage advantage to 22% from 28% at 4K.", "Generationally, the 5070 runs 23% faster than the 124 FPS on the 4070, 54% faster than the 91 FPS on the 3070, and 157% ahead of the 59 FPS for the 2070.", "Finally for raster, we’re now at 1080p for Resident Evil 4. This one is interesting for the further closing of the gap between the 5070 and 5070 Ti, which now ranges from 282 FPS to 224 FPS for a 26% improvement on the Ti. The 7900 XT is about 18% higher framerate here.", "We’re moving on to ray tracing now. NVIDIA has historically held significant advantages in some games for ray tracing.", "AMD says it has significantly improved its ray tracing performance. We explained why the company is claiming this in our ", ", so this will become highly relevant in tomorrow’s reviews.", "Black Myth: Wukong is up first. This is one of the two titles in this RT test suite that heavily favors NVIDIA. We’re testing with upscaling here.", "At 4K, the RTX 5070 ran at 40 FPS AVG. That has the 5070 Ti at 30% ahead, with the 4070 Ti about tied with the 5070. AMD doesn’t appear until the 7900 XTX, down at 20 FPS AVG. That’s a massive lead of 99% over the 7900 XTX. The 5070 doubles the 7900 XTX’s performance.", "That’s not good for AMD’s last generation. We’ll see if that lead can be halved with the new generation. The 5070 leads the RTX 3080 by 44%. Based on math from AMD’s claims in its presentation, that’s about where it should land here. Too bad no one knows if that’s a good reference point yet.", "At 1440p, the 5070 Ti ran at 88 FPS AVG, the 5070 at 73 FPS AVG (between the 4070 Ti and 4070 Ti Super), and the original RTX 70-class card ran at 24 FPS AVG. AMD’s best here, as of today and not tomorrow, is the 7900 XTX at 37 FPS AVG.", "Now for 1080p. The 5070 held a 97 FPS AVG here, encroaching on the 4090 but still not beating it. The 5070 Ti leads the 5070 by just 15% in this situation, with the 5070 now ahead of the 4070 Ti and Ti Super cards after slow gains in the other resolutions. The 7900 XTX ran at 49 FPS AVG, closer to a 4060 and behind the 3070. AMD named the 3080 in its slideshow announcing the card. If it lands near that mark, it’d be around or ahead of the 66 FPS AVG result for the FTW3.", "Speaking of: EVGA really knew what was coming when it left the GPU market.", "Dragon’s Dogma 2 is back with RT now. This one is more balanced between the vendors.", "At 4K, the 5070 ran at 49 FPS AVG, establishing a 9% lead for the 7900 XT. That’s a similar gap to what we saw without RT. The 5070 Ti leads by 30% again here, with the 7900 XTX leading that. ", "At 1440p with RT, Dragon’s Dogma 2 puts the 5070 at 83 FPS AVG, reducing the 5070 Ti’s lead to 24%. The 7900 XT sits between both, with the 7900 XTX ahead of the 5070 Ti.", "Based on the charts AMD has released, the math would position the 9070 and 9070 XT as flanking the 5070 Ti, but we’ll find out soon enough.", "Generationally, the 5070 leads the 4070 by 23%, the 3070’s 51 FPS by 62%, and the 2070 non-Super by 145%.", "Down to 1080p, the 5070 Ti’s lead over the 5070 is now 22%, with the 7900 XTX still leading the Ti and 7900 XT still leading the 5070. The 4070 is relatively close to the 5070 here, now with an 18% advantage to the 5070. ", "But maybe the 4090 can breathe some excitement into it. The 4090 ran at 169.2 FPS AVG. If we multiply the 5070 by a billion, that’d put it at 107.4 billion FPS AVG, which is an uplift of 6,347,516.73%. This is clearly the card to get. And as we all know, it’s not possible to multiply the 4090 by arbitrary numbers with lossless scaling because then that would hurt 50-series marketing.", "Dying Light 2 with RT is next. This first one is 4K upscaled. The RTX 5070 ran at 44 FPS AVG here, just below the 4070 Ti. The 7900 XTX held 46 FPS AVG in this one, again showing AMD’s prior deficit in RT performance. It’s not as bad as in Black Myth, but considering the original pricing of the 4070 Ti and 7900 XTX, AMD was in a position that was hard to fight from. We’ll see how the 9070 series compares tomorrow.", "At 1440p, the 5070 beats the 7900 XT by 13%, falls behind the 4070 Ti, and allows the 5070 Ti, which is basically an RTX 4080 v3 or v4, a lead of 27%.", "At 1080p upscaled, the 5070 produced 116 FPS AVG and again sat just below the 4070 Ti, with the 7900 XTX and 7900 XT flanking the 5070. The 5070 Ti ran at 141 FPS AVG, which will be the number for AMD’s 9070 XT to target.", "Generationally, the 5070 leads the 4070 by 25% and 3070 by 58%.", "Resident Evil at 4K upscaled is next. This one has the 5070 at 91 FPS AVG, roughly tying the 4070 Ti once again. The 7900 XT leads the 5070 by 18%, with the 5070 Ti leading by 29%. The 7900 XTX sits ahead of that at 134 FPS AVG.", "At 1440p, the 5070’s 149 FPS AVG put it 23% ahead of the 4070 and 70% ahead of the 3070. The 7900 XT leads the 4070 Ti and 5070.", "Finally for RT, our new Cyberpunk results with the updated game version.", "First, with 4K and RT Ultra, the 5070 ran at 17 FPS AVG. This is without upscaling and is intentionally the heaviest workload we run.", "That positions it right between the 7900 XT and 7900 XTX. That’d be unfortunate positioning if AMD weren’t launching something with better RT in a day, but we’ll have to check in tomorrow for the rank.", "The 5070 Ti continues its trend of being NVIDIA’s third or fourth iteration of a 4080 card and leads the 5070 by a huge 56% here. The workload is just too heavy for the 5070 to handle and it has neither the bandwidth or compute capability.", "Here’s RT Ultra at 1080p. The 5070 held 64 FPS AVG with these settings, putting the 5070 Ti about 32% ahead. The 7900 XTX trails the 5070 here, unfortunately for AMD’s former flagship.", "We also run RT Medium for Cyberpunk. We’ve found that RT Ultra and RT Medium can significantly affect the hierarchical ranking of NVIDIA and AMD, so we run both. NVIDIA runs away at Ultra.", "With these settings and at 4K still, the 5070 now runs at 22.5 FPS AVG. This reduces the 5070 Ti’s lead to a more normal 35%. The 5070 just didn’t have the ability to keep up at 4K/RT Ultra.", "We’ll keep thermals short and simple. Using our usual benchmark of Port Royal at 4K and looping, we measured the 5070 FE at steady state at around 74 degrees Celsius for GPU core temperature. The memory temperature was about 76 degrees. Both of these numbers are acceptable; memory is well within spec and is completely fine. Core has some room for a hotter computer case. The core temperature isn’t impressive, but is acceptable, and there’s a little bit of buffer there.", "The 5070 FE’s fans ran at about 2500 RPM to maintain this temperature. We skipped acoustic testing this time since we have the two 9070 reviews we have to get through. ", "For efficiency as usual, we use a power interposer in between the GPU and the power supply. That means we’re intercepting slot power and the PCIe power through the cables and we do that so we can isolate the GPU entirely, measure its power consumption during a workload. Then we take the frame rate numbers to do some simple math and produce an efficiency number. ", "In these charts, you’ll get a few things. You’ll get the total power consumption for that workload in watts and you also get its efficiency in FPS per watt not workload-normalized so we allow it to run at the frame rate that it can naturally run at. ", "For efficiency with Final Fantasy 14 at 4K, we ended up with this data. This chart isn’t as dense as our 1440p chart that’s up next.", "The 5070 FE ran at 0.33 FPS/W here, pulling 233W during the workload. The 5070 Ti pulled 264W, allowing it an improvement in efficiency to 0.37 FPS/W. AMD’s prior RX 7900 XT wasn’t particularly efficient, giving NVIDIA a large advantage in efficiency for the 5070. The FPS was close enough to be mostly observably equal to a player, but the 7900 XT ran at just 0.25 FPS/W from its 324W power draw during the test.", "We’ll have to see what the 9070 series does to improve this, as this has been one of AMD’s GPU weaknesses over the years.", "At 1440p, the 5070 ran at 0.65 FPS/W. That puts the 5070 Ti as about 12% more efficient than the 5070 when producing a variable workload. The AMD 7900 XT pulled 325W in this test, landing at 0.53 FPS/W. Its framerate is higher, but the power is also disproportionately higher, which hurts its efficiency despite a higher framerate.", "At 1080p, the 5070 hits nearly 1 FPS/W. The 4060 Ti has passed it for efficiency, with the 5070 Ti improved by 0.11 FPS/W on top of the 5070’s 1.0 result. The 7900 XT is down at 0.75 FPS/W and is still pulling about the same power as previously.", "F1 24 at 4K and with ray tracing is up next. In this one, the 5070 produced 0.17 FPS/W, pulling close to TDP at 246W in order to produce its hardly playable framerate. The 5070 Ti ran at 0.20 FPS/W, with the 4080 ranking at the top for its balance of power and framerate. Note that bar size changes from numbers that look the same are valid -- it’s just from the hidden decimal places.", "The 7900 XT ran at 0.12 FPS/W, a significant fall from the 5070’s result. The 9070 series has a lot of work to do here.", "At 1080p and still with RT, the 5070 ran at 0.55 FPS/W, again giving the 5070 Ti a 13% efficiency advantage. We’re curious to see where the 9070 and 9070 XT land. The 7900 XT isn’t competitive in efficiency, with a lot of this particular result being because of its relatively low RT performance last generation. That’s what AMD is trying to tackle.", "In Black Myth without RT and at 1080p, the 5070 Ti held a 0.53 FPS/W rank, putting it in the second slot. The 5070 is at 0.48, with the 4060 Ti still trading back-and-forth depending on the test. The ", " was at 0.31 FPS/W, with the 7900 XT just below that. The 5070 is not NVIDIA’s most power efficient card due to the performance trade-offs, but is relatively efficient overall.", "In Dragon’s Dogma 2 at 1440p and with RT, the RTX 5070 ranked at 0.36 FPS/W, sandwiching it between the 4090 that it’s not better than and the ", ". The 7900 XT is down at 0.28 FPS/W, yielding an efficiency benefit in a non-normalized framerate workload of 29%. That’ll be the mark for the 9070 series to hit.", "Finally, in Starfield rasterized at 1440p, the 5070 ran at 0.43 FPS/W and landed just below the 4090, which it remains not better than, again. The 7800 XT (read ", ") from AMD ran at 0.32 FPS/W, so AMD has a lot of ground to gain here tomorrow. This will be an area we’ll focus to test for improvements, as theoretically, it should be better than it was.", "One thing’s for certain: NVIDIA’s marketing about the ", " being a ", " was wrapped entirely in bull**** and built on a foundation of manure, which is only fitting for a company whose CEO is never found without a leather jacket.", "The GPU market is insane right now. The fact that we sorted Newegg for $450 to $650 GPUs and got basically one is insane. The current buying experience matches that of the COVID-era boom around late 2020 and the 2017 crypto mining boom. That makes it hard to evaluate value, and broadly speaking, we’d say to just wait for things to cool off if your current machine can last you a bit longer. You’ll likely save money as pricing settles. If that doesn’t matter to you, maybe time will -- and unless you get lucky and snipe an early stock of the cards, you may at least save some time.", "As for its value, we’re going to kick the can to tomorrow’s reviews of the ", " and ", ". We don’t think you should buy this card until you learn about AMD’s competition, as the on-paper price is in similar territory. We’ll see how the in-reality price is for both of them.", "Check back for the ", " and ", "."]},
{"title": " NVIDIA Giveth, NVIDIA Taketh Away | RIP PhysX 32-bit (GTX 580 vs. RTX 5080)", "paragraph": ["NVIDIA Giveth, NVIDIA Taketh Away | RIP PhysX 32-bit (GTX 580 vs. RTX 5080)", "Last Updated: ", "The Highlights", "A GTX 580 is up to 81% better than NVIDIA’s technologically “outdated” RTX ", " as the GPU from 2010 is suddenly relevant again.", "We even brought back a GTX 980 (read ", "), and pitted it against the $1,000+ RTX 5080 from 2025. The 980 is a better gaming experience than the RTX 5080 in some of the tests we’ll be running in this story. ", "We even dug Mirror’s Edge out of the grave for this, surviving an onslaught of EA Origin pop-ups to do so. In this game, the 5080 struggles versus older hardware.", "Steve Burke", "Patrick Lathan", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "In fact, we even put the RTX 5080 with a GTX 980 as an accelerator card to improve the performance.", "And all of that is because of PhysX. NVIDIA’s “way it’s meant to be played” was once marketed as a game-changing feature, and they were right. But now, some variations of PhysX are no longer supported.", "A couple of weeks ago, a user responded to an ", ", saying that PhysX still isn't working on the 50 series cards. Attempting to force it on via a config file edit in Borderlands 2 and turning on the PhysX indicator shows it's running on the CPU. In response, NVIDIA stated that This is expected behavior as 32-bit CUDA applications are deprecated on GeForce RTX 50 series GPUs, citing ", " that had (up until then) drawn little attention from the gaming community.", "This is an insight into what happens when vendor-specific solutions are abandoned, and even though the affected games are ancient, it breathes some healthy skepticism into topics like vendor-specific graphics improvements. Today, we have a lot of those that include DLSS and its many sub-features, Reflex, frame generation, and other technologies that could end up in an NVIDIA graveyard. Even ray tracing: There’s no guarantee that’s processed the same way forever, especially with dedicated hardware for it.", "Let’s get into the PhysX situation.", "Rumors of its demise are ", "exaggerated, but not greatly: NVIDIA hasn't fully killed PhysX (not yet, anyway), but it has dropped 32-bit CUDA support, and therefore 32-bit PhysX games are affected. ", "A user on the ResetEra forum has ", " based on a ", "; big thanks to those guys for rescuing lists from rules-obsessed Wikipedia editors and their crusade to convert every list into a ", ". Yes, this bothers us.", "PhysX has had a long, long history, and it's not actually gone. For example, newer games with 64-bit PhysX shouldn't be affected. ", "We're particularly confused by the ", " that leads with the statement that As far as we know, there are no 64-bit games with integrated PhysX technology, but it then mentions Metro: Exodus and The Witcher 3, both of which are 64-bit games. ", "Further adding to the confusion, PhysX doesn't HAVE to run on a GPU, so even removing GPU acceleration doesn't necessarily completely kill the feature in games.", "In order to better explain the current situation, we have to explain what PhysX was trying to be.", "PhysX was part of NVIDIA’s SDK suite for developers that attempted to make it easier to integrate higher-quality graphics effects, with the downside being that it’d run either exclusively or minimally just better on NVIDIA hardware. This is a familiar story even to today. NVIDIA also drives integration by providing engineering resources to game developers. The company used to send engineers out to different game developer campuses to help them program and integrate features in their games and while they were there, they would sometimes optimize drivers. ", "To paraphrase Wikipedia, PhysX was originally developed by NovodeX AG, which was acquired by Ageia in 2004, which was acquired by NVIDIA in 2008. ", "It originally ran on discrete PPU (or Physics Processing Unit) accelerator cards, but NVIDIA adapted the tech to run on CUDA cores. We're only concerned with NVIDIA PhysX titles here: pre-2008 games from the Ageia era already required the ", ", and we're not going far enough down the rabbit hole to test whether that still works.", "PhysX is a physics engine SDK, usually associated with destructible environments, ragdolls, fluid, fabric, interactive fog, and particles in general. NVIDIA's tagline for games it collaborated on in the heyday of PhysX was ", ", and PhysX was the poster child for that philosophy. Games like Mafia II look dramatically different with PhysX enabled; The developers even put NVIDIA’s name on the cars during the benchmarking scene, turning the NVIDIA experience into ", " the way it's meant to be played. ", "If you turn off PhysX in games like Mirror's Edge, it straight up removes objects from scenes. If you were using AMD or (GabeN forbid) Intel graphics in 2010, you were getting inferior versions of the highest-profile AAA games.", "PhysX can be run on CPUs, but historically not well, which is obviously to NVIDIA's advantage.", "David Kanter, who has appeared many times on our ", " as a technical analyst (including for our ", "), finally gets his “I told you so” moment. It took 15 years, but he can finally say it.", "As David Kanter ", ", The sole purpose of PhysX is a competitive differentiator to make Nvidia’s hardware look good and sell more GPUs. He complained that PhysX uses an exceptionally high degree of x87 code and no SSE, which is a known recipe for poor performance on any modern CPU. [...] Even the highest performance CPUs can only execute two x87 operations per cycle, meaning that performance will always remain bad, even with 2025-era CPUs. ", " to Kanter back then by stating that PhysX 2.X dates back to a time when multi-core CPUs were somewhat of a rarity. NVIDIA noted that it was still possible to implement multithreading and seemed to place the blame on developers, further stating that SSE and multi-threading support would be improved. ", " with the SSE2 option to improve performances in CPU modes was released a month after Kanter's post, so he can claim accomplishment there, and PhysX 3.0 was ", " with effective multithreading.", "Our understanding is that David Kanter’s post back then created a firestorm within NVIDIA back in that time.", "All of that puts the 32-bit games from that era between a rock and a hard place, since these are the games that are now losing GPU acceleration AND run like shit even on modern CPUs. ", "We've seen games as late as 2014 (Borderlands: The Pre-Sequel) that appear to use PhysX 2.X. In contrast, some more modern post-2.X games like The Witcher 3 ", ", instead ", ".", "If PhysX really did prioritize CPUs starting with 3.0, it would explain why NVIDIA suddenly lost interest. ", "With the release of 3.0, ", ", which helps explain why The Witcher 3 with its PhysX clothing isn't GPU accelerated (although ", "). ", "The last time we thought about PhysX was with ", " from ", ", most notable in our minds for being completely broken in Fallout 4 ", ". There are still engineers toiling away within the NVIDIA Omniverse framework, though, with the most recent PhysX release at time of writing being ", ".", "We agree with Kanter’s analysis of the time and see many parallels to today. It’s not wholly bad to advance graphics in step with developers if you’re the hardware vendor, it’s just that lock-in that becomes problematic. We sort of saw this with Intel’s first version of APO, where the feature only worked on CPUs Intel wanted to sell, but not CPUs that could truly benefit from it.", "We selected five 32-bit games for testing: Batman: Arkham City, Borderlands 2, Mafia II, Metro: Last Light, and Mirror's Edge. We rejected Assassin's Creed IV Black Flag because it has an FPS cap, but more importantly (as AMD owners may already know), you aren't given the option to use PhysX at all without GPU acceleration in that game. This is especially galling because the big ", " appears to have brought the PhysX version up to 3.3.0, so there's a chance it might not run completely terribly on a CPU if that were allowed.", "And that brings us to another point: Nothing in this article is news to AMD users. AMD users are used to getting shafted in these situations, but may feel vindication knowing that owners of $2,000 GPUs can’t properly play games from 15 years ago.", "Judging by the admittedly not-very-scientific method of opening the PhysX .DLLs and doing a Ctrl+F search for version numbers, all of the games we’re testing appear to be using PhysX 2.X. Remember, pre-3.X PhysX games are likely to run poorly without GPU acceleration. Mirror's Edge uses 2.8.0, Mafia II and Metro: Last Light use 2.8.3, and Borderlands 2 and Batman: Arkham City use 2.8.4. These last two could therefore have better CPU performance due to the added SSE2 option, depending on the developer's implementation.", "We used the latest compatible driver for each GPU, which was ", " for the 5080 and 980 and ", " (March 2018) for the 580. ", "We also used the PhysX System Software version that shipped with each of those driver packages, so 9.23.1019 for the newer cards and 9.17.0524 for the 580.", "All games were run at 1080p on our ", " GPU test bench, and GSYNC was universally disabled (as always). ReBAR was enabled where possible (the 580 doesn’t support it), and CSM was enabled by necessity for the GTX 580. Installing the 980 as a secondary GPU pulled 8 lanes from the primary PCIe slot, so all 5080+980 results were run in x8/x8 mode.", "The NVIDIA control panel was used to manually assign PhysX processing to each device, and we confirmed that PhysX processing with the 5080 was always performed on the CPU regardless of assignment ", ". 64-bit PhysX games should run normally with GPU acceleration on 50 series, but that's not what we're testing. We also didn't test the 980 with CPU PhysX; it was tempting, but outside of our scope.", "Comparing PhysX performance is a little tricky because performance depends on the scene. Mirror's Edge runs fine on 50 series cards until broken glass shows up, for example. The benchmarks we've selected here are worst-case scenarios that feature heavy PhysX, since that's what we're testing. ", "Mafia II is up first, mostly because the canned benchmark scene starts with the explosion of two cars plated with “NVIDIA” after they’re shot to pieces. ", "Mafia II has pros and cons as a test candidate. It was a flagship PhysX title with prominent effects, but on Steam the original version is now only available as a bundle with the 2020 remaster, which makes it less likely that players will revisit the original. ", "Mafia II really went in with NVIDIA at the time. The game uses ", ", which included modular PhysX components like clothing and particles. ", " when the APEX PhysX setting is at Medium or High, the game will utilize both your CPU and a suitable NVIDIA GPU and clothing effects will always run on the CPU unless you have a second PhysX-capable NVIDIA GPU dedicated solely to PhysX and APEX Clothing effects [...] are the most strenuous aspect of the game. That could mean that PhysX on the CPU has a chance here. We maxed out the settings and set APEX PhysX to High when enabled.", "The APEX Clothing effects are obvious if you're looking for them, but really this benchmark is a showcase for rubble: chunks of concrete and glass being blown a part, and wood scattered across the scene with PhysX on, and there's no replacement for them with PhysX off: they just disappear. This is another game where the real experience requires PhysX.", "Here’s the chart. It’s insane.", "With PhysX on, the RTX 5080 is the worst performer in the chart. That’s right: Over $1,000 to get performance worse than the GTX 580.", "Even more insulting than the chart, Mafia II's benchmark concludes with a graded result, and the 5080 got a D. It told us, The performance is not optimal. Please adjust your system settings and run the test again. This is coming from a game so old that it thinks Windows 11 is Windows 7. It averaged 30.3 FPS with wild variation between individual benchmark passes, showing behavior nearly identical to the GTX 580 when PhysX processing was assigned to the CPU with that card, including the variation between passes. With PhysX processing done on the GPU, the GTX 580 is 85% ahead of the 5080, with improved lows as well. Just to reiterate: This card is 15 years old and it is outperforming the RTX 5080. ", "On the 580, GPU PhysX is 81% ahead of CPU PhysX (at 56 to 31 FPS), and CPU PhysX clearly sucks in general. So far that lines up with our theory about 2.8.4 onwards being more CPU-favorable, since Mafia II appears to be on 2.8.3.", "Turning PhysX off gives the 5080 a 1,267% uplift to 414 FPS, so it may be worth taking that route if you're stuck with a low-performing 50 series card and can’t afford to upgrade to a GTX 580 anytime soon. Of course, if you can upgrade from a 5080 to a GTX 980, there’s room for a 198% improvement.", "Alternatively, traveling back to 2006 and adding in a dedicated PhysX accelerator paired with the 5080 (a GTX 980 as the accelerator, in this case) gave a respectable 441% uplift to 164 FPS average. 0.1% lows were at 60 FPS and made it the best balance of performance and visuals on this chart. NVIDIA has finally achieved what it always wanted: You now need a dedicated accelerator GPU for physics processing, it just took them 15 years to do it.", "2013’s Metro: Last Light is technically the most recent release on this list, although it's still a 32-bit application—or, as NVIDIA ", ", thanks to a highly efficient streaming system Last Light’s world uses less than 4GB of memory. ", "Advanced PhysX is an on-or-off toggle for all PhysX effects, which NVIDIA categorized as Debris & Destruction, Explosive Enhancements, Fog Volumes, and Cloth. ", "We've spent many, many hours benchmarking Metro: Last Light, so for old times' sake we used our old VHH graphics preset: Very High quality, AF 4X texture filtering, low motion blur, no SSAA, and high tesselation. This was one of the benchmarks that built GN in the early days.", "Last Light includes an unusually user-friendly standalone benchmark that lasts three minutes without loading screens, which is why we used it so frequently back in the day. Initially, there's not a dramatic difference with PhysX on versus off until about two minutes in, when explosions and gunfire start to blast chunks of concrete across the scene. Visually, the developers did a fairly good job of making up for the lack of PhysX when the option is disabled (at least in this scene). PhysX helps, but disabling it won't ruin the game. On a GTX 980, it looks great. It’s also not bad on a GTX 580. The 5080 is a different story. It’s bad.", "In all tests with the 5080 (including the 5080+980 combined test), the animation is bugged out for the train at the beginning of the scene as it comes to a stop.", "As we can see on this frametime plot, things are overall OK until the end. Performance ruins the experience and completely tanks on the 5080 and 9800X3D (read ", ") as soon as the PhysX effects kick in. This makes it unplayable. If you watch ", ", you can see that the sharp spike at the end of this plot makes up a full third of the benchmark chronologically, with framerates dropping down below 10 FPS for the last minute straight. It doesn’t look that way on the chart because of how the frame time chart plots, but this is a significant portion of the test time.", "Note that we're logging the entire benchmark run here, so these bar chart results aren't comparable to our ancient GPU charts. The early non-PhysX part of the bench helped the 5080 to score relatively high in terms of average framerate, but the exceptionally poor 1% and 0.1% lows are due to the performance completely falling apart as soon as explosions and gunfire start up. It is totally unplayable, which is unfortunate, because NVIDIA said PhysX is the way it’s meant to be played.", "Even the GTX 580 (with GPU acceleration) coped with this section of the bench better, as indicated by its superior 22.3 FPS 1% and 19.2 FPS 0.1% lows. Watching the benchmark in action makes it clear that the 5080 completely failed this test.", "The best playable framerate scored with PhysX was with the 5080 and 980 working together, paying homage to Ageia as it was meant to be. The two averaged 252 FPS with much more reasonable lows. Disabling PhysX on the 5080 vastly improved performance as usual, but that's not a reasonable option in this game. Although this one copes better than Mafia II, it does still totally change the experience. AMD players have lived with this reality for over a decade, but now NVIDIA’s own customers -- for those who play older games -- get to experience vendor lock-out.", "Out of curiosity, we also ran a HWiNFO log during a pass of the Last Light benchmark with the paired 5080 and 980. For the 5080, core load and HWiNFO's D3D Usage metric had a near 1:1 correlation, and for the 980, core load and the Compute_0 Usage metric had a similar correlation. Plotting those two against each other reveals the point at which the PhysX effects kicks in, with the 5080's usage dropping over the course of the benchmark as the workload bottlenecks elsewhere, while the 980's usage rises at the same time. The 5080's bus load was maxed out during the whole bench run, which makes some sense given the reduction of PCIe lanes.", "Mirror's Edge is the oldest game on our list. There aren't many graphics options, and PhysX is a simple on-or-off toggle. But the graphics load in Mirror’s Edge was absolutely brutal for its time, with glass breaking in particular causing major problems for hardware that couldn’t handle it. Natively, the game is capped at 62 FPS. We were forced to edit the config file to uncap the framerate for testing, which would reportedly lead to a softlock later in the game. This is another game where just turn PhysX off is a potential argument, even though we don't agree with it. We'd argue that the PhysX version of the game is superior, with lots of broken glass, fog, and fabric that's frequently completely missing with the setting off, but the PC version with added PhysX was only released a couple months after the original console launch.", "Here’s the chart.", "The built-in Mirror's Edge flyby bench was inadequate, so we selected a simple bench path that includes breaking glass, which seems to be the major trigger for poor performance in this title. The 580 outperformed the RTX 5080 when GPU-accelerated PhysX ran on the 580 to the 5080’s CPU PhysX. Although the average framerate was roughly tied, the lows on the 5080 FE indicate huge problems with frametime pacing that ruin the experience. Just like Mafia II, the run-to-run variance was extremely high with CPU PhysX on both the 5080 and 580.", "The solo GTX 980 beat the 5080 by 36%, which isn’t the way those numbers are supposed to go. The 5080 + 980 pairing beat the solo 5080 by 276% with significantly improved lows and the experience is a lot better. The retired press from the PhysX era can all finally say, “I told you so.” Of the charted results, the paired cards scored the best. The 5080 with PhysX disabled showed 475% uplift, but that's at the cost of removing PhysX items from the scenery, and even with PhysX off, the 5080's lows were weak.", "As with Mafia II, GPU-accelerated PhysX performed significantly better on the 580 than CPU PhysX, another possible indication of kneecapped CPU performance in the older PhysX versions.", "Borderlands 2 is up next.", "We've confirmed that the Low setting for PhysX in Borderlands 2 ", ", so we're labeling that setting as PhysX Off on the chart. PhysX effects include debris, cloth, particles, and Smoothed-Particle Hydrodynamics (SPH) fluid. We maxed out the settings and set PhysX to High when enabled. Borderlands 2 appears to grey out the PhysX option when no compatible card is detected, but this doesn't actually affect the setting, it just stops you from adjusting it without manually editing the config file. Great job, developers.", "Borderlands 2 contains a built-in PhysX test scene that's accessible with some light modding. This offers a good overview of how the game copes with a lack of PhysX: some liquid and cloth is replaced with flat textures, some completely disappears, and sparks and rubble are completely eliminated. As with the other titles we've tested, just turn PhysX off isn't acceptable advice: it's a huge part of the game's visuals and it’s what NVIDIA and this game used in its marketing. AMD users of the era can, once again, finally feel heard and vindicated.", "Here’s the chart.", "The 5080 avoided landing at the absolute bottom of the chart here, but this is a more CPU-friendly PhysX 2.8.4 title, as we can see from the fact that CPU PhysX on the 580 scores higher than GPU acceleration on the same card. Still, the 980 with GPU acceleration outperformed the 5080 by 7% -- and we even used a 5080 with ", ". The 5080 plus 980 combination failed to launch at all in this title and isn't included on this chart.", "Turning PhysX off gained 447% performance for the 5080 with an average of 518 FPS, but again, that's not an option anyone should recommend. You should be able to play a game from 13 years ago on a 5080 without disabling core features.", "Batman is up next.", "Other Arkham games would have worked, but we picked Arkham City since it's a little newer than Asylum. In Arkham City, ", " newspapers, flags, ropes, fog, sparks, glass, and general destruction. We maxed out the settings with PhysX set to High when enabled. When we tried this with our 5080, the game noted that our performance would be reduced; it suggested installing a nice GTX 570 instead with a GTX 460 as a dedicated PhysX card, which it accurately says would be an upgrade from our 5080. And you could do just that: You could go buy a used, older card if you’re an enthusiast of these games but want 50-series hardware.", "The game has a built-in benchmark that features heavy use of PhysX in several scenes, and we logged performance for the entire duration across all of them. Unfortunately, the scenes are relatively short and have black loading screens between, which can artificially inflate framerates. Examining our frametime plots showed us that the black screens caused frametime spikes rather than dips, but these were relatively short. For a more serious review -- not that a benchmark using a GTX 980 and RTX 5080 in the same system to test a 14-year-old game isn’t serious -- we'd never log across loading screens like this. ", "The benchmark makes it very clear that PhysX is necessary to see the game as it was intended to be seen, especially the segment where display cases break and shower the floor with glass that's completely absent without PhysX.", "There was serious stuttering on all GPUs other than the GTX 580. That could either be because the framerates are far above what the developers planned for, or because the 580 used a different driver than the rest. ", "The 5080 is off to a promising start here at 152 FPS average, giving it a 73% advantage over the GTX 980's GPU accelerated result. However, we can also see that going from PhysX on to PhysX off with the 5080 resulted in a 248% performance boost up to 529 FPS, while the same change on the 980 only increased performance by 59% up to 140 FPS. That's because the 980 is processing PhysX onboard, while the 5080 necessitates running it on our 9800X3D instead, which is a huge bottleneck.", "The 580 results are also interesting, with the PhysX CPU result actually 12% ahead of the PhysX GPU result. As we mentioned, this is a PhysX 2.8.4 title that may make use of the more CPU-friendly SSE2 instruction set, so it makes some sense that the CPU performance isn't completely abysmal.", "The Arkham City graphics menu recommends running a secondary card as a dedicated PhysX processor, which is exactly what we did with our 5080 + 980 test. Ignoring the stuttering issues, this was the best result on the chart, allowing us to enable PhysX effects while averaging 215 FPS. It shouldn’t be a surprise that, of cards dating from 2025 to 2010, the 2025 card is the best -- but it is, and only when paired with the 2014 card. That's a 41% uplift gained by adding in an 11 year old graphics card. In terms of frametime consistency, the winner is the 580.", "It's not the biggest deal in the world that a list of games from 12-15 years ago, several of which have been remade or otherwise re-released, are now more difficult to run on PC. That’s not the concern here.", "The broader issue is that NVIDIA has a habit of trying to come up with exclusive graphics tech for games. The exclusive part is key. For example, RTX-specific ray tracing features, DLSS, MFG, 3D Vision, Ansel, TXAA, WaveWorks, MFAA, DLAA, HBAO+, Reflex, and HairWorks.", "You get the point. This drags the rest of the industry along in its wake, and then when they abandon the tech down the line, the customers are left holding the bag. That's NVIDIA's prerogative as the eternal market leader, but it doesn't make it feel any better for us suckers with 3D Vision monitors and glasses in our attics. And we actually liked 3D Vision.", "But it’s interesting: NVIDIA is making decisions on graphics, which isn’t all that controversial. It’s the implementation that’s problematic. It isn’t necessarily an anti-trust issue to decide to use its power and development resources to force improvements to graphics or to make game development easier in a way that benefits the technology provider that’s in that position; however, it can become one depending on how NVIDIA decides to execute on that vision, and that needs to be carefully monitored if it maintains its 90/10 split in the market.", "The bigger problem today is just that this move came as an unexpected (to us) side effect of the removal of 32-bit CUDA support in new cards, which appears to have blindsided everyone and could have other downstream effects beyond PhysX. For example, ", " that ", " and ", " compute performance was unexpectedly low in benchmarks due to OpenCL 32-bit support breaking without warning.", "This is also an issue for game preservation in ways that feel related to Stop Killing Games, but for different reasons.", "It's very likely that some of these games could be tweaked to run better with CPU PhysX by swapping .DLLs or otherwise modding them, but we can't take it for granted that some genius on a forum will always be there to clean things up, and that's not the point. You could spend thousands of dollars on a brand-new NVIDIA GPU, and in the best-case scenario you'll still have to do extra work to get these games playable with NVIDIA's own abandoned feature.", "We don't have a decisive call to action here. In the short term, we think NVIDIA could probably fix PhysX; there are probably plenty of reasons that it would be difficult, but we're willing to bet that with a $3 trillion market cap, they can figure out a way to get Borderlands 2 running at a stable framerate on a 50-series GPU. ", "In the long term, this feels like a grim omen for other NVIDIA-specific features that are integrated into games (especially if it’s core to how that game feels), or even newer PhysX games—we seriously doubt that Fallout 4 is the only half-assed broken implementation of 64-bit PhysX. ", "Fifteen years from now, who knows whether features like Reflex and MFG and DLSS and even ray tracing (as it is done today) will be compatible with the current hardware. Ray tracing in particular seems like it’ll go through a paradigm shift at some point just because it’s so new."]},
{"title": " Tearing Down Sapphire's RX 9070 XT Pulse: Thermals, Fan Response, & Noise", "paragraph": ["Tearing Down Sapphire's RX 9070 XT Pulse: Thermals, Fan Response, & Noise", "Last Updated: ", "The Highlights", "Today we’re tearing down Sapphire's 9070 XT Pulse because we wanted to see how it’s assembled and to look at its build quality.", "The 9070 XT Pulse uses a 3-fan solution and we used it in ", ".", "Steve Burke", "Vitalii Makhnovets", "Jimmy Thang", "Taking an initial look at the card, we noticed that the fin stack was bent. We’re going to examine to see if it’s properly secured or if there is a manufacturing issue. At first glance, we don’t think it should affect performance too much, but maybe acoustics. ", "The back of the card has a large flow-through area, which is good, and it’s coupled with a single fan. This is different from NVIDIA’s solution on its FE cards where it puts the PCB in the center of the card and pushes air through the sides.  ", "For comparison, the ", " card has a smaller flow-through area with its shorter card design. ", "The fans on the 9070 XT Pulse are different sizes and the 2 fans on the outside spin in the opposite direction from the middle one. ", "The rear side of the card has a perforated PCIe slot that is supposed to let some air escape but if you look closely inside, you’ll notice basically what is a wall for the fin stack and that’s because the fins are oriented vertically. This means the air is mostly going to come out the top of the card and not the bottom. ", "Some air will also get pulled in through the front of the card and pushed out the back. This is all pretty standard thus far.  ", "Sapphire’s RX 9070 XT is a 3-slot card with a full 3-slot PCIe bracket. This is great as it allows the card to be a bit more rigid. ", "The card doesn’t have any dual VBIOS or anything fancy and it doesn’t have any physical switches, but it does run two 8-pins.", "In our ", " of the card, we didn’t end up running our usual frequency, thermal, and acoustic tests because we were so focused on the GPU, the gaming performance, and power consumption. So we’re going to include some of that data in this story, but first, let’s get into the tear down. ", "Prepping to open up the card, we see a bunch of Phillips 1 screws on the backplate. ", "On the back of the card, there are 4 screws for the retention mechanism, which holds the cooler to the GPU. We noticed that one of the screws had a tamper seal, which simply had the letter “P” on it. We’re not exactly sure what that’s supposed to indicate, maybe Pulse? ", "The leaf spring uses captive screws. ", "Before opening up the card, we’ve got to remove some last few screws on the rear of the card. ", "Opening up the card and taking the frame off, we can see that there are screws holding the fans in place, which can be removed for easy repairability. ", "The fan cable is accessible without needing to take the rest of the heat sink off, which is awesome to see. ", "Moving forward, we can now remove the heat sink off the card, which exposes the GPU’s long die. ", "The underside of the heat sink has a plate for the memory contact coupled with a standard copper coldplate. ", "On the PCB, there are a couple more screws securing the PCB to the backplate. In total, there were 16 screws we had to remove, which isn’t bad. Getting access to just the fans, however, requires removing 10 screws. ", "Taking a look at pressure distribution, we noticed some uneven pressure on one side of the GPU die. Looking at the copper coldplate, we can see that the contact here was not that good and the pressure was different from the top to the bottom. With the GPU, it’s really important that the whole die has contact so components don’t die. Sapphire’s implementation of thermal paste isn’t going to kill anything, but it is bad contact.  ", "Taking a look back at the PCB and examining the thermal pads, they look pretty standard. Eyeballing it, they look around 1mm thick. One of the thermal pads has a small circular indentation on it, which is likely just a small hand-assembled mistake. ", "Looking back at the cold plate, we can see that it directly contacts some of the heat pipes, which goes underneath the memory. This helps with cooling.   ", "Directly on the heat sink itself, we can see additional thermal pads, which are for the MOSFETs. Examining the heat sink, we can see that it’s very slightly bowing down. This shouldn’t affect thermal performance. ", "On the back of the PCB, there are no thermal pads, which means they are not making use of the metal backplate the card has. That’s always a shame to see. This might amount to a couple of degrees difference in most cases, which can be common in lower-end models. ", "Overall, the card has very simple construction with a standard PCB and standard execution. It’s got five 6-millimeter heat pipes, which is very typical. The card uses a tried and true design that isn’t innovative.   ", "We have a ", " of the Yeston RX 9070 XT Sakura Sugar Atlantis OC, aka “Waifu Edition,” coming up soon with fully detailed charts. Those include this Sapphire card and the Atlantis, so we’ll keep these shorter today.", "Starting first with the RPM-to-thermal response, we get this chart. The Sapphire RX 9070 XT Pulse’s GPU temperature hit about 56 degrees Celsius for average temperature in a controlled ambient of 21 C. That’s not bad. The hotspot ran at 81 degrees, which is also actually not bad in an absolute sense. Having nearly a 30-degree gap between them isn’t great, but we’re beginning to learn that this is unfortunately common for this generation so far. In Sapphire’s case, the reduced mounting pressure at the top of the die doesn’t appear to be making a measurable difference in the hotspot-to-core delta because the other two cards we’ve tested also exhibited this behavior but with more even pressure on the die. It just seems to be a behavior this generation.", "Either way, it’s not in throttling territory and is still OK, but the memory temperature is a problem: It’s running at 90 degrees Celsius. The reason for this isn’t anything beyond Sapphire’s cooler design being relatively simple and its fan curve being relaxed as it is becomes a problem.", "This chart shows the fan RPM as plotted against these temperature values. Sapphire and AMD really need to get this fan situation under control. There’s no reason for it to behave this erratically. VBIOS typically controls fan behavior via temperature targets so this is within Sapphire's control, but AMD could also do more here. The Pulse’s fan blasts to 1,560 RPM and holds, drops to 1,400 and holds, then drops to 1,300 for 5 seconds, then climbs to 1,390 RPM for about 30-40 seconds, then suddenly drops precipitously to 1,100 RPM, then spikes to 1,258, then drops to 1,000 RPM, then climbs to 1,170, then drops to 1,130 and holds for a few minutes. It eventually fluctuates a few more times.", "This is erratic behavior and we’ve rarely seen fans behave like this in a fixed, ongoing, unchanging workload. Unfortunately, this is extremely noticeable as an end user, because you’ll hear an irregular and annoying ramp/de-ramp rapidly cycling within a 2-3 minute period. It’d be better if it went to a higher speed and held. But Sapphire is running its fans too slow anyway, as shown by the 90-degree memory thermals. Because it’s following the relatively low 56-degree GPU temperature for the fan speed, the VBIOS isn’t able to tell the fans to spin up fast enough to deal with the memory temperature. This was actually a problem on older liquid-cooled cards a long time ago where you’d have MOSFETs and memory burnout, because the core was running cool enough, the fans weren’t ramping adequately. This resulted in hot memory and VRM, but the card didn’t “know” that because it was following the core temperature. This needs to be worked on.", "Tested in our ", ", here’s a look at the acoustics when the card was at steady state (once the fan actually settled). Because the fans were hardly spinning at the end of the test, allowing the memory to hit 90 degrees, the card was extremely quiet. It’s a little too close to our noise floor (before we upgrade our microphone, anyway), but we measured it at around 16.5 dBA at 1 meter. The 5090 FE is plotted for a comparison here. This card also hit 90 degrees on the memory, but is running a 575W heat load on the core instead of 304W. It’s also running louder.", "The Pulse is quiet, but it’s too quiet. Sapphire has a ton of room to boost the noise without it becoming noticeable. And remember, you can always manually tune it back down if you’d rather incinerate your memory in a case. 90 becomes 95 inside a case pretty fast.", "Finally, here’s the GPU core frequency plot. This shows the GPU hitting about 2,997 MHz at first launch of the workload, then settling around 2,916 MHz at steady state. ", "” spec. It’s not at that speed once the workload is actually settled, but on a technicality, it did hit or exceed 2970 MHz for about 10 seconds.", "We’re happy with how easy Sapphire's RX 9070 XT Pulse was to disassemble and the access to the fans is great. There were some QC issues but nothing that would prompt us to return the card and some people might not even notice those issues.  ", "As for the quality outside of the tear-down, we already showed gaming performance in ", " of the ", " and commented on all of that in a ", ". For this model specifically, Sapphire needs to work on its VBIOS tuning for the fan RPM to better deal with ramping memory thermals despite otherwise OK GPU core thermals. It has plenty of room to ramp the fans higher and most users wouldn’t notice that bump over the speed of their case and CPU fans.", "We like the assembly approach and the ease with which you can get into the cooler, especially for replacing fans without disturbing the paste. This was done well by Sapphire. The assembly overall was pretty good. There were downsides, which included some QC stuff with the fin stacks being bent, but it doesn’t impact performance. The good news is that the fan speed can be adjusted either manually by users or after sales by Sapphire with a VBIOS push…hopefully."]},
{"title": " Wild Design: Yeston RX 9070 XT Waifu Sakura Sugar Atlantis GPU Review & Benchmarks", "paragraph": ["Wild Design: Yeston RX 9070 XT Waifu Sakura Sugar Atlantis GPU Review & Benchmarks", "Last Updated: ", "The Highlights", "Today we’re reviewing the ", ". The card has a VBIOS switch, an LED switch, 3 fans, and it is supposed to smell like the ocean. The company even shows it getting dunked in the ocean in their ", ".", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "The bad news is that it’s $850 to $900, depending when you find it in stock. The good news is that the ", " and none of this matters anyways. This is still somehow cheaper than some of the other flagship ", " cards out there.", "Yeston is the China-based video card manufacturer that we first found out about when we reviewed the ", ", and we never knew it’d turn into a half-decade-long series of reviewing their different approach to GPUs. ", "In the time since, we also looked at ", ". We also tested ", ", which we called “Waifu edition.” We later looked at their ", " with blue, purple, and white coloring, and most recently, we tested ", ", which actually had a less fan-service-y thematic and blended some neon Cyberpunk-like styling in a way that makes it clear the big video card partners can absolutely do more - and it doesn’t have to just be pink and purple, either.", "Surprisingly, Yeston has managed to make overall effective designs despite clearly investing the majority of its focus on looks or theming. The old RX 580 Cute Pet and more recent Sakura cards, whether or not they’re your specific style, have shown that there’s a ton of room for more uniquely visualized video cards without going pure black-and-RGB. They’ve also done well overall with thermal design.", "But Yeston has gone overboard: They have a whole universe now.", "In addition to having ", " and lore written into its manual for its characters in an almost comic book like style, Yeston has just recently ", " its new cast of future back plate art characters. ", "There’s ", ", from a Cyberpunk dystopia. His name is “Game Ace.” ", "But we assume the GPU will be widely rebranded as the “Yeston Husbandu” edition. They’ll have anime GPUs for everyone.", "Let’s get into the review.", "The new RX 9070 XT Atlantis we’re reviewing, despite being called “Atlantis,” isn’t water-cooled. It uses 3 fans and a modestly sized finstack.", "Yeston’s ", " says it employs “chameleon effect paint” that “unfolds resplendent and ever-shifting visual feats for gamers under diverse lighting scenarios,” which, credit to them, is like the inverse of PowerColor’s prologue about hellstones and dark obelisks.", "The Yeston card has a dual-color shroud with a fade from purple to pink and has color-matching everywhere. They’ve done a good job with the color theory on this card. The PCB is white to match the white back plate, showing good attention to detail, as is the PCIe bracket. The stickers on the fans even have tiny dots of glitter inside of them to dazzle and impress all your bros when they check out your PC for LAN parties. The back plate has, uh-- well…", "...This. We suppose it’s not surprising what we’d get with Yeston involved so that hasn’t changed. ", "Yeston’s 9070 XT edition Waifu has a backstory once again, this time apparently involving... playing guitar and singing, or something. We’re not really sure. ", "But we’re going to take credit for popularizing the Yeston cards as the “", "” cards back before we even knew the name of their company.", "What we didn’t know was that the company itself would then follow our lead and the immense popularity behind that name and begin ", " -- but they did.", "And Yeston, if you’re reading this, we just want you to know that we didn’t mean it. That’s not meant to be a real name. It was a joke. ", "Anyway, the important part is that the marketing says it “comes with an ocean-themed fragrance module, which ensures a long-lasting pleasant scent.”", "Well, we’ll see about that. We’re going to tear this card down now and look for the alleged “fragrance module.” It definitely has been blasted with perfume, but up until now, we haven’t seen that integrated in a “modular” way.", "The back of the card has a large flow-through area. ", "The fin stack is vertically-oriented, which means the air should go out the top and bottom of the card, which is pretty typical. One downside is that the card’s shroud is unfortunately covering maybe about 15% of the finned area. This means more area could have come out from the card if it weren’t blocked by a big piece of plastic. That is unfortunate and will affect thermal results. ", "The card has three PCIe power connectors at the top. On the back, there are 2 holes with switches inside them. One of them is a BIOS switch and the other is an LED switch toggle.", "Removing the back plate is pretty straightforward with a handful of screws to unscrew. There’s also 4 screws which secure the heat sink to the PCB. ", "The leaf spring is a standard design. It also has isolating pads on it and captive screws in the corner. ", "Removing the cooler from the card, the contact patch looks to use a phase-change pad. The memory uses 3 pads, which are on the nickel-plated copper cold plate. This means the GPU and memory use the same cold plate. ", "The card uses 7 heat pipes, which go through the entirety of the card. ", "The card also employs thermal pads for VRM and MOSFET cooling in the image above. ", "There’s also a little plate near the center here, which looks like it was designed for stabilization.", "The card has as thick of a fin area as it can get, particularly for the flow-through area.", "Looking at the PCB, the company has really good attention to detail on the white board, which matches the white back plate, and compliments the light-colored shroud on the front well. The color matching is cool to see.   ", "In terms of the design of the PCB, the company has got room for extra phases.", "Moving forward with the tear down, we removed some screws to remove the PCB from its back plate. Doing so exposes some very beige thermal pads on the back plate, which measure roughly 2-2.5 millimeters. It’s good that Yeston is taking advantage of the metal on the back plate with the thermal pads here, as it helps cool down the memory modules. ", "To release the shroud from the fin stack, we had to remove 4 screws. One of the screws featured a cut-out to accommodate a screw driver, which is a nice design. ", "The shroud has a pretty large PCB for the LEDs. We also noticed a foil inside, which we presume is to help reflect some of that light to try and get things looking brighter. Everything is routed through one cable. Each of the 3 fans is mounted with 4 screws, which is pretty standard. ", "This shroud area is where we also found the scent module. We asked for opinions of the scent around the office and got several opinions which ranged from it smelling like: a car freshener, a free sample kiosk at a mall, fabric softener, and a Glade plugin. ", "We don't know what the scent module is made of. It feels like it’s made of plastic and we’re not sure how Yeston is implementing its smell. ", "This plot of temperature at equilibrium compares the Yeston card against the ", " that we already ", " and recently did a", " on. We’ll keep adding to this.", "So far, the two cards are hitting the same GPU edge temperature at 56 degrees Celsius when in a controlled ambient of +/- 1* C from 21 C. The coolers achieve the same performance on the GPU core. Hot spot temperature is relatively high on both, but not yet untenable on the Yeston card: It’s at 85 degrees when left to run at its auto settings, or 84 with our noise-normalized target that we’re beginning to collect data for. We haven’t run the Pulse XT at this target yet.", "The memory temperature is the real differentiator: The Yeston card held an 82-degree memory temperature result, which is acceptable. The Sapphire Pulse XT is running too quietly for its own good here, hitting 90 degrees Celsius on memory in open air. In a hotter case, this will become a problem. We think the Pulse should ramp its fan speeds more. They’re the same for core, but the Yeston card has a significant memory advantage.", "Both cards are at the same power level, so noise remains a key differentiator.", "As for the Silent VBIOS on the Yeston card, its fan speed was identical and the test results were identical. We could not find a real change between the two VBIOS options. ", "This plot shows thermals over time to better understand the fan ramp and hysteresis.", "The Yeston GPU ramped to about 50 degrees initially, kicking on the fan to 1,450 RPM and holding temporarily. This briefly stalled the temperature climb, but then the temperature continued ramping -- which is expected behavior until it hits steady state -- and weirdly, fan speed dropped massively after this. It fell from 1,450 RPM to around 1,100-1,160 RPM. We’ve seen this behavior on AMD cards in the past. This behavior is controlled mostly by VBIOS.", "Plotting the Sapphire GPU, it oddly exhibited similar, but more exaggerated behavior: The Pulse XT initially aggressively ramped its fans to 1,560 RPM, then dropped them to 1,400, then dipped to 1,330, then back up to 1,400, then down to 1,130 RPM, then back up to 1,250 RPM, then down to settle at 1,096 RPM until it settled even lower at the end of the test at steady state. This erratic fan behavior is just plain bad: This kind of fan fluctuation is noticeable to a user. You’re more likely to notice a change in noise than a constant, louder noise, and this amount of change over a span of 10 minutes would be noticeable.", "We’re not sure what it is in VBIOS or AMD’s drivers that would be causing this behavior, but it should be flattened and corrected.", "This next plot was taken in our ", ", which is useful not only for hiding from ", " and ", ", but also for benchmarking components. Our chamber was a major investment in our test quality and accuracy and we’ve already gotten value out of all the time savings from it.", "We’re looking at just the steady state fan speed here. Here’s the plot of the Yeston RX 9070 XT Atlantis card against the Sapphire Pulse that we ", ". Both are shown represented by their fan speeds they ran during thermal benchmarking at steady state.", "The Yeston 9070 XT has one spike at around 164 Hz, another small bump at around 400 to 515 Hz, then a gradual fall-off after that. Its frequency distribution is relatively typical. For reference, the ", " -- which is louder -- is also plotted. You can see that the 9070 XT Atlantis follows the general trend of the ", " (read ", "), with the exception of the 5090’s spike around 2,000 Hz and 3,200 Hz.", "The 9070 XT Pulse from Sapphire ran quieter than the Yeston 9070 XT Atlantis overall, which is also reflected in this incredibly flat frequency spectrum plot. We’re too close to the noise floor for good readings here. Once we buy our new microphone equipment, we’ll be able to drop the floor closer to 6 dBA. For now, the Pulse’s VBIOS temperature target results in a low noise level.", "We’ll quickly go over some gaming charts. There won’t be much meaningful change here, but that’s expected. Most of the benefit from these partner models is in so-called “quality of life” features, such as better cooling, better acoustics, extra VBIOS or LED switches, looks, and overclocking power headroom (but the silicon lottery itself is mostly the same between cards).", "For that reason, we’ll keep it short. We’ve removed all cards from these charts except the 9070 series. For comparisons against NVIDIA and other AMD cards, check our ", " or ", ".", "In Resident Evil 4 at 1440p, the 9070 XT Atlantis outperformed the 9070 XT Pulse on a pure technicality: We’re seeing about a 1 FPS advantage for the Yeston card.", "At 4K, we saw a consistent result: It’s up at 103.6 FPS AVG against 102.9. That is well within variance and margin of error. You could get this kind of swing basically by restarting the test enough times. If you can notice this kind of improvement, you should probably sign up for a reflex research facility or something.", "It’s at least consistent: In Starfield at 4K, we saw the same behavior. The Yeston card is marginally faster in framerate. This isn’t a meaningful change, but it is becoming a pattern. The difference in lows is not meaningful. These are identical results.", "Final Fantasy at 4K has the two 9070 XTs we’ve tested as nearly perfectly identical. But of course, the most adept gamers among you will identify the 0.1 FPS AVG difference.", "In Cyberpunk 2077: Phantom Liberty at 1080p with RT Medium, we measured the Atlantis card as 0.3 FPS AVG higher than the Pulse XT. There’s no meaningful difference here.", "We’ll call it there since this is clearly all the same.", "Once again, Yeston has managed to make something that has some actual color theory to it, showing actual attempts at design. If its aesthetics aren’t your thing, we get it, but the company is doing things that are different. It’s taking risks and that’s great to see.", "While Yeston looks like it uses meme/anime archetypes, they’re still designing things, that, in many cases, do pretty well. This particular card, however, does have middling thermal and acoustic performance. It is competitive with the ", " and it manages its fan curve and RPM response much better. In addition, the Yeston card’s thermals are better. ", "In terms of overall performance, it’s fine. It achieves what it needs to achieve. If you like how it looks and are willing to pay whatever its street value is, then it’s fine as we found no major issues with it."]},
{"title": " Fake MSRP", "paragraph": ["Fake MSRP", "Last Updated: ", "The Highlights", "In a previous video, we stated, “", ".”", "It turns out that AMD got close.", "Launch day came and went for small, scrappy savior of gaming AMD, pulling itself up from its $163 billion bootstraps to remind all of us that “this one is for the gamers” and that we should all be mindful of ", ". Well, we’ve been listing NVIDIA’s current ", " for the last 2 months, and now it’s time to look at AMD’s challenges.", "Steve Burke", "Jeremy Clayton", "Vitalii Makhnovets", "Tannen Williams", "Jimmy Thang", "We tracked sales and sentiment for the launch of the ", " and made the map above. In green, you can see areas of extreme customer satisfaction with AMD. Major cities in the US did pretty well. Far better than NVIDIA. ", "Now let’s look at the dissatisfied areas: ", " for AMD. And because we didn’t embark on a 5-hour round-trip road trip, we got to experience internet purchasing first-hand. We buy most of our partner models to review rather than request them these days, and that meant we got to experience the absurd reality of it all.", "At first, it seemed to go well: We thought we’d gotten multiple orders through at Newegg at 9:08 AM, 8 minutes after launch, and again at 9:28 AM Eastern, which meant we were late up to 30 minutes and still saw seemingly tons of options in stock.", "But then we received these messages from Newegg canceling our orders, and it turns out, ", ".", "When we tried to buy GPUs at MSRP from Amazon, we were met with this: ", "We did the only rational thing that well-adjusted adults would do: We spent two days obsessively gathering information about prices of GPUs for playing video games.", "Only 12 of 51 models that we catalogued across 4 retailers were at MSRP in the US. Of the remaining 39, 5 were ", " and 16 were 30-40% over MSRP, which is worse than we’ve seen in most prior GPU launches, except for the 50-series. ", "In some ways, it’s a “normal” launch: There are always models over MSRP. That’s normal. But it felt bad this time because of just how many were so far over MSRP. But the good news is that it wasn’t a ", ": More like a highly compressed cellulose arboreal composite launch...", "But Micro Center enjoyers had a different experience:", "We noticed that a Micro Center had 45% of its total inventory at MSRP.", "And that seems like a much better distribution of MSRP cards than what was experienced by those of you who live in a small place allegedly called “the rest of the world.” We're told it’s a nice place to vacation.", "Today, we’re digging through the evidence we’ve collected to better understand the ", " (read ", ") launch and put some context to the absurdity.", "We prepared this table of RX 9070 XT (read ", ") prices through a combination of data from ", " and some manual data collection. It shows the card model, retailer, original and updated price (if applicable), how much the price changed, and how much the price is elevated over the base MSRP of $600. Because of the way Amazon aggressively de-lists and removes prices, anything from Amazon is just what we came across in a spot check on the morning of launch. Pricing data may change by the time we publish due to a fluid market.", "The average price of all 9070 XT models, ignoring quantity, is $739, or $139 higher than AMD’s base $600 MSRP. With all cards included, that makes the average increase over MSRP 23% by model – with non-MSRP occupying a range from 20% over to a terribly bad 42% over, which is completely insane. Please do not spend that much more for one of these cards. Only 12 of the 51 listings we cataloged were actually at MSRP.", "s were the worst, with the Magnetic Air OC variant taking the top spots along with the PowerColor Red Devil Limited Edition at Micro Center. Expressed as an average, XFX’s 9070 XT models all combined were 29% over MSRP. The ASUS TUF cards fill in next at 33% over MSRP. ASRock generally stayed the closest to MSRP, with its cards coming to an average of 11% over MSRP. ", "Interestingly, Best Buy and B&H show price reductions across a few listings – all of which had extremely elevated initial prices. The worst was the ASUS TUF at B&H for $1,100, later reduced to $800. B&H might be able to argue these were placeholder prices since it’s only selling these GPUs via waiting list, but we can’t be certain.", "Best Buy’s situation was similar, with an initial listing price of $950 for the Gigabyte AORUS ELITE, which later dropped to $760. This may coincide with the lime-limited “deal” pricing we saw from Best Buy initially on launch morning, whose “deal” text was later removed. Our understanding is that AMD had a conversation with Best Buy after seeing this, causing the retailer to remove what appeared to insinuate that the launch price was a limited time and that it’d climb later.", "Now we’ll move on to the RX 9070 non-XTs. MSRP is supposed to be $550 for these, which we maintain is $50 too high and intentionally creates an upsell. ", "The good news is that it’s not $550. The bad news is that it’s more.", "The average price of all listings is $628, which is $78 higher than the base MSRP of $550, or an average of 14% over. 13 of the 38 cards we gathered info on were at that base MSRP – a better ratio than the XTs. The average increase over MSRP for all 9070s shown here is 14%, with the raised price models in a range from 13% at the low-end for the ", " at Micro Center, up to the Sapphire NITRO+ at a 31% increase over base price, which was also at Micro Center.", "That puts the most expensive 9070 we found at $720, which is obviously atrociously bad. Nobody should pay even close to that for one of these cards. ", "It’s actually the same price as the ASUS 9070 XT Prime OC at Newegg. At those prices, you’d be better off buying a used NVIDIA GPU on eBay at those prices.", "In fact, every single 9070 that wasn’t MSRP was actually more expensive than MSRP 9070 XTs. That’s also insane, and might be another piece of evidence pointing to AMD dropping the MSRP of both of these GPUs at the last moment.", "Average increase per board partner is a lot closer for the non-XTs by percentage, to the point that it’s not worthwhile to get into the specific numbers. ASUS was technically the worst.", "Overall, adding all the 9070 XTs and 9070s together, the average percent increase over MSRP is 19%. We don’t know whether that’s normal or not for AMD since this is the first time we’ve gathered that data for AMD, but we’ll bring up a point from our ", ". ", "The ", " – regarded as the most expensive “normal” 4090 – sold for 25% over MSRP. That’s a high-end GPU with a bunch of unnecessary, expensive bells-and-whistles from a company that largely sells its brand image. Tons of these AMD 9070 XTs (and some non-XT) are way across that percentage threshold, again including some at 42% over MSRP. That’s a bigger price hike than the Strix 4090. ", "In this case, modern midrange GPU price bloat continues, even if it’s not as high as NVIDIA’s 5070 Ti class of GPUs.", "According to this detailed product listing sheet from the Dallas Microcenter, which is the only such one we were able to find, we observed 421 out of 920 cards, or roughly 46%, were sold at MSRP. More specifically, 319 of the 705 9070 XTs and 102 out of 215 9070s were listed with MSRP. This accounts for about 45.25% of 9070 XTs and nearly 47.5% for the non-XTs.", "As seen in this chart we put together, each manufacturer listed had at least one MSRP card for both variants of the GPU. In these listings, excluding MSRP models, percent over MSRP ranged from 12.73% on the low end to 41.67% on the high end.", "It’s normal for AIB partners to charge more than baseline MSRP. They tack-on extra features, they have quality of life options like extra VBIOS, “hellstones,” apparently, and quieter cooling.", "What isn’t normal is the amount of upcharge we’re seeing this generation for both NVIDIA and AMD. Both companies’ partners have totally lost the plot, but AMD’s in particular feels bad because it marketed itself as the savior of gaming at affordable prices. ", "We dug back through decade-old reviews from our own publication, TechPowerUp, Tom’s Hardware, Anandtech, and others. We took prices from launch day of the GTX 1080 Ti and RX 5700 XT (read ", ") GPUs to compare their average price increases over baseline MSRP. Remember: There are multiple MSRPs. There’s the base price from AMD or NVIDIA, but then the MSRP for each individual model. What we’re proving is that the cost increase in partner MSRP over baseline has gotten way worse.", "Here’s the GOATed GTX 1080 Ti. We ", " a lot of these. As you remember, the 9070 XT had multiple cards at 42% over MSRP. The ", " was the only card at 42% over MSRP, technically about 43%, and that’s a specialized XOC card. Those are basically extinct today. Cards of that quality don’t exist anymore.", "The next highest is the Lightning Z, which was a competing card to the KP and was 24% over MSRP. In fact, most of the cards of that era were about 7% to 10% over MSRP, including some of the best ones. The EVGA 1080 Ti FTW3 (watch", ") and SC2 (watch ", ") were both excellent cards. The 1080 Ti Armor (watch ", ") was a basic 1080 Ti for MSRP, but could be converted into an excellent water-cooled card with its reference PCB.", "This chart is hugely different from what we just saw in the 9070 and 50-series launches. Partners have gotten out of control.", "Here’s the ", ". The 5700 XT had two prices. The first was $450, but after it ", " itself, it came down to $400 pre-launch. Using the $400 price as the reference since that was launch pricing, the uplift for the cards we found via TechPowerUp and our own prior GN reviews ranged from 3% to 20% increased over MSRP. The $480 Taichi OC+ was among the highest.", "There are models we didn’t list for each, but this cross-section gives you cards from all over each stack.", "We are confident that data supports the delta against MSRP increasing with time. That means AMD and NVIDIA share blame with the partners for setting possibly unrealistic targets. ", "We’ll come back to the fake MSRP discussion in a minute. First, it’d help to have perspective on volume and if this was a “paper launch” like NVIDIA’s.", "Micro Center can be sort of a microcosm for our inventory report: It’s just one chain and it’s hyper localized, but because we have data for its RTX 50 launch, we can more easily get a like-for-like comparison perspective on AMD’s. ", "By crawling through web posts and cross-referencing them, we were able to conclude that Micro Center had nearly 12,000 known cards in stock (excluding a few stores we couldn’t find data for). ", "For reference, this spreadsheet circulated on Reddit after users tallied the Micro Center inventories for the 50-series launch day. The Madison Heights and Sterling Heights stores are actually the same, so subtracting those 10 duplicate entry units from the ", "s and 91 units from the ", "s (read ", "), we end up with 223x RTX 5090s and 2,302 RTX 5080s for launch day. ", "Overclockers UK also posted some numbers. Gibbo from OC UK posted ", ":", "“We do have several deliveries due today and next week, so we might have more available later. We have sold around 5000 units now, warehouse is working very hard to get them all shipped out today.”", "That puts us at 12,000 units for a localized store in the US and 5,000 units for a UK-based store. Speaking with someone at AMD off-record, GN learned that AMD and its partners shipped “tens of thousands” of units to the North American market alone, with most of those being 9070 XT GPUs.", "The break-out is more interesting: We don’t have the break-out for each store of the 9070 vs. 9070 XT quantities, but of the 11,657 total tallied, we were able to identify the model of 2,528 of them. The split of these is about 22% 9070 non-XT to 78% 9070 XT. ", "We think this supports the theory that AMD doesn’t actually want to sell the RX 9070 GPUs. We think that’s a model designed to create an upsell to the 9070 XT, like a decoy product. ", "AMD did this with the 7900 XT and 7900 XTX (at $900 and $1000), with that difference just months later becoming about $200. Within a year, the difference was at times $250.", "To us, it doesn’t matter why AMD does this. We don’t care about AMD’s perspective. All we care about is the consumer perspective. And for the consumer, the reason a company might upsell them is irrelevant -- all they know is they’re getting upsold. Maybe the yields are so good on the XT that they have to fuse products off to even create a non-XT. But if that’s the argument, then they might as well drop the price for the goodwill and price accessibility since there aren’t that many anyway -- but then the 9070 wouldn’t serve what we assume is its purpose, which is to purely function as a tool to create an upsell to a 9070 XT.", "We next checked with several system integrators we know. They have a very different perspective on the success of AMD’s launch than retailers for DIY.", "The first SI we spoke to sold 50 systems with 9070 XTs and 20 systems with 9070s on launch day. That SI had just over 1,000 systems with RX 9070 and RX 9070 XT cards available for purchase. That’s about 7% of the built systems that were sold on launch day. The SI told us that this was “better than expected” as compared to AMD’s previous launches.", "For perspective, that same SI previously told us that they had 20 units of RTX 5090 GPU (read ", ") on launch day and that they sold out in about 2-4 minutes. There may be some influence from the wider market there: As users couldn’t buy retail DIY cards, they may have resorted to pre-built machines.", "Another SI told us that they sold 7 units of 100 available on launch day. Interestingly, that’s also 7% -- so that’s two very differently sized system integrators at the same sell-through of inventory. The second SI sold about 30 units of RTX 5090 systems on launch day, which was 100% of availability.", "It was interesting to gain the perspective of these companies. For the first, it was a better launch than expected -- but only in the context of AMD. For the second, the launch was viewed almost as a dud. In both situations, the average non-enthusiast “video game enjoyer” doesn’t buy AMD, at least in pre-built PCs.", "AMD has to make inroads there eventually. For it to do that, it needs unshakeable goodwill in the enthusiast DIY segment so that those people become their evangelists.", "Between the two SIs we spoke with, one received 50.5x more AMD GPUs than it received NVIDIA cards on day one, yet it made less revenue from them. The other received about 100x more since they’d only received a single 5090 initially, though they got another 20 or so on launch day, so that’d still put it at 5x more. ", "Using Micro Center only as another control, they received 4 times as many RX 9000 series cards as RTX 5000 series cards.", "By all accounts, this is not a “paper launch” in the way the RTX 5000 series was. This appears to be more normal, in that there was a good amount of supply, just not enough to satisfy initial demand. ", "So the supply wasn’t fake. Now we question whether the “MSRP” is fake.", "Since it seems that AMD panicked when it caught wind of ", ", we can continue the speculation that it never planned to sell the cards at these prices. If AMD is subsidizing partners, distributors, and retailers to hit the lower-than-expected price, then the new concern becomes whether the announced price is “temporary.”", "Found via ", ", at least three distributors have publicly stated that MSRP will only apply to the first shipment of cards.", "Swedish retailer ", " announced in a machine translated post:", "“Prices apply only to the first delivery of the respective model. We have now been told how the recommended prices, so-called MSRP prices, work for the launch of the AMD Radeon RX 9070 and RX 9070 XT. We must not say exact prices for the release, but simply explaining they will apply to a limited number of cards.”", "The company clarified (which has also been machine translated):", "“Our second delivery from PowerColor is already waiting, and we can not offer it at MSRP prices. This means that we will first sell the Reaper models at MSRP price and the stock balance will tick down as usual until the first delivery is sold out. Then, with a certain delay, the stock will be filled with new cards and we will then release the Reaper cards for order again – but then not at MSRP price.", "“If you get through an order with MSRP price even if the cards are sold out, we will of course give you that price, but we unfortunately have no opportunities to continue selling cards at MSRP price after the first deliveries are sold out.”", "Retailer ", " this in its forum post:", "“MSRP is capped quantity of a few hundred, so prices will jump once those are sold through.”", "Another UK retailer, eBuyer, reportedly cancelled pre-orders that were processed at MSRP after it sold out of the first delivery of cards. They ", ":", "“Unfortunately, we were only allocated a limited number of units at the price offered by AMD, and we won't be receiving any additional stock at this price. As you can imagine, this launch has been extremely popular, and we have now sold out at that price. As a result of this, your pre order has been cancelled, and any payments have been reversed.”", "A separate ", " claimed he checked out at £569.99 but the price increased to £664.98 when processing his payment. ", "eBuyer repeated its previous statement explaining the finite number of MSRP cards and added, “once these were sold we did have to sell these are normal cost [sic].” This would seem to indicate that it’s not simply from taxes being added after the fact.", "But AMD has responded. AMD emailed us a statement from Frank Azor, whom you may remember from a previous AMD launch where he bet customers that, unlike its competition, he’d have stock at launch. He bet $10. He lost the bet. We’re not sure if he ever paid it out. ", "Just like when AMD’s other now-former executive claimed -- we think lied -- about AMD dropping GPU prices after panicking at NVIDIA’s launch as some sort of 6D chess grand jebaiting strategy, AMD has continually used NVIDIA and riled-up a tribal mentality as a shield for its own incompetence.", "Emailed to us, Frank Azor said this:", "“It is inaccurate that $549/$599 MSRP is launch-only pricing. We expect cards to be available from multiple vendors at $549/$599 (excluding region specific tariffs and/or taxes) based on the work we have done with our AIB partners, and more are coming.  At the same time, the AIBs have different premium configurations at higher price points and those will also continue.”", "Speaking with insiders, we learned that AMD is “enabling” partners to continue this pricing. When we asked what “enabling” means here, we were told that AMD is working to lower cost to partners either through direct price reductions or through rebates and marketing development fund, or MDF. MDF is money that partners can use to spend on AMD-approved advertising efforts. If you see ads pop-up on YouTube for AMD’s GPU partners at some point, it’s likely that money went from AMD itself and through the partner to trade for artificial suppression of the GPU price.", "But based on the statement they sent to the media, it’s still unclear whether cards for MSRP can be expected or not going forward. The statements from distributors and AMD directly contradict one another. AMD can certainly say “launch-only pricing” is inaccurate, but the fact of the matter is the sellers previously mentioned have increased prices. ", "If AMD really wanted to enforce its MSRP, it could technically not distribute to retailers who don’t honor the price, but that seems unlikely. It doesn’t matter how much AMD claims pricing wasn’t launch-only: By not offering its own reference model for sale as NVIDIA does, it is an accomplice to the murder of its launch price. It has allowed partners to drift from the baseline because they’re all doing it, and without AMD there to undercut them, there’s no anchor to hold it back down. There are pros and cons to this: On the upside, AMD can avoid an EVGA departure situation. On the downside, partners can run wild, and AMD absolutely shares some of that blame. If AMD doesn’t control the final price because it doesn’t sell the final product, it can’t truly guarantee the price it advertised. ", "For all the sh*t NVIDIA gets, it does have this aspect of things together. It is controlling, overbearing, and levers its position to enforce strict requirements. Even if that’s often a bad thing, it can also work in favor of consumers.", "We’re based in the US and are most familiar with that market, so that’s what we’ve looked at so far. But from reading comments from viewers internationally, it’s become clear that you all got screwed the most.", "We’ve collected reports from 16 different countries outside of the US, all sharing a similar sentiment of MSRP cards evaporating in seconds to minutes.", "A user from Europe reported, ", " ", "One from Australia says,  ", "  ", "Another EU resident expresses, ", " ", "A Polish user describes,  ", " And the list goes on.", " Netherlands retailer Megekko continuously increased prices throughout the launch.", ", “At 15.00 their website crashed, and megekko kept on raising the prices, if im correct they raised the price 3 times in total. Now it costs 1100euro for a 9070xt that has 600dollar msrp.”", ", “Bought one from megekko for 930€ and was ‘sold out’ 3 seconds later, only to come back fully in stock but suddenly ANOTHER 100€ added.”", " adds that the retailer even increased ", " pricing. ", "Because we don’t have actual numbers here, we can’t make any definitive claims. That being said, these reports seem to suggest that non-US distributors, excluding OCUK, didn’t receive as much stock as those in the US did. Specifically, stock being sold at MSRP. Interestingly, this is with new tariffs in the US.", "Based on our research, it does appear as if the cost increase in partner models has increased over time. Partners are shipping cards at a percent price higher than baseline MSRP that is greater than what they’ve done historically in the past from what we’ve briefly looked at thus far. ", "This might indicate that launch MSRPs might be for show. We think the situation boils down to greed. If we’re being charitable to partners in that they are raising prices just to survive the low margins, then the MSRPs are bull****. ", "When we covered EVGA’s GPUs, we learned that the company was just making $4 per card, so their margin was functionally zero. When NVIDIA let off the pressure to hit certain baseline prices, EVGA would stop selling these lower-margin cards to push pricier models that yielded higher margins. This is something we can’t fault them for given the low margin they had to contend with. ", "The pricing situation seems to have gotten worse. The argument that the tariffs are behind this is kind of BS because other countries outside of the US are getting screwed even more. In addition, these cards have been stockpiled in the US before the tariffs went into effect. Tariffs will have an effect, but we don’t buy it when you look at the total situation across both AMD and NVIDIA over the last 2 launches. We’re seeing a price creep due to companies realizing they can make more money on video cards, especially since they realize people will pay for it. The end result is that people get screwed. The delta against baseline MSRP is widening."]},
{"title": " The Great NVIDIA Switcheroo | GPU Shrinkflation", "paragraph": ["The Great NVIDIA Switcheroo | GPU Shrinkflation", "Last Updated: ", "The Highlights", "NVIDIA is giving you the least amount of CUDA cores for a given class of GPU than ever before. ", "Today an ", " is comparable to a GTX 950 (watch ", ") in some ways when you run some numbers. An ", " isn’t distant from a 2060 (read ", ") in some considerations. The relationship between the number of CUDA cores the flagship has and the number of CUDA cores the lower-tier GPUs has been getting worse basically across the board. The amount of money you have to spend, even adjusted for inflation, to buy the GPUs has been staying flat or rising.", "When this happens in any other product category it’s called shrinkflation.", "Steve Burke", "Jeremy Clayton", "Vitalii Makhnovets", "Jimmy Thang", "We’ve already talked about the ", " and availability, but what we’re doing now is revisiting a topic that we ran about 2 years ago in a video called the ", ", in which we explored why no one was buying 4080s (watch ", ") at the time. It wasn’t just the money but because the relationship of what you got for the money. We’re taking the concepts where we broke out the pricing, the components, the die area, etc. and applying it to the 50 series and, in short, it has not gotten better.  ", "We just have 2 main charts to go through in this article but they’re really interesting. Now that NVIDIA has shipped everything except for the 60-class card, we’ve got a good amount to look at. The real goal of this is to explore the relationship between the money and what you get for it, but we’re also going to compare some of the cards against prior generations and doing some inflation adjustments.  ", "We started working on this piece for the 5080 launch and then realized it’s going to get worse. So, we waited for the 5070, which is now here (", "). Let’s get into the data for this.", "This chart compares the percentage of the Flagship CUDA core count that each configuration is. Due to architectural changes, we’re not interested in the raw count of CUDA cores, but the percentage occupancy of the maximum config for the flagship die.", "Our chart plot tracks each same-named GPU class across NVIDIA generations on a percentage scale representing how many CUDA cores each has relative to a larger configuration. The GPUs are all shown relative to the CUDA core count of that generation’s top gaming, non-Titan GPU – the ", ", ", ", 2080 Ti (watch ", "), 1080 Ti (read ", "), and so on – which we’re calling the Flagship-class. If you see 100% anywhere, that means it is equal in CUDA core count to the flagship.", "We went with the 3090 (watch ", ") for the 30 series rather than the late-arriving, cash-grab, full die 3090 Ti (watch ", "). We had to make a judgment call.", "The Flagship-class is plotted relative to the largest die’s maximum possible core count. The GTX 780 Ti (watch", ") is one of the few exceptions where NVIDIA made a flagship with the full non-cut-down die. ", "The GTX 780 (watch ", ") had 80% of the CUDA cores that the flagship 780 Ti did. The RTX 2080 (watch ", ") brought that down to 68% of full CUDA count, then just 59% for the 4080, but it gets worse. The 5080 is a mockery of an 80-class card with only 49% of the flagship-class CUDA count configuration. We don’t care if the die is different or not for this chart, just the config.", "The 3080 temporarily bucked the trend at 83%, which was great. This correlates with its incredibly good value and performance at launch with positive reviews. Back in our ", ", we said, “The card performance overall is impressive. It’s a big recovery from the 20 series when we reviewed it and called 3 of the cards a waste of our time because they were 1080 Tis and then complained for 55 days about how there was no RTX and the cards were named RTX. So this was a big turnaround for NVIDIA.”", "That also, however, aligns with the reviews we and others gave to the 3090 and 3090 Ti. For example, in our 3090 Ti review, we stated, “For us, hard pass on this. 8-12% for $2,200 is insane.”", "And with an overclock back then, we were able to nearly equate the 3090’s performance with the OC 3080. That’s how close they were.", "The odd 80 Ti/Super class from the 20 series to 40 series occupy the space between the 80 class and the flagships. There’ll likely be another between the 5080 and 5090. ", "The Super refreshes really should be called the “oopsies” edition GPUs. NVIDIA rolls these out when they make an “oopsies” on price and public sentiment, using Supers to meet halfway on price. Our hope is that the 5080 and 5090 gap ends up again as an “oops, let’s fix this” rally from NVIDIA with a mix of the 2080 Super’s (watch ", ") or ", "’s relatively sane pricing along with the 3080 Ti’s (watch ", ") aggressive configuration. That might start to help fix this a little bit. ", "The 70 Ti/Super class drops hard. The 1070 Ti (watch ", ") had a 68% CUDA core configuration for this class, falling to just 41% for the 5070 Ti (read ", "). By this logic, the 1070 Ti offered far more GPU relative to the 1080 Ti than the 5070 Ti is to the 5090.", "Next, we’ll expose NVIDIA’s grand switcheroo between the 70 and 80 class GPUs. ", "From the 770 series to the 3070 (watch ", "), the CUDA core count of the 70-class cards once reliably was between 53-59% of the flagship’s CUDA core count. ", "Then the ", " bore only 36% of the CUDA cores the 4090 had, and the card falling in the 50-60% range was now the 4080.", "Moving into the present, the RTX 5070 has an anemic 28% of the flagship’s configuration. If you were to extend the 70-class line out on its previous trend, you’d arrive around the same position as where the 80-class is now. Strictly speaking in proportions and if we want to do funny percent math, the 3070’s (watch ", ") core allocation relative to its respective flagship was 100% higher proportionality against the 5070’s.", "The 60-class is where it gets really bad.", "That 28% figure for the 5070 is lower than almost every 60 class configuration. The 60 class traditionally occupied the 30-40% range with a high outlier in the 20 series at 44%. This tracks with the fact that ", " on the 2060 at its release – more positive than the 2080. The 3060 returned to the low 30% range, but the ", " got slashed to 19%. Here’s what we said of the 4060’s worse cousin, the 4060 Ti, “", ".”", "And that brings us to the 50-class. The 19% on the 4060 is where the 50-class has sat multiple times. NVIDIA covered this segment during the 20 series with the 16 series GPUs, which we didn’t plot for sake of simplicity. Moving forward, the ", " was a 24% configuration, and it’s no wonder why the 4050 got canned – it would be like scraping the bottom of the barrel so hard that you just get splinters.", "But what’s crazy is that the 5070 barely clears the 27% config of the old GTX 950. That’s just sad.", "Now that we’ve established the trends, let’s keep all of that in mind and analyze pricing in the same way.", "This line plot tracks the launch price of all the same GPUs in each class, adjusted for inflation from the month of each GPU’s launch to January 2025.", "Right away, we see that the flagship class has changed massively. The 780 Ti, 980 Ti (watch our ", "), and legendary 1080 Ti fall within a consistent $100 spread. The 980 Ti was slightly cheaper at a $650 launch price, which is $865 after the inflation adjustment. The 1080 Ti sits at $912, in stark contrast to the massive jump of the 2080 Ti at $1,510 adjusted. That’s a 66% cost increase gen-on-gen for the customer. It was technically available for $1,000, but in very limited quantities, and the vast majority went for $1,200, which is what we adjusted from.", "The price went up again for the 3090, with a slight relief in the 4090, before jumping again to the $2,000 mark with the 5090. It undoubtedly costs more for NVIDIA to make a 5090 than it did to make a 1080 Ti, but there’s no argument that more than double the retail price is painful for a consumer.", "The 80 class has also risen, though not to the same extreme degree as the flagship class. The GTX era 80s had inflation-adjusted prices between $734 and $886. There was a slight bump to just over $1,000 in the 20 series, followed by relief to the mid-$800s at the 3080, before rising insurmountably to the 4080.", "When taken alongside the CUDA core configurations, all of this underscores both just how good the 3080 was and how terrible the 4080 was. The 3080 had a spike in core allocation and a return to “normal” pricing, while the 4080 fell off core config cliff and the price went up at the same time. Coming to the present, the 5080 is back at the same relative price as the 2080, but at a much worse relative CUDA core count.", "The 80 Ti/Super class is an oddball – as if NVIDIA hasn’t been able to decide whether it’s better as a later, better value 80 class alternative like in the 20 and 40 series, or if it should be a weirdly positioned, poor value cash-grab like the 3080 Ti.", "The 70 Ti/Super class has risen in price across the generations that it’s existed, from roughly $500 at its introduction in the 10 series to $849 in the 40 series. AMD Radeon GPUs were competitive in this price bracket back in the 10 and 20 series days, which is likely the reason why we see this aggressive pricing during that time period. From the 30 series onward, NVIDIA’s dominance has allowed this class of card, specifically, to sit comfortably between the 80 and 70 classes.", "The 70 class has managed to stay relatively flat from one end of the chart to the other. The all time low price was in the GTX 900 series at $440, and the high point was the 20 series at about $750. That’s a large swing, but it’s stayed relatively flat since then.", "The 60 class paints a similar picture. The inflation adjusted price line is generally flat overall with a slight downward trajectory since the 20 series, but in that same time the core config has gone into the dumpster. We don’t know anything about a theoretical future 5060, but we’d bet it won’t be a pleasant addition to this data set.", "Finally, the 50 class hasn’t seen much action, but it hasn’t seen many releases in recent years – probably because the 4060 took its actual place. Judging by the 3050, NVIDIA is probably unwilling to launch a GPU for under $250 again, let alone the $145 mark of the 1050 (watch ", ").", "Over the years, the means of product segmentation have migrated. Product segmentation isn’t inherently an evil thing, and especially in the world of silicon where the costs are enormous to make any of these products, but it can be applied in ways which just don’t feel good as a consumer. Segmenting the 1080 Ti at 11GB versus the Titan cards at 12GB didn’t feel particularly bad. It was obvious what they were doing, but the affected user base was much smaller.", "Some of the other ways NVIDIA has historically segmented its products include splitting double precision out into only the highest-end cards, which at one point included Titans. Another is by forcing users over to Quadro for verified drivers as an additional layer of liability reduction for big organizations.", "Neither of these two segmented features are noticeable to the vast majority of end users, so it doesn’t feel as bad to the consumer. Over time, that has drifted to VRAM increasingly, which now means there is a new developing class of users. ", "For the gaming audience, we get situations where a $750 video card can find itself in situations of unplayable stuttering and latency nearing 800 ms PCL due to VRAM overload and swapping.", "Joining the scientific user base that once needed double precision, or now might need various machine learning capabilities, there is now the segmented customer base of so-called “creators.” Not just YouTubers, but anyone making 3D art, games, or similar media.", "These users are being pushed into the 90-class, which is further diminishing the capabilities of the highest-end gaming cards ", "pushing those high-end gaming consumers into price categories of professionals who use their GPUs to make money. It’s easier to shrug it off knowing it’ll make back the time, even if it’s still unpleasant.", "Back in our ", ", we talked about how all of this is predicated on the assumption that the names mean anything. Like Whose Line Is It Anyway, sometimes it feels like the names are made up and the prices don’t matter.", "We’ve been open about our opinions about this changing over the years: At one point, it did feel like names were somewhat arbitrary. It is just a name, and it’s ultimately the specs and price that matter. But the shift came over the last couple generations, where we came to appreciate that what’s in a name is important.", "NVIDIA has used the 80-class cards to establish an expectation in customers, and regardless of whether NVIDIA intends it to still be perceived as the high-end as opposed to some mid-range card (which it is now), the fact is that their consumers do perceive the 50 name as intended to be high-end.", "This is sort of a death of the author scenario, but then NVIDIA doesn’t want to name a $1,000 video card a “5070.” That creates new problems. ", "NVIDIA has died as the author, and the consumer is now in control over what these names mean. To quote someone in the industry, it’s the “perception of reality” versus the reality. ", "If NVIDIA wants to establish a reality where an 80-class card is half of a 90-class card, they can do that; however, if the end users perceive that a 5080 should be a true high-end device, that’s all that actually matters. NVIDIA is also responsible for this. The company spent a decade establishing the 80-class cards as the top-of-the-line, behind only the Ti class cards. It has now bifurcated those two lines and created a large gulf between them.", "And this is getting worse with 5070 cards that are now more similar to older 50-class cards.", "And so while the name itself is technically arbitrary as compared to the specs, the name matters. It defines an expectation. ", "Let’s explore that philosophy a bit more. If Toyota suddenly starts shipping rebadged Yugos that it calls Camrys, that’s going to cause problems with the customer base. That’s what NVIDIA is doing. If the AMC Gremlin is sold under literally any name, it’s going to cause problems.", "The point is, the RTX 5080 is a Yugo. Or a Gremlin. Or a Ford Pinto. And NVIDIA has spent a decade branding it as a supercar (and it was at one point a supercar). ", "Zooming back out, we think the overall picture is clear. NVIDIA has downsized essentially all of its gaming GPUs in terms of relative configuration compared to each generation’s flagship. All of the lines go down. The chart from earlier had a lot of words to say one thing: Line go down = bad. We don’t want the line to go down. We want the line to stay the same or go up.", "The 80 class is now in line with former 70 class GPUs and the 70 Ti/Super class is now in line with former 60 Ti class territory. The last 60 class card was configured like a 50-class of yore. ", "Some might argue that the ", " and ", " being such monsters skews the comparisons, but we think that’s more of a perception issue based on NVIDIA's success at pushing the cost of the high-end higher. NVIDIA’s flagship GPUs have been very large pieces of silicon since the 20 series, and the CUDA config cutting had barely begun at that point, and the MSRP wasn’t as high as it is now.", "The price of NVIDIA’s GPUs has generally gone up over time, even accounting for inflation that does things like turn the former $700 1080 Ti into a $912 GPU in today’s money. But then you look at $900 GPUs in today’s money and that’s a 9070 XT. And the 9070 XT isn’t positioned where the 1080 Ti was. The closest GPU might be the 5080 at $1,000 and that also doesn’t feel like a 1080 Ti by price. Flagships, however, are the worst, rising from that level to $2,000 with the 5090. Non-flagships haven’t risen quite as much, but it’s still significant. In this case, line go up = bad. For the consumer, anyway.", "The 70-series here is one of the most textbook examples of shrinkflation. While the price point has stayed fairly consistent for a few generations, remember that the relative CUDA core configuration has dropped by a huge amount during that time. It’s gone from $610 with a 56% configuration in the 30 series, down to $550 with an embarrassing 28% core configuration in the 50 series.", "NVIDIA is giving you a half-size slice of the GPU pie with the ", " than it did with the 3070, but it’s charging you basically the same amount of money for the privilege.", "All of the GPUs are victims of the configuration cutting we talked about. Even the technically-cheaper-than-they-used-to-be 70 and 60 class cards are providing less of a share of the capabilities of their respective flagships than they used to. ", "And AMD isn’t immune to this, of course. We have an entire ", " that delves into this. NVIDIA, however, holds 90% of the market, and it’s important for you to understand how your money is disproportionately losing value when it’s spent with NVIDIA versus many years ago.", "We don’t have an answer for this. It’s sort of too big, but it’s important to know about and to start thinking about. Maybe enough people will pay attention to this so that it will help them make informed purchasing decisions."]},
{"title": " Get It Together, NVIDIA | Terrible GPU Driver Stability", "paragraph": ["Get It Together, NVIDIA | Terrible GPU Driver Stability", "Last Updated: ", "The Highlights", "How the tables have turned. NVIDIA, is now playing the role of AMD circa Vega, which is not good. NVIDIA’s drivers have had stability problems since the launch of its ", " and we’ve been able to replicate them.", "In one game, we had system crashes after enabling NVIDIA’s frame generation, which is unfortunate since it marketed the 50-series on the back of MFG and ", ". We had reboots loading into Cyberpunk, crashes and driver errors in Tomb Raider, and issues with screen distortion and artifacting.", "Steve Burke", "Vitalii Makhnovets", "Tannen Williams", "Jimmy Thang", "But these issues didn’t show up in our review of the 50-series, which was our first hint that it’s related to a driver version issue. ", "Game developers have recently begun recommending rolling back to older NVIDIA drivers: ", ", the studio which NVIDIA has heavily promoted for partnership with its AI features, threw NVIDIA under the bus, stating, “Using driver versions 572.xx or later may result in occasional frame drops or stuttering [...] If issues persist, we recommend installing version 566.36.” This driver is from December. ", "Developer ", ", “Using driver versions 572.xx or later may result in occasional frame drops or stuttering.”", "This aligns with our findings from the past week, where we’ve been trying to replicate these issues that have been widely reported online. ", "Interestingly, we found that the order of the monitors in Windows, as in the display out order of monitor 1 and monitor 2 in the OS via the actual hardware connection to the video card, seemed to affect stability. ", "User reports commonly note various display problems like ", ", ", ", and sometimes even unprompted ", ". This includes other types of crashes too, like crashing to desktop. Upon a closer inspection, it wasn’t only 50-series users dealing with the issues. Many users of NVIDIA’s previous generations of GPUs, particularly the 40 and 30 series, are also affected by the recent drivers. ", "Several users speculated on the impact of multiple monitors, the impact of mixed or higher refresh rates, and even how NVIDIA’s own G-Sync might be affecting the driver stability. ", "There’s been at least one ", " on Reddit with hundreds of reports and these issues have ", " since the launch of the 50-series. ", "We’ve been able to replicate these issues and have isolated some of the causes. We also have some stopgap solutions. They’re not great, but may help for the time being. This also applies to multiple card generations. As far as we know, it impacts the 30 to 50 series GPUs.  ", "User reports seem to point to driver ", " as the most stable recent driver. ", "This version was released on December 5th, 2024, just prior to the 50 series launch in January. In the four months since that driver’s release, NVIDIA has posted six GeForce Game Ready Drivers and at least four ", " specifically aimed at fixing bugs and system crashes.", "Time to get into our testing configuration.", "In order to better understand the driver problems that previous generation NVIDIA users are currently experiencing, we attempted to recreate some of the issues ourselves. ", "Before we began, we went through an assortment of ", " to find games, system configurations, and specific settings that seemed especially problematic to get a starting point for our testing.", "For our testbench setup, we used a modified version of our standard test bench. We also bought a couple games that people had particular issues with. Our standard GPU review bench did not exhibit any of the issues with drivers initially, so we modified it.", "Components included these:", "So we have a very intentional mix of different resolution displays, different G-Sync compatibility, different refresh rates, and, of course, we’re going to change the drivers as we go through our testing.", "Our first goal was to simply identify a game crashing. From there, we’d recollect what occurred leading up to the failure and then document a process that we could follow to ensure the crash happened every time. Once we were able to consistently reproduce the complication, we’d change one variable at a time while keeping all others the same in order to isolate the factors involved and determine possible causes. For each instance, we separately disabled G-Sync, frame generation, DLSS, and sometimes other settings (depending on the game). We also moved to a single monitor and then swapped output ports on the GPU between the two monitors for each game issue we experienced. Suffice it to say, this all took a while.", "Here’s what we found:", "In our testing on NVIDIA’s most recent driver, ", ", we found four different instances of game crashes that could be consistently reproduced. ", "In Star Wars Outlaws, we experienced failures after selecting “resume” in the startup menu. In Marvel Rivals, we’d observe system reboots either directly after applying frame generation in the pre-menu settings, or after applying the settings and then exiting to desktop from a match. ", "In Cyberpunk 2077, we encountered reboots when loading into the game. ", "In Shadow of the Tomb Raider, when running the in-game benchmark we faced a game crash along with a driver error. After rolling back to a previous driver, we could no longer replicate any of these same failures on any of these games. And that’s the reason this took a week or 2 to put together because we tried to isolate to see if it was a game problem, something relating to NVIDIA, or NVIDIA settings in that game.", "Based on our initial findings, we believed the driver issues may be affecting some users that are operating on a specific combination of hardware and displays/graphics settings. Specifically, those using two monitors with G-Sync and frame gen enabled. We also found something really interesting regarding the physical output ports on the GPU itself and how the monitors are identified in Windows display settings. We don’t fully understand it yet, but we’ll go over that observation shortly.", "We have more findings to go over first.", "DLSS and Reflex may also factor into the equation, but unfortunately we weren’t able to make a clear determination. In some games, DLSS or Reflex is automatically enabled when using frame gen. Meaning, we weren’t always able to fully isolate each of these variables because one will force the other. Additionally, sometimes lowering the refresh rate to 120Hz on our second monitor would resolve issues, while other times it didn’t. ", "Something that especially stood out to us was that we could only replicate 3 of the 4 failures when both monitors were connected via DisplayPort and when monitor 2 was checked as the main display in Windows settings. ", "As seen in the image above, when our Acer monitor was plugged into what we’re calling slot 3 and our Alienware monitor was plugged into what we’re calling slot 2, we didn’t have any issues. But when we swapped the slots the monitors plugged into, effectively converting “monitor 1” to “monitor 2” within Windows and vice versa, and then made monitor 2 the main display, we saw the crashes again consistently. ", "This is less to do with the physical ports being used and more to do with how Windows and the drivers are treating the monitors in their “1” and “2” slots. We couldn’t tell you why this behavior causes issues, but if you’re having trouble, swapping monitors 1 and 2 could potentially help.", "We actually found this by accident. The day after we recorded our first game crash, we reconfigured the bench and began trying to trigger it again, but couldn’t. It wasn’t until we realized that the only difference was that the DP output slots on the GPU had been changed. After switching them back to the original position, we were suddenly able to observe the failure again. To our surprise, this same circumstance appeared in multiple games.", "As for similarities between the issues: In Star Wars Outlaws, Marvel Rivals, and Cyberpunk 2077 (all games that natively support DLSS 4), we were unable to produce a failure when either G-Sync or frame gen were disabled. We also separately couldn’t trigger a crash after swapping output slots or on a single monitor setup.", "DLSS 4 and frame gen are also problems here. It’s not just the monitor order or the monitor ports.", "The error in Shadow of the Tomb Raider was different from the games previously discussed. This game was unaffected by G-Sync. It also doesn’t feature a frame gen setting (at least the version we tested doesn’t). Additionally, it experienced the same failures on a single monitor and after swapping output slots. So none of the other issues we’ve talked about thus far were the cause for Shadow of the Tomb Raider.", "Instead, we were able to boil this problem down to having “RTX Shadow Quality” set to Ultra in the in-game settings. And we know for a fact that this didn’t always cause a crash because we have run tests on it with RTX Shadow Quality set to Ultra in prior versions of our benchmark suite with different drivers. ", "In regards to our analysis, the main commonality between all four of these games is that they crashed on NVIDIA’s most recent drivers at the time of testing, but after rolling back to 566.36, we were no longer able to trigger that same error. ", "Rolling back to driver version 566.36 doesn’t guarantee that crashes will stop. From what we’ve read online, there are still issues with that driver. In our case, we are unable to prompt the same failures we had previously been able to. This, along with various user reports, seems to suggest that driver 566.36 is currently the most stable driver that NVIDIA has released recently. 566.36 is from December and predates the launch of the RTX 50 series, so would not be compatible with 50-series cards.", "There are a lot of other issues reported online, but that’s what we’ve replicated so far.", "Many users saw ", " in games that didn’t occur until after multiple hours of gameplay. As much as we’d like to, we can’t spend several hours playing a random game to see if it will possibly crash. It’s just too unpredictable. On the same note, just because we weren’t able to repeat our failure when we turned G-Sync or frame gen off, doesn’t mean that turning these options off will solve all problems, but hopefully it’ll help some of you.", "There were some other issues we commonly saw in our research:", "We’ve seen ", " that there’s an issue with waking from sleep or resuming from idle states and we were able to create at least one of these by accident. We noticed on one of our personal PCs that there were issues waking the system from sleep when the PC had been idle. And on wake, the monitors appear to turn on but don’t receive any signal and the screens remain black. Fixing this required a PC reboot. Windows has its own decades of issues with sleep and S3 states, so it’s hard to specifically pinpoint who’s at fault for this one between NVIDIA and Microsoft.", " we’ve seen going around has to do with the alt+tab shortcut acting buggy and freezing games when switching windows while playing a game. ", "We did occasionally encounter this bug, but it wasn’t something we saw every time and seemed to be resolved pretty easily by pressing the Windows key or alt+tabbing back into the game. Again, this one is difficult to pinpoint between NVIDIA and Microsoft. ", "NVIDIA has had some driver notes addressing parts of this, despite the driver not fixing everything.", ", one open issue states, “[Cyberpunk 2077/Half-Life 2 RTX] PC may bugcheck with error 0xd1 when playing game while using DLSS Frame Gen + G-SYNC [5144337].” ", "We’re glad that issues relating to frame gen and G-Sync are being acknowledged, but we’d like to see more from NVIDIA here. This is a relatively vague description and only mentions two games that are affected by this much larger issue. ", "NVIDIA has also had multiple hot fixes. We’ve reported on some of them where it’s saying it’s trying to fix issues with the original 50 series and then just basically everything. ", "We’ve known that NVIDIA has shifted its focus towards ", " and away from its gaming market. That’s fine -- but it shouldn’t be screwing up areas where it has long had such refinement. NVIDIA is known for its driver stability, and the company, in its series of screwups for 2025, is starting to chip away at that in an era where AMD’s drivers have become relatively stable. These driver issues are another mark upon NVIDIA’s tarnished gaming reputation with the 50-series launch as the company shifts focus, but losing prior-gained ground shouldn’t be in the cards, and NVIDIA hopefully will recognize that these issues are damaging to its long-term brand credibility.", "We’ll end off with some suggestions for users experiencing issues:", "For non-50 series users who are confronted with game crashes on NVIDIA’s latest drivers, we’d first recommend swapping the order of your display outputs on the GPU itself. We don’t fully understand how effective this fix is yet, but it’s simple and worked for us. We’d also suggest swapping cables to HDMI, which is not ideal, to see if that changes anything as a stopgap.", "If you don’t feel strongly about G-Sync or frame generation being enabled, we would then suggest disabling one of those settings and see if you’re able to resolve the issue that way until NVIDIA is able to get its s*** together. Considering NVIDIA’s whole ", " lately has been frame generation, this is a bad solution for NVIDIA, but hopefully it’s a stopgap.", "If neither of the above work for you, our last suggestion would be to rollback to a previous driver. If you’re able to recall a specific driver that you previously used that didn’t cause any problems for you, we’d advise reinstalling that one. ", "In our case, ", " seemed to remedy our problems and seems to be shared by users as one of the more stable ones currently available. ", "As general process control, we’d recommend installing drivers directly from NVIDIA’s website and disconnecting from the internet for installs and uninstalls. We always uninstall previous drivers using Display Driver Uninstaller (DDU) in safe mode, pause windows updates, and perform a clean install before reconnecting to the internet. It’s not something that we experienced, but we have seen user reports claiming that installing drivers using the NVIDIA App led to certain issues, and reinstalling the same driver but from NVIDIA’s website instead solved those problems. ", "Unfortunately, all of these suggestions are only temporary workarounds, and we can only wait for a new NVIDIA driver to provide a legitimate solution and get it together. This has been an absolutely abhorrent and completely embarrassing launch for the company. This is the worst NVIDIA launch we’ve covered and it may be the worst GPU series launch we’ve ever covered. That’s saying a lot considering AMD has had some impressively bad drivers for years. NVIDIA has taken that over. At least with Intel Arc and its Alchemist GPUs, our expectations were low, and Intel has taken notable steps to address its issues. NVIDIA, on the other hand, continues to fumble in impressively bad ways. This is the type of thing that helps the company lose market share. ", "In the meantime, we will continue to monitor the driver situation and will provide an update when we find a more stable solution provided by NVIDIA."]},
{"title": " NVIDIA GeForce RTX 5090 Founders Edition Review & Benchmarks: Gaming, Thermals, & Power", "paragraph": ["NVIDIA GeForce RTX 5090 Founders Edition Review & Benchmarks: Gaming, Thermals, & Power", "Last Updated: ", "The Highlights", "This is a big review, we’ll respect your time: The short version of the review of the RTX 5090 Founders Edition is that the thermal solution is surprisingly good for GPU thermals, if a bit warm for memory thermals, the rasterization gaming uplift at 4K over the ", " (watch ", ") is anywhere from 20% to 50% (depending on the game), ray tracing at 4K is commonly around 27% to 35% uplift over the ", ", and performance improvement at resolutions like 1440p and 1080p see lower improvements. An additional storyline to this review is that the ", " (read ", ") remains completely insane in the best ways, because it was able to keep up even at 1080p without major bottlenecking in some benchmarks.", "Today, we’re looking at gaming performance, efficiency, thermals, acoustics, ray tracing, and power consumption.", "Steve Burke", "Patrick Lathan", "Mike Gaglione", "Jeremy Clayton", "Tim Phetdara", "Jimmy Thang", "First off, we have a huge amount of content related to this card coming up since the Founders Edition model is so unique. Make sure you check back regularly over the next few days to catch our benchmarks in common mini-ITX cases, the impact of the GPU on CPU and CPU cooler thermals, and some other tests. We also have a tear-down coming up.", "Normally, these Founders Edition models don’t warrant a ton of discussion. This one does, but we’ll keep it short.", "The RTX 5090 Founders Edition moves to a 2-slot design and uses a dual flow-through configuration, so they’ve sandwiched the PCB centrally and offset the PCIe slot to the side and down as a result. That also means that NVIDIA needs a separate PCB for the I/O that feeds monitors, connected via a flex cable to the main PCB. To get a 2-slot cooler capable of handling 575W or more, NVIDIA is using liquid metal with a triple-walled gasket to both contain the liquid metal and prevent exposure that could change its consistency and efficacy. ", "The FE model does a lot of small things to improve performance, like exhausting the air out the top of the card and away from the GPU inlet. You’ll see that in our Schlieren imaging below.", "We have a ", ", Lead Thermal Engineer on the FE card, breaking down the changes.", "The NVIDIA RTX 5090 is supposed to be $2,000 and will have official availability on January 30th, joined by the $1,000 MSRP RTX 5080 on the same date. NVIDIA also has the 5070 Ti and 5070 launching in presumably February for $750 and $550.", "The NVIDIA RTX 4090 had an MSRP of $1,600, then was regularly priced around $2,000-$2,500 due to shortages and demand, and is basically out of stock except at terrible third-party seller prices now. The ", " (watch ", ") is AMD’s closest competitor. Pricing is around $870 to $900. The company has also bowed out of the high-end race. The 9070 and 9070 XT, AMD’s next cards, should be coming around March or so.", "Intel is currently only fighting at the low-end and mid-range.", "Which makes all of this somewhat weird, because there are no head-to-head competitors right now. The closest comparison is the RTX 4090, then maybe the ", " from AMD’s side. ", "The RTX 5090 has 32GB of GDDR7 memory, which is a big change, and runs on the Blackwell architecture, which follows Ada Lovelace. It’s introduced alongside multi-frame generation (MFG) and DLSS4, which we’ll talk about later. ", "The 5090 is also a true PCIe Gen5 device, but that’ll be another separate piece soon to check back for the differences.", "If you want to see our testing methodology, we’ve published the test bench and the list of games and their settings ", ", which will let you get quick answers to what we’re doing. It doesn’t have every answer, but we’re slowly adding to it with each review cycle. ", "Here’s a thermal chart running the RTX 5090 under its auto VBIOS fan curve with a Port Royal RT stress test at 4K.", "GPU temperature plots at about 72 degrees Celsius once it hits steady state for overall temperature when tested in a controlled room ambient of 21 to 22 degrees Celsius. This GPU temperature is genuinely impressive considering the size of the card, and that’s important to remember. At 2 slots versus that 4-slot monster we’ve seen for the last few years, this is an excellent result given the size. Our prototype testing already told us what NVIDIA can do with a fully committed, fatter design if you’re curious what that’d look like.", "Memory temperature ran warm, unfortunately, at 89 to 90 degrees Celsius. This is higher than we’d like to see, especially considering it could be warmer in certain case configurations with a higher internal ambient temperature. This is technically still within the TjMax of these memory modules as far as we could find, so there isn’t an imminent threat to the card, but this would be an area for NVIDIA to improve; our primary concern is in hotbox cases or small form factor solutions, which we’re looking into as a follow up that you should check back regularly for. While these results are higher than what we’d like to see, in most high airflow ATX cases, it is okay.", "Adding GPU fan speed to this chart, the fans both hit around 1570 RPM. We should get to acoustic testing for more on this.", "We took the RTX 5090 to our ", " to evaluate it. A good GPU temperature is an achievement at this size, but that can almost always be done by just blasting the fan speeds and compromising on noise levels.", "We ran the card at the default fan RPM that the card set itself to at steady state under our standard thermal workload. ", "Here’s the frequency spectrum plot. In our ", " with a noise floor of about 14-14.5 dBA on the day of testing, the RTX 5090 was measured in our passive test bench at about 32.5 dBA total. That’s at a distance of 1 meter.", "The RTX 5090 had some spikes during testing, including above our frequency cutoff, but overall has a very gradual curve for the plot. The limited presence of peaks and spikes in this plot help illustrate the relative uniformity of the whirring noise, which we subjectively think helps it blend into the background more. Noise is subjective, so although this plot objectively tells us that there’s a ping at 350 Hz and a bump in the plot around 515 Hz and again around 2,000 Hz, what matters is how it sounds.", "This is a ", " for you to judge on your own. Note that this is not identical to what we’re presenting as we have boosted it for purposes of being level with our video audio. Listen for the type of noise, not the volume.", "In our ", ", he explained that the 5090’s thermal solution was designed to reduce recirculation using angled covers, which direct airflow. ", "In this image, we're looking at the GPU straight-on, with it perpendicular to the camera frustum. This is when the fans are off but the heat load has already started. You can see the density change as the hot air leaves the card passively.", "As the fans turn on, we see a sudden flare-up and movement of air to the right through the flow-through area out the back and toward the CPU tower. What's super cool here is that we can see the air kick up and out to the right at a 20-30 degree angle or so. We also see a really high flow area of air exiting from the fins at the outer edges of the heatsink design. This hyper focuses the flow and reduces recirculation around the front area of the card, which just means the whole design is incredibly efficient at getting air away from the board and into case exhaust fans.", "Here's the table shifted to see more exhaust. The flow-through area has super high speed exhaust, illustrating why flow-through is so much more effective than shoving air straight into a PCB wall.", "Looking at the fans spinning down at the end of a load and returning to passive cooling. Everything drifts up and away.", "This next angle shows the card on the left and centered. The most interesting thing we see is this straight line of air shot out from those fins at the outer edges of the fan diameter. This is what Gutenberg was talking about in our interview, where they're capitalizing on the area of most efficacy for the fan blade.", "Finally, here's the card straight-on, where we can see the amount of air shot up and out. You'll want to choose cases with some spacing between the glass panel and the card to help get the warmed air away faster.", "This next line plot is to ensure the GPU is functioning properly and meets the spec NVIDIA publicly claims. NVIDIA claims the 5090 runs at 2.01 GHz base and 2.41 GHz boost, with room for that to change based on the load. Assuming the software monitoring is correct for this new architecture, we measured about 2600-2700 MHz during the test, commonly 2600-2650 MHz.", "The RTX 4090 ran at about 2745 MHz in the same benchmark back when it launched and we tested it. Frequency clearly isn’t everything though, and it’s common that higher end configurations bring frequency down in some capacity. It’s also true that architectural differences also make frequency indirectly comparable.", "Ultimately: The card is exceeding the specification advertised by NVIDIA, so it’s running as expected, which is good. ", "Let’s get into gaming benchmarks.", "In Final Fantasy 14 at 4K, the RTX 5090 ran at a comically high 182 FPS AVG, with 1% lows that were nearly identical to the average framerate of the RTX 4090. That makes it 31% higher average framerate than the RTX 4090.", "For a quick value discussion: The RTX 5090 is supposed to be $2,000, with the RTX 4090’s MSRP previously being $1,600. The 4090 is not commonly available anymore for a reasonable price, though. MSRP-to-MSRP, the 5090 is 25% more expensive and 31% higher framerate in this test. The memory capacity increase benefit isn’t seen in this game either, as that’d be more of an impact in professional applications like Premiere, 3D work, or ML workloads.", "The RX 7900 XTX ran at 104 FPS AVG, the same as when we tested it in December (so there’s been no change), which gives the RTX 5090 a lead in this rasterized benchmark of 74%. The 0.1% lows are about the same between all of these devices at the top-end, which mostly comes down to pacing within the game. ", "Prior NVIDIA flagships include the RTX 3090 Ti (watch ", ") at 88 FPS AVG, meaning that the 5090 has doubled that performance. The frametime pacing was excellent on the 3090 Ti as it closely follows the average. The 3090 (watch ", ") was more or less a flagship as well and at 77 FPS AVG. The 6950 XT (watch ", ") was also once a flagship, closer to the RTX 3080 (watch ", ") for performance.", "The RTX 2080 Ti (watch ", ") held a 54 FPS AVG, meaning 5090 owners would see an increase of 237% over the 2080 Ti. ", "At 1440p, the 5090 again continues the comically high framerate by running at 317 FPS AVG. This has it about 17% ahead of the RTX 4090’s 272 FPS AVG. The advantage has been trimmed here, which could be because of an encroaching CPU bottleneck and/or because of architectural changes -- 1080p will help answer that below.", "For games like this, you’d need a high-end CPU and ideally more intensive resolution to really get full use of the 5090.", "Since we’re bottlenecked, we’ll move along but quickly stop to look at 1080p -- just for fun.", "If you thought the previous framerate was funny, cast your sights upon 407 FPS AVG at 1080p. Sorry -- that’s 407.", "FPS AVG. ", "Whew. Close one. As we all know, 407 FPS AVG is below the threshold of acceptability for the modern gamer. That 0.1 FPS is critical and is what finally pushes NVIDIA into playable territory for this game.", "In serious news: The RTX 4090 at 376 FPS AVG means the 5090 is still about 8% ahead. This test really is just for fun though, but is a good reminder of the limitations of even a ", " to boost the ceiling. ", "Black Myth: Wukong is relatively new to our test suite and is tested using the built-in benchmark. We benchmarked it at 4K for this. Currently, we consider this test in our suite to be “experimental,” meaning our confidence in it is present, but lower than other tests as we evaluate its reliability. We have been moving toward removing experimental status from it with each review.", "At 4K and where we’ve only tested a handful of cards due to the intensive load, the RTX 5090 ran at 86 FPS AVG with lows at 74 and 70. This has it 28% higher in average framerate than the 67 FPS AVG of the RTX 4090. So far, we’re seeing a few titles around this 30% number at 4K. Comically, the 1% lows, which for us is an average of the slowest 1% of frames, are higher than the average framerate for any other card on this chart; in fact, even the RTX 5090’s slowest 0.1% of frames are faster than the average framerate of the RTX 4090. That’s crazy.", "The 7900 XTX’s 49 FPS AVG gives the 5090 a 74% lead, with the 3090 Ti giving it an 89% lead. Improvement over the 2080 Ti is enough to feel irrelevant as a percentage, as it takes it from totally unplayable to relatively fluid.", "At 1440p, Black Myth has the RTX 5090 at 130 FPS AVG, 23% improved over the RTX 4090’s 106 FPS AVG. The lows also improve. The rapid rundown against other flagships is as follows:", "The 5090 has a 51% higher average framerate than the 7900 XTX, 75% higher than the 3090 Ti FTW3 (RIP EVGA), 99% higher than the RTX 3090 Master, and 189% higher than the RTX 2080 Ti former flagship.", "Black Myth Wukong is heavy enough that 1080p still has some meaningful spacing, even without ray tracing. The RTX 5090 ran at 160 FPS AVG, with good frametime pacing establishing 127 FPS and 116 FPS lows. The 160 FPS result has it 20% ahead of the RTX 4090, diminishing the earlier lead (which was 28% at 4K, 23% at 1440p, and now 20%). This isn’t just a CPU limit, as we also saw in Final Fantasy, but speaks to other advantages on the 5090 especially at higher resolutions. We think the memory bandwidth is likely a large part of that additional scaling.", "The RX 7900 XTX ended up 113 FPS AVG, with the 3090 Ti former flagship at 94 FPS and the 2080 Ti at 62 FPS.", "Starfield is up next. We haven’t run that many cards for this at 4K, but have a lot of 1440p data. We’ll start with the more limited 4K data set.", "At 4K, the RTX 5090 held 108 FPS AVG with lows that were within expectations for this game. The RTX 4090 ran 92 FPS AVG, giving the 5090 a lead of just 17%, lower than we’ve seen in some other tests.", "The lead over the 7900 XTX’s 77 FPS AVG is 40%, with the lead over the 58.3 result for the 3090 Ti at 85%. The 3080 (watch ", ") was down at 48 FPS AVG, with the 2080 Ti at 33 FPS AVG. AMD’s 7900 XTX and ", " (read ", ") are its highest-end cards available for the company right now, but the 6950 XT was a good deal in the back half of its life.", "At 1440p, the RTX 5090 ran at 147 FPS AVG against the 132 FPS AVG of the RTX 4090. This is down to a 12% uplift. The 7900 XTX ran at 112 FPS AVG, a big improvement from its 4K result as you would expect, with the 4080 FE (watch ", ") at 108 FPS AVG. The ", " (read ", ") would be around 1-3% better here if we had retested it.", "There aren’t many reasons you’d play this game at 1080p with an RTX 5090, but just for sake of data: The 5090 ran at 165 FPS AVG here, with the 4090 at 155 FPS AVG. Although technically better for the 5090, we’re effectively at the CPU limit here.", "Dragon’s Dogma 2 is up next. This is another new one that we added in 2024 and has been heavy on GPUs and CPUs alike depending on the test area.", "In this limited suite of cards, we have the RTX 5090 at 133 FPS AVG, leading the RTX 4090 by 35%. This is one of the largest gains we saw in our test suite. The lows and 0.1% lows also scaled up, showing that frametime pacing wasn’t at the expense of higher FPS.", "The RX 7900 XTX ran at 77 FPS AVG, with the 4080 FE at 72 FPS. Again, the ", " would be about 1-3% above that.", "The 2080 Ti from 2018 ran at 36 FPS AVG, and that’s without RT. The improvement to the 5090 is 267%. Climbing the flagships, the 3090 Ti’s 64 FPS AVG ends up giving the 5090 a 108% lead.", "At 1440p, the RTX 5090 FE climbs in framerate to 189 FPS AVG, with extremely well-paced frametime consistency shown in the high 0.1% and 1% low values.", "The 5090 ends up leading the 4090’s 156 FPS AVG by 21% and the 7900 XTX by 50%. The lead against these cards has fallen from the 4K results. ", "Although we’re in territory where it’s not meaningful for the experience, it’d help us to understand the behavior by looking at 1080p. The framerate still increases, so we weren’t totally bound by the CPU. The 5090 hits 214 FPS AVG, leading the 4090 by 13%. What’s interesting is that the 4090 is now at the same framerate that the 5090 had when the 5090 was at 1440p.", "Cyberpunk is up now. We’re testing the Phantom Liberty expansion in-game in the expansion area.", "The RTX 5090 ran at 95 FPS AVG, with lows at an impressive 81 FPS 1% and 77 FPS 0.1%. These lows are excellent numbers and similar to what we saw in Black Myth: Wukong, where the 5090’s lows are outperforming the 4090’s average. The improvement in average FPS was large at 50%, moving from 64 FPS AVG on the RTX 4090. This is the biggest gain we’ve come across so far. Cyberpunk is very particular though and sensitive to areas of the game. Checking with Wendell, his Level1 Techs team saw similarly huge uplift.", "The RTX 4090 had a large 32% lead over the RTX 4080 already. As for the older cards, the 5090 and 3090 Ti are in entirely different classes. The 2080 Ti is down at 27 FPS AVG and struggling to run, although to its credit, its frametime pacing in relation to the average is excellent -- it’s just that the framerate is low.", "At 1440p, the RTX 5090 ran at 181 FPS AVG, with lows at 126 and 108. The RTX 4090 held a 137 FPS AVG, with the advantage of the 5090 being reduced to a still respectable but lower 33%. The 7900 XTX ran at 120 FPS AVG here, which has remained a good result considering the price of the 7900 XTX as compared to its neighbors. That story is totally different with RT, though.", "The RTX 3090 Ti ran at 91 FPS AVG, with the 2080 Ti at 57 FPS AVG.", "We were fully CPU bound at 1080p, so we’ll skip it.", "Dying Light 2 at 4K is another heavy load for these GPUs. The RTX 5090 shows a familiar scenario of the 1% lows and 0.1% lows, which represent the slowest frames in our test passes, outperforming the average framerate of the RTX 4090. NVIDIA has managed to move the needle for at least the flagships, which we think is partly thanks to cache and memory configuration changes.", "The 5090 leads the 4090 by 38%, another impressive jaunt not distant from what we saw with Phantom Liberty. The 7900 XTX did OK in this test as compared to the 4080. The 5090 runs 74% higher average framerate than the 7900 XTX and also costs about 127% more, depending on what price the XTX is. For professional users though, the memory benefit isn’t accounted for in almost any gaming scenarios we test and would be in other applications.", "At 1440p, the RTX 5090 holds a 216 FPS AVG against the 4090’s 173. This has the 5090 25% ahead of the RTX 4090, down from its lead of 38% at 4K. We won’t burn chart time on it, but 1080p is only about 15 FPS higher, so part of this reduction in scaling is because we’re starting to approach the CPU limit.", "Resident Evil 4 is up next, first rasterized and at 4K.", "The RTX 5090 landed at 207 FPS AVG here, with lows running higher as a result of consistent frame pacing. The end result is a lead over the 151 FPS AVG of the 4090 by 37%, a lead over the 7900 XTX of 64%, and lead over the 4080 of 101%. Against prior flagships, the 3090 Ti landed at 89 FPS AVG, giving the 5090 an uplift of 133%.", "At 1440p, the RTX 5090 continued scaling and hit almost 350 FPS AVG, with lows that are at ridiculous levels with 281 FPS 1%. This puts the 5090’s average framerate 25% ahead of the 4090’s average framerate, so we’re seeing a reduction from the 37% at 4K, consistent with what we’ve seen elsewhere.", "The 7900 XTX held on at 232 FPS AVG here, followed by cards like the 3090 Ti at 162 FPS and 2080 Ti at 92 FPS AVG.", "At 1080p, we see there was still scaling all the way up to almost 400 FPS AVG, which is crazy. This has reset our expectations of where the CPU ceiling is. If anything, this is showing just how good the 9800X3D is for keeping up so well.", "The gap between the 5090 and 4090 is around 9% here, so we are actually hitting external limits.", "And now we’re moving to ray tracing benchmarking. This contains games like Black Myth and Cyberpunk, which tend to favor NVIDIA, and games like Resident Evil, Dying Light, and Dragon’s Dogma, which give some more variety.", "Black Myth is first. This is an experimental chart, so once again, our disclosure is that experimental charts have a greater risk of unexpected results as we are still researching its behaviors. This particular title is considered experimental in our test suite because its performance leans so heavily in one direction that we want to slowly accumulate results to explore it further.", "The 5090 ran at 88 FPS AVG at 4K, outperforming the RTX 4090’s 65 FPS AVG result by 36%. That’s a big jump. This is with upscaling, so it’s not like-for-like with the 4K raster results.", "AMD’s 7900 XTX ran at 20 FPS in this title, which is why we say it’s NVIDIA-favored. The 3090 Ti ran at 34 FPS AVG here.", "Skipping 1440p and going to 1080p with FSR to get more cards on the chart, here’s where we land. The 5090 is at 158 FPS AVG here, leading the 4090’s 120 FPS AVG result by 31%. Against the 3090 Ti, the 5090 leads by 103%, and against the 2080 Ti’s 49 FPS AVG, it’s about a tripling.", "The ", " (watch ", ") outperforms the 3090 Ti in this test when using FSR, with the entire top half of the cards outperforming the 7900 XTX. This test, again, is heavily favored for NVIDIA with the heavy ray tracing use.", "Dragon’s Dogma 2 is up next. Again, we haven’t done a ton of 4K Ray Tracing tests here because it’s such a heavy workload normally, but the RTX 5090 ran at 113 FPS AVG with lows at 97 FPS and 94 FPS. The 4090 landed at around 85 FPS AVG, giving the 5090 an uplift of 33%. The RX 7900 XTX does better in this game compared to Black Myth, instead outperforming the RTX 4080 and 3090 Ti, the latter of which is at 55 FPS AVG.", "At 1440p, the 5090 jumped to 165 FPS AVG and the 4090 held 136 FPS AVG, still keeping about a 30 FPS gap between them, or an improvement generationally of 22%. The uplift has fallen as compared to 4K, keeping with prior trends. The 7900 XTX does similarly here to last time, landing just ahead of the RTX 4080 (watch ", ").", "At 1080p, the 5090 continues to climb to 194 FPS AVG, reducing the generational uplift to 15% over the 4090. Let’s move on to something more interesting.", "Here’s Dying Light 2 ray-traced. Again, we haven’t historically run 4K here because only the 4090 and 4080 could be argued as capable. It looks like this next generation of hardware -- and hopefully that also includes AMD’s next card -- is changing that. The RTX 5090 ran at 109 FPS AVG, leading the 80 FPS result of the 4090 by 37%. The 7900 XTX is led by 137%. AMD has publicly claimed that its next generation will significantly improve upon this, so we’ll see where they land probably closer to March.", "At 1440p, the RTX 5090 ran at 176 FPS AVG and held lows of 152 and 126. The 176 result has it about 40 FPS, or 29%, ahead of the RTX 4090. The 4080 hit 104 FPS AVG with the 3090 Ti at 88 FPS. Our 2080 Ti was approaching a decent framerate, but still falling short at 46 FPS AVG.", "At 1080p, the 5090 held 224 FPS AVG, mostly establishing that we weren’t bound previously by the CPU. So when it was at 4K, the scaling was a 37% generational improvement, then 29% at 1440p, and now is 24.5% at 1080p. The reduction from 1440p to 1080p isn’t as big as we might expect from other tests, probably because there remains enough GPU load to where the CPU isn’t heavily taxed.", "Resident Evil 4 with Ray Tracing is up now, tested at 4K first. The 5090 ran at 210 FPS AVG using FSR as defined in the chart title. The 160 FPS RTX 4090 result establishes a 31% generational improvement favoring the 5090.", "The lead over the 7900 XTX is 56%, with the improvement on the 3090 Ti at 113%.", "We’ll keep this short: At 1440p, the RTX 5090’s lead falls to 23% over the 4090. This trend is consistent.", "Cyberpunk with RT Ultra at 4K is heavy even for the RTX 5090 when not using some form of upscaling, which we toggle off in testing specifically because of how unreliable Cyberpunk’s sticky settings are. The 53 FPS AVG puts the 5090 35% ahead of the 4090’s 39 FPS AVG result, remaining consistent with prior tests. The poor, old 2080 Ti nearly burst into flames trying to run this, holding an 8.8 FPS AVG as it crawled across the finish line.", "4K with RT Medium is interesting. Dropping from Ultra to Medium predictably increased performance, but grew the gap between the cards with a 59 FPS AVG and 40 FPS AVG result.", "Now we’re getting into efficiency benchmarking and idle power consumption. For this, although we tested a lot of games, we’re going to simplify the charts and just look at a couple of game tests plus idle. These convey the whole story pretty well.", "Testing is done by measuring the GPU power consumption at the PCIe cables and the PCIe slot with an interposer. Although we initially had trouble getting the card to work on the riser due to PCIe generation differences, in the final hours before going live, we found a solution to measure through the riser. This testing eliminates the remainder of system power consumption, so we’re isolating for just the GPU.", "Testing idle power consumption, the RTX 5090 FE landed at 46W on the desktop with our benchmarking approach. The RTX 5090 FE measured lower in idle power draw than the ", " (read ", ") and about the same as the ", " (read ", "). Even just sitting there, it’s drawing a good amount of power. Our testing uses Windows High Performance power plan for benchmarking performance, so switching to Balanced may help reduce this; however, we use that plan for all tests, so these are like-for-like comparable. We measured the RTX 4090 at 28-29W. The 5090 has relatively high idle power consumption with our test approach and this is an area where there’s clearly some room for improvement if only judging by the 4090, although the power consumption of the TDP is higher on this card.", "Final Fantasy 14 at 4K is low on results since we just started using this for efficiency for this launch. The RTX 4090 was the most efficient here, at 391.7 W to produce 138-139 FPS AVG. That puts it at 0.35 FPS/W. The RTX 5090 FE was efficient as compared to the other cards we’ve tested here, but technically worse off than the 4090. Realistically, they’re about the same. Despite framerate improving by 31%, the power consumption also increased by 37%. The end result is reduced or equal efficiency versus the last generation. This might be why NVIDIA is pushing the narrative so hard that MFG improves efficiency, except that’s like saying “why compare apples to apples when you can compare apples to oranges?”", "In the very least, against the 3090 Ti in a like-for-like comparison, we can see clear and massive iterative improvements.", "We’re showing 1440p to get a wider selection of cards, though the lighter load won’t look better for the 5090. The RTX 5090 ended up around 520W average for this work, landing it at 0.61 FPS/W. Efficiency is down comparatively overall since we saw the performance advantage also go down when at 1440p. The card should show the best gains in heavy 4K/RT workloads like F1.", "Here’s F1 24 at 4K and with ray tracing.", "On a technicality, the RTX 5090 is the most efficient in this test. It pulled 569W on average during testing and had spikes up to 580-590W, and because of the framerate advantage over the RTX 4090 with its 428W draw, it ends up at 0.21 FPS/W instead of 0.20. This isn’t particularly exciting and we have to highlight that NVIDIA’s claims of efficiency improvements largely centered around artificially generating frames, which isn’t like-for-like because the frame itself may not be the same or comparable.", "First of all, we need to start with NVIDIA’s complete bulls*** marketing. Unfortunately, NVIDIA just couldn’t help itself except to unfairly misrepresent its RTX 5090’s performance in the following slide on its site.", "This image shows the RTX 5090 as being 2x faster than the ", " regularly, but as you all know from the review you just read, that’s not true. This image doesn’t say “different DLSS versions where we needlessly compare apples to oranges even though we have nothing to be shy of if we tested properly, it says “Performance.” And the accompanying caption isn’t even part of the image. Just saying “Performance” while making big 2x bars makes the 5090 look 2x better than the ", ". NVIDIA technically lists the DLSS version in the bottom, but most people don’t know what that means. Most people don’t know that writing “DLSS 4” under BOTH bars of the RTX 4090 and RTX 5090 isn’t actually the same setting. DLSS 4 does not do the same thing on both of these devices. NVIDIA’s own line of gray text that blends into the background at nearly the same color states the test configuration. This states that Frame Gen was used on the 40 series and 4X multi-frame gen was used on the 50 series, which isn’t like-for-like. NVIDIA is generating more artificial frames per real frame on the 5090 than the 4090, but they just list “DLSS 4” under the bars instead of making it clear.", "NVIDIA didn’t have to do any of this, but between this insane reach of marketing and the claim CEO Jensen Huang made about an RTX 5070 performing the same as an RTX 4090, it comes across like NVIDIA feels like it isn’t good enough on its own. It has to put a bunch of makeup on the charts to be good enough.", "Anyway, enough of the marketing bulls***. The recap is this:", "We’ll have a lot more coming up."]},
{"title": " Intel Arc B570 'Battlemage' GPU Review & Benchmarks, Low-End CPU Tests, & Efficiency", "paragraph": ["Intel Arc B570 'Battlemage' GPU Review & Benchmarks, Low-End CPU Tests, & Efficiency", "Last Updated: ", "The Highlights", "Today, we’re reviewing the ", " Battlemage GPU. The B570 has an MSRP of $220 and follows-up the $250 ", " that we reviewed previously. Intel’s B570 price point lands it in territory where AMD’s ", " (watch ", ") and ", " used to fight. Today, that price class is mostly vacant of modern architecture solutions. The ", " (watch ", ") is the closest, typically around $250, and sometimes on sale. NVIDIA’s ", " (watch ", ") remains around $300 typically.", "Battlemage had an overall good launch. Lately, it’s been getting coverage for a potential for driver overhead in some test configurations that cause disproportionately bad performance on older CPUs. In addition to our ", " test platform, we also ran several cards back through on a ", " (watch ", ") with locked clocks and an ", " (watch ", "). The short answer to the question of whether it changes performance is “no.” The long answer is that we have extra charts to show why not. There are scenarios where it can matter, but other than a couple instances, they do not really emerge in our test suite.", "Steve Burke", "Patrick Lathan", "Mike Gaglione", "Jeremy Clayton", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "Anyway, let’s get into the ", " review.", "Check out our ", " if you want more detail on frametime pacing and on the basics of the architecture. For a quick recap of the specs:", "The ", " GPU is a 20 Xe-core configuration on 5 render slices, a 190W TBP, and 12GB of GDDR6. Memory bandwidth is relatively high for a card of this class, at 456 GB/s. The B570 card drops 2 of the Xe cores to land at 18 and is still set up on 5 render slices. RT units get cut down as well, TBP is at 150W, and memory is set up at 10GB of GDDR6 with a 380GB/s bandwidth. The memory interface is a smaller 160 bits.", "Here’s a quick pricing recap:", "At the time of writing this ahead of launch, we checked Newegg and Amazon for several GPUs.", "The Intel B580 GPU is mostly out of stock at the actual MSRP and being scalped at the time we’re writing this. On Newegg, it’s $340 and up right now, which is far too much to pay. It’s likely that when this story is published, the retailers will restock with B580s that are closer to normal, but we can’t review the future.", "The RTX 4060 is currently around $295 to $320, with units regularly available at $300.", "The AMD RX 7600 is $250 as of writing this, making it the closest price competition on a relatively modern architecture.", "Enough of that. We have a lot of charts to get through today, so let’s start with the alternative CPU testing.", "We are going to present charts that have 3 CPUs per card on them. The way to use these is not to compare the GPUs to each other, but rather to compare the same GPU against itself across 3 CPUs. This is to test whether Arc is disproportionately impacted by lower-end CPUs, meaning to test whether relative percent scaling against its competition worsens on a more likely pairing of a lower-end CPU.", "We locked the ", " to its single-core frequency except across all cores for one set of tests, then we used a ", " for the other set. ", "The current topic, at least as we’ve seen it mostly discussed in comments, is that Intel may be disproportionately hurt by driver overhead. Our testing is done with the intent to create a GPU bottleneck, as this isn’t a CPU review, and our content is done with maximum controls with the intent that you’d check both the CPU and GPU review. In this instance, we are still enacting controls, but potentially using a lower-end CPU. We kept our game settings the same, though, which means that even 1080p will often be GPU bottlenecked.", "This chart is for Final Fantasy 14 at 1080p.", "We’ll look at all of the B580 rows first:", "There is no substantial change to the B580’s performance across these three CPUs with this test configuration.", "Moving to the ", ": The 4060 on the ", " bench, 5600X bench, and 12400 bench performed identically. It was about 112-114 FPS AVG on all of them. There is no substantial change to performance.", "The ", " saw a performance drop on the i5-12400, but on the other two systems, was about the same.", "With the B570, we observed approximately equivalent performance from the 12400, 5600X, and the 9800X3D (read ", "). As such, the percent difference between all of these devices is overall comparable in this test, despite which CPU is used.", "Across all tested devices, we did observe a reduction in 0.1% low performance as the CPU was reduced to lower performance levels. As an example, the RX 7600 with the 9800X3D, at 84 FPS 0.1%, versus with the 5600X at 62.1. This is expected.", "Here’s the test at 1440p. In this benchmark, we did not observe a meaningful difference in B580 performance across the 3 CPUs. The same is true for the RTX 4060 and the RX 7600. We are not able to detect any differences beyond slight variance across platforms. The B570 also does not scale differently and scores almost identically across the three platforms. The data consistency for average FPS is actually remarkable. This means that the unbound data later will be sufficient for establishing differences between averages.", "As for lows, we are seeing consistently reduced lows on the lower-end CPUs in this game. The 5600X and 12400 both had worse 0.1% lows than the 9800X3D with the B570. With the RTX 4060, we’re seeing stable 0.1% lows across all 3 devices. With the ", " (watch ", "), we saw differing lows between the 9800X3D and 12400. With the RX 7600, we saw stable lows across all 3.", "It would appear that, based on the B580, B570, and ", " (read ", ") data, there may be an argument to worse lows on lower-end CPUs for Arc. We’ll need more games.", "At 4K, everything is remarkably consistent. This mostly includes lows as well, although exceptions like the 9800X3D and 5600X for the A770 apply.", "Broadly speaking, the GPUs are about the same here across all configurations here.", "This is Cyberpunk at 1080p/Ultra. We’ll go through it fast: The results do not change CPU-to-CPU. The only differences are on the RTX 4060, where we see worse lows on the lower-end CPUs, the A770, where we see a very slightly lower average, and the ", ", where we see a change in 0.1% lows. The B580 and B570 do not exhibit a change. In fact, realistically, the CPU change does not affect any of these results with regard to how we do a standard review. They are the same. This is GPU-bound, so that’s what you’d expect. Some of the internet has lost the plot and think “Arc bad at 1080p,” but it’s not that simple. It depends on the GPU load and the game.", "Starfield is known to be problematic for Arc. We have that discussion in the standalone chart, but we’ll focus only on scaling within a given card here. We did not observe a difference in the relative ranking of the B580 or B570 versus their competition in this test. Relative percent scaling did not get worse with lower-end CPUs.", "At 1080p, there is a slight difference at the top-end with the 7700 XT and the 12400 as a potential CPU bind comes into play.", "The RTX 4060 is identical in AVG FPS performance across all 3 CPUs; however, we observed worse frametime pacing on the 5600X and 12400 for the RTX 4060. Ultimately, they are the same level of reduction from the 9800X3D, so the two lower-end CPUs are comparable to each other.", "The RX 7600 is identical in AVG FPS performance and within variance on all 3. Again, the 9800X3D has a slight advantage in frametime pacing.", "The B580 is identical on all 3 for AVG FPS. There is also no meaningful difference in frametime pacing or 0.1% low performance. Note though that the B580 has some troublesome lows in this title already, but they don’t get worse on lower-end CPUs.", "The B570 is the same and the results are within variance for all 3 metrics.", "This is Resident Evil 4 at 1080p.", "The 7700 XT exhibits a slight ceiling with the 12400, but is mostly comparable. The B580 ran at 128 FPS AVG with the 9800X3D and 122 with the 5600X. We didn’t run this test on the 12400 configuration. The B570 had all 3, though: The 9800X3D has it at 110 FPS AVG, or 5% ahead of the 5600X configuration and 5.7% ahead of the 12400 configuration.", "The RTX 4060 ran at 107.9 FPS AVG on the 9800X3D and 106.5 FPS AVG on the 12400. The RTX 4060 shows a top-to-bottom range of 1.3%, smaller than the observed difference on the B570. This slightly reconstructs the stack such that the B570 ends up tied or slightly under the RTX 4060 rather than ahead of it by 2.1%; however, the reduction puts the RTX 4060 on like-for-like hardware maximally 2% ahead. Between the two, they’re realistically about the same.", "As for 0.1% low performance, the Arc cards underperform compared to the RTX 4060 on all CPUs. This does not get disproportionately worse on the 5600X or 12400 and instead scales with the average. The disadvantage in lows exists on the 9800X3D standard CPU and on the lower-end ones.", "Next up is Baldur’s Gate 3. We only run this test at 1440p and 4K due to the low load. ", "In this test, the RX 7700 XT found a hard bottleneck with the i5-12400. This capped out at 79 FPS AVG, as opposed to the unbound test at 133 FPS AVG. This would be appropriate for a CPU review, but does not show GPU performance. The RTX 4060 on the 12400 further reinforces these limits (although bounces off of them way harder, with much worse 0.1% lows as a result of the CPU, not the GPU). The RTX 4060 exhibits identical AVG FPS with all 3 configurations. The lows are better on the 9800X3D as it allows the GPU to hit frame pacing without external binds, which is expected behavior.", "The RX 7600 is restricted by the CPUs with the 5600X and i5-12400, with both lower than the 9800X3D’s result. Again, this is normal and is the expected result from a CPU bind. Lows are hurt as a result of limiting the ceiling.", "The B580 also experienced a performance reduction with the 12400, but a much larger one with the R5 5600X. To do some quick math:", "The RX 7600 at 77.1 FPS AVG with the 12400 gains 11.1% by moving to the 9800X3D.", "The B580 with the 12400 at 63.7 FPS AVG gains 16.2% by moving to the 9800X3D. That’s not as a big of a difference as we might expect, but it is larger than we saw on the 7600.", "The 5600X is a far different story, with a maximum uplift of 32% from the 5600X unit to the 9800X3D at 74 FPS AVG. This may be the driver overhead.", "The B570 shows similar behavior, with scaling worse on the 5600X than on the 12400. Lows are not disproportionately worse on any of them; in other words, the lows follow the behavior relative to other devices also scaling with the CPU.", "This would possibly change our recommendation for a 5600X user, but not a 12400 user where there is only a 3 FPS difference.", "At 4K, the 7700 XT is the same on both CPUs for AVG FPS, but worse in frametime pacing on the 12400. This is expected behavior when using a worse CPU.", "The ", " has identical performance between the 9800X3D and 5600X.", "The RTX 4060 has identical performance between all 3. There is a 1.3 FPS AVG difference as a result of not only run-to-run variance between the 3, but also the frametime pacing is also much better on the 9800X3D for the RTX 4060, which will influence the AVG FPS results.", "The RX 7600 has the same AVG FPS on all 3 CPUs, with better frametime pacing on the 9800X3D.", "The B580 has identical performance on all 3 CPUs for AVG FPS, with a slight 1% low advantage on the 9800X3D. ", "The B570 is identical on all 3 CPUs, with better lows on the 9800X3D.", "All of this behavior is expected for a GPU bind. ", "Black Myth will be brief as well: At 1080p/High, which is our standardized test platform, there is no meaningful, broad difference in scaling.", "The numbers do not change in any meaningful way. The 7700 XT is the same on both, the 4060 is the same on all 3, the 7600 is the same on all 3 (with the exception of reduced lows on the 12400), the B580 is the same on all 3 and lows are within variance run-to-run. The B570 is the same on all 3, with lows within the wider variance at the low-end. The A770 is the same on both.", "We’ll look at one more. ", "In Dragon’s Dogma 2, they are all the same from CPU-to-CPU, with a few notes.", "The 7700 XT is roughly identical. The RTX 4060 is mostly identical, with the 12400 potentially showing marginally worse performance. The RX 7600 is the same across all 3, with slightly worse 0.1% lows. ", "The B580 is the same across all 3, with worse 0.1% lows on the 5600X specifically. The B570 is the same across all 3 in all 3 metrics.", "The A770 is the same in all 3 metrics.", "Let’s quickly talk results: First, in most scenarios, there is no meaningful impact. The biggest situation was with the 5600X in Baldur’s Gate 3. The 12400 did not react as violently. The secondary impact is in some 0.1% low differences, but these often also manifested on other devices.", "This does not affect how we review GPUs. We have to make that clear here. There is no data to support that our conclusions would be different if we ran lower-end CPUs with these cards. It would just cap the ceiling of how much change you can see. ", "That’s not to say there isn’t driver overhead or that there can’t be. We are aware that multiple outlets have now shown this. However, we tested with High and Ultra settings and simply were not able to replicate the impact. Our belief is that in scenarios of extremely high framerate, such as 200+, or in situations where the CPU is heavily bound from low settings and lower resolutions, that’d be where you’d see the difference. But we don’t test GPUs for review with low settings and we currently don’t test esports titles, so these would not show up in our data.", "Others do. We’d encourage you to check them, as everyone in this space provides a different set of tests for unique value. This story is long enough as is, but what we can say is that our entire usual suite has now been validated on two low-end CPUs and we have found the performance does not meaningfully change the conclusions except perhaps in one main scenario tested.", "Final Fantasy 14 at 4K is up first for the unbound benchmarks on the 9800X3D.", "In this one, the B570 ran at about 41 FPS AVG, establishing a 16% advantage for the B580 at 47 FPS AVG against a 14% price bump by MSRP. This is pretty close to linear. The B570 roughly ties the A770 in AVG FPS and 1% low, with 0.1% lows close enough. It also outperforms the RTX 4060 by 11%, the 3060 by 23%, and the A580 (read ", ") by the same. The RX 7600 card landed at around 32 FPS AVG, giving the B570 a notable lead, especially at the price. There are also substantial improvements on the ", ", which was the previous leader in this price class (though it eventually sold for cheaper).", "For some references to older cards, we also have the GTX 1070 (watch ", "), GTX 1060 watch ", "), and GTX 1650 (watch ", ") present. ", "At 1440p, the B570 ran at 75 FPS AVG against the B580’s 86 FPS AVG, which puts the B580 about 15% ahead of the B570. It had a marginally higher lead at 4K. The B570 now sits between the A770 and ", " (watch ", "), so the A770 has slightly re-positioned itself as resolution came down. The RTX 4060 also gets closer to the B570, now at 72 FPS AVG, nearing equivalence despite a larger gap previously.", "This is the same behavior we saw in the ", ": The higher the resolution goes, generally speaking, the more of an advantage Battlemage has over its peers in the class. The lead over the RX 7600 is 14% here, with the ", " and 3060 (watch ", ") below it. Some older reference anchors include the RTX 2060 (watch ", "), GTX 1070, 1060, and 1650.", "Frametime pacing on the B570 is good overall, performing similarly to the RTX 4060 for frame-to-frame interval. ", "At 1080p, the B570 loses its advantage against the RX 7600 and RTX 4060. The B580 maintains a lead over these two cards with its 124 FPS AVG, although its frametime pacing, indicated by the 0.1% lows, is worse than what we’re seeing on the RTX 4060 and RX 7600. We dove into this in the ", ".", "Overall, Battlemage and the B570 remain a large improvement over Alchemist, especially at the price; however, we still see that reduction in relative performance as resolution decreases, even with an unbound configuration. At 1440p and higher, Battlemage when unbound seems to be more competitive than it is at 1080p.", "Starfield is next. Intel had a lot of problems with Starfield when the game launched -- namely, the problem was that it didn’t work.", "But it does now. Despite working, NVIDIA and AMD retain an advantage with the RTX 4060 and RX 7600 cards. The B580’s 41 FPS AVG leads the B570’s 36 FPS by 12%. The RX 7600 leads by 17%, with the 4060 leading by a staggering 31%. This is an example of one of the games where Battlemage is disadvantaged even when unbound, even at 1440p.", "At 1080p, the B570 GPU ran at 47 FPS AVG, planting it between the A770 of last-gen and the RX 6600 XT. Against Alchemist, it’s clear that Battlemage is a huge improvement when considering the configuration size of the A770 GPU against the B570 GPU. Against itself, Intel has definitely improved in huge ways. Against competition, the RTX 4060 and RX 7600 both hold advantages at both the resolution and with the game.", "The B580 ends up 10% ahead of the B570 in this test, so its value isn’t always linear.", "Resident Evil 4 at 4K was one of the B580’s strongest titles. In this test, the B580 marginally outperformed the ", " (watch ", ") in averages, with the 0.1% lows close enough to be comparable given wider margins. The B580 at 46 FPS AVG leads the B570’s 40 FPS AVG by about 16%, aligning with some of the other 4K results. The B570 ends up outperforming the RX 7600 by 7% and the RTX 4060 by 14%, which is an incredible lead for the B570 when fully GPU-bound. Considering the RTX 4060’s price, this is a big lead for Intel.", "The improvement on the ", " is also noteworthy, with similar gains.", "Lows on the B570 are not meaningfully different from those on the RX 7600, 6600 XT, or RTX 4060. The frame pacing is comparable.", "At 1440p, the B580 is still spaced about 16% over the B570. The B570’s lead over the RX 7600 has reduced and they are now mostly equivalent, with the B570 experiencing less consistent lows. This is something we showed in our ", ", if you’d like to learn more about why it hits this ceiling.", "The RTX 4060 also climbs relative to the B570, with its 70 FPS AVG result reducing the B570’s advantage to just 6%. This is while the RTX 4060 maintains slightly better 0.1% low results for a better average frame-to-frame interval. The B570 is still overall better here, but as we continue to reduce resolution, that’ll change.", "This is 1080p. With these settings, the B570 is now roughly tied with the RX 7600. The RTX 4060 is encroaching on the B570, which has had its lead when GPU-bound cut to 2%. That’s still impressive for the price and for the age of Intel’s new architecture. If we imagine the B570 line item were some hypothetical new NVIDIA card at $220, this would be an amazing move in the right direction for NVIDIA. The fact that Intel is still proving itself and working through some teething pains is the only hesitation that remains, though they have reduced that generationally so far.", "Even still, the B570’s frametime pacing is inconsistent. It bounces around in this title, with run-to-run variance higher than we see on any AMD or NVIDIA device. This remains a challenge in some specific games. It’s overall acceptable, but not as consistent as its peers.", "As for the B580, its lead over the B570 is about 18 FPS, or 16.4%.", "Next is Baldur’s Gate 3, which remains one of the best titles launched in the last couple years.", "At 4K, the B570 ran at 40 FPS AVG with our Ultra settings. This has it just below the RTX 3060 and above the A580, RX 6600 (watch ", "), and RTX 2060. The B580’s 44.8 FPS AVG result leads the B570 by 13%, with both exhibiting limited scaling in the 0.1% lows, indicating frame-to-frame consistency issues as compared to NVIDIA neighbors.", "1440p has the B570 at 67 FPS AVG, between the A750 and A580. The generational uplift isn’t nearly as impressive here as in some of the other games. The B580 is about 11% better than the B570 here, with the RTX 4060’s 80 FPS AVG putting it 20% improved in average FPS, plus a significant uplift in 0.1% lows to represent smoother frametime pacing. The RX 7600 outperforms both the RTX 4060 and B570, including in lows.", "Let’s move on to Cyberpunk: Phantom Liberty at 1440p.", "In this test, the B570 ran at 46 FPS AVG, with the B580 at 54 FPS AVG. The B580’s lead is about 16%, which is consistent with other high load scenarios; in fact, the B580 bordered on the RTX 4070 in this test, which we didn’t see happen elsewhere but which has consistently happened in this game. Its lows aren’t nearly as good as what the RTX 4070 offers (at 50 FPS 0.1% to 31 FPS), but this was still a good showing for Battlemage.", "The B570 reinforces that, functionally tying in average with the RX 6700 XT (watch ", "). This is an impressive feat. For both, it’s the memory bandwidth benefitting the cards here. Unfortunately, the low pacing just isn’t as good on the B570 as its neighboring devices, including the larger config A750. The B570 leads the 4060 by 18% here in a staggering flip favoring Battlemage for averages, again with the caveat of the lows being better on NVIDIA.", "At 1080p, the B570 ran at 71 FPS AVG, with the B580 sustaining a 13% uplift in average framerate. Battlemage still has worse lows than neighbors. At this resolution, the RTX 4060 begins to encroach on B570 and functionally ties it in average framerate while offering substantially improved frame pacing behavior. The RX 7600 is the same, roughly tied with the RTX 4060 and overall a better experience than the B570.", "Black Myth: Wukong is up next, tested at 1080p/high first. With these settings, the B570 maintains about 40 FPS AVG with lows around or below 30 FPS averaged. This has the RX 6600 XT (watch ", ") and RTX 3060 both above the B570, with the B570 above the RX 6600 non-XT (watch ", ") and RTX 2060. The B580’s 46 FPS AVG gives it a lead of 15%, with the RX 7600 16% ahead and RTX 4060 (at 54 FPS AVG) ahead of the B570 by 36%. That’s a huge lead for the 4060.", "At 1440p, the B570 is reduced to 30 FPS AVG. This gives the RTX 4060 a 22% lead, with the B580’s 35 FPS about 15% ahead.", "Dragon’s Dogma 2 is up next, first at 1440p/Max without RT. In this test, the B580 sticks to a 15% lead over the B570, so that’s consistent. The RTX 4060 leads the B580 and the B570 alike, with the RX 7600 about tied with the RTX 4060 and within run-to-run variance. The B570 is not particularly strong here. It’s about the same as the 3060 and outperforms the RX 6600. The price is noteworthy, although the B580 is overall more competitive in raw performance. In the least, lows are comparable in this test to non-Intel parts.", "At 1080p, performance falls overall as compared to competition. This is consistent with other tests. The gap from the B570 to the B580 remains 15%, with the 4060 now leading the B570 by 30% and the B580 by 7%. AMD’s RX 7600 also holds a similar lead.", "Dying Light 2 is up now. At 1440p, the B570 ran at 53 FPS AVG in what’s one of the strongest relative showings unbound for the card. This has it ahead of the RTX 4060 by 8%. Lows are also better, which is important for Arc. The lead over the RX 7600 is 13%. As for the B580, Intel’s $250 baseline model is about 18.6% ahead of the B570 here.", "At 1080p, the B580 maintained an 18.7% advantage at 87 FPS to 73 FPS AVG over the B570. The RTX 4060 lands between the two and is closer to the B570. Intel has marginally better 0.1% low averages here. The RX 7600 is roughly tied with the B570 in this test.", "We’re moving on to ray tracing now, tested with the unbound configuration. We’ll keep this as focused as possible. These tests are not comparable to the rasterization performance, especially as some settings (such as upscaling) may change.", "In Resident Evil 4 at 4K with RT and FSR, the B570 ran at 43 FPS AVG and with lows overall acceptable for its average. That has it ahead of the RTX 4060 in a strong showing for Intel. The B580 leads the B570 by 16%, which puts it functionally identical in performance to the ", ".", "At 1440p, the B570 ran at 66 FPS AVG and tied with the RX 7600 in every metric. Considering the B570’s price advantage at time of writing, that’s a competitive spot to be. The RTX 4060 leads the B570 by 8%, flipping from what we saw at the higher resolution and consistent with knowledge that Arc disproportionately scales better at higher resolution. The B580 is 15% ahead of the B570 here.", "At 1080p, the B570 ran at 81 FPS AVG. The RX 7600 now slightly outperforms it. Realistically, these are the same perceived performance, but lower resolution performance scaling remains stronger on NVIDIA and AMD. The RTX 4060 is now up at 95 FPS AVG, a lead over the B570 of 17%. The B580 is about tied with the 4060.", "Dying Light 2 with RT is up now. At 1080p, the B570 ran at 55 FPS AVG and held proportional lows, which is what we want. These results have it close enough to the RTX 4060 that they’re experientially the same. The RTX 4060 has a lead of 5% over the B570, with the B580 leading both at 65 FPS AVG. The B580’s average framerate is 18% higher than the B570 in a notable distinction. The RX 7600 lands below all of these, closer to the RTX 3060 and below the ", ". Intel’s Arc has overall strong RT performance in this title.", "In Dragon’s Dogma 2 with RT and at 1080p, the B570 ran at 39 FPS AVG. Unfortunately for Intel, this is one of its worst relative results. Ray tracing in this game is hard for the Intel cards. They don’t maintain the scaling from elsewhere when tested against the 7600 or RTX 4060 here.", "At 1440p, the B570 holds a 31 FPS AVG, the B580 a 36 FPS AVG, and the 7600 and 4060 are both just under 40 FPS AVG. Again, Intel is disproportionately disfavored in this test set.", "Cyberpunk with RT Medium is next. Battlemage remains super competitive here, with the B570 performing better than the RTX 4060. The average framerate is about the same, but the RTX 4060 suffers from wildly inconsistent frametimes in this test. We showed that in the ", " with a frametime plot, where the 4060 was spiky as a result of its VRAM limitations.", "The B580 keeps its 16% lead over the B570 in this test, with both outdoing the RTX 4060. The ", " even struggles in this, also suffering from inconsistent run-to-run variance and low performance for 0.1%. AMD has problems of its own, mostly just that it’s unable to compete in this test. The RX 7600 is down under 30 FPS AVG. At this price point, Battlemage is actually the best in this specific test and setup.", "Black Myth: Wukong is up now. This is one of our experimental charts. This designation is reserved for charts where we’re still evaluating the methodology and the accuracy, and so you shouldn’t assign as much weight to these since we are still leaving open the possibility of some sort of test limitation or issue.", "As it stands now, the B570 lands between the ", " and A580 with RT. The B580 is about the same as the ", " (watch ", "), with the B570 outperforming the RX 7600, so both are competitive with AMD. NVIDIA is up in orbit though with this game, with the RTX 4060 up at 52 FPS AVG in this test with these settings.", "Efficiency testing is up next. This is also a part of our suite of experimental tests, meaning we are still developing methods and that there is more room than typical for possible error or future revisions. This testing is done with an Elmor Labs PMD2 that has been calibrated personally by Elmor on our request. Testing includes both PCIe slot and PCIe cable power consumption, but excludes all other power, including the CPU.", "In idle testing, Intel Arc remains power hungry as compared to its competition. Using our test platform as configured for benchmarking, the B570 pulled about 30W idle. The B580 was around 35W. This is overall high.", "Baldur’s Gate 3 at 1440p shows FPS/W, meaning that higher framerate and lower power will create the most efficient result. Higher is better.", "The most efficient device here so far is the 4060 Ti of those tested. The B580 was in the middle of the pack, at 0.52 FPS/W. That had it between the 6600 series. The B570 is more efficient than the B580, at 0.55 FPS/W and below the RX 7800 XT.", "Final Fantasy 14 at 1440p is an OK showing for the B570. At 0.54 FPS/W, it’s near the RTX 4060 and better than the B580. This is an OK spot to be in for Intel.", "At 1080p, the B570 produces 0.81 FPS/W and sits again below the RTX 4060 and above the B580 and ", ". Against AMD, Intel is looking good, but NVIDIA maintains its advantage here.", "In Black Myth at 1080p, the B570 sits between the RTX 4060 and B580 again. Performance is acceptable overall and far improved from the A-series, like the A580 or A770.", "Cyberpunk is the last one. This is a pretty good showing for Intel: The B570 isn’t tied with the RTX 4060, but it’s getting a lot closer. The 0.28 FPS/W result is far improved over the 7800 XT and puts it in 4th of the devices tested so far. Note that the ", " (watch ", ") looks inefficient here as it is becoming bound by other components at this resolution.", "Providing some highlights, our ", " conclusion generally feels very similar to our conclusion with the ", " in that Intel has definitely improved over Alchemist. The ", " and ", " are often outperforming the ", " and ", ", which are larger configs, especially the ", ". That’s a good place for Intel to be against itself. Against the competition, there’s a lot of trading back and forth. There are some games where the B570 is similar to or slightly exceeds the ", ", but there are situations where the opposite is true. The trend that persists is that the higher the resolution is, regardless of the discussion around driver overhead, the Battlemage series cards will typically either gain on the competition or pull away from them, depending on where they started. You could also look at it the other way and say that as you approach lower resolutions like 1080p, results get closer together, and many times they’ll trade blows. ", "Like with our ", ", we didn’t experience any spectacular failures and crashes this time. Compared to Alchemist, the card is far improved. While NVIDIA’s drivers are known to be the most stable, Intel is certainly improving here.", "In terms of value, the B580 remains a very competitive price, and the B570 is similar.  On average in our results, the B580 tends to be about 15-16% better than the B570. At the upper end of that, we’ll see about a 18.7-19% advantage for the B580 over the B570. At the lower-end, we’ll see about a 10% gain or so. That performance difference largely aligns with the price difference between the 2 cards with the B580 going for roughly $250 vs the B570’s roughly $220 price."]},
{"title": " NVIDIA GeForce RTX 5080 Founders Edition Review & Benchmarks vs 5090, 7900 XTX, 4080, & More", "paragraph": ["NVIDIA GeForce RTX 5080 Founders Edition Review & Benchmarks vs 5090, 7900 XTX, 4080, & More", "Last Updated: ", "The Highlights", "We’re going to provide the bottom-line up front: The ", " (Be mindful of scalped prices) is anywhere from 30% to 68.9% better than the ", " (Be mindful of scalped prices) at 4K, depending on game, with results commonly in the 45-55% range. Against the ", " of similar price, the ", " (Be mindful of scalped prices) is within striking distance. They are commonly within 10% of each other. As for the generational gain of the 5080 vs. the ", ", it depends on the game. We saw 16%-20% in some tests, but we also had several results as low as 7-10%, which is about as boring as possible. ", "There’s a ton more nuance to get into, but that gives you some expectations in case you got what you needed and want to dip out. One of the more interesting tests we’ll be getting into though will be efficiency, where the RTX 5080 ends up potentially making a case for itself more than the power-hungry 5090 did. Its lower power budget helps there. The thermal testing is also interesting, considering the 5080 FE drops to paste rather than liquid metal and also makes changes to the heatsink itself.", "Steve Burke", "Patrick Lathan", "Mike Gaglione", "Jeremy Clayton", "Tim Phetdara", "Jimmy Thang", "We’re keeping this review really simple and short (by our standards) today. ", "First up, we have to disclose some office gambling behind the scenes. Jimmy has bet Jeremy that if the 5080 can beat the ", " (Be mindful of scalped prices) at any one benchmark, he’s going to get some free tater tots. ", "We’ll quickly cover pricing.", "The NVIDIA RTX 5080 has an MSRP of $1,000 and launches on January 30th, along with the $2,000 MSRP RTX 5090. ", "The 5070 Ti at $750 and 5070 at $550 will follow in February. Pre-launch pricing on Best Buy indicates that MSRP options will be slim outside of the NVIDIA Founders Edition, so adjust your personal value assessment based on what they actually show up for on launch day. The most expensive one we can see right now is $1,400 – and we’d say don’t buy that one.", "The previous generation RTX 4080 ", " (watch ", ") following the infamous “", "” of the “4080 12GB” – which actually became the ", " (Be mindful of scalped prices). More recently, the ", " (Be mindful of scalped prices) launched at $1,000, providing a value increase despite its nearly indistinguishable performance from the base ", ".", "AMD’s Radeon ", " is the closest price competition for the 5080, which currently starts as low as $830 but is more commonly around $930. Down from that is the ", ", ranging from $650 to $710 and in a decidedly lower price bracket. AMD says its 9070 series cards will be arriving in March.", "Intel GPUs haven’t scaled up to this market category yet – that’s a hopeful “yet,” for the record.", "And now for a quick overview of the basic specs. For the full details, check out our ", " of these cards.", "The Blackwell architecture-based RTX 5080 has 10752 CUDA cores and 16GB of GDDR7 on a 256-bit bus. These specs are way down from the 5090’s configuration – almost exactly half – making for probably the biggest gap there’s ever been between the top 2 tiers on launch day.", "The RTX 5080 is also a PCIe Gen5 card, but as our recent ", ", it barely makes a difference at all in games to run on Gen4 – or even Gen3.", "This review will again focus on high-end GPUs, and you can see our test methodology ", ". As a reminder, our site is free of third-party ads and contains our game settings and test bench. To see the low-end, check out our ", ".", "Here’s the thermal chart.", "Under a full workload for the GPU, the RTX 5080’s temperature with auto settings landed at 65-66 degrees Celsius for the GPU. Considering the change to thermal paste from liquid metal, the real impact here to reduce the temperature is in the power consumption reduction. We’ll look at RPM as well, though.", "The memory temperature plotted at about 72-75 degrees Celsius for the 5080, which is well within the TjMax restrictions of the memory on the card, which should be about 105 degrees for that.", "As for 5080 fan speed, it held about 1,470-1,500 RPM. That makes its acoustic profile similar to what we saw in the ", ", so you can check that for noise samples and a frequency spectrum. It’s a little quieter overall.", "The 5090’s GPU temperature in this test was 72 degrees Celsius, with the 5090’s memory at 90 -- we weren’t happy about that, despite being within spec. Once in a hotbox case, that 90 degree result becomes a concern. Finally, the 5090’s fan ran about 100 RPM higher when left to its own devices, resulting in a 5080 FE, which despite moving away from liquid metal is not really at a disadvantage. It’s doing okay overall, especially because of the fact that the power consumption is down. ", "Frequency validation is up now. This is just to ensure the card is hitting at least the spec set by NVIDIA.", "The RTX 5080 clocks in this benchmark held relatively flat, although not perfectly flat, at around 2670 MHz. NVIDIA’s website claims 2.62 GHz boost clock, so it is technically exceeding the minimum spec.", "The RTX 4080 ran at about 2775 MHz in this benchmark, consistent with what we saw between the 5090 and 4090 (watch ", "). The frequency is higher on the 4080, but the architecture has changed and made this an indirect comparison.", "The RTX 5090 bounces around between 2475 to 2670 MHz or so, mostly landing below the 5080. It’s relatively common for the fuller configurations to run lower clocks, but higher core counts.", "Time to get into game testing. We’ll keep these short this time since the comparison is relatively simple.", "Final Fantasy 14 is up first and at 4K.", "The RTX 5080 landed at 112 FPS AVG, behind the RTX 4090’s 139 FPS AVG result and the 5090’s 182 FPS AVG result. That makes the 5090 faster than the 5080 by a massive 62%. ", "AMD’s ", " directly competes with the 5080, but does allow the 5080 a lead of just under 10 FPS in this benchmark. Lows are about the same between them.", "Against the 4080 and ", ", the 5080 is about 15% better.", "Generationally by name, the 3080 (watch ", ") held a 71 FPS AVG in this benchmark, yielding a 58% uplift to the 5080. The 2080 Ti’s (watch ", ") 54 FPS AVG gets basically doubled by the 5080.", "As a note, some of these charts have the 1070 (watch ", "), 1060 (watch ", "), 2060 (watch ", "), and other older cards on them. The 1080 Ti (watch ", ") hasn’t been rerun yet this year.", "At 1440p, the RTX 5080 held 217 FPS AVG against the 5090’s 317 FPS AVG. We’re not fully CPU-bound here, so the 5090 still has relatively high scaling at 46% ahead of the 5080. For the same comparison, the 4090 led the 4080 original by 36% and the Super by basically the same because they’re basically the same card.", "The 7900 XTX (watch ", ") remains neck-and-neck with the RTX 5080, with the two functionally identical from a player experience standpoint. The 5080 is technically ahead. The 7900 XTX is the strongest competition to the 5080 in this rasterized test when looking at pricing.", "The 4080 and ", " improve from about 200 FPS AVG to 217, or a relatively boring 8-9%.", "Down the stack, we have the ", " at 171 FPS AVG, the ", " at 151 FPS AVG, and the ", " at 150 FPS AVG. The generational comparison to the 3080’s 129 FPS AVG gives the 5080 a 68% improvement, a bit better than observed at 4K.", "Finally for Final Fantasy, 1080p has the 5090 at that same impressive 407 FPS number we mentioned last week, with the 5080 at 302 FPS AVG. Despite the heavier CPU load, the advantage remains 35% for the 5090 over the 5080; still, that’s nothing compared to what we saw at 4K.", "The 4090 leads the 5080 by 24%, at 376 FPS AVG to 302. The 7900 XTX is closer than ever to the 5080 and is tied in all practical senses. It’s looking good here, especially with the price, but this ignores ray tracing testing that tends to still favor NVIDIA.", "Black Myth: Wukong is up next, tested first at 4K and rasterized. This is a heavy workload for these cards, with the RTX 5090 at 86 FPS AVG and holding strong frametime pacing as indicated by the 1% and 0.1% lows. The RTX 4090 is next (at 67 FPS), followed by the RTX 5080 at 58 FPS AVG. This has the 4090 as 16% better than the 5080 and the 5090 as 48% better than the 5080.", "The RTX 4080 Super (read ", ") and 4080 are functionally identical and give the 5080 an underwhelming 6 FPS lead, which is about 12%. The 5080 also leads the 7900 XTX by 17%, with AMD’s card falling disproportionally behind in this test with its 49 FPS result. Lows on the 7900 XTX are commendable though and show impressive consistency.", "Strong prior-gen cards include the 3090 Ti (watch ", ") at 45 FPS AVG and 3080 at 36.6 FPS AVG, with the 3080 yielding an uplift of 57% to the RTX 5080 and similar for the 6950 XT (read ", ").", "At 1440p, the RTX 5090 leads the chart at 130 FPS AVG, making it 23% better than the 4090 and 34% better than the RTX 5080. ", "The 5080 and 4080 are disappointingly close at only a 9% improvement for the 5080. The lead over the 7900 XTX also reduces down to 13% here, with lower resolution drawing them closer.", "Noteworthy other cards include the 3090 Ti at 74 FPS AVG, the 7900 XT (read ", ") at 71 FPS AVG (which isn’t bad considering its price at various points in history), the 3080 at 62 FPS AVG, and the 2080 Ti at 45 FPS AVG.", "Scaling continued at 1080p, where the 5090 boosts to 160 FPS average from the 130 FPS result at 1440p. The RTX 5080 still trails the 4090, but they get close and the 4090’s advantage is reduced to 6%. ", "Generationally, the 5080 leads the 4080 by 7%, down from its lead of 9% at 1440p and 12% at 4K. The 7900 XTX still trails by about 10 FPS here. It’s a shame that AMD decided not to compete at the high-end this generation, as a generational step over the current XTX may have been a serious contender to the 5080. There’s still time though.", "Starfield is up at 4K. First, we have to address this absolute roast of a comment from our ", ". “I would like to correct one mistake GN made in this review, where they stated that there aren’t many reasons to play Starfield at 1080p but in actuality there aren’t many reasons to play this game at all.”", "Ouch. Well, anyway, at 4K, the RTX 5090 held 108 FPS AVG and led the 5080 by 41%. Not the best we’ve seen, but still a large gap. For reference, the 4090’s 92 FPS AVG led the 4080’s 71 FPS by 30%. Comparatively, that makes the gap between the last generation 90 and 80-class cards smaller than the current generation.", "Against the 4080, the 5080 is about 5 FPS improved. That’s not very exciting. NVIDIA’s angle will probably be pricing.", "The 7900 XTX actually defeats the 5080 on a technicality in this one as well, with frametime pacing equivalent between them and the average FPS functionally identical. There is no perceptible difference between these, which is a benefit to the 7900 XTX in this rasterized scenario.", "At 1440p, the 5090 climbs to 147 FPS AVG and leads the 5080’s 110 FPS result by 34%. That reduces the lead versus 4K. The 7900 XTX also climbs with a very slight but irrelevant victory over the 5080, with the lows identical when rounded. ", "Against the nearly perfectly matched 4080 and 4080 Super, the 5080 holds an unimpressive 2.5% lead. That’s not very exciting.", "Older cards worth highlighting include the 3080 FTW3 (RIP EVGA) at 72 FPS and 2080 Ti at 50 FPS AVG. AMD’s 7900 XT is also noteworthy for its performance when considering some of its historical pricing.", "At 1080p, the RTX 5080’s 132 FPS AVG gives the 4090 a lead of 17% and the 5090 a lead of 24%. The 5080 matches the 4080 equally here, with the 4080 Super within error -- just like its entire pointless existence, sort of like Starfield at 1080p.", "The XTX also nearly equals the 5080, although NVIDIA has an advantage on a technicality.", "Dragon’s Dogma 2 is up now, first at 4K rasterized.", "The RTX 5090 ran at 133 FPS AVG and held well-paced lows behind it. Its lead over the 4090’s 98 FPS is 35% here, with the lead over the 5080 at 57%. This is one of the largest gaps thus far. For comparison, the 4090 led the 4080 non-Super by 36%, meaning that the 4090 and 4080 were closer together than the 5090 and 5080 are to each other.", "The 7900 XTX’s 77 FPS AVG has it outperforming the 4080 cards and behind the 5080 card, which leads by 10%.", "The 3080 did OK in this test at 50 FPS AVG, with a 71% improvement to the 5080.", "1440p has the RTX 5080 at 134 FPS AVG, achieving 71% of the performance of the RTX 5090 at about 50% of the price. The RTX 4090 leads the 5080 again, this time by around 20 FPS.", "As for AMD, the 7900 XTX lands at 126 FPS AVG for a 10 FPS gap between the two cards. The 4080 lands at 122 FPS AVG, keeping the 5080 at 10% ahead.", "1080p has the cards crushed together, although there’s still a gap of 49 FPS between the 5090 and 5080. That’s 30%, which is a lot for 1080p, but this isn’t necessarily a scenario to plan for.", "The RTX 4080 is right next to the 5080. Although the gap is 10 FPS average, the reality is that very few people would notice 165 FPS vs. 156 FPS, particularly in this game.", "This is where we would test Cyberpunk: Phantom Liberty -- if it worked. We’ve had repeated issues with getting the 50-series cards to run Cyberpunk without some sort of game-level issue occurring where it just won’t launch or crashes. We had this with the 5090, but reinstalled the game and that fixed it. We can’t state for certain that it is a fault of the 50-series cards and not some other game update, especially as Cyberpunk has had so many problems over the years, but what we can say is that it continuously kept breaking. We removed it from this review until the game is more stable. Again, we’re not sure if it’s unique to these cards or not, but we know that Jay had similar issues in his testing.", "Dying Light 2 at 4K is next. The 5080 ran at 81 FPS AVG, giving the 4090 a 13% lead and the 5090 a 56% lead. That’s a large improvement for the 5090 over the 5080. The 4090 improved over the 4080 by less, at 36% here.", "The 5080 leads the 7900 XTX by 12% here, with the 7900 XTX’s 73 FPS AVG result landing between the 5080 and 4080. Speaking of, the 5080 leads the 4080 cards by about 21%.", "We’re seeing large gains from the 3080 to the 5080, as expected, with the 2080 Ti below even the 3080.", "At 1440p, the RTX 5080’s 149 FPS AVG puts it close to the 7900 XTX’s 141, with lows between them also comparable. The 5080 is advantaged, but that gap was larger at 4K. The 5090 also has its lead cut down to 45%; although still significant, the doubled price with the 5090 jeopardizes its value for anyone not using it in VRAM-intensive work scenarios.", "The 4080 cards were again almost identical, re-proving why we didn’t waste our time in that review. The 5080 leads them by 12%.", "At 1080p, the 5090 led the 5080 by 44%, which is really more impressive for the ", " (read ", ") than anything else. That is a gigantic gap when considering how any prior CPU we’ve used for these benches would be bottlenecking the top 2-3 cards. The 4090 also maintains a lead of 19% over the 5080. ", "In Resident Evil 4 at 4K, the RTX 5080 fell behind the 7900 XTX by 4 FPS. Lows are about the same, but advantaged on the 7900 XTX. The 5090’s lead over the 5080 is massive in this one, at 68.9% with these settings. That’s a huge gulf. Looking back, the 4090 led the 4080 by 47%. There are two main ways to look at this: One, the 5090 is just that good; two, the 5080 is just that unimpressive.", "To figure out which it is, we can compare the 5080 to the 4080. The improvement here is 19%. NVIDIA’s best argument for itself will be the price as compared to the original 4080. The 7900 XTX wins that argument in this particular game, though.", "At 1440p, the advantage in the 5090 over the 5080 is reduced to 56%, though that’s still a lot. The 4090 is still more than 50 frames per second faster than the 5080, with the 7900 XTX now 4% ahead. That’s not a huge gap, but considering the generational difference and price of the XTX, we remain disappointed that AMD has signaled it likely won’t launch a replacement this generation. Maybe they’ll reconsider.", "The 5080’s lead over the 4080 drops to just 11% here.", "We’re on to ray tracing testing now.", "Black Myth: Wukong is up first, with a caveat that this game is unbelievably NVIDIA favored. We have other RT tests that are more balanced, but this is one of the heaviest workloads and also happens to benefit NVIDIA. Cyberpunk would also fit that bill, but we removed it for the stability issues we mentioned.", "At 4K with FSR as defined in the chart title, the 5090 held 88 FPS AVG, the 4090 ran at 65 FPS AVG, and the 5080 ran at 59 FPS AVG. That sets a 15% lead over the 4080 FE’s 51 FPS AVG. ", "Some notables: The 3080 just can’t really handle these settings and is down at 28 FPS AVG. Jumping to the 4080 from the 3080 would be an 83% improvement, with the 5080 giving an uplift of 112% total from the 3080.", "Sadly, the 7900 XTX is worse than the 3080 in this benchmark.", "As for the 5090, it ran 51% higher framerate than the 5080 with these conditions. Sadly for Jimmy, the 5080 did not defeat the 4090 here -- but there’s hope.", "At 1080p but still with the same FSR settings, the 5080 operated at 122 FPS AVG and -- what’s that? -- the 5080 outperforms the 4090 in this one by 1.5 FPS AVG. No one said the win had to be meaningful and a win is a win -- and as soon as I reported the results, I heard they were considering a rematch with the 5070.", "The 5080 roughly matches the 4090 in this result, with the 5090 leading the 5080 by 30%. The 1080p restriction with FSR is what’s making this less exciting than typically.", "Dragon’s Dogma 2 with RT is up next. This one is more balanced.", "The RTX 5090 at 4K ran at 113 FPS AVG with maximum RT, which puts it 33% over the 4090 and 57% over the 5080. The 7900 XTX is much more competitive in this one than Black Myth, running at 66 FPS AVG and landing between the 4080 Super and 5080.", "The generational uplift is 16% from the 4080 FE to the 5080 FE. ", "At 1440p and still with RT, the 5080 held about a 7% lead over the 7900 XTX. That’s not bad for AMD’s last gen card in this game. As for the 4080 FE, the 5080 is about 10% ahead. Not very exciting for NVIDIA overall with the 5080 in this one. Let’s move on.", "At 1080p, the 5080’s 146 FPS AVG had it only about 9 FPS over the 4080. The 5090 still keeps a 33% lead over the 5080, despite slimming down versus the 4K result’s 57% gap.", "This isn’t that interesting, so let’s skip ahead.", "With ray tracing for Dying Light 2 and tested at 4K and upscaling, the RTX 5080 ran at 67 FPS AVG and trailed the 4090 by over 10 FPS, with the 5090 leading the 5080 by 63%. ", "Over the 4080, the 5080 leads by about 17%. The 7900 XTX is between the 3090 Ti and 4070 Ti (watch ", "), trailing the 4080, and obviously therefore trailing the 5080.", "At 1440p with RT and upscaling, the 5080’s 117 FPS AVG lands it 12% ahead of the 4080. The gap is shrinking here. The 7900 XTX trails somewhat significantly here and gives the 5080 an advantage of 35%.", "At 1080p, the 5090 proves that there’s still headroom in the CPU (impressively) with its 224 FPS AVG, leading the 5080 by 41%, but the 4080 and 5080 get squished together with only a 9% advantage to the 5080 between them.", "The 7900 XTX is closer to the 3090 Ti here, keeping the 5080 about 30% ahead.", "Finally for RT, Resident Evil 4 at 4K with upscaling is up. The RTX 5090 ran at 210 FPS AVG with these settings, or a 54% improvement over the 5080’s 136. The 7900 XTX is much more competitive here, with the title generally being a lightweight RT implementation. We keep it around for that reason: If we have a heavy one like Black Myth, it helps to balance representation with a light one. The 7900 XTX looks much better here than in other RT tests.", "The 4080’s 117-119 FPS AVG makes the scaling in the 5080 overall boring, unfortunately, with the improvement being hardly noticeable.", "Here’s 1440p. The 5080 jumps to 205 FPS AVG, the 5090 to 290 FPS AVG, and the 7900 XTX to 195. The XTX is still competitive here, especially given the price and generational differences; likewise, the 4080 still makes the 5080 relatively uninteresting. This feels like a sidegrade.", "Power efficiency testing is next, measured using power interposers and capturing only GPU power. We are not measuring total system power for this and instead isolate for the GPU. The PCIe slot is intercepted and measured as well.", "Idle power consumption is far better on the RTX 5080 than the RTX 5090. Keep in mind that idle power testing is very situational to the monitor, refresh rate, and power plans -- but our test setup is identical unit-to-unit, so that’s all that matters here. They are all under the same conditions.", "Under these conditions, the RTX 5080 was at 12.75W when idle on the desktop. This is close (but improved upon) the RTX 4080’s 15-16W idle power draw, both of which are far below the 4090’s 29W and 5090’s 46W power consumption. ", "Final Fantasy 14 at 4K had the RTX 5080 at the top of the chart for efficiency. Comparatively, this is a great result. Its 298W draw here leaves headroom in the TDP budget, with the relatively high framerate enabling it to outperform the 269W 4080 Super for efficiency and performance alike. It also outdoes the 5090, which scored 0.34 FPS/W. The 5080 significantly outdoes the RX 7900 XTX, which ran at 0.24 FPS/W and 430W.", "This appears to be a possible strong point for the RTX 5080.", "1440p gives us a lot more cards on the chart since we’ve tested more mid-range devices, but with the downside that the high-end devices scale their best at 4K. That means we lose some of the framerate scaling advantage.", "The 5080 is still tied for the most efficient on this chart after rounding, aligning with the 4080 Super as the most efficient GPU we’ve tested yet. It’s at 0.75 FPS/W while pulling 290W, up from the 268W of the 4080 Super but also up in framerate. The 4090 pulled 386W here, with the 5090 at 520W.", "For efficiency in F1 24 at 4K and with RT, the RTX 5080 ties the 4090 and is within reasonable variance of the 4090 and 4080 Super results. The 5080 pulled 330W in this test, putting it notably lower in power consumption than the RTX 5090’s 569W draw here, but still more than the 4080 Super’s 291W. The 7900 XTX is significantly less efficient in this particular workload, hampered in part by RT but also just by its 422W draw.", "Check back soon for our ITX testing with the FE cards and for transient power testing coming up. We’ll look at power excursions in that. We also have a story about MFG, or multi-frame generation, almost entirely complete and coming up. That’ll delve into NVIDIA’s new DLSS and frame generation tech in detail.", "Otherwise, that’s all the numbers for now. The quick recap is:", "With several partner models listed at $1,200 to $1,400 in pre-launch listings, the value isn’t compelling. We also continue to take issue with NVIDIA’s hugely misleading “benchmarks” on its website:", "The 5080 is shown as being 2x the speed of the ", " in several tests, but again, this has to do with its MFG 4X Mode that’s only available on the 50-series. We’re testing that. The boring range of 10% to maybe 20% in some situations is more common. We ranted about this in the ", " if you want more.", "This is why NVIDIA is pushing MFG so hard: The 5080 otherwise is a boring product generationally. When the gap is sometimes 10 FPS over the ", " at the same price, it’s just hard to get excited about. It seems like a tool to create 5090 sales.", "As for the bets of tater tots within the office, it looks like Jimmy wins this one. They’ll have a rematch for the 5070 and 4090."]},
{"title": " Fake Frames Tested | DLSS 4.0, MFG 4X, & NVIDIA's Misleading Review Guide", "paragraph": ["Fake Frames Tested | DLSS 4.0, MFG 4X, & NVIDIA's Misleading Review Guide", "Last Updated: ", "The Highlights", "As simply as possible, NVIDIA is being a dick. NVIDIA has inducted open-source software into its FrameView tool, made its own improvements without, as far as we can tell, contributing those same changes to the original source code base, and then distributed outdated information to the press in a 100+ page review guide talking about how to properly test its devices. While NVIDIA has some valid points in how to measure generated frames, the biggest counterpoint is that their statements are based on year-old software that already made a major shift away from the msBetweenPresents metric that NVIDIA is now contesting. The license allows NVIDIA to act this way, but it’s just not productive and can actually be detrimental to testing efforts. Intel has told us that NVIDIA is welcome to contribute to the PresentMon tool and play with everyone else, but NVIDIA is doing NVIDIA things.", "Steve Burke", "Patrick Lathan", "Vitalii Makhnovets", "Jimmy Thang", "As for why this is happening: It’s all relevant because of frame generation and multi-frame generation, which is the topic we’re digging into today. Whatever you want to call them -- generated frames, artificial frames, or “fake frames” -- they are very difficult to test and measure accurately. ", "We’re only scratching the surface of this complicated subject today. This article will first define what DLSS 4.0 actually is and what it’s inclusive of, we’ll cover benchmarking methodology concerns and our issues with NVIDIA’s framing of it (plus the things they get right), and then we’ll present some performance data evaluating NVIDIA’s new models. There is something interesting here, and we absolutely think frame generation is worth talking about as a smoothing method but it’s going to take a couple of stories to get through as it’s complicated. ", "Despite the problems we have with NVIDIA’s PresentMon framing, DLSS 4.0 is worth diving into. NVIDIA seems aware of how confusing the rollout of the new DLSS features is going to be, and its mix of DLSS version numbering and GPU generation support make it complicated to follow.", "You may have seen this chart before that details the feature set and what does and doesn’t work across various RTX series GPUs. Some of this is segmentation, some of it is hardware, some of it is potentially temporary segmentation that could be changed.", "Taking a step back, DLSS stands for Deep Learning Super Sampling. That name was already strange seven years ago when it was introduced, because supersampling usually means rendering above the native resolution of a display and downscaling. For example, rendering your game at 4K on a 1080 screen would result in an expensive but crisp image with excellent anti-aliasing. DLSS is upscaling, which is the opposite. For DLSS, NVIDIA trained an algorithm on sets of extremely high resolution screenshots on a per-game basis, and then used that algorithm for real-time upscaling: you could (for example) render your game at 1080 on a 4K screen and get a cheap but mostly okay-looking image. The use of high resolution screenshots for training is what made it kind-of-sort-of supersampling; DLSS is no longer trained per-game, but the name has stuck around.", "All of this was relatively straightforward until DLSS 3.0 came out in 2022 which introduced Optical Multi-Frame Generation. ", "OMFG continues NVIDIA’s propensity for initialisms like ", "AA. OMFG is ", " (later referred to as Frame Generation 2X or just plain Frame Generation, because now DLSS 4 has Multi Frame Generation). With this, the original functionality of DLSS was renamed DLSS Super Resolution. Now we're at a point where NVIDIA could recommend, for example, enabling Deep Learning Super Sampling Super Resolution Ultra Performance.", "As for Frame Generation, it falls under the DLSS umbrella even though it's not directly tied to supersampling or upscaling. DLSS 3.5 added ray reconstruction to the DLSS family, and now DLSS 4.0 has added Multi Frame Generation 3X and 4X and has changed the underlying model for the other DLSS features.", "So, DLSS 4, DLSS 3.5, DLSS 3, et al. are groups of features and updates. If a game has DLSS 4, that means it has some of the DLSS 4 features, most likely MFG, but not necessarily all of them.", "The ", " that with 50 series AI handles 15 out of every 16 pixels to multipl[y] frame rates by up to 8X are based on using the maximum 4X MFG setting with the DLSS Super Resolution set to Performance, which was formerly the minimum quality setting. That would mean that at 4K, one 1080 frame would be rendered for every four frames displayed.", "MFG is available for the 50-series cards; as of this writing, no other cards support MULTI Frame Generation. Frame generation can be supported elsewhere but MFG is unique to the 50 series right now. It’s also the centerpiece of NVIDIA’s misleading marketing slides claiming 2x performance gains of the ", " over the ", ".", "The misleading chart above is because MFG includes 4X (which is up to three AI frames for every one rendered) and 3X (up to two AI frames for one rendered) modes. The existing Frame Generation (2X) mode has been improved, but remains exclusive to 40-series and newer, and FG, in general, still only works in games that implement it.", "To paraphrase NVIDIA, the ", " combined four elements: a previous frame A, a current frame B, an “optical flow field generated by Ada’s Optical Flow Accelerator,” and data provided directly from the game engine about motion and other elements. Using these inputs, the card could throw together a so-called fake frame, or a generated one, between A and B at the cost of queueing up frame B for a little while. ", "Now of course, it’d be ridiculous and a fundamental misrepresentation of the nature of frame generation if you were to get on stage and say something untrue like ", "It doesn't extrapolate into the future, it interpolates (intelligently) into the past. This gets confusing if you think about it too much.", "This creates the feeling of a smoother framerate with some added latency, which is why NVIDIA Reflex has always been a mandatory setting when enabling Frame Generation, a feature that ", ". Reflex clears the render queue so that frames are delivered with as little latency as possible, which helps mitigate the latency inherent to frame generation. ", "Fundamentally, it seems that Frame Generation, in general, is not for turning low framerates into playable framerates: it's for turning playable framerates into high framerates. This is still true for MFG; as ", ", the acceptable input framerate is still about the same for 3X or 4X as it was for 2X. ", "Higher input rates mean fresher data for Frame Generation, smaller gaps to bridge, and less time to notice flaws. That’s the theory. MFG is still bridging the same gap between the newest rendered frame and the previous one, it's just doing it with up to three AI frames rather than one. On the plus side, this theoretically means that latency shouldn't be worse with MFG than with regular FG.", "If you have a 60Hz monitor, it appears that you are not the target audience. There's no point in using Frame Generation to boost past your monitor's refresh rate. That's not just our opinion: ", " at rates higher than the display refresh rate can reduce latency, but ", " frames at a higher rate is just wasting compute power on frames you won't see. This is why ", " have topped out around 240FPS.", "As for the Optical Flow Accelerator, with DLSS 4, Ada's hardware Optical Flow Accelerator is out of the picture. ", "DLSS 4 Frame Generation is solely handled by regular Tensor cores, which is why Digital Foundry ", " potentially coming to more cards. NVIDIA claims that the new model is faster and uses less VRAM, which makes it feel like the only point of the OFA was to make frame gen exclusive to the 40 series. MFG is not possible using the old model since it ", " ", "NVIDIA did confirm to us that Blackwell, which is the new architecture for the 50 series, does have a hardware OFA unit, and we presume that it'll be used for backwards compatibility with games that don't implement the new framegen model.", "Time to get into flip metering and some issues we’ve had with NVIDIA’s flawed understanding of PresentMon, plus NVIDIA’s stated reason for restricting MFG to the 50-series.", "NVIDIA has given two reasons for locking MFG to 50-series: first, the 5th generation Tensor cores are significantly improved, and second, Blackwell has hardware support for Flip Metering. ", "Flip Metering shifts responsibility for frame pacing from the CPU to the GPU driver in order to effectively pace out fake frames (or generated ones), which has become more important with MFG. This takes place immediately prior to scanout. Again, Blackwell's implementation of Flip Metering is hardware based, so it can't be ported to 40-series as-is.", "This is where NVIDIA’s flawed understanding of PresentMon comes in.", "PresentMon is a fully open-source utility that is maintained by Intel, but can be contributed to by anybody. Other companies like AMD have worked with Intel on maintaining and advancing parts of PresentMon. ", "PresentMon measures performance. It captures data. It’s able to work at a lower level with Windows and helps to analyze the frame time, framerate performance, animation error, and more. It is the key backbone to most of the performance analysis software that’s out there. Even if you don’t use PresentMon, if you’re an enthusiast who tries to measure your performance, you might use something else that does. CapFrameX is a reskin of PresentMon, and RTSS also appears to use PresentMon. We just use the core command line version of it, but recently helped JayzTwoCents start using the user interface version of PresentMon.", "Intel’s ", " several times to explain advancements to it and how it works. It is one of the most trusted testing utilities for measuring component performance, and, again, its open source nature is critical to that, especially as it’s maintained by Intel. ", "Unfortunately, NVIDIA has decided not to contribute to and maintain PresentMon in a significant way, and that positions us like a marriage counselor talking to Intel on the PresentMon side and NVIDIA on the “they-don’t-understand-how-it-works-side-but-they-sure-have-some-opinions” side. NVIDIA has instead taken an ancient version of PresentMon core and inducted it into its FrameView application. It then proceeded to make adjustments to that code, but as far as we can tell, NVIDIA has elected not to contribute to the open-source project it took from. This has resulted in a bifurcation of major versions between applications. This is a big problem and NVIDIA is sort of at the heart of it. ", "Related to Flip Metering, NVIDIA has pushed hard for a switch from PresentMon's MsBetweenPresents metric to the MsBetweenDisplayChange metric. While we understand why they’re trying to do this, we think this is a flawed premise. That’s because PresentMon already switched off of MsBetweenPresents, and in fact, began doing so around a year ago when Tom Petersen joined us to talk about the change. NVIDIA is pushing for a change that everyone already made except for them, as they were running an older version of PresentMon in their FrameView tool. That’d be like saying “Y’know, I think it’s about time we consider electricity instead of candles.”", "We think NVIDIA’s FrameView software is most likely based on PresentMon 1.10.0 from February of 2024, based on inspecting the results output.", "The current version of PresentMon (2.3.0) no longer supports either of the metrics NVIDIA is talking about under those names, switching instead to a FrameTime metric based on CPUBusy and CPUWait (which NVIDIA says is also inadequate). ", "MsBetweenPresents is an ancient metric inherited from ", ", which was basically the only frametime tracking tool around when PresentMon began development. It tracks the time between Present calls, which tell the graphics engine to finish up and put the frame on the screen, but it doesn't reflect animation time or time on screen. ", "MsBetweenDisplayChange ALSO doesn't track animation time. ", " How long the previous frame was displayed before this Present() was displayed, in milliseconds versus msBetweenPresents, which was the time between this Present() call and the previous one, in milliseconds. In contrast, the current PresentMon FrameTime metric is the best estimate of the time between the game taking snapshots of its physics engine. ", "Despite NVIDIA’s decision to not participate in supporting the tool everyone else does and instead maintain its own out-of-date toys, it does have one good point in all of this. The valid part is that situations like MFG have a problem, where there's external frame metering very late in the pipeline that may make the on-screen framerate smoother than MsBetweenPresents would imply. Using MsBetweenDisplayChange does allow NVIDIA's flip metering to be taken into account, so it makes sense to use it specifically for tracking NVIDIA’s frame generation.", "But we don’t think MsBetweenDisplayChange is sufficient, either, and that’s what NVIDIA is telling everyone to use.", "We mentioned animation error, which we’ve talked about with Tom Petersen in the past: just because frames are delivered at an even pace doesn't mean that the things being shown in those frames have been animated at an even pace. Animation times and flip times must be consistent. ", "This was a problem with SLI and CrossFire, where frames could be delivered at a constant rate, but could appear stuttery anyway because animation timing didn't line up with the flip timing. Ideally, in the long term, we'd move towards using FPS as a metric for raw horsepower and animation error as a metric for smoothness so to speak, but that's outside the scope of this piece.", "A more specific issue, frankly put, is that NVIDIA is being a dick about PresentMon, an open-source tool, claiming that FrameView has solved certain bugs to make MsBetweenDisplayChange accurate in more scenarios without communicating those changes to the developers. That leaves us with a situation where we're forced to use NVIDIA's version of an open-source tool that NVIDIA has closed off, to then test NVIDIA's hardware because of unspecified updates that NVIDIA has made with supposedly bug fixes that NVIDIA has not explicitly disclosed. You can see why there are a lot of problems measuring an NVIDIA product. This also calls the entirety of the premise into question, as there are no external means to inspect NVIDIA’s tools. ", "This isn’t illegal under PresentMon's current license, but it is rude. AMD is even currently collaborating to support tracking Fluid Motion Frames, but NVIDIA is not.", "Anyway, let’s get back to MFG and DLSS. We’ll talk about image enhancements next.", "NVIDIA is switching away from Convolutional Neural Networks to a transformer model for DLSS (rolling out as a beta). This change affects all RTX cards. The gist is that the new model should have a better understanding of which areas of the screen are important, and therefore, according to the reviewer’s guide, has greater stability, reduced ghosting, higher detail in motion, and smoother edges in a scene. This is an image quality improvement, not a performance improvement, and may actually worsen performance a bit. NVIDIA notes that While Ada and Blackwell both benefit from this new model, the Transformer model is often more performant on Blackwell. ", "We'll show our own results later in this piece.", "For each of the DLSS4 features we've discussed—the new frame generation model, multi frame generation, and the transformer model for DLSS SR and RR—there are now driver-level overrides. For example, with a game that supported the original FG and a card that supports MFG, you could use the driver to force MFG. This is a whitelist system, so not every game will support overriding, and the ones that do won't necessarily have every DLSS 4 feature available. We don't expect this to get a ton of use; the interface is (currently) confusing, and we'd assume that most developers willing to go through the hassle of getting whitelisted for overrides will just update their games.", "There are plenty of other new features that were announced alongside the 50 series, but we're just talking about DLSS here. NVIDIA Reflex isn't technically DLSS, but it is a dependency, so we're throwing it in. Reflex's new feature is ", " which is similar to the reprojection tech that's been used in VR. It checks mouse input at the last possible moment, and if it detects an update, it shifts the camera over to approximate the correct movement. The unrendered pixels are then painted in. Whether or not this represents a literal reduction in latency is arguable, but it should ", " like it.", "Time to get into performance testing. We have a couple groups of comparisons here. The primary objective is to compare the impact of the old and new models that NVIDIA is using, not to compare the RTX 4090 to the RTX 5090. There are a lot of challenges with analyzing so-called “fake” frames though, one of which is that it isn’t clear that the amount of generated frames remains consistent. Another challenge is that, although we will have a control on the charts for “pure” frames, generated frames aren’t a like-for-like comparison by the very nature of them not being the same as standard rendered frames.", "Our test bench information is detailed on the website, which is free of third-party ads and includes the hardware configuration. You can check that out for the hardware if you want to know what we’re using.", "Another important thing: We're not covering image quality in this piece -- that’ll come later -- but we will go over performance numbers. Image quality is an entirely different deep-dive. ", "NVIDIA provided six games to press with the new DLSS 4 features available. We dug through them to find some way to isolate features for testing. Four of the games had native feature implementations and two were whitelisted for driver overrides. ", "As mentioned earlier, we were forced to use FrameView for all benchmarks involving frame generation. For the purposes of these tests, we're including generated frames in our averages.", "Our first task was to compare performance of the old framegen model to the new one on both a 4090 and a 5090. The company has not claimed that image quality will change or improve with the new method. The only two games available to us with BOTH models were Marvel Rivals and Dragon Age: The Veilguard, both through driver overrides, but we were also able to make a usable comparison with Hogwarts Legacy. We’re using the games that work with it.", "For this set of charts, we’re focusing on comparing the upcoming red and orange bars for the impact of different models. The blue bar is all real frames, meaning the comparison is not like-for-like with the generated frames. ", "We’re just going to present the numbers and talk about them. It’s a very tricky subject, which benefits NVIDIA because it makes it hard to evaluate, but that is the nature of artificially generated data.", "Here’s Dragon Age: The Veilguard at 4K with maximum settings. We manually increased it above the highest preset here. DLSS SR and AA were not used for these tests and Reflex was enabled even for the control runs without frame generation. ", "Each card should be compared against itself. We’ll start on the 4090. The new model with FG2X on the 4090 ran at 107 FPS AVG against the old model’s result of 100.7 FPS AVG, an increase in fake+real frame perceived performance of 6.26%. If we were to filter out the fake frames to only real frames to evaluate the overhead, then that percentage change comes down.", "The RTX 5090 ran at 143.4 FPS AVG on the new model and 136.4 on the old model, an improvement in the as-captured result of 5.1% uplift in perceived performance. Again, there’s more nuance if you filter out the artificial frames.", "Hogwarts Legacy is up next. This one didn't have a driver-level override for the frame generation model, so we had to control that variable by switching back and forth from the press build, otherwise the results would be invalid. But, complicating it more, RT features were updated in the press build, so we disabled all RT effects for these tests. We first compared the public and press versions of the game with frame generation off to ensure that the comparison is even valid. Disabling RT effectively equalized performance between the versions (107.3 to 106.9 is within error, as is 151.9 to 152.6), making them valid for comparison.", "That brings us to this chart: In Hogwarts Legacy, the 4090 had a 14% uplift in (perceived) performance from 153 FPS up to 175 FPS average with the new model, while the 5090 had a 10% uplift from 224 to 247 FPS average.", "Working backwards based on the output framerates, we can deduce that the new frame generation model is easier on the GPU. This allows more resources to be dedicated to rendering, enables a higher input framerate, and that then comes back around to benefiting frame generation. The other piece of the puzzle will be determining whether subjective image quality has changed in a later story, but from a performance perspective, switching away from the OFA is better.", "The second feature we tested in isolation was the old Convolutional Neural Network model versus the new Transformer model. This affects both DLSS Super Resolution and DLSS Ray Reconstruction; we were able to test SR in isolation, but RR (ray reconstruction) requires SR to be enabled.", "First up is Veilguard, again using the driver override feature for A:B testing. Ray reconstruction isn't an available feature in this game, so this is purely a super resolution test. We used the DLSS SR Quality preset which, given the 4K output resolution, means a 2560x1440 render resolution. ", "On the 4090, performance suffered using the new Transformer model versus the older CNN model, with the older model retaining a 5% performance advantage. The No DLSS control result is included for context, but that's not the comparison we're focusing on here.", "On the 5090, the older CNN model had a similar performance advantage of 4%, averaging 105 FPS versus 101 with the Transformer model.", "The difference between performance degradation on the two cards is miniscule, but these results would technically align with NVIDIA's claim about the Transformer model being more performant on Blackwell. The differences are too small here to make that a firm conclusion. What we can say with certainty is that the new model is a little lower performance than the old one in Veilguard.", "Cyberpunk 2077: “Crashing Liberty” is up next. When it works, it has ray reconstruction as a feature, so we were able to test both DLSS SR alone and DLSS SR and RR in combination…when it worked. As noted during our ", ", it's possible for ray reconstruction to raise or lower performance depending on the systems that it replaces in a given game; however, it continues to have no significant performance impact in Cyberpunk. We recorded results without RR, but we cut them from these charts because it made no difference.", "The losses aren't huge: the 4090 with DLSS and ray reconstruction dropped from 71 FPS with CNN to 68 FPS with the transformer model, a 5% advantage for the old model in terms of performance.", "On the 5090, switching to the new model dropped average FPS from 92 to 86, a 7% performance advantage for the older model on this card. Anecdotally, we’ve noticed that the newer model reduces ghosting and visibly improves the appearance of animated textures in Cyberpunk, so this level of performance loss is likely an acceptable tradeoff.", "Because the new DLSS SR/RR model comes with a performance hit (unlike the straight upgrade to FG), we expect many games updated to support the model will take the same approach as Cyberpunk (hopefully without the crashing) and offer a choice between CNN and Transformer in settings. Hopefully those toggles actually work: we always relaunch games between settings changes, but we noticed that relaunching Cyberpunk with our specific settings would switch to the Transformer model invisibly while still claiming to use CNN in the menu. We were forced to toggle CNN off and on from inside the game in order to test it reliably. All of this was observed in the public 2.21 Steam release. This is an extremely subtle bug that wasted a ton of our time.", "Our final performance comparisons are frame pacing with Frame Generation enabled. This comes with two major caveats: first, we're using FrameView for logging, so the plotted frametimes are MsBetweenDisplayChange. Second, we don't have a way to toggle frame metering on the 5090, so we're forced to make a general comparison between FG 2X behavior on the 4090 (without frame metering) versus the 5090 (with frame metering). Ideally, we'd run FG 4X on the 5090 alone, with versus without frame metering. ", "The new framegen model was used for these comparisons.", "Here’s Dragon Age again.", "As always, making a comparative plot is complicated by the fact that the higher-performance card renders more frames. The 4090's plot shows the kind of up-and-down variation between every frame that might be expected from frame generation, with the majority of the pass oscillating up and down by 1-2ms on each individual frame. That may not be enough to cause a visible problem in this title, but it's a good illustration of the problem that NVIDIA is trying to address. The 5090 actually had visibly wider deviations from the average on the whole, but the up-and-down deviations didn't occur between every single consecutive frame. We’d want to see much flatter lines, ideally. Most people notice excursions at 8-12ms, based on prior interviews we’ve done, but you’d still want a flatter line ideally.", "Hogwarts Legacy showed results closer to what NVIDIA promised with frame metering. The 4090 still exhibits some up-and-down behavior between individual frames as real and fake frames alternate, while the 5090's frametimes are clearly more stable. The game also renders at a very high framerate, though, so the actual time delta in milliseconds between frames is miniscule even on the 4090. The 5090 also doesn't completely eliminate the occasional frametime spike, with a particularly large one shown at the end of this pass.", "Breaking down DLSS 4 into its individual components: the new frame generation model performs better broadly speaking and there shouldn't be a tradeoff in visual fidelity, although we haven't confirmed that. The updated model also theoretically makes single frame generation possible on other Tensor-equipped RTX cards, but NVIDIA has made no indication that it plans to support that.", "The new Transformer model for DLSS SR and RR performs worse than the older CNN model, but it should also look better, and our anecdotal experience so far suggests that it's worth it. We may follow up with an in-depth visual comparison.", "Frame pacing with frame generation enabled should be improved versus 40 series, but this would mostly apply to MFG, and 40 series can't do MFG. Still, our extremely limited testing does show that frame metering has an effect.", "We'd also like to really drive home that the ideal scenario for frame gen is to make already acceptable framerates into extra-smooth framerates on high refresh displays, like the 4K 240Hz OLEDs that have been coming out recently. Sometimes NVIDIA seems aware of this, and other times it claims that the 5070 is equivalent to a 4090 because of MFG. If you have bad performance, Frame Generation may disappoint you; DLSS Super Resolution is a more helpful option in that situation."]},
{"title": " NVIDIA RTX 5090 PCIe 5.0 vs. 4.0 vs. 3.0 x16 Scaling Benchmarks", "paragraph": ["NVIDIA RTX 5090 PCIe 5.0 vs. 4.0 vs. 3.0 x16 Scaling Benchmarks", "Last Updated: ", "The Highlights", "Out of respect for your time: The answer is 1 to 4%. It’s 1-4% different between PCIe Gen5 and PCIe Gen3 x16 on the ", ". Gen4 x16 and Gen5 x16 are about equal to each other, with some instances of Gen3 x16 (which is comparable to Gen4 x8 in bandwidth) yielding about a 4% advantage to Gen5 x16.", "So that’s the bottom-line up front and save you the time, but we’ll also make this story simple while hopefully giving some background on PCIe.", "Steve Burke", "Mike Gaglione", "Tim Phetdara", "Jimmy Thang", "These stories are always really fun experiments and some of the simplest we do. Today, we’re testing PCIe generation impact on the RTX 5090 (read ", "). We love doing these stories because they allow us to look at the future of the interface and protocol to try and see where it might start limiting high-end devices. Historically, we’ve seen about a 1-3% swing from the newest generation to the prior one when at the front-edge of a new PCIe generation. The RTX 5090 is unique for being the first super high-end consumer video card with PCIe Gen5 support natively, so we’ll test scaling from Gen3, Gen4, and Gen5.", "In most scenarios, anyone spending $2,000 on a GPU won’t be running PCIe Gen3 -- but it’s still an interesting test, and PCIe Gen3 x16 would be comparable in maximum theoretical bandwidth to PCIe Gen4 x8, so it still helps there.", "This should be a quick and fun look at PCIe scaling.", "We don’t want to judge you if you’re a super gamer who would be hindered by a 1-4% loss, but most people aren’t going to notice.", "Because the content is so simple and you have the answer already, we’re going to do some explainer basics for anyone brushing up on how it all works. ", "Here’s a ", " showing the maximum theoretical bandwidth of different PCIe generations. Wikipedia has always been great for this. The PCIe generation technically goes up to a planned Gen7 this year, but currently, the highest-end supported on consumer motherboards is PCIe Gen5. ", "Each PCIe slot has a certain amount of electrical lanes and a certain physical slot size. Although some slots look like they are full x16 length, they may be x8 wiring. In almost every modern motherboard relevant to our audience though, the first PCIe slot will be fully wired for 16 lanes. ", "PCIe Gen5 on transfers 32 GT/s per lane, which means x16 is about 63 GB/s and x8 is 31.5GB/s. If we shift the highlights right one column and up one row, you’ll see that PCIe Gen4’s x8 speed is the same as PCIe Gen5’s x4 speed and that PCIe Gen4’s x16 speed is the same as PCIe Gen5’s x8 speed for the maximum theoretical bandwidth. This pattern of doubling continues all the way up, so PCIe Gen3 x16 is the same as PCIe Gen4 x8 in maximum theoretical bandwidth.", "That simplifies things for us, because that means testing PCIe Gen3 x16 will achieve effectively the same thing as testing PCIe Gen4 x8, so we can cut our testing in half since the speed mostly just doubles generationally.", "Another thing to be aware of is that interfaces and protocols often are not the limiter, but the device. Unless you’re buying the newest device on an outgoing interface, like SATA or AGP at some point, the device will typically be incapable of saturating the link it’s connected to.", "PCIe support needs to match on 3 devices in order to utilize the maximum supported generation on any one link in the chain.", "For PCIe Gen5 support on the RTX 5090 to be actually utilized, you’d need the motherboard, GPU, and CPU to all support the same maximum PCIe generation. In this block diagram above of a CPU, you can see that there are at least 16 PEG lanes, or PCIe Graphics lanes, available to the motherboard for use with the GPU. ", "These lanes peel straight off of the CPU and don’t go through the chipset first and are often assigned to the top PCIe slot.", "That slot then needs to actually be a PCIe Gen5 slot, in this example. Finally, the GPU itself needs to be PCIe Gen5.", "All of these things can work together without being the same generation. You can use a Gen3 motherboard with a Gen5 card or a Gen5 motherboard with a Gen3 card. They will still work through the interface, but the maximum theoretical bandwidth will cap at the slowest speed of any device linked in the chain.", "While we’re on the subject, a common misconception is that a full-length PCIe slot is automatically going to be a x16 slot. First, a lot of PCIe slots are not electrically wired for x16. You can see this by looking into the slot for the pins. If you see half populated, it’s x8. If you see even fewer, it’s x4, but full-length possibly just to be capable of accepting a full-physical length card.", "Likewise, PCIe slots wired from the chipset rather than the CPU may run on an older PCIe generation and will also have to jump through a link to the CPU. You can check your motherboard manual for how they wire these slots.", "And as a final note: Some GPUs only run on x8. This can be problematic for users of older generation motherboards, because suddenly a PCIe Gen4 x8 card will suffer on PCIe Gen3. The RX 6500 XT (watch ", ") is even worse: It’s Gen4 x4, so socketing it into a Gen3 slot will significantly hamper it.", "This isn’t a problem on the 5090 since it’s fully wired for x16, but worth bringing up.", "OK, enough explanation. A few things on testing: We ran some of our most consistent benchmarks, but ultimately, they all show the same thing so we’re keeping the total count of charts low and simple. ", "One thing we aren’t testing is machine learning or so-called “AI” performance, so we can’t speak to how the behavior might change there. It’s possible there would be an impact. We’re focusing on the gaming impact today.", "If you want to see what test platform we are using, our game settings, and more of our methodological information for GPU benchmarking, you can visit our ", " for all of that. ", "Let’s get to the benchmarks.", "Dying Light 2 at 4K showed a maximum difference of 1 FPS AVG between results. If anything, we’re excited about the remarkable consistency as it gives us some confidence in this game’s low run-to-run variance with this test pattern. The PCIe Gen3 x16 result appears to slightly lose performance. We’re looking at about a 1% difference. Lows are not meaningfully affected, especially given their wider deviation, but it does appear there is a similar reduction.", "At 1440p, the Gen5 result was at 216.1 FPS AVG, with Gen4 at 215.5 and Gen3 at 215.4. These are functionally the same. There might be a slight difference here, but not one anyone would ever notice in gaming...unless, you’re a super gamer.", "In Black Myth: Wukong at 4K, the Gen5 result held 85.5 FPS AVG, Gen4 held 84.7, and Gen3 held 83.1. That is a progression, but not a meaningful one. The 84.7 to 85.5 results are within reasonable run-to-run variance of +/- 1 FPS. The Gen3 result allows the Gen5 result a 2.9% advantage, which does appear to be a real change, but not one to worry about. Lows are not outside of usual here.", "At 1440p, the range was 124.8 to 129.9. This is the widest range yet at 4%, some of which will be variance. The lows scale mostly in-line with the average. This is one of the more interesting results, and even then, you’re going to be far more limited by whatever CPU is still on Gen3 than the PCIe generation itself. This would also be comparable to a Gen4 x8 result by theoretical bandwidth. ", "1080p was pretty interesting. The range was 153.3 to 159.8. The Gen5 result was again about 4.2% ahead of the Gen3 result and 1.7% ahead of the Gen4 result. These are real differences and the Gen3 result is noteworthy, but when 4% is an exciting change, you know there’s not much to talk about.", "Because Black Myth: Wukong was so interesting, here’s the ray tracing results for the same. The 4K result has the Gen4 and Gen5 entries identical. The Gen3 test is behind by about 2 FPS AVG, which again seems repeatable and real, but not particularly interesting. That’s about 2.6%.", "At 1080p with ray tracing, Black Myth runs at 158 FPS AVG for the Gen5 result and 151 for the Gen3 result, establishing a 4.2% improvement to the Gen5 option. This aligns with the non-RT results.", "Resident Evil 4 at 4K rasterized has Gen5 at 206.7 FPS AVG, Gen4 identical, and Gen3 at 204.2 FPS AVG. The improvement from Gen3 to Gen5 is 1.2%.", "At 1440p, the range was 344 to 349 FPS AVG. Lows are again incredibly consistent between Gen4 and Gen5 results, which is encouraging to see from a methodological standpoint. On a technicality, Gen4 is 0.3 FPS AVG ahead of Gen5, but this is within error and variance. There’s no difference. The Gen3 result is slower, with Gen4 and Gen5 about 1-1.4% faster.", "At 1080p, the 5090 Gen4 and Gen5 results are again within variance of each other. Gen4 is 3% faster than Gen3 here.", "Let’s look at one more, but we have enough here to come to a conclusion.", "In F1 24 at 4K, the Gen5 5090 result ran at 291 FPS AVG and was basically tied with the Gen4 result. The Gen3 result ran at 285 FPS AVG, so the fastest entry leads Gen3 by 2%. ", "As we said at the start, this one is really simple. 1-4% is the difference we observed between PCIe Gen5 vs PCIe Gen 3. We ran this test in 16 scenarios mixing rasterization and ray tracing for different games, including 3 resolutions for each. The tests matched our ", " test suite.", "This is the same we’ve seen every generation, which is between a 1-3% difference. Where it would really matter if there’s some 6500 XT type of card where the manufacturer x4 or x8 instead of a 16 wired card. That’s where the generation would really start to potentially matter.", "Not many people are going to be slotting in a $2,000 card into a really old motherboard, but even if you did, the Gen 3 x16 results don’t look like a huge deal, where you’d maybe start to lose 2-4% performance maximally from what we’ve seen."]},
{"title": " Zotac RTX 5080 Solid Overclocking, Thermals, Noise, & Gaming vs. Founders Edition (Review)", "paragraph": ["Zotac RTX 5080 Solid Overclocking, Thermals, Noise, & Gaming vs. Founders Edition (Review)", "Last Updated: ", "The Highlights", "Today we’re reviewing the Zotac RTX 5080 Solid. You should not buy it. At the time we wrote this, it’s being sold for $1,270 on Newegg, which is a ripoff for an RTX 5080. That’s 27% more than MSRP, and the 5080 was already a hard sell at $1,000. A 27% hike is horrendous value, and that’s about the start and end of our review. Thermally, the card is fine. Acoustically, it’s also fine. But the price is a ripoff.", "Zotac has two main models of 5080: The Extreme Infinity and the Solid. We’re reviewing the Solid OC model, which has a boosted clock. The marketing is amusing for both the Solid and the Extreme Infinity", "Steve Burke", "Mike Gaglione", "Tim Phetdara", "Jimmy Thang", "“To gaming and beyond!” “Infinity Mirror,” “Spectra ARGB,” “Icestorm 3.0,” and “up to 9 composite heatpipes,” because that sounds better than explaining that the 5090 and 5080 are different. It even has a “card-length heatsink,” which is good because we’d rather have that than a backplate and fans extending past the heatsink... And yes, the PCB is shorter than the heatsink. ", "Despite its price, we’re still going to test this card and see if it’s designed well, we’re going to tear it down and look for problems. We’ll test it thermally and acoustically as well. ", "We’re borrowing the card from a system integrator because we don’t want to work with the partners directly for them these days and we haven’t been able to grab one when they go on sale. Supply appears to still be about 0. Let’s get into the testing of the Zotac 5080 Solid.", "The last few Zotac cards we looked at had major oversights of design. The worst one had a huge heatsink that didn’t contact the MOSFETs. This card didn't have that issue. ", "Zotac’s website says the “Solid” series is “no frills, all action.” We don’t know what that means. It’s a video card.", "The card also has “a powerful cooling system” “*available on select models.” Good. We like the uncertainty of the product page specific to this product.", "The site also says:", "“With a stealthier aesthetic and engineered for durability and performance, the ZOTAC GAMING SOLID is for those who demand pure performance over anything else.”", "As for actual features, it has an LED that alerts users of an improperly inserted 12V-2x6 connector, a dual VBIOS switch, a partial flow-through area on the back, and uses a massive heat sink. Unfortunately, the card uses a lot of plastic, including on the back and its design blocks some of the exhaust. ", "Zotac’s RTX 5080 Solid is much larger than the 5080 Founder’s Edition version (read ", "), taking up over 3 slots. One nice thing about the card is that it uses a larger bracket, which helps with structural rigidity. ", "The card uses a typical 3-fan design but has a somewhat large flow-through area on the back. Unfortunately, Zotac’s design blocks off roughly 20% of the card’s flow through here.", "The card comes with a 3 8-pin adapter for the card’s 12V-2x6 connector. ", "The card has a unique plastic “grill.”", "The back is similar with some perforated holes, but underneath, you’ll see a lot of plastic obstructing airflow. ", "Measuring the fans, they are 95mm ones and have a ring around the outside, which are supposed to help direct the airflow straight through a little more.  The first 2 fans are going to push air straight into the PCB in a more traditional way with the third fan pushing some of the air out the back. ", "To remove the aluminum backplate, we simply remove several screws on the back, which expose approximately 2.5mm thick thermal pads that contact the backside of the memory and VRM. ", "Next, we removed the card’s backplate by removing some screws.", "To remove the front plate, we, again, removed some screws. ", "Moving forward, we removed one cable on the back. ", "From there, we removed the GPU’s leaf spring. ", "Removing this section of the PCB exposes 2 connected fan connectors, which we need to disconnect to proceed further with the tear down. ", "From here, we can see plastic around the GPU die, which is uncommon. We can also see that the card also has 2 additional 2mm clay-like thermal pads that cover the card’s inductors. ", "The card also has 3 Zotac-branded fuses. From what we’ve heard a while back, these fuses won’t act fast enough to protect the card but does help the RMA center help identify where the failure happened.", "Flipping the card over, we can see a vapor chamber. We also see the memory contacting a separate plate.", "The GPU uses seven 6mm heat pipes, which is a lot.", "The card has thermal pads that make contact with the MOSFETs, which ", ".", "We also noticed a thermal pad that touches the card’s R10 inductor.", "The card’s fan cables are very accessible, which is good in case you have a fan die at some point. ", "Cleaning off the thermal paste from the 5080 GPU, we can see the GB203-400-A1 die, which is a lot smaller than the 5090 die. ", "Next, let’s move into our thermal testing. ", "We ran this prior to the tear-down in order to preserve the card as-is for testing. We tested both VBIOS options for thermals and frequency.", "In a quick head-to-head, tested using the auto settings and whatever VBIOS tells the card’s fans and clocks to do, we landed on these results. The 5080 Founders Edition card ran at 32 dBA in our ", " and pulled 315W board power under this workload. Those variables put the GPU temperature at 65 degrees Celsius and memory at 72.8 degrees Celsius. The Zotac 5080 Solid tested with the same software and auto conditions ran at 31.1 dBA and 360W. The workload doesn’t pin these to TDP, but is consistent. ", "The Zotac card runs a higher out-of-box power budget and its higher clocks are pulling more power. Even with the higher power draw and marginally lower noise levels, the Zotac 5080 card manages lower temperatures than the 5080 FE. Considering the enormity of the Zotac card, this is what we need to see. The 4-degree reduction in GPU and 7-8 degree reduction in memory thermals gives the Zotac Solid an advantage, although not in size, but the size is working in its favor.", "This chart shows the frequency over the test pass. The FE card plotted around 2650 to 2680 MHz on average, holding relatively stable under this test workload.", "For reference, the 5090 has a lower and spikier clock. The configuration is much larger and the 5090 makes up for the difference in other ways.", "Adding the Zotac 5080 solid to the chart, its clock is higher than the NVIDIA FE model, landing at 2790 to 2842 MHz. This is a pretty significant uplift. We’ll test that in some performance scenarios momentarily to see what it actually does.", "The next chart is produced using our hemi-anechoic chamber that we built with support from our ", " backers and our supporters on ", ", which allows us to isolate noise and ensure a like-for-like testing environment day-to-day.", "This chart shows the 5090 Founders Edition and the Zotac 5080 Solid. The 5080 Founders Edition is mostly equivalent to the 5090 Founders Edition, with the exception that the fan curve runs slightly slower and so the noise is reduced by about 1 dBA in our workloads.", "The Zotac Solid doesn’t encounter the same 180 Hz spike we saw in the 5090 and 5080 FE coolers, but does have its own spike around 433 Hz. The curve generally follows the same path, with marginally higher noise levels in the 1000 Hz to 1600 Hz range, but lower noise levels in most other places. The Zotac Solid overall manages to keep its noise levels down and avoids being obnoxious. It is making use of its size. ", "This is a quick VBIOS comparison for the Zotac 5080 Solid. Between the two VBIOS options, frequency is almost completely identical. There is no meaningful difference.", "For thermals, the silent VBIOS runs about 3-4 degrees warmer on the GPU from its reduced fan speeds. The fans run about 4-6 percentage points slower than the default VBIOS. The memory temperature climbs about 3 degrees. There’s not a big impact to thermals from the VBIOS change and the fans don’t really change a lot either.", "In Resident Evil 4 at 4K, the RTX 5080 Solid ran at 128 FPS AVG and led the 5080 FE by 4.2%. That’s not a bad uplift, but it’s bad for almost $300 more, though. Lows are within usual variance and benefitted similarly.", "At 1440p, the 5080 Solid held 237 FPS AVG against the 5080 FE’s 224, which is a 6% lead. That’s a big jump within the same GPU model. Again, the price isn’t justified, but at least we’re seeing an impact from the pre-overclock by Zotac.", "In Black Myth: Wukong at 4K and ray traced with upscaling, we saw the RTX 5080 Solid at 60 FPS to the FE’s 58.6. That’s a 2.6% improvement over the FE model.", "At 1080p and with RT with upscaling, the Solid ran at 128 FPS AVG to the FE’s 122. That’s a 5.5% improvement over the FE model.", "In Final Fantasy 14 Dawntrail at 4K, we saw the 5080 Solid at 117.5 FPS to the FE’s 112.4, a 4.5% uplift. This trend repeated across the other games we tested. It is consistent, so we’ll stop here with the game benchmarks as it tells the same story. In short, it’s generally about 3-6% better.", "Overclocking has some bugs on the 50-series right now. We haven’t dug too much into this bug, but it appears as if the voltage offset slider has an issue with the 50-series at present and reduces GPU clocks when used. We ended up setting it to 0 instead.", "This quick table shows the overclock stepping with 3D Mark Steel Nomad. From stock, we were able to hold an offset of 700 MHz core, which is huge, without a memory offset, landing the result at 8160 points. The uplift from stock was an insane 28%. This was not replicated in real-world use cases so check your expectations. Adding memory clocks introduced instability without dropping the core offset to 650 so we did that.", "Unfortunately, we weren’t able to use the 700 MHz offset with the memory offset. We also were unable to find stability from these clocks in any gaming use case, so sadly, it was purely synthetic. This is mostly interesting from a competitive overclocking standpoint.", "The next testing was only done for a performance check. We did not burn this in for stability, so we want to really heavily emphasize that this overclock is not stable in all games we test. It was only stable in Final Fantasy XIV: Dawntrail at 4K. You’d have to spend time tuning it down to dial it in, but we wanted to present what we found so far.", "The stock 5080 FE ran at 112 FPS AVG. The 5080 Solid, out of the box, ran at 117.5 FPS without any background applications. We saw performance degradation when we began running Zotac’s utility in the background in addition to changing the clocks and fan speeds, so just increasing the power offset and applying up to a 200 MHz core offset resulted in performance equal to or worse than stock. We were able to run the Final Fantasy benchmark with stability up to a 500 MHz core offset and 1200 memory offset; however, we’re not certain if there are any invisible background issues with this memory offset especially out of this game.", "The end result was a 125.7 FPS AVG, which led the stock Zotac Solid result of 117.5 FPS AVG by 7%. That’s not a bad uplift but it’s not that exciting. The lead over the FE model is almost 12%, which is more meaningful.", "Overall, that’s a decent amount of OC headroom from the base FE result, while the 7% uplift is typical for recent generations. In no real-world case were we able to replicate the Steel Nomad uplift.", "Finally, here’s the frequency chart in Final Fantasy. This isn’t comparable to the earlier charts for frequency. Out of the box, the card ran at 2625 MHz. Memory ran at 1875 MHz, but keep in mind that there’s a multiplying effect for GDDR.", "The core after a 500 MHz offset ran at 3120 MHz, which is almost 1-to-1. The memory after offset ran at 2025 MHz. This is about correct and what we’d expect after multiplying the numbers for GDDR effective speeds.", "As an important note here, this type of testing mostly looks at the impact from the power percent slider offset. Broadly speaking, GPU variance from the “silicon lottery” has more total impact than any particular partner model outside of its power boosting headroom (and the super high-end models sometimes being binned, but this is rare on anything but flagships).", "The Zotac RTX 5080 Solid is built well overall. We didn’t see any massive red flags with this card except for its price. If you don’t care about that and you just want a 5080, this card is fine, again, except for its price. We didn’t have any major complaints with its thermals, assembly, or acoustics.  ", "The thermals, in particular, are a little bit better than the Founder’s Edition card, but not much better as they probably should be given the size of the card. The memory was improved a decent amount, however, being roughly 7 to 9 degrees cooler.", "Performance is roughly 2-5% better out of the box than the Founder’s Edition card. ", "In the past, we found Zotac’s MOSFETs weren’t contacting the thermal pads for the heatsink, but that, fortunately, wasn’t the case here. ", "Overall, there was nothing hugely detrimental here aside from the value as $1,000 for a 5080 is already very questionable. It’s hard for us to compare the thermal performance when we only have this partner model. We haven’t been able to get any others yet, but that’s something we’d like to dive deeper into provided we can get more cards in."]},
{"title": " Do Not Buy: NVIDIA RTX 5070 Ti GPU Absurdity (Benchmarks & Review)", "paragraph": ["Do Not Buy: NVIDIA RTX 5070 Ti GPU Absurdity (Benchmarks & Review)", "Last Updated: ", "The Highlights", "You should not buy the ", " (beware of scalped prices), or really, probably not any of the high-end cards right now. The market is in chaos and conditions are at an all time low for consumers. It benefits this entire industry, including us, if everyone mindlessly consumes, but we’re telling you not to be a part of that cycle. This is not the time to buy an NVIDIA video card. The company says the ", " (beware of scalped prices) will be ", ", but we don’t believe it. In fact, some partner models have already been spotted at ", ", with plenty of others coming in at $850 to $900. We heard of one that’ll have an MSRP above $1,000. That’s more than a 4080 (watch ", "), which is insane. ", "NVIDIA calls it the RTX 5070 Ti, but it’s really more like an ", " (beware of scalped prices) V3 -- or V4 if you count the ", ".", "Steve Burke", "Patrick Lathan", "Mike Gaglione", "Jeremy Clayton", "Vitalii Makhnovets", "Jimmy Thang", "The TLDW up front is that the ", " (beware of scalped prices) is about 12-16% ahead of the 5070 Ti in some of the 4K gaming scenarios we tested, the 5070 Ti is about 28-35% ahead of the ", " at 4K, but down in the 20-28% range commonly at 1440p. The lead of the 5070 Ti over the ", ", which is the closest recent price neighbor, is only 7.8% to 20% in a lot of 4K situations, or commonly 12-16%. One of the worst scenarios we saw was an impressively bad 3.9% uplift from the ", " to the 5070 Ti at 1440p.", "You should not buy this video card. You shouldn’t even read this article. We’ll save you the time: NVIDIA has become fat and monopolistic and AMD has decided it won’t compete in the high-end, and Intel is not there yet, leaving everyone with a worse ecosystem.", "The ", " (beware of scalped prices) to the ", " is a difference that has now been subdivided several times. Like the ", " (beware of scalped prices) and 4070 Ti (watch ", "), which was a 4080 12GB originally, already subdivided it. Likewise, the ", " subdivided it further. The 4070 Ti Super (read ", ") subdivided that again, and now, the 5070 Ti subdivides it once more.", "There are so many subdivisions in this block that it’ll have an HOA by next week... ", "In one of our tests, we saw an average gap between cards in this upper-end of 6.7 to 8 FPS card-to-card, depending which you want to count. That really means that the only relevant factor is price (except for maybe ", " in the few places it diverges, where that’ll matter for professional users). But even VRAM has mostly been split into the 90-class and everything else.", "The 5070 Ti is often the same performance as the 4080, which is the same as the ", ". The improvement on the 4070 Ti Super, which was close to the same MSRP, is hardly meaningful. This aligns with NVIDIA’s launch strategy of either leveraging its monopolistic positioning or boring the ever-living f*** out of people with stagnated change. Meanwhile, it appears that AMD is sticking to its failed strategy of MSRP = NVIDIA - $50. Let’s get into the rest of the review.", "We’re taking a look at the ", " model, which we assume is named like that because ASUS is trying to get Logan Paul’s attention. Or maybe it has electrolytes, which is what the gamers crave.", "The RTX 5070 Ti has 8960 CUDA Cores, 16GB of GDDR7, and a 256-bit bus. The memory spec is identical to the RTX 5080 (read ", "), with the 5080 having more CUDA cores but being a significant cut-down from the 5090 (read ", "), which is more than what we’ve typically seen. ", "We have the full specs in a separate article ", ". ", "Pricing is going to be the biggest problem for this GPU. Supply has been non-existent for the ", " and 5080 and prices have skyrocketed into true FOMO targeting territory. We posted a ", " just a few days ago.", "And in time for that, the 5070 Ti will launch with its own glut of pricing issues. We know one board partner has an actual MSRP north of $1,000 for one of its models. This gets worse considering the lower overall price of $750, which means that the proportional hike over expectation becomes untenable.", "There’s really not a lot of ground to cover here that we didn’t in the intro, so let’s just get into the data.", "For the testing here, we had to remove a couple of cards from the charts to make space. Specifically, we removed the 3090 (watch ", ") and 3090 Ti (watch ", "). If you want the data for those cards, check our ", " as it has all that.  ", "In Final Fantasy 14 at 4K, the RTX 5070 Ti landed at 97 FPS AVG with lows at 83 and 80. That’s the same as an RTX 4080 which, under normal conditions, might sound like a generational improvement on the arbitrarily named GPUs. Instead what we have is total generational stagnation because the 5070 Ti will regularly sell at prices, at least for now, approaching what the 4080 was. Even at only a slight elevation to $850, the card is simply too close to the last generation performance equivalent.", "The ", " outperforms the 5070 Ti by 7.4%, with the 5080 16% ahead and the 5090 at 87% ahead. As for the ", ", which was the cheapest partner model for a while, that’s at 82 FPS.", "Generationally by name, the 5070 Ti improves on the 4070 Ti by 34%, but the 4070 Ti Super is the more recent price replacement. The lead over the 4070 Ti Super is just 13%. That’s stagnation. We have the RTX 2070 Super (watch ", ") in a future test, but the 1070 (watch ", ") is here if you want something older. The improvement is 332% over Pascal, now 9 years old. ", "At 1440p, the 5070 Ti ran at 187 FPS AVG. 1% and 0.1% lows are where they should be based on other results, so there’s nothing exceptional here. The 5070 Ti outranks the 4070 Ti Super by just 15 FPS, or only 9%. Sadly, this is one of the better ones, but that’s still brutal and is one of the most boring improvements possible when considering the MSRP similarity -- and that’s before you go get ripped off for more.", "As for other 70-class cards: The 5070 Ti’s uplift over the 4070 Ti is 24%, then 72% on the 3070 Ti (watch ", "), 94% on the 3070 non-Ti (watch ", "), and 307% on the 1070. The uplift has diminished for each of these as resolution came down to 1440p, despite the 5070 Ti not being anywhere close to a CPU ceiling.", "AMD’s RX 7900 XTX (watch ", ") leads the 5070 Ti by 13%, up from 7% at 4K. The 5070 Ti also leads the ", " by just 9% here.", "At 1080p, things get even worse. The 5070 Ti leads the 4070 Ti Super by only 6%, or just 15 FPS average. Over the 4070 Ti non-Super (watch ", "), which remains an absurd distinction, we’re only seeing a 16% advantage on the 5070 Ti. No wonder NVIDIA wants everyone to type the framerate into a calculator and multiply it artificiality by MFG.", "The new card is just 10% over the ", ", then 74% over the 3070 Ti.", "Black Myth: Wukong is up now, tested at 4K. We’re removing the experimental chart labeling and feel that this test has had enough public visibility to clear that bar.", "The 5070 Ti ran at the exact same framerate as the RTX 4080. NVIDIA has basically re-released the 4080, and the price isn’t even that different -- ", ". In other words, NVIDIA has now released three RTX 4080s. This is the third one. At some point, it just seems like this is too much.", "The 7900 XTX matches the 5070 Ti here. The difference is irrelevant and unnoticeable. ", "Against the 4070 Ti Super’s 45 FPS AVG, the 5070 Ti leads by 13%, or 27% over the 4070 Ti non-Super and similarly over the 7900 XT. The lead over the 3070 Ti is 81%.", "At 1440p, the “RTX 4080 v3” ran at 87.2 FPS AVG, with lows at 74.9 and 70.3. The third iteration of the 4080 isn’t the best one, though: The first version of the 4080 and second version of the 4080 are within error of each other and technically ahead of v3. But on the v3, aka the 5070 Ti, NVIDIA has enabled Multi-Fiat Generation to make it more interesting, though.", "The RX 7900 XTX is about the same as the 5070 Ti here, with the 4070 Ti Super just below it. The 5070 Ti is only 10% ahead of the 4070 Ti Super and 20% ahead of the 4070 Ti, with a similar lead over the 7900 XT. ", "At 1080p, the 5070 Ti is again roughly tied with the 7900 XTX, although credit to NVIDIA for having improved 0.1% lows -- just not by an amount anyone would notice in play. The frametime pacing is still good on both.", "The 4080 Super (read ", ") and 4080 are again within error of each other and, although they’re outside of error vs. the 5070 Ti, the real error is the GPUs we launched along the way.", "The 5070 Ti ends up leading the 105 FPS 4070 Ti Super result by a staggering, mind-blowing 9.7%, made only more impressive by the fact that this was already functionally the same as the 4070 Ti’s 100 FPS.", "The 7900 XT (read ", ") sits just below this.", "Starfield is up now. At 4K, The RTX 5070 Ti ran at 68 FPS AVG, this time allowing the RTX 4080 the important distinction of... being technically better.", "The 5080 only leads the 5070 Ti by 12% here as well.", "Troublingly for the 5070 Ti in this test, the 7900 XT nearly matches the RTX 5070 Ti, with the 7900 XTX ahead of it by 13%.", "The 4070 Ti Super and 4070 Ti aren’t that different from each other in this one, either.", "At 1440p, the 4080 Super and 4080 are exactly tied, with the 4080 Sub-Super, or as NVIDIA calls it, the “5070 Ti,” at 101 FPS AVG. ", "The 5070 Ti ends up basically tied with the 7900 XT. The 7900 XTX holds an advantage at 11% ahead. The 5070 Ti’s improvement, if you can call it that, over the 4070 Ti Super is an impressively boring 3.9%, with the lead over the 4070 Ti at 11%. That’s impressive -- mostly because we’re impressed NVIDIA could make something so impressively stagnant.", "At 1080p, Starfield has the 5070 Ti below the XTX, which has a slight lead at 6%. More impressively, the 4070 Ti Super ran at 120 FPS AVG. Between the 5080, the 4080s, the 5070 Ti, and the 4070 Ti Super and 4070 Ti, NVIDIA has managed to make a video card for seemingly every individual framerate between 110 FPS and 132 FPS. Why they’d do this, we have absolutely no idea.", "Dragon’s Dogma 2 is up now. This one has the ASUS RTX 5070 Ti Electrolyte, which is what the games crave, at 73.6 FPS AVG. That’s right between the 4080 Super and 7900 XTX, making the 5070 Ti the first NVIDIA RTX 4080 Super-Super on the market. We won’t be impressed until they launch the triple-S-tier.", "The 5080’s lead over the 5070 Ti is just 15%. That small of an uplift is going to weigh on NVIDIA.", "The 5070 Ti leads the 4070 Ti Super by 18% and the 4070 Ti by 35%. The 7900 XT sits between the two 4070 Ti variants.", "1440p reduces the 5070 Ti’s relative ranking, pushing it below the 4080 and 4080 Super, the two of which are tied and within error of each other. The 4070 Ti Super’s 106 FPS AVG result also makes for a boring positioning of the 5070 Ti. Again, we’re back to a card for every couple FPS. More than ever, this means price matters more.", "The 7900 XTX leads the 5070 Ti by about 6 FPS here.", "At 1080p, the RTX 5070 Ti’s 151 FPS AVG basically ties it with the 7900 XTX, which itself is tied with the 4080 (which is tied with the 4080 Super, which is a waste of chart space and so isn’t shown).", "Generationally, the 5070 Ti leads the 4070 Ti Super by 10% and 4070 Ti by 18%.", "Resident Evil 4 is up now, first rasterized. The 4K test has the 5070 Ti at 107 FPS AVG, with the 5080 at 122 and leading by 15%. Both are behind the RX 7900 XTX at 126 FPS AVG.", "The 5070 Ti is ahead of the 4070 Ti Super by 20% and 4070 Ti by 34%. The ", " (watch ", ") is between these and the regular 4070, followed by the older 3070 Ti at 53 FPS AVG.", "At 1440p, the 5070 Ti is just below the 4080 FE. The 5080 leads the 5070 Ti by 13%. ", "NVIDIA basically took what previously would have been a 51 FPS gap from 224 to 173 FPS between the 4070 Ti Super and 5080, then split the difference with the 5070 Ti. ", "The 7900 XTX is ahead by 17%, with the XT just below the 5070 Ti.", "We’re moving to ray tracing testing now. We’ll start with Black Myth, which is heavily NVIDIA favored. Then we’ll look at some that are mixed or lighter workloads.", "At 4K with upscaling as defined in the chart header, the 5070 Ti ran at 52 FPS AVG and tied the RTX 4080 and 4080 Super. The 5080’s 59 FPS result had it 13% ahead. Over the 4070 Ti Super, we see a 15% lead for the 5070 Ti. AMD gets absolutely crushed in this test.", "At 1080p and still ray traced, the RTX 5070 Ti ran at 112 FPS AVG and led the 4080. The 5080 is improved on the 5070 Ti by 9%. The proximity of cards from the 4070 through the 5080 is crazy, though: We have the 4070 at 80 FPS, then the Ti at 92, then the Ti Super at 95, then the 4080 at 106, then the 4080 Super which isn’t shown but the same, then 5070 Ti at 112, then the 5080 at 122 FPS.", "Dragon’s Dogma 2 at 4K with ray tracing is next. ", "In this one, the 7900 XTX is more competitive and lands at 66 FPS AVG, which is between the 5080 and 5070 Ti. It’s unfortunate that AMD gets crushed so hard in some of the other games, like Black Myth: Wukong because it does OK in the ones that are less crazy intensive. The 5070 Ti ends up basically tied with the 4080 Super, which is basically tied with the 4080. The jump over the 4070 Ti Super’s 54 FPS AVG is 18% here.", "1440p positions the 5070 Ti between the 4070 Ti Super and 4080. It’s not clear why this card needs to exist, but it does. The improvement against the 4070 Ti Super is just 10.8%. The 7900 XTX runs at 108 FPS AVG and is between the 4080s and the 5080. ", "At 1080p, the 5070 Ti ran at 131 FPS AVG and was roughly tied with the 7900 XTX. The 4080 leads the 5070 Ti here by a few percent. The 5070 Ti leads the 4070 Ti Super by 9%, followed by the 7900 XT in the middle, then the 4070 Ti at 16%.", "In Resident Evil 4 at 4K with ray tracing and upscaling, the RTX 5070 Ti ran at 118 FPS AVG and tied the 4080 and 4080 Super exactly. It’s within run-to-run variance and error. The 7900 XTX leads in this lightweight RT workload with a 14% advantage, posting a big difference from the heavier Cyberpunk and Black Myth workloads that we run.", "At 1440p with the same settings, we see a similar lineup. The 5070 Ti is again within error of the 4080 and 4080 Super, which are the same. The 7900 XTX is slightly improved. The 4070 Ti Super is slightly behind. This is uninteresting.", "Efficiency remains a relatively new test for us to include in each review, so we haven’t re-run the 4070 cards for efficiency yet.", "In Final Fantasy 14 at 4K, the 5070 Ti landed at 0.37 FPS/W. It pulled 264W in this test, approaching its TDP spec. The 5080 ends up slightly more efficient, with the 4080 Super equivalent. The 7900 XTX is at a large disadvantage here due to its power consumption.", "In Final Fantasy 14 at 1440p, the 5070 Ti ended up at 0.73 FPS/W, which has it just below the 4080 and 5080. The 5070 Ti improves on the ", "-class cards, but also is significantly more efficient than the 7900 XTX.", "In Black Myth Wukong at 1080p, we found the 5070 Ti to be between the 4080 Super and 5080 for efficiency. The 7900 XTX shows again that this is its weakness, but its particular performance deficiency in Black Myth in general is hurting it disproportionately.", "In ray tracing performance with F1 24, we found the 5070 Ti to perform about the same as the 4080. The 7900 XTX scores significantly lower. Overall, here you’re seeing much lower numbers than in some of the other charts and that’s because this is a heavy ray tracing workload tested at a higher resolution.", "All of this means that NVIDIA is basically just selling you an RTX 40 series card, maintaining elevated prices, and doing so while pushing DLSS4 and MFG as the only real differentiating factor on the 50-series cards. ", "We already have ", ", which you can check out for a deep dive. We also have a ", " with an image quality comparison, including a frame-by-fake-frame break-down of MFG, where we analyze the AI or synthetic frames against the keyframes, or the native frames. We do this at 2X and with MFG 4X.", "The improvements in the Transformer model over the older CNN model for image quality are apparent; meanwhile, the generated frames serve their purpose of smoothing, but sometimes look bad. What they don’t do is turn a low frame rate like 20 FPS into something that is instantly playable. But as far as image quality, it’s highly situational; in some situations, DLSS ends up better than native because game developers have decided to ruin their games with terrible default options, which shouldn’t happen, but there are also a lot of scenarios where it looks awful. We also found bugs in the driver override features that NVIDIA has pushed to the public. This includes sometimes it incorrectly running the generated frames in the wrong places.", "This quick thermal chart at steady state during a looping 4K Port Royal workload and it shows the GPU and memory results. We don’t have other 5070 Ti cards to compare, so we can’t produce a like-for-like comparison. The 5080s are only here for reference.", "The 5070 Ti came in 2 dBA quieter than the ", " (read ", ") and was warmer while operating at a significantly lower reported board power during the test. The ASUS cooler is favoring noise here, but is also just not particularly effective. Overall, the performance is fine -- this is more than acceptable and well below throttle territory -- but this does seem to be one of the lower cost coolers for its size.", "Acoustic testing is up next. We’ll keep this brief. As a quick positive, ", " is about to get way better for future testing -- or more accurately, our microphone equipment. We’ve recently learned that with a microphone upgrade, we can bring down the noise floor closer to 5dBA, which is crazy exciting. Currently though, we’re on our more economical equipment.", "With the current noise floor of 14-14.5 dBA, we measured the ASUS 5070 Ti Prime at 29.2 dBA with this frequency spectrum plot. We observed one spike at around 300 Hz. Otherwise, it follows what we have seen in other cards. The falloff begins at 2000 Hz, levels briefly at 3500 to 5000, then continues the path. The loudest range is 1000 Hz to 1800 Hz, aside from the 300 Hz spike.", "These two added lines show the Zotac 5080 and ", " (beware of scalped prices). The coolers should track about the same as long as the fan RPM is the same between the other 5080 and 5090 alternatives by the same vendor. The NVIDIA card had a spike around 180 Hz and another at around 380. The Zotac card had one in the 430 Hz range. Broadly, the NVIDIA FE is louder than both of these.", "This will change in the future as prices move, hopefully, but for now, we don’t recommend buying this card. Honestly, it’s probably just a good idea to wait in general right now. But let’s just recap why that is as quickly as possible:", "Broadly speaking, we found that the ", " performs in the range of 9% to 16% better than the ", ", depending on the resolution and game. The ", " is often better than the ", " in rasterized testing, with the range in our games spanning equivalence to 17% at the high end, but more commonly 6% to 13%. There were some instances of regression for the 7900 XTX vs the 5070 Ti, but as has been the case, it only got really crushed in Black Myth or Cyberpunk-type ray tracing. The 5070 Ti only improves on the ", " by a range of 2.2% to 20%, often 12-16% if you’re looking at the heavier resolutions. That is not a good improvement for a generational jump and the actual street price we expect as compared to the ", "’s original street pricing, especially with the instances below 10% performance. It’s an awful value. Remember that the Super series was regularly in stock for its actual MSRP.", "As we’re reviewing this, we can’t see the actual street price of the 5070 Ti in advance and we don’t review the future as we don’t know where the prices will land at launch, but based on what we’ve seen from the ", " and ", ", our strongest recommendation right now is to just generally wait to buy a video card and let the market calm down.  ", "Finally, the 5070 Ti is equal to the ", ". We don’t care what the ", " MSRP was, because the 4080 Super effectively overwrote it. That was $1,000 and was actually available at around $950 to $1,050 for much of its recent life.", "For AMD’s part, it really needs to not screw its new GPUs up. Typically, whatever AMD says its price is, it comes down in about 1 quarter, because they usually push it way too high. It’s really disappointing that AMD said it’s not going to be targeting high-end GPUs this generation. ", "Overall, we think it’s not a good time to buy a GPU and wouldn’t recommend buying a 5070 Ti."]},
{"title": " AMD RX 9070 & 9070 XT GPU Prices, Specs, & Release Date", "paragraph": ["AMD RX 9070 & 9070 XT GPU Prices, Specs, & Release Date", "Last Updated: ", "The Highlights", "AMD's RX 9070 XT MSRP is $600, with the 9070 at $550. They are releasing on March 6th, which is a day after the RTX 5070 launches.", "That’s a weirdly small $50 gap between these, but AMD isn’t a stranger to smothering one product with another. It did that with the ", " and the ", " before. ", "AMD today announced its RX 9070 series GPUs -- again. It announced them ", ", but then decided it didn’t want to announce them, so its announcement shriveled up and receded back whence it came. But now, AMD is proud to re-announce its announced RX 9070 series.", "Steve Burke", "Vitalii Makhnovets", "Tim Phetdara", "Andrew Coleman", "Jimmy Thang", "The RX 9070 is positioned to fight the RTX 5070, with the 9070 XT up against the ", ". AMD has decided to steal NVIDIA’s naming this time, growing tired of the naming scheme that brought us the R9 270, R7 370, RX 480 (watch ", "), Fury, Fury X (watch ", "), RX 580 (watch ", "), Vega Frontier Edition (watch ", "), Vega 56, Vega 64 (watch ", "), back to RX 590 (watch ", "), Radeon VII (watch ", "), RX 5700 XT (watch ", "), RX 6950 XT (watch ", "), and RX ", ".", "Maybe leaving the old names behind is for the best. We look forward to seeing what they do when they hit the dreaded “10.” Maybe AMD will be the first to bring us the 10,080 Ti…XT.", "First up, the price: At $50 apart, it seems like these cards will smother each other. Until we can publish test data, we won’t know which one will cannibalize the other -- but it seems likely, as happened with the 7900 XT and 7900 XTX when they were about $100 apart at launch.", "A quick pricing recap:", "AMD’s ", " is currently priced at around $500 to $530 depending on where or if you can get it. The ", " has been around $550 (though has been mostly out of stock lately). The RX 7900 XT is basically gone, but was around $630 to $640 at the end of last year and more commonly around $680. The 7900 XTX was as low as $800 to $820 in November and was commonly $930 in January. It launched at $1,000.", "The 7900 XT received a review from us entitled “", "” in December of 2022, knocking it for the $900 price point. We ", ", so less than a year later, because you could get some models for $720. AMD dropped the price by 20% or so in less than a year. ", "The ", " became an awesome value after the price drops at least for a window there, especially in raster performance. ", "We’ll talk more about the pricing once we have benchmark numbers in. That’ll include NVIDIA’s lineup.", "With that context, let’s get into the specs of the 9070 and 9070 XT.", "AMD provided this spec sheet for its RX 9070 and RX 9070 XT. The RX 9070 will have 56 Compute Units, or CUs, against the 64 on the 9070 XT (a 14% increase in CUs). AMD has done splits like this before, like Vega 56 and 64, but the architecture has changed dramatically since then.", "In a call with the press, AMD claimed that the reason it didn’t go up to something like 80 CUs is because it didn’t want to make something super expensive. That definitely would have been very expensive. It would have been a larger die so that is accurate that the costs would go up. We also think that the architecture might just struggle to compete with a ", " at the cost they would need to hit to do so and that’s probably a large reason for this as well. AMD is focusing on the mid-range, where the architecture is perhaps better tuned to compete.", "The hardware ray tracing accelerators match the CU count at 56 and 64, with AMD’s so-called “AI accelerators” at 112 and 128 units.", "Boost clocks are significantly different between them: The 9070 XT is able to make more use of its extra 84W of power budget to hit an advertised boost of 2.97 GHz, with the RX 9070 non-XT at 2.52 GHz (the original slides said 2.54, but AMD brought that down before announcement). Memory capacity is identical between them at 16 GB. Both cards will utilize GDDR6 at 20 Gbps. Board power is advertised at 220W and 304W, hopefully with room for board partners to scale up with overclocking support. NVIDIA’s OC support has been relatively lackluster this generation, despite what the company claimed. Hopefully AMD can make it exciting. ", "Finally, the cards technically are on PCIe 5.0 x16 slots, but ", ". There almost certainly won’t be any impact with the 90 series either with the exception if they were to cut down the slot on a lower-end model or something, but for this, it won’t matter. DisplayPort is up to 2.1a and HDMI at 2.1b.", "Here’s the block diagram for the RDNA 4 die and architecture. AMD noted that this same die will be used for the 9070 and 9070 XT. The company says this will be 356.5mm^2, contain 53.9 billion transistors at most, and run on a 4nm process node. And then the 9070 would have some of the CUs basically turned off. AMD says that this is monolithic silicon and not a chiplet design.", "This variation of the GPU has 4 Shader Engines, within each is contained 8 dual-compute units. L2 Cache is centralized and located towards the middle of the logical block, totaling 8MB max of L2, with 64MB of infinity cache at the outer edges and closer to the memory controllers. ", "AMD’s big claim here is a renewed focus on ray tracing performance, where it says it has doubled ray intersection rates and improved ray traversal, alongside changes to how it’s handling bounding boxes for BVH probing. This is a big focus for AMD this generation and it is somewhere the company needs to focus because they’re pretty competitive in raster compared to NVIDIA a lot of the time, but there’s instances where they get completely crushed in ray tracing. ", "Here’s a closer look internally. The area we’ll focus is on RT. Within what AMD calls the compute engine, AMD now has 2x ray accelerators to handle box and triangle intersections. AMD noted that the second intersection engine within the accelerator “doubles the performance for both ray-box and ray-triangle testing” over RDNA 3, although remember that this doesn’t mean a clean doubling in performance in an actual ray tracing game scenario. AMD noted that RT processing takes advantage of a 128KB shared memory block, also shown here.", "This slide was dedicated to RT improvements specifically and highlights the addition of AMD’s dedicated ray transform block, which it says will “offload transformation as you transition from the top-level RT structure to the bottom level, where there may be many instances of a particular geometry.” Previously, shader instructions handled this task and, AMD says, added overhead to ray traversal which it claims to now have eliminated. ", "The ray accelerators have the ray transform block and two intersection engines, which themselves required changes to BVH handling to be fully leveraged. ", "AMD said it is moving to an 8-wide BVH solution from a 4-wide option on earlier hardware, which it couples with its new oriented bounding box approach that attempts to reduce wasted, empty space in bounding boxes by better conforming to the geometry in the scene, theoretically reducing false positives and also reducing performance overhead and loss during geometry intersection probing.", "The slide claims that traversal performance improves by 10%. Again, this is not a literal 10% gain in the final framerate in an RT game, but is a building block in a series of others to contribute to AMD’s claimed uplift.", "This slide above was pretty cool. The right side shows AMD’s register allocation, with the top-right showing RDNA 3 and the bottom-right showing RDNA 4. Between the two, there’s a change from static allocation in RDNA 3 to dynamic in RDNA 4. AMD highlights that RDNA 3 would reserve registers which may not be put to work, so it’d hold them in case they were needed, potentially not need them, and end up with inefficiency and unavailable resources. RDNA 4 is trying to resolve this. The bullets on the left make all of this pretty clear, stating that the improvement is in efficient utilization, largely because registers can be released or requested as needed.", "AMD is claiming that its RDNA 4 CUs improve traversal by 2x over RDNA 3 when iso clock and bandwidth. The 3D block in the image is supposed to roughly illustrate where AMD thinks it’s finding most of its performance: It appears that the 2x intersectors and BVH8 change (from 4) are the largest contributions.", "RDNA 4 also introduces more out-of-order queuing and aims to reduce latency of memory requests, which AMD claims further benefit RT performance. Further out of order execution allows work to complete even while longer latency requests are processing or queuing. AMD makes an example out of an uncached leaf node on the slide above, which would contain the lowest level of detail in an RT workload and could otherwise hold up a scene. ", "Let’s get into the first-party benchmark claims next. We won’t spend a ton of time on these since you’ll be able to find plenty of third-party reviews soon enough, but it will help set expectations for what AMD is targeting.", "AMD’s quick reference slide shows a claimed 26% uplift against the RTX 3080 and 38% uplift against the 6800 XT. AMD didn’t show anything from NVIDIA’s 40 or 50 series here.", "At 4K/Ultra and without upscaling, AMD is marketing the RX 9070 non-XT as an average of 21% improved over the RX 7900 GRE. The 7900 GRE was originally a $550 card. AMD is showing non-RT performance as improving up to 28% on baseline 100%, with the ray tracing performance showing a disproportionately favorable gain to the new architecture at up to 34%. This is good for AMD, as it was weakest in ray tracing historically. This disproportionate gain won’t wipe-out AMD’s deficit in something like Cyberpunk 2077 or possibly Black Myth: Wukong, but the key will be whether it can close the gap with better value.", "At 1440p/Ultra and native, AMD claims the 9070 will be 20% faster on average, with the peak at 38% improved for ray tracing and 26% improved for raster. AMD observed a slightly larger improvement in RT at 1440p for F1, which is interesting, despite overall losses in scaling in raster. 4K diverging from 1440p isn’t abnormal, though. One thing we do want to call attention to and give AMD credit for here though is that they’re showing native performance. Even if they show FSR, that’s fine if they kept it locked to the same FSR options between their older and newer gen cards if they’re comparing their own products to each other; showing native is a better step than that. This is a massive improvement over what we’ve been complaining about NVIDIA doing, which was comparing its 50 series to its 40 series and enabling MFG 4X on the 50 series but not the 40 series and then just making it look like they are wildly better than they actually are. So we do want to call attention to and give AMD credit for making a more fair head-to-head comparison between its own products here rather than enabling some special multiplier on one and not the other.", "As for the RX 9070 XT, AMD compared it against its 6900 XT and NVIDIA’s RTX 3090, again lacking in any 40 or 50 series comparisons here. It claims a 51% uplift over the 6900 XT and 26% average uplift over the RTX 3090.", "Against the same 7900 GRE, AMD claims an average uplift of 42%, or 66% in F1 24 with ray tracing at the high end. AMD claims it saw the same uplift in Cyberpunk with RT. In raster performance, the gains max-out at 48% over baseline.", "At 1440p, AMD is seeing lower overall average uplift, with a slight uptick in F1 24 with ray tracing.", "We could run these percent scaling improvements against our own numbers to approximate where AMD would land since we have all the details we need here to calculate the expected performance. Launch is only a few days away though, and we’d rather test the cards than extrapolate on data that we have no control over or insight into. We’ll have third-party numbers in our own reviews soon enough.", "Pricing is going to remain the key concern for these cards. AMD is doing some interesting things architecturally. We’ve covered a bit of that in this article. AMD has plenty of opportunities to have…ROPs and cables that…are not going to burn. The field is set for AMD to have a victory here. It is up to the company to execute on it. We just made a ", "” that talks primarily about the pricing, but the reason AMD has this amazing opportunity is because of NVIDIA’s screw-ups. ", "Pricing is the key concern, but we’ll withhold judgment on it until we review it about a week from now.", "From what we understand, it sounds like supply will be okay, but it’s hard to know what that really means.", "AMD really needs to gain market share. According to Jon Peddie Research, AMD is close to the lowest they’ve ever been in the GPU market at around 10 percent while NVIDIA is down in terms of reputation and trust in their brand, so now is the time for AMD to strike. We’ll let you know if they execute on that soon."]},
{"title": " Intel Arc 2024 Revisit & Benchmarks (A750, A770, A580, A380 Updated GPU Tests)", "paragraph": ["Intel Arc 2024 Revisit & Benchmarks (A750, A770, A580, A380 Updated GPU Tests)", "Last Updated: ", "The Highlights", "When Intel Arc launched, we spoke with respected technical analyst David Kanter. He said, “Intel doesn’t have to be number one. It just has to be second place. Intel won’t take market share from NVIDIA; it’s going to take it from AMD.”", "And he was absolutely right. Intel Arc is competing in the budget market right now. NVIDIA doesn’t compete there, and that’s something an NVIDIA employee told us many years ago, “We don’t compete on price. We compete on quality.”", "But AMD does compete on price, and that’s been their strongest position against NVIDIA. Today, Intel is threatening that position. ", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "The launch of Arc was abysmal, though, and our immediate concerns were that Intel would kill the project before it could fix its drivers. ", "But our early conclusions were that, when it worked, the hardware was competitive -- it’s just the “when it worked” part that made it impossible to recommend.", "That has slowly been shifting. Today, we’re revisiting Intel Arc again -- now going on almost 2 years later -- to see how it’s improved from driver updates alone. There aren’t any hardware changes here, so Intel’s newly established positioning has been gained purely from driver and software updates. This ", " we’re showing is just one of the two most recent drivers -- and Intel has published similarly sized updates for over a year now. ", "That’s dangerous for AMD and NVIDIA when they compete in a similar price class, because AMD and NVIDIA’s drivers are so impressively mature and established already that there’s little extra juice to squeeze out of driver updates.", "We think AMD is the most threatened in the market right now. It’s competing stronger, almost oddly, at the ", " price class than at the $200-$300 mark, and that’s despite NVIDIA nearly abandoning it.", "Today’s testing will be focused on overall driver updates and performance improvements for Intel Arc GPUs. We’re testing with the latest 5252 drivers that are supposed to further bolster performance in several games, but this was preceded by the 5234 drivers that offered a huge list of Dx11 improvements and some Dx12 improvements. ", "The article will be a mix of benchmarks and some commentary in the conclusion. Intel Arc is a rapidly changing beast, which means it needs more frequent revisits to ensure we’re all up to date on the status of the devices. What we’ve learned thus far is that drivers may be harder to make than hardware, in some ways, or at least from the perspective of the millions of combinations of software and hardware that drivers must address.", "With some quick browsing, here’s the update on the relevant part of the market.", "The ", ", which is what we’re testing, is typically around $290 to $300. The ", " has its cheapest entry at $205, a ", " that we tested at $210, and plenty of others in the $220 range. The ", " has been the card we’ve tended to recommend most out of Intel’s lineup. The ", " is priced at $165 at the lowest, with other options at $180. The ", " is priced at around $120 these days, with the ", " -- the only card not tested today since it’s too low-end for these tests -- at around $90 to $110.", "For competition, the ", " is NVIDIA’s cheapest 40-series card, priced at around $300 to $320. The ", " is still around $400 and is in a substantially different price class from Intel’s options. The ", " is around $250 these days for the 8GB model and will underperform every single one of these cards we’ve mentioned except the ", ", and the ", " isn’t worth mentioning. There’s also the ", " at $285. For AMD, it’s mostly the ", " at $260, the ", " at $330, and the ", " at $200, with the 6600 XT at $240 and ", " at $250. The 6600 series cards are the most relevant from AMD for price-to-performance.", "There’s a surprising amount of cards in this price class, but most of them are from Intel and AMD right now. NVIDIA only has one modern option anywhere close, with the rest from last generation. The ", " technically just launched, but it’s not really a competitor here with its core count cut-down and clock drop.", "For the charts today, we’re removing the ", " and ", ", the ", ", and ", " to make space for the lower end of the stack. Check the ", " for the high-end. We’ve also just published article versions of the ", " and ", " reviews. Our site is all entirely funded by our community, so to support our ad-free written reviews and archival of our videos in an easily searchable format, head over to ", " and please consider grabbing one of our ", " with PC component designs, our ", " with extreme heat resistance, or our ", " that we’ve carefully chosen and designed for video card disassembly and reassembly, like for re-pasting.", "Let’s get into the testing.", "You can find additional test methodology notes in our ", ".", "Resident Evil 4 had the Intel A750 at 104-105 FPS AVG, which has it about tied with the ", " and ", " GPUs. That’s a great place for the A750 to be, and at a lower price than the RX 7600 (watch our ", "), it’s also competitive. The ", " pushes up to 116 FPS AVG, leading the brand new, freshly launched $330 RX 7600 XT (watch our ", ") by 5.2% while costing $40 less. ", "As for NVIDIA, its last-gen ", " is about equal, while the new ", " -- about $10 more than the ", " -- falls behind in this chart. That’s remarkable comparative performance for Intel.", "For the ", ", we saw a 91 FPS AVG that ranked it between the RX 6600 (watch our ", ") -- currently still available for $190-$200 -- and RTX 2070 Super (watch our ", "). It’s not distant from the GOATed 1080 Ti (watch our ", ").", "At $165 to $180, the A580 (watch our ", ") is outperforming the RX 6600 (watch our ", ") in both average FPS and lows while costing less. ", "Finally, the A380 (watch our ", ") is predictably at the bottom of the chart: It’s the lowest end card we’ve tested recently, so we’d need to add the GT 1030 (watch our ", ") or GTX 1650 (watch our ", ") class cards to compare closer. At about $120, it can at least somewhat play games with dropped settings. The A580 is about 160% better for just 38% more money, though.", "At 1440p, the A750 and A770 (watch our ", ") remain in completely playable territory despite the increase in graphics strain. The A580 is also in playable territory, although depending on preferences, maybe just barely. The A380 predictably can’t handle this.", "The important comparisons go like this: The A750 runs at about 72FPS AVG, tied with the brand new, significantly more expensive ", ", which falls in relative position in this test from increased pixel processing load. That means the RX 7600 XT is 57% more expensive than the A750 for equivalent performance. Yikes. The RX 7600 is also functionally tied but still costs more.", "As for NVIDIA, the RTX 4060 allows Intel a lead of almost 5%, but Intel maintains the cost advantage.", "The A580 also punches above its weight class, landing at 62FPS AVG and leading the RX 6600 by 7%. ", "Finally, the A770 leads the 7600 XT by about 9%, with the 4060 Ti leading the A770 more notably at about 14%.", "At 4K, the A770 doesn’t quite make it to playable territory without upscaling assistance or lower settings. Comparatively, it is now about equal to the 4060 Ti -- which has shifted down due to weaknesses in memory bandwidth. ", "We’re next moving to Rainbow Six Siege. This game was the bane of Intel’s existence at launch, posting some of the worst performance we’d ever seen for this level of hardware. It was so bad that Rainbow Six was one of the first titles that Intel specifically targeted for improvements, prompting follow-up testing where we saw the parts begin to get better.", "In today’s updated chart and first at 4K, the A750 runs at 79 FPS AVG and roughly ties both the RTX 4060 and RX 7600 in average, 1%, and 0.1% lows. Given that it’s cheaper than both, that’s another strong position -- especially with the frametime pacing now being fixed.", "The A770 sits between the RX 6700 XT -- which itself outpaces the RX 7600 XT -- and the RTX 4060 Ti. The A770’s lead over the 7600 XT is 8%, with a lead of 10% over the 4060. The 4060 Ti leads the A770 by 12%.", "Just for perspective, we have two A580 entries on this chart, which is intentional. Other cards haven’t changed nearly as much, indicating that Intel’s improvements largely come from its drivers, not the game itself, which has also updated. The old A580 result had it at 36FPS AVG with completely unplayable and highly inconsistent lows. The new drivers have brought that up to an impressive 68 FPS, or a 91% improvement. This shows how much power the drivers have when they’re not as mature as NVIDIA’s are. The lows have gone from broken to actually consistent. That pulls it ahead of the RX 6600.", "At 1440p, the Intel Arc cards fall in the ranks -- comparatively, they’re doing a lot better at 4K against competition. The A750 outperforms the RX 6600 XT by 5.3%, but the RX 7600 leads the A750 by 13%, up at 177 FPS AVG. The A770 also doesn’t scale as strongly here, roughly tying the RTX 4060 and falling behind the RX 7600. ", "That odd behavior continues at 1080p, where Intel struggles to keep rank with its normal competition. The RX 7600 now leads the A750 by around 25%, a massive change. The A770 is also behind the RTX 4060 and RX 7600. At least they’re playable, but this does illustrate Arc’s weakness as being its general unpredictability at times.", "At 1440p, the $290 Arc A770 rivals the $400 4060 Ti, the latter of which has an advantage of only 7% despite a price increase of 38%. Against the 7600 XT, the A770 manages a lead not only in better pricing, but in outright performance, with a 10% advantage. ", "The A750 is roughly tied with the 7600 XT, 4060, and 7600, meaning the primary differentiating factor between these in Dying Light 2 is price. As for the A580, it’s competitive with the 6600 XT here, which is a good spot for it to be.", "At 1080p, the 4060 climbs and equals the A770 GPU. The 7600 isn’t far behind. The A750 approaches the RX 7600 levels, but has clearly fallen somewhat from its higher resolution rankings.", "In Final Fantasy at 4K, the A770 runs at about 56 FPS AVG, which has it 5% ahead of the RTX 4060. The 4060 leads the A750 by 9%. AMD’s RX 7600 XT is about tied with the A750, doing it no favors in a price battle. Finally, the A580 is now about equal to a 6600 XT.", "At 1440p, the A770 is tied with the 4060 in all metrics, leading the 7600 XT and 7600. The A750 is perceptibly equal to the 7600 from a user experience standpoint, although with technically better 1% lows, and the A580 is flanked by the 6600 and 3060 (watch our ", "). Intel is competing with its similarly classed parts. That’s all it needs to do.", "At 1080p, a wider gap forms again: This seems to be a trend between some games with Intel. The 4060 at 190 FPS AVG now leads the A770 by 3.7%. The A770 is about tied with the 7600 for AVG FPS now. Its only advantage in this chart is price.", "In an absolute sense, the A580 and A380 are both playable here.", "Unfortunately for Intel, it is sometimes just completely broken. GTA V appears to be one of those times. In this test, none of the Intel cards can get out of the 30 FPS range at these settings. Based on the previous charts, the A770 should at least be up around 50 FPS, if not closer to 60, but it’s just not doing it here. ", "Starfield is another one that’s specifically broken, in a sense, on Arc -- and they know this. In fact, their latest driver ", " -- but we aren’t seeing the fix. We tried with these drivers and the ones that predate them one revision, and both produced the same result.", "Unfortunately for Arc, its performance mirrors that of GTA V’s in the prior test in that it is just clearly broken. It runs but the RTX 4060 has a framerate multiples faster, with the RX 7600 also boosted way beyond what we’ve seen in other games.", "It’s instances like these that hurt Arc’s wide-reaching viability, and these are the only reasons we hesitate when answering whether or not someone should buy Arc.", "Our ray tracing tests are next. Some of these games are shared with the earlier ones for rasterized tests, but use different settings and aren’t directly comparable. As an interesting note, RT hardware is available even on the Arc ", ". It won’t run well for most applications, but the hardware is there.", "We’ll start with Cyberpunk and 1080p/Medium RT settings without upscaling. If you want to use upscaling to boost performance, go for it -- but for purposes of comparing two devices by relative performance, this is what we want.", "In this test, the ", " ran at 38 FPS AVG and held strong lows that were proportional to the average. You’d want upscaling or reduced settings to get a more stable experience here, but again, our goals are to compare in the relative sense.", "The ", " outperforms the ", " by 3.4%, putting Intel dangerously close to NVIDIA when considering NVIDIA’s general advantage in RT workloads. And in fact, the A770 has stronger 0.1% low performance that we’ll see in a frametime plot in a moment. The ", " has more sporadic performance in frametime pacing with these settings than we’d typically see. ", "The ", " allowed the 4060 an 18% advantage, but still managed a significant lead over the RX ", ".", "This frametime plot shows the raw frame-to-frame interval in milliseconds, or the time required to render a frame as presented in its base metric of time. We’re currently showing two passes of the RTX 4060. Here, you can see that one of the passes had several spikes higher than 50ms. The other pass has one bad spike to about 110ms, which is one tenth of a second that you’d be staring at the same frame, which is a pretty big spike.", "The A770 is much more consistent and lacks any of these massive spikes. That’s how 0.1% lows are supposed to be used: They’re an indicator to point us toward a problem, and here, the problem is the 4060’s ability to consistently deliver well-timed frames.", "1080p/Ultra is where we see NVIDIA really pull ahead of AMD, with unbelievably large gaps that illustrate how higher RT loads will disproportionately benefit NVIDIA performance.", "Despite being unplayable, the raw performance shows that Intel manages to keep up better than AMD. Price-for-price, Arc is impressive: A 28 FPS AVG result for the A770, still with relatively flat frametimes, has it close to an ", ". That’s a $290 Intel card competing with a $420-$450 AMD card. The lead over the ", " for the A770 is 46% here, with the A750 leading the RX 7600 by 58%. The A750 also manages to maintain more proportional frametimes than the RX 7600, which sees them diverge from the average more noticeably.", "The RTX 4060 leads the A770 in a way that we’d still classify as “not even close,” but it’s not NVIDIA that Intel has to beat right now. It’s AMD.", "As for why Intel does so well in Cyberpunk specifically, Intel’s Tom Petersen provided some engineering insight when we asked why. He said this, “In Cyberpunk, we see good results from the BVH cache since a large fraction of the time in that app with RT heavy workloads we are walking BVHs. It also is likely that the thread sorting unit is helping.”", "The thread sorting unit is a physical piece of hardware of the GPU, while the BVH cache is an area where Intel has spent significant special optimization effort. We’ll talk more about these topics in the future.", "In Resident Evil 4 at 1080p and with RT, using quality FSR, the A770 landed at about 84 FPS AVG and tied the RX 7600 (although it maintained better frametime consistency in the 0.1% lows). The RTX 4060 leads the A770 by 14.6% here, with the A750 tying the RTX 2070. This game is a lighter RT workload, so AMD is able to recover its position in this particular title. We see similar behavior in Tomb Raider with RT, where only one RT feature is actually used.", "We’re including 1440p because it reinforces an earlier point: The A770 is able to gain ground on the RTX 4060 here, which has its lead reduced from 15% in the 1080p chart to just 1.3%. The resolution bump is hard for the 4060 and 4060 Ti cards to handle at scale. ", "Dying Light 2 is significantly heavier as an RT workload than Resident Evil 4 and tends to have wider gaps between AMD and NVIDIA. At 1080p, the A770 ran at 66 FPS AVG and actually managed to technically outmatch the RTX 4060. The A750 follows, with the RX 7600 and its 46 FPS AVG just an afterthought. The A750’s lead over the 7600 is 30% here.", "At 1440p, the A770 is slightly ahead of the RTX 4060 again, with the A750 just behind. AMD’s RX 7600 series cards are dragging behind here.", "As usual, we have plenty more data, but that recaps the trends we see in all our other tests. You can find some additional data in our recent GPU reviews that also featured some Arc benchmarks.", "Outside of gaming, Intel still has some challenges with idle power consumption and is less efficient than NVIDIA frame-for-frame, but when competing on price, AMD has historically shown that power efficiency is a secondary consideration. There has to be a trade-off somewhere. To us, as long as the power isn’t completely outrageous, getting strong gaming performance is a more important foundation when at this price class. Intel can’t fight battles on all fronts.", "We’ve also separately deep-dived into Intel’s Arc drivers and software suite as recently as just a couple months ago, when we did ", ". ", "As for conclusions, they’re simple: When Intel Arc works, it works exceptionally well for the price class that it’s in. This is a stark change from initial launch when several games just simply didn’t launch or stuttered in unplayable ways. Intel has made remarkable improvements in its drivers.", "It seems Arc is still somewhat binary, despite its strong performance: It either works, in which case it is a scary competitor for AMD more than for NVIDIA, or it’s functionally broken and stuck at 30 FPS. In this round of tests though, the amount of times that it was broken is far lower than we’ve seen in the revisits over the past year. We’re at two titles for this test: GTA V and Starfield. Now, we tested 14 games total when including unpublished tests, so 2 of 14 still isn’t a great percentage -- but both are on ancient engines, so maybe there’s a link there. We do think that Intel remains in the class of buyers where it should probably be someone with enthusiast-level knowledge; however, it’s slowly exiting that class and becoming something that can be recommended at more of a mainstream level. ", "That’s good news for Intel. ", "If you can categorize a user between “enthusiast” and “mainstream” -- and maybe that categorization is just called “patient” -- then Intel Arc can now be recommended to such a group.", "As for ray tracing, Intel is competitive with AMD and is outclassing it in many scenarios. NVIDIA still holds significant advantages in overwhelmingly RT-heavy titles like Cyberpunk, but once again, when it works, Intel is competing in sometimes stronger ways than AMD.", "For value, the ", " has held strong recommendations when it has occasionally dropped to $180, but even at $210, we think it makes sense to buy now. It is starting to clear those hurdles. ", "We’d still advise against recommending it to anyone who is more sensitive to issues with specific games in one-off cases, or to fully mainstream users who are incapable of troubleshooting on their own, but we do think this is beginning to find stability outside of the enthusiast market. For a lot of our audience, if you’re spending $200, it makes sense to seriously consider now.", "The ", " is also posting better value now that its price has fallen below $300, and certainly it puts some pressure on the ", " and ", ".", "We still want to be very clear, though: Arc will have frustrating moments for specific games. Whether or not those apply to you may just be chance, but it is improving.", "As a result of the improvement, we’re actively working on some PC build guides with Arc GPUs. We’ll follow those up with some NVIDIA and AMD builds as well, as we’re planning to revive our PC building guides that built our website its hardware foundation back in 2010. Check back for that."]},
{"title": " PC Part Failure List Update: CableMod 12VHPWR Angled Adapter Failures & Recall", "paragraph": ["PC Part Failure List Update: CableMod 12VHPWR Angled Adapter Failures & Recall", "Last Updated: ", "The Highlights", "For those unaware, we maintain ", " that includes a mailing list established to alert consumers of potentially dangerous device failures, or minimally, device failures which may not be dangerous but could cause damage to a PC. The PC part failure tracker includes a PC hardware failure list, ", ", which we just recently updated to include CableMod's 12VHPWR Angled Adapter failures. We previously reported on the Angled Adapter Recall when it was announced a few weeks ago. You can find that coverage in our ", ", timestamped 03:30.", "We recently dispatched an email to those who've signed-up for the Catastrophic PC Failure Newsletter (you can ", "). This short post will be the same thing we sent out via email, but available on the website and without entering your email anywhere. The newsletter list is only ever used for alerting subscribers to PC component failures and recalls. We maintain the list because we realized that many people build their computer or buy their laptop, then never check up on the PC industry again until it's time to build or buy another one. The list helps keep people aware of issues that could become safety concerns or fire hazards (or could just lead to disablement of a device).", "The letter is pasted below. It's short and simple. This is the same as the email.", "Steve Burke", "Subject: PC Failure List Update: CableMod 12VHPWR Angled Adapters", "Sent: February 25, 2024", "GamersNexus has been in communication with CableMod regarding confirmed failures of CableMod 12VHPWR Adapter units. GamersNexus has additionally received outreach from viewers regarding this issue.", "The ", " has been updated. An update log is at the bottom. Deeper details are provided in this email.", "Yes. CableMod has noted to GamersNexus that it has no plans to pursue further CableMod 12VHPWR angled adapter projects, and as such, we consider this resolved. The existing products are to be destroyed and rendered useless and existing customers are to receive compensation in the various forms offered by CableMod. CableMod has additionally been actively reimbursing, replacing, or repairing video cards affected by their own device failures. If yours has been affected, you should ", ".", "GamersNexus believes the manufacturer is acting in good faith and has taken adequate steps to resolve this issue from what it has observed thus far. If this status changes, we will provide further updates.", "Thank you for your continued support of our maintenance of this list. If this list is helpful to you, please consider a ", " via our store page, a purchase of a ", ", or a ", ". We recently launched our ", " to help fund our further efforts.", "Thank you,", "Steve Burke", "Editor-in-Chief, GamersNexus"]},
{"title": " AMD Radeon RX 7600 XT GPU Benchmarks & Review: Power Efficiency & Gaming", "paragraph": ["AMD Radeon RX 7600 XT GPU Benchmarks & Review: Power Efficiency & Gaming", "Last Updated: ", "The Highlights", "We’re on a tear right now with iterative GPU review updates, this time adding Baldur’s Gate 3 in for the ", " review and benchmarks. AMD’s new card starts at $330 and slots in over the ", ", which is around $270 right now, and we’ll be benchmarking it in the usual suite plus new additions like Cyberpunk 2077. We also have our brand new power efficiency testing that we debuted in our ", ". ", "Anyway, the pricing of the 7600 XT is going to be immediately problematic, but this is what you get when you demand more VRAM: memory is one of the more expensive non-GPU components on a PCB, and doubling it adds cost. Whether it should add $60-$70 of cost is maybe debatable, but that’s how AMD priced it. The trouble is that if a card isn’t sufficiently powerful to utilize the extra capacity, the impact to performance won’t be realized. We’ll look at all of that in this review. AMD also increased the power budget on the 7600 XT, so it’s getting clock bumps alongside the memory capacity doubling. Otherwise, the CU count, stream processor count, and even the memory interface are all the same as the ", ".", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "Let’s start with a quick pricing update:", "Jeremy on the team put together this quick reference table for GPUs that might be relevant in this price range. We averaged the price of several of the cheapest cards for each SKU, eliminating outliers like those listed by third-party sellers.", "The RX 7600 (watch our ", ") is currently averaging about $274, so it’s still near the launch price. The ", ", the prior next class up, is $454. The 7600 XT will be determined at launch but should be around $330.", "Where you can still find the ", ", it’s about $213 -- that definitely keeps it relevant. The ", " is also super relevant and is as low as $190 now, but typically around $200-$210. The ", " is also relevant, at $260, as is the ", ", which is a direct price alternative to the 7600 XT and runs 12GB of memory that’s more likely to be utilized anyway.", "NVIDIA’s closest competition remains the ", ". It hasn’t launched anything near the A750 yet.", "Other options might include the used market, but for those buying used, AMD is contending largely with itself.", "In terms of specs, it is nearly identical other than the power budget and the memory capacity. There’s a frequency boost alongside the power budget increase. We’ll look at the full power draw later in the review.", "Let’s get straight into the testing.", "You can find additional test methodology notes in our ", ".", "Our power efficiency testing is brand new. We explained this in the ", " in depth and had a lot more charts, but will just be showing one initial chart here for the 7600 XT. We’re still refining all of this testing and adding to it, but Starfield will mostly tell the story for all the results for the 7600 XT for efficiency.", "As a reminder, this is in FPS/W, or effectively frames per joule. Higher is better. The RX 7600 XT is the worst on this chart, down at 0.27 FPS/W. That has it behind the original RX 7600, which was more efficient in this test by 12%. Interestingly, there was about a 12% change at most in Starfield between these cards, so it at least scaled fairly close to 1-to-1 for the performance increase in this particular game. But that still makes it clear where AMD got its gains: Blasting more power, with the card now 40W higher in total power consumption. The 10-point highs won’t be charted separately this time, but landed at 229W for the 7600 XT and 196W for the 7600. If you see nothing else from the 4070 Ti Super review, check out the efficiency section for more information on this new testing.", "The first summary chart looks at the RX 7600 XT vs. the RX 7600. The power budget drives part of this, with the memory driving the larger numbers but only in scenarios where the memory is actually utilized.", "Cyberpunk with ray tracing is our recently added test. With medium settings, we saw about an 11% increase at 1080p and RT, whereas we saw a significant increase of 34% with 1440p. That’s not a playable framerate, but percentage-wise, it serves its academic purpose of illustrating that memory ", "have a big impact when constrained, it’s just that the card isn’t fast enough at a core level for the memory to be relevant here. ", "On to the rest of the games:", "Generally speaking, we’re seeing about a 5.5% uplift at 4K where tested and about 7% uplift at 1440p and 1080p. Some break-outs include F1 at 10% for 4K and Starfield at 12% for 1080p. RT uplift was generally within the same range, aside from Cyberpunk’s more intensive settings. If we eliminate Cyberpunk from the averaging, that brings the approximate improvement down closer to 5% from 7%, and that’s in exchange for 22% more money. Not great, and the scenarios where you need that memory while also being in playable territory are rare.", "The next summary has to be broken into two pieces: We’re presenting RT separately from rasterized testing. As we explained before, we do this because we try to keep as much of the math as possible in the direction of percent increase. ", "Anyway, here are the RT results when moving FROM the RX 7600 XT TO the ", ".", "The scale is insane for Cyberpunk. With the newly-added testing, we accommodated both Cyberpunk with ultra RT and with medium RT. We did that because we noticed increasing RT load on the GPU disproportionately favors NVIDIA -- which is a real advantage, so that’s fine -- but we wanted to represent both options fairly.", "At 1080p and RT ultra, we saw an 85% uplift. The card is crumbling under this much load. The 1440p result isn’t really fully representative: The cards are both so overloaded that they are totally unplayable without any upscaling assistance, and even then, it’d be rough. But the nature of being that overloaded is that the FPS numbers start skewing and are largely meaningless anyway. Even still, it’s 60%.", "With lower medium RT settings, the RTX 4060 (watch out ", ") maintains an advantage of about 30%, which is still significant.", "In Dying Light 2, the 4060 also has about a 26-33% advantage.", "After that, we have 3 lighter RT workloads that fall below 15% improvement for the RTX 4060. This gives you a fairly representative picture of the two types of RT titles right now: Those that supplement raster graphics and those that frontload RT visuals. It’s up to you on what kind of games you play with regard to whether this matters.", "With rasterized benchmarks only and now looking at percent improvement in the RX 7600 XT against the RTX 4060, with the 7600 XT going in the positive direction, we see an average wash between them. When it’s better, the 7600 XT tends to be about 3-5% better. When it’s worse, it tends to be 2% to 5% worse. Generally speaking, it most consistently did worse in 4K with games that are lighter. Tomb Raider, GTA, and Final Fantasy won’t meaningfully utilize that extra VRAM, so it provides no value. As such, and particularly in Final Fantasy where we tend to see NVIDIA disproportionately favored (a counter to Starfield, which disproportionately favors AMD), it’s the core specs of the GPU that matter more than the VRAM.", "In the 2023 remake of Resident Evil 4, the RX 7600 XT ran at 72.7 FPS AVG against the 69.9 FPS AVG of the RX 7600. Normally, we’d round those two numbers -- but we need every fraction of a frame of difference to even begin to tell these two cards apart unless memory-bound. The 7600 XT’s lead is 4% -- so we’re even lower than ", " 1080p levels of uplift territory when compared to the ", ". ", "The 7600 XT’s closest NVIDIA competition would be the RTX 4060 at 68.8 FPS AVG, just below the RX 7600 and with no meaningful difference to frame pacing. It’s between the two for price. The RTX 4060 Ti 8GB card is about $390 to $400, so it’s 20% more expensive than MSRP for the 7600 XT and about 24% higher performance in AVG FPS, up at 90.", "The 7600 XT doesn’t meaningfully move the needle from the 6600 XT in this test.", "At 1080p, the RX 7600 XT’s 110 FPS AVG led the RX 7600 by a staggering, mind-blowing 4.1%. We were worried we’d have to break out the double-digits for this review, but as we all know, numbers above 10 are in finite supply. We just wastefully used one right there. Rumor has it that this is also why NVIDIA launched its ", ": To protect the supply of double-digit numbers.", "As for competition, the 4060 ends up right between them when compared to the newest test run. They’re about the same, including in 1% lows. The ", " runs about 28% ahead of the 7600 XT at the 20% price bump. Intel’s ", " is due another round of testing with its current beta drivers, but as of about 10 days ago, the ", " was clocked at 105 FPS AVG in this test. That has it just below the RX 7600 baseline card. Intel currently has a $70-$80 price advantage over the 7600, so this is fiercely competitive. But it’s still more sporadic than NVIDIA and AMD for game-to-game reliability, despite significant improvements. You can check out our recent ", " to see how Intel has updated its drivers.", "Starfield is up next. Tested at 1440p, this 2023 title has the RX 7600 XT at 51.7 FPS AVG and the RX 7600 non-XT at 46.6 FPS AVG. That’s about an 11% swing to the XT, which is far more than we saw in many of the other games tested today. That’s about the most exciting it’ll get. F1 is also in this range.", "This result positions the 7600 as behind the RTX 4060, which itself is behind the 3060 Ti (watch our ", "), and the 7600 XT is behind the 4060 Ti (watch our ", "). The 4060 Ti leads it by about 15% here.", "At 1080p, the RX 7600 XT leads by 12%, which is a significant margin when compared to the other positions we’ve seen in this testing. Unfortunately, that doesn’t show up in many other places. The 7600 XT ends up about equal to the ", " here, with the 7600 behind the 4060. ", "On to the games. We started running entirely new tests for Baldur’s Gate 3 since it’s been updated so much since our last round and in the last couple hours before posting this, we managed to get 6 cards through and noticed something: Overall, the results aren’t too different. We’re still re-running everything, but for purposes of giving as much referential data as possible, we’re also including old data. The disclaimer here is that performance has improved. Anything marked 1/24 is directly comparable. ", "Some quick examples: The ", " has improved by 3.8% from the September version of the game, with the 4060 about the same as its original result.", "For directly comparable data at 4K, the RX 7600 XT is about 5% better than the RX 7600 and roughly equal with the RTX 4060. The RTX 4060 Ti’s 47 FPS AVG result gives it a strong lead over the new XT.", "1440p is up now. Old-to-new, we saw a 3.5% uplift in the RX 7600 since September, 4% in the RTX 4060 since the last test, 3.2% for the 3060, and 7.6% in the 7700 XT (watch our ", "). That’s interesting data to have as well. But for direct comparisons with our new data, the 7600 XT leads the 7600 by the same predictable amount we’ve seen a few times now. The RTX 4060 sits about tied with it once again.", "Dying Light 2 from 2022 is up next. In this one, the RX 7600 XT ran at 58.9 FPS AVG -- again, we’ll need every one of those digits -- to the 7600’s 56.7 FPS, a staggering 3.88% difference. If AMD had pulled an NVIDIA and done a price-for-price swap, then we’d be neutral toward that change. But a price hike for under 4% is simply not worth it in this scenario.", "The A750 (watch our ", ") manages to outperform the RX 7600 and sits just behind the 7600 XT, including with roughly equivalent lows. That’s great positioning for Intel’s GPU and shows driver maturity. NVIDIA’s RTX 4060 is between the 7600 and 7600 XT as well, with indistinguishable lows. The 4060 Ti leads the 7600 XT by 17% here, so its advantage has diminished in this game.", "At 1080p, the RX 7600’s 86 FPS AVG allows the new 7600 XT a lead of 6.5%. That’s so exciting. We can’t wait to pay 22% more money for that.", "NVIDIA’s 4060 sits between these two again, so this is perhaps one of the limpest games of leapfrog since the launch of Skylake #39.", "The ", " is also between the 7600 XT and 7600, with the A750 behind a bit. The 4060 Ti again sets the ceiling for this group of cards. None of the cards on the chart would be worth upgrading from to one of these -- you’d have to go further back, maybe to the 1050 Ti (watch our ", ").", "Now we’re moving to our older and reliable set of benchmarks, which allows us to have years of comparative data against older cards. These are mostly useful for rapidly establishing scaling performance. Although we’re adding new games, we won’t necessarily be replacing the old suite with them. We might run them partly in tandem to give us more percent scaling numbers to work with. It’s also useful for seeing scaling at 4K.", "Speaking of, here it is. At 4K, the RX 7600 XT ran at 51 FPS AVG, behind the 4060’s 54 FPS result and ahead of the RX 7600’s 49 FPS AVG result -- wait, sorry, 48.8 -- by 3.5%. Great. Maybe AMD can sponsor another F1 team with all the extra money per XT they sell.", "Intel’s A750 runs at 49 FPS AVG here, with lows actually in-step with the average. That has it between the 7600 and 7600 XT while costing significantly less, if you’re willing to deal with occasional Arc driver issues.", "At 1440p, the RX 7600 XT’s 102 FPS AVG has it 2.5% ahead of the RX 7600, tied with the RTX 4060, and meaningfully ahead of the A750 this time. This isn’t interesting, so let’s move on.", "In F1 at 4K, the RX 7600 XT ran at 62 FPS AVG, leading the 4060 by 8.6% and the RX 7600 by 10.3%. That’s at least a more meaningful change. It’s not worth the money for it but it’s one of those sparingly used double-digit numbers. This seems to align with the resolution bump, which is likewise reflected in the lows of the 7600 vs. 7600 XT. The XT does better for frametime pacing here.", "As for the 4060 Ti 8GB, that landed at 73 FPS -- a lead over the 7600 XT of about 18%. The Intel ", "’s 67 FPS AVG result also leads the 7600 XT here.", "At 1440p, the RX 7600 XT’s 111 FPS AVG result leads the RX 7600’s 103 FPS average result by 8.3%. F1 seems to just scale better between these two.", "The A750 is down alongside the RX 7600, with the A770 up with the RX 7600 XT. NVIDIA’s RTX 4060 is between the two RX 7600 cards, creating options every couple of FPS. The total range encompassing all these models is relatively narrow, so it’ll ultimately come down to other features or price.", "At 1080p, the 7600 XT leads the 7600 by 3.3%, with the 4060 about tied with the 7600. The A750 runs slower than the 7600 here, down at 134 FPS AVG but with acceptable lows. It’s similar to a 2070 Super (watch our ", "). AMD’s 7600 XT scaling has reduced as we’ve dropped resolution, which makes sense given that most of the improvement is theoretically in memory.", "In Rainbow Six Siege at 4K, the RX 7600 XT ran at 82 FPS AVG, leading the RX 7600 by 1.2%. Great. And that’s at 4K. The RTX 4060 is about tied with these results, so they’re all basically within run-to-run variance. The 4060 Ti leads more meaningfully, although has its own issues with getting embarrassed by the 3060 Ti.", "The A750 falls behind in this one, but given the new pricing, it’s not in a bad value position at 4K.", "At 1440p, the RX 7600 XT has about a 1.6% lead over the RX 7600. Now, if we worked at AMD, we’d want that number to sound more impressive -- so here’s how to do it: In the 4K test, the 7600 XT was 1.2% better than the 7600. In this test, it’s 1.6% better. So the percent increase in percent increase is actually 33%, which sounds a lot better than 0.4 percentage points and is still technically correct, which is the only kind of correct that matters for marketing.", "The RTX 4060 is just behind the RX 7600 baseline card, with the A750 further down the stack than its proportional positioning in other games.", "Final Fantasy 14 is up now. At 4K, the RX 7600 XT ran at 47 FPS AVG, leading the original 7600 by all of 1.7%. The A750 actually leads both of these, including in lows, with a 48.8 FPS AVG. The 4060 is ahead of that, at 53 for 4K. That establishes a 13% lead for the 4060 over the 7600 XT. The 4060 Ti’s 63.6 FPS AVG result produces a 19.5% gap over the 4060 baseline card.", "As for older cards, the RTX 2070 is similar in performance to the modern 7600. The 7600 XT leads the 6600 XT by about 6%, so not particularly exciting.", "At 1440p, the RX 7600 XT leads the baseline 7600 by 3%, with the ", " about tied with the original 7600. Even if these are linked primarily by name, that’s just a disappointing swing. The original launch MSRP of the RX 6600 XT was $380, but we’re going on 3 years since its launch and not much has changed.", "GTA V at 4K at least posts more of a change, but still not enough to justify the price. The 7600 XT gains 8% over the original 7600 here, moving from 54 FPS AVG to 58. That puts the 7600 XT between the 4060’s 63 FPS AVG and the 3060 XC’s 57 FPS AVG. Intel’s A750 doesn’t do that well here, down at 31 FPS AVG. If anything, this test serves to show that Intel’s GPU performance still isn’t as predictable as NVIDIA and AMD options. Generally speaking, we can accurately predict that the 7600 and 4060 will normally be relatively close to each other in performance. But the A750 still bounces around based on the game.", "Time for ray traced testing. We’ll start with our freshly re-added Cyberpunk with a mix of RT ultra and RT medium, leading with RT medium.", "At 1080p and with medium RT settings, the ", " and ", " are about equal to an end user without upscaling. Upscaling mostly proportionally scales, so you can factor that in if you’d like. The difference is about 11% for these results. There is no heavy constraint on VRAM here -- at least, not anything exceeding what the cards are already capable of.", "As for the ", ", its lead is massive here, as discussed in the summary charts. We also saw that with the ", " tying the ", " here, and it gets worse as RT load increases with Ultra.", "You could make this work on the ", " cards with upscaling and settings tuned down a little more.", "At 1440p and with medium still, the RX 7600 XT posts an 18 FPS AVG result. This is more for an academic exercise: The RX 7600 is actually struggling enough here that its FPS becomes unreliable and generally spikier, we have less data to work with, and it is also starting to get overloaded. Also, in situations of percent scaling, a +/- 1 FPS change can have a big impact on the difference calculated, so these tend to get exaggerated. Regardless, the XT is significantly improved here.", "Memory is never so simple, though: the RTX 4060 has less than the 7600 XT, but its baseline performance and ability to process RT helps it keep a lead.", "At 1080p/Ultra, the RX 7600 XT and RX 7600 post similar scaling to the 1440p/Medium results. The RTX 4060 leads the RX 7600 XT by 85% here. Again, with this higher RT load, NVIDIA is scaling better.", "Now for Dying Light 2 with ray tracing and at 1440p. Here, the RX 7600 XT ran at 31.3 FPS AVG, leading the 7600 by about 6.8%. That’s on the higher side, but still not a huge swing for the price. The RTX 4060 runs this one at 41.5 FPS AVG, leading the 7600 XT now by 33%. The 4060 Ti has an advantage of 70% over the 7600 XT, not distant from the RX 7700 XT.", "AMD’s 7600 series cards have a particular weakness in some ray tracing tests, and that’s showing here.", "At 1080p, we’re seeing a 7.6% advantage in the 7600 XT over the original RX 7600. The cards still struggle though, ultimately landing below the Intel A750 and RTX 4060, both of which are in the low 60s for framerate. AMD is struggling to get into the 50s with its RX 7600 series cards.", "In Resident Evil 4 with ray tracing and at 1440p, the RX 7600 baseline performed at 65 FPS AVG, establishing an improvement of 2.8% for the RX 7600 XT. That puts the RTX 4060 up at 71 FPS AVG, or 7% ahead of the RX 7600 XT.", "At 1080p, the RX 7600 XT leads the 7600 by 2.2%. The 4060 is about 12% ahead of the 7600 XT in this one. The gap isn’t as wide here for an RT test as we’ve seen in Dying Light and Cyberpunk for NVIDIA.", "Finally, in flat-out, 100% power consumption and fully maxed -- which is similar behavior to what you’d see in a completely taxing render workload -- we have the RX 7600 XT at 200W against the original 7600 non-XT’s 163W. That’s where a lot of the performance uplift is coming from: In situations where we did see 10% or 12% swings, like in Starfield and F1, it’s derived from the added power budget more often than from the memory change alone. The VBIOS allowed up to 232W when overclocking, which had it roughly aligned with the much less efficient A750. NVIDIA’s 4060 holds an overall efficiency advantage here.", "This ", " isn’t particularly interesting and serves as a great reminder for everyone that more memory doesn’t automatically make a card better. There is a functional limit to what can be leveraged, and it’s not just limited by bandwidth, but also by what the cores are capable of.", "In this instance, the card is generally not powerful enough to leverage the memory. In the one instance we found where it was memory-bound, there was a huge swing -- it’s just not common enough to shop for. The rest of that average 5-7% uplift comes from the power increase and clock increase.", "We can’t recommend this card. It really just doesn’t make sense at the price and is a boring launch, especially flanked by ", " that at least had the courtesy to retain a price with the upgrade or drop it. AMD is in a tough spot in the $200-$300 market: It’s flanked by its own older options, like the", ", and in the $200 class, by Intel’s increasingly relevant Arc A750 GPU. ", "We’d pass on this one. Simple as that."]},
{"title": " AMD Radeon RX 7900 GRE GPU Review & Benchmarks vs. RX 7900 XT, 7800 XT, RTX 4070 Super", "paragraph": ["AMD Radeon RX 7900 GRE GPU Review & Benchmarks vs. RX 7900 XT, 7800 XT, RTX 4070 Super", "Last Updated: ", "The Highlights", "AMD liked its ", " so much that it’s launching it a second time, this time to the rest of the world. The card originally shipped to China, adopting the naming “Golden Rabbit Edition” for the launch, and we actually bought it last year -- but because of its limited availability, we never got around to reviewing it.", "AMD has changed its mind and is now making the ", " available at an MSRP of $550 for the rest of the world. That’s a huge change, because the card slots-in and shuffles the stack at the now-critical battleground of $500-$600, which NVIDIA is currently heavily occupying with its doubled-up ", " and ", ". The RX 7900 GRE allows AMD to now offer more selection in the same price range, giving NVIDIA some competition that we think is deserving of coverage.", "Intel Arc is absent in this price category, but we just ran a ", " of it for those interested in performance.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "This card has already launched so it isn’t a new GPU, but it’s now more widely available and is worth talking about. ", "There are more partner models available now than at its original launch. ", "The $550 price mark anchors it right against the RTX 4070 (watch our ", ") and 4070 Super (read our ", "). It may displace the ", ". We wouldn’t be surprised to see its price drop alongside the ", ".", "Here’s a quick overview of the specs.", "The RX 7900 GRE has 80 Compute Units, which is cut down from 84 on the ", " and boosted from 60 on the ", ". The gap between the 7800 XT (watch our ", ") and 7900 GRE will primarily emerge in situations where the compute workload is higher, although the 7900 GRE’s clocks are lower than the 7800 XT by pure spec sheet. Partner models can boost this higher, however, and will make-up for the difference.", "TDP is about the same between these cards, hence the lower power budget available for boosting while carrying more CUs than the 7800 XT. Memory bandwidth is also superior on the 7800 XT as a result of higher memory clocks. The 7900 XT’s main advantage is the hugely increased memory bandwidth.", "It’d help to get a quick pricing update to understand the closest alternatives. ", "The RX 7900 GRE should be $550 when it hits retailers worldwide.", "The RX 7900 XT (read our ", ") has finally fallen in price -- again -- and seems to be stable at around $730 to $750, but we’ve seen some options occasionally hit $700. At $700, it’s becoming a good overall value. But even that is $150 more expensive than the base 7900 GRE price, so they’re different price classes.", "The RX 7800 XT has an MSRP of $500 and currently has units from $490 to $500 with regular availability. That’ll be the closest price alternative to the 7900 GRE at $50 cheaper.", "NVIDIA’s closest price competitors would be the RTX 4070 Super at the upper end, at $590 and up. Decent cards can be had at $600. The RTX 4070 wasn’t discontinued and has been kept at around $550 officially, but we saw a few models around $525 to $540 on Newegg.", "As for the third player in the market, Intel’s closest card would be the ", " at $290 to $300. This is a distant price class and isn’t really competition for someone seeking to spend in the $500+ range, but check out our ", " for our thoughts on it.", "Let’s get into the benchmarks.", "In Resident Evil 4 at 1080p, the RX 7900 GRE landed at 223 FPS AVG, which has it between the ", " and the RX 6950 XT (watch our ", "). The 6950 XT was about $600 when we last saw it available new. The 4070 Super is currently $590 to $600, so the 7900 GRE ends up cheaper here while outperforming the 4070 Super by 3.1%. It’s not likely to be noticeable, but it is a real advantage (and the price is noticeable).", "That means the ", " leads by 13%, with the 7900 XT 17% ahead of the 7900 GRE. Lower down the stack, the ", " remains an impressive performer and sits just below the 4070 Super, with the 7800 XT at 198 FPS AVG, giving the 7900 GRE a 13% lead.", "At 1440p, the 7900 GRE’s 157 FPS AVG has it 10% ahead of the 4070 Super, a significant boost from its 1080p lead of 3.1%. Going up to the RX 7900 XT would get you about 17% more performance for the price hike. Dropping down to the 7800 XT, we see an advantage form for the 7900 GRE of 15%. ", "Other notables include the RX 6950 XT, which is about equal to the 7900 GRE, and the original ", ", also about equal. Uplift over something older, like the RTX 2070 (watch our ", ") at 58 FPS AVG, would yield a 170% improvement to the GRE.", "At 4K, the RX 7900 GRE ran at 82 FPS AVG and landed between the ", " and 4070 Ti “", ",” the latter of which was about tied with the 6950 XT as well. The 7900 GRE now leads the 4070 Super by an impressive 15.6%. That’s why we test at all three of these resolutions: As we’ve seen in the past, NVIDIA’s new non-flagship 40-series cards struggle to keep scaling as the resolution increases. AMD has a disproportionate advantage against the 4070 Super here. ", "Buying up to the 7900 XT would give a boost of 19% with these settings. This is worth considering but the price hike is definitely noticeable. ", "Rainbow Six Siege is up now. First at 4K, the RX 7900 GRE ran at about 154 FPS AVG. That’s the same as the 4070 Super and behind the 3080 Ti (watch our ", "). The 7900 XT leads the 7900 GRE by about 23% here, a noteworthy advantage attached to a noteworthy price increase of about 27-30%.", "Against the 7800 XT, the 7900 GRE leads by 6.3%, or in terms of the absolute, 9 FPS average. The 7900 GRE falls exactly where you’d expect -- between the 7900 XT and 7800 XT -- but in this case, it’s more similar to the 7800 XT than the 7900 XT.", "Moving on to 1440p, the 7900 GRE runs about 7% ahead of the 4070 Super. The 7900 XT’s lead over the 7900 GRE this time is about 14%.", "Generally speaking, the 7900 XT starts to produce a meaningful uplift here, with the ", " not particularly meaningfully different in this title; however, that changes in ray tracing later.", "As an upgrade, the 7900 GRE produces an appreciable improvement over the last-gen 3070 (although the 3070 is still perfectly fine – watch our ", ") and over AMD’s ", ".", "At 1080p, the 7900 GRE is about tied with the 6950 XT, leads the 4070 Super marginally, and leads the 7800 XT by 4.6%. Overall though, this plays pretty well at 1080p on just about anything within the last few generations.", "Dying Light 2 is up now. At 4K, the RX 7900 GRE ran at 58 FPS AVG, which has it just barely hitting the minimum that most people target for framerate. Settings adjustments would fully accommodate 60 FPS. That has it about equal to the 4070 Ti and just ahead of the 4070 Super; however, realistically, all 3 of these devices produce about the same experience.", "Increasing budget to the 7900 XT would improve framerate by 18%. The ", " would yield a similar uplift. Against the RX 7800 XT, the 7900 GRE yields a 13% uplift. It’s almost perfectly in between the 7900 XT and 7800 XT.", "At 1440p, the RX 7900 GRE’s 118 FPS performance has it about equal to a 3080 Ti or 4070 Ti, with the 6950 XT slightly leading. The 7900 XT’s lead is only 14% here. The 7800 XT also happens to allow the 7900 GRE a 14% lead, planting it perfectly in between. As for the 4070 Super, the lead is about 6% while the price is lower for the GRE.", "At 1080p, the 7900 GRE’s lead over the 4070 Super evaporates as the two cards converge to functional equivalence. The 7900 XT and the 7800 XT position themselves equidistant from the 7900 GRE, with the superior card in each scenario leading by about 12-14%.", "We’re moving on to Final Fantasy 14 now. At 4K, the 7900 GRE runs at 98 FPS AVG and produces the same overall experience as the ", " and RTX 3080 (watch our ", "). The 4070 Super leads this time, now by 7%. ", "The GRE is less centered between its AMD peers this time: The 7900 XT leads by a noteworthy 27%, with the 7800 XT getting led by about 13%.", "NVIDIA’s alternatives include, again, the 4070 Super, with the 4070 Ti Super ranking a little ahead of the 7900 XT. Upgrades from RTX 2060 (watch our ", ") or RTX 2070 (watch our ", ") class cards would be meaningful, but anything more modern can wait another generation or two.", "At 1440p, the 7900 XT begins running into overhead in this particular game, as we’ve talked about before. That extends to 1080p. The 7900 GRE therefore lands closer to it than when outside of these conditions, although the GRE still fully scales -- so its lead over the 7800 XT remains about 10%. The 4070 Super outperforms the GRE here. They swap positions depending on the game.", "GTA V at 4K is one of the charts we keep around for generational comparison data because our results don’t ever change -- you can see the 5700 XT here as an example of that. ", "The 7900 GRE runs at about 106 FPS AVG, which has it leading the 4070 by a slight 3.7%. The 4070 Super leads again in this one, at 118 FPS AVG and establishing an 11% uplift. The 7900 XT has another one of its stronger leads in this test, with the 4K resolution contributing, up at 24% advantage over the GRE, closer to parity with the price increase. Against the 7800 XT, the 7900 GRE is relatively close this time: It’s an 8% lead.", "As for the 5700 XT (watch our ", "), the 7900 GRE improves over the former flagship by 94%. It’s about 2x the framerate. For a reminder, Intel Arc struggles with our test settings in this game. Disabling MSAA for Intel Arc improves its performance disproportionately from the impact to AMD and NVIDIA.", "Starfield is up now. This is a title that AMD tends to do well with.", "At 4K, the 7900 GRE runs at about 60 FPS average. Lows are expected and consistent. The 4070 Super produced a 53 FPS result, giving the 7900 GRE a 9% lead this time. The 7800 XT is closer to the 4070 Super than the GRE, with the GRE holding a 13% lead. That’s similar to what we’ve seen elsewhere. The same is true for the 7900 XT, which keeps its 19% lead over the GRE.", "At 1440p, the 7900 GRE’s 91 FPS AVG has it just behind the 4070 Ti and Ti Super and leading the 4070 Super by 5%, reduced from 9% at 4K. This continues NVIDIA’s trend of sometimes suffering disproportionately at higher resolutions.", "Otherwise, the lineup remains comparable to before. We added the RTX 2080 to this chart, so you’ve got an extra data point you can use for this one.", "Now we're moving on to ray tracing benchmarks. Some of these games are the same games but with RT and settings changed, so the numbers can't be transplanted between the charts.", "Cyberpunk is our heaviest RT workload, so we’ll start there. We’ve also shown that AMD falls increasingly behind as the RT workload in this game increases. This is the lightest of the two settings we test, meant to represent a balanced option between the vendors. Ultra is next and is what allows NVIDIA to pull wildly ahead.", "At 1080p/Medium RT, the ", " runs at about 57 FPS AVG, giving the ", " a 14% lead and leading the ", " 13%. NVIDIA is where it gets interesting: The ", " now leads the ", " by a more remarkable 34%. If you really care about super heavy ray tracing, especially in Cyberpunk or games like Dying Light, then NVIDIA still maintains the advantage. But in lighter RT games coming up, it evens out. Just depends on the load.", "Arc actually does extremely well in Cyberpunk with RT, roughly equating the ", " with the much cheaper ", " GPU. This is due to architectural choices the Intel team made. Unfortunately, since the stack stops at the ", ", they don’t have anything up at the 7900 GRE levels of competition.", "At 1080p and with Ultra RT settings, the 7900 GRE falls to 40 FPS AVG, this time leading the ", " by 17% and with the ", " about 12% ahead of the GRE. But this is what we were talking about: Even the RTX ", " non-Super is outperforming the ", " here, with the ", " now benefiting from an overwhelming advantage of 63% over the 7900 GRE. It’s not even close anymore.", "Resident Evil 4 is way, way kinder to the AMD stack. This is more representative of lighter-weight RT workloads and we’re using FSR Quality on all devices here.", "The RX 7900 GRE’s 91 FPS AVG result has it about equal with the 4070 Ti (watch our ", ") and 6950 XT, producing the same experience. The 7900 XT leads the 7900 GRE by 17% in this one, with the 7800 XT’s 83 FPS AVG giving a 10% lead to the GRE.", "Notably, the GRE leads the 4070 Super this time around, which itself is about tied with the 7800 XT.", "At 1440p, the GRE ran at 137 FPS AVG and fell behind the 4070 Super, although they’re less than 3% apart. Otherwise, everything else is predictable on the AMD side -- the 7900 XT and 7800 XT remain the flanks, and on the NVIDIA side, AMD is more competitive here than previously. That’s especially true now that the 7900 XT has dropped and held its cheaper price.", "At 1080p, the 4070 Super continues its upward trajectory and gains an 8% advantage over the GRE. As we’ve seen elsewhere, the AMD part is benefited by the higher resolution here, while NVIDIA benefits from the lower resolution.", "In Dying Light 2 with ray tracing, we’re back to a performance disparity closer to the Cyberpunk Medium results. Starting with 1080p, the RTX 4070 Super’s 119 FPS AVG leads the 7900 GRE by a comparatively staggering 24%. For the times AMD led this card in rasterization, NVIDIA is definitely trying to make it up in some of these RT loads. Positioning against the 7800 XT is the same as before: The GRE is about 14% better.", "At 1440p, the 7900 GRE runs at about 65 FPS AVG. It’s still capable of this game with RT when using FSR quality like this. The 4070 Super keeps its 24% lead. The 7900 XT and 7800 XT remain positionally the same as before, with the 4070 non-Super ahead of the GRE now.", "For power consumption, this is pretty quick. The 7900 GRE that we tested measured out about 270 watts when it was under a complete workload. The 7900 XT was around 313 just for reference. The 4070 Super, which was the closest competitor in the rasterized testing, was at 222 watts so NVIDIA definitely holds an efficiency advantage here. And then the 7900 XT with the Hellhound partner model card was at 330 watts. ", "The ", " performs exactly as you’d expect: Generally speaking, it’s often equidistant from the ", " and ", ". Some scenarios that are more memory bandwidth-constrained or core clock sensitive allow the ", " to get closer to the ", " and the ", " to pull ahead more notably.", "The 7900 GRE trades places with the ", " in many of the rasterized tests we ran. It also is disproportionately favored at 4K in some of these tests, where NVIDIA’s bandwidth choices allow it to slip in the ranks and lose some of that proportional scaling it has at 1080p. ", "NVIDIA holds a significant advantage in some of the RT workloads, to the extent that you really should strongly consider going that route if heavy RT games -- like Cyberpunk -- are part of your play plans. If not, or if the RT games you’re interested in are more focused on singular features or reduced RT strain overall, then the relevance is reduced.", "Again, this isn’t a new card, but we do think it’s relevant as a competitor to the NVIDIA 4070-class cards."]},
{"title": " FPS Benchmarks Are Flawed: Introducing Animation Error | Engineering Discussion", "paragraph": ["FPS Benchmarks Are Flawed: Introducing Animation Error | Engineering Discussion", "Last Updated: ", "The Highlights", "We recently had the chance to catch up with Intel engineer Tom Petersen, with whom we’ve spoken in the past about benchmarking concepts like ", ". This time, we talked about the open source PresentMon 2.0, which is an update to an open-source tool from Intel that has long since supplanted FRAPS. We've been using PresentMon for around a decade at this point in our benchmarks, as have many other reviewers; however, the updates aim to bring new metrics into play to reveal bottlenecking more readily. We showcased some of these in our ", ".", "In this discussion, we talk about the inadequacies of looking at just frametimes.", "Steve Burke", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "With PresentMon 2.0, which is currently in beta, the software will show GPU wait times within the render time, which shows the interdependency between the GPU and CPU. Previously, PresentMon introduced GPU Busy (msGPUActive), but GPU Wait allows us to see inside the GPU Busy metric to determine if the GPU (despite appearing busy) is still waiting on the CPU in between its rendering operations.", "PresentMon 2.0 will also show simulation time error, a representation of stuttering. Whereas frametime measures variations in the delivery interval for each frame, simulation time error directly measures errors or a mismatching of game animation / the game state and the frame being presented. In other words, when the game just sort of feels bad but doesn't necessarily have a direct latency problem or frametime problem. This might be an instance where the simulation is erroneously matched to the frame being presented, meaning you're viewing data which is effectively out of sync with the visual, despite a potentially good frametime itself.", "According to Petersen, you ideally want the step between frame times to be uniform.", "PresentMon 2.0 is still a work in progress but GamersNexus is experimenting with creating an error per second metric that will indicate, most likely, when a particular game is problematic. Dragon's Dogma 2 gave us a strong start to that.", "In our discussion, Petersen also mentioned that Intel is also working on a software-based click-to-photon tester, which would start by looking at a USB event like a mouse or keyboard click (such as a Windows ETW marker). This can't truly be click-to-photon since there is no external capture of the photon part, but it may be a first step to giving 'normal' tools to end users without needing hardware. NVIDIA's FrameView also provides a PCL, or PC Latency, measurement that provides a level of evaluation for total system latency sans input and display out. Learn more about that in our recent ", ".", "Since software latency measurements aren't perfect, Intel is also making a hardware solution called the Latency Measurement Tool (LMT). It’s still being refined, but Petersen says that it will eventually be integrated with PresentMon and will be completely open sourced, including PCB schematics, software, and hardware solutions. This would be an alternative to NVIDIA's LDAT. Conceptually, the devices do the same thing, but differences in openness and in capability set them apart. NVIDIA's has some more advanced functionality baked into the software, while Intel's will be (theoretically) wide open.", "In the ", " embedded above, we take a look at PresentMon 2.0’s interface, which highlights how the software is able to examine CPU and GPU bottlenecks. The tool also has very robust histogram features. ", "Petersen says that PresentMon 2.0 will be out soon and we hope to see how it might impact our testing methodology moving forward."]},
{"title": " The Greatest GPU of All Time: NVIDIA GTX 1080 Ti & GTX 1080 2024 Revisit & History", "paragraph": ["The Greatest GPU of All Time: NVIDIA GTX 1080 Ti & GTX 1080 2024 Revisit & History", "Last Updated: ", "The Highlights", "Today, we’re revisiting the GTX 1080 (watch ", ") and the best card NVIDIA ever made: The GTX 1080 Ti (watch ", ").", "This card is the GOAT. No questions about it. Steve actually still uses it at his house in his personal machine. Specifically, he uses an EVGA GTX 1080 Ti SC2 ICX card (watch ", "), which he really liked for the performance and overall size. ", "It’s so good that we’ve revisited it now at least 2 or 3 times, and this time, it’s with all the modern cards on the charts. We also added some new charts to this revisit to help get up to speed quickly.", "Steve Burke", "Patrick Lathan", "Michael Gaglione", "Jimmy Thang", "For many years now, and with each revisit, we have said that the GTX 1080 Ti is a mistake that NVIDIA will never make again. Its MSRP was only $100 above the GTX 1080, or maybe $200 depending on how you counted the mess of FE models and partner models of that era. But even at the higher end of that, it was a relatively small price jump for a significant performance improvement. It was the ", " of the era.", "When the RTX 20 series launched, it only made the 1080 Ti look even better.", "The 20 launch really is what cemented the 1080 Ti in its place. With the launch of the RTX 2080 (watch ", "), we told everyone to just buy a 1080 Ti instead. That’s because they could still be had for -- believe it or not -- around $700 in many cases. ", "The MSI Armor series was a barebones, trash-tier cooler that made for a dirt cheap entry to the 1080 Ti that could be converted into a hybrid or liquid cooled card to create a monster. The SC series also competed strongly here. And at that price, it was commonly $100 under the new 2080s while offering equivalent or sometimes better performance. The namesake feature of the 2080, “RTX,” had 0 games at launch and would not for a long while after. While RT is relevant today, there was no telling how long that market would take to shape-up at the time.", "The 1080 Ti immediately gained legendary status with that launch. Now, 7 years later, it can still handle a lot of the games in our testing at reasonable FPS. Its biggest weakness is a lack of support for modern features like RT hardware. If you’re OK without it, depending on the games you’re playing, it may remain good until the next generation.", "The GTX 1080 Ti launched in March of 2017, about a year after the 1080’s launch in 2016. It was a powerful one-two punch from NVIDIA. At the time, its newest competition from AMD would have been the RX 580 (watch ", ") that launched in April of 2017, which itself was a refresh of the RX 480 (watch ", "). Otherwise, the 1080 Ti was up against an aging generation of Fury cards. ", " for another several months, and largely to disappointing reception.", "This was also in an era when AMD was absolutely plagued and riddled with driver problems. If the AMD drivers had a door, opening them was like walking into a dark room filled with roaches. They’d scatter.", "AMD’s drivers have grown substantially since then and improved in huge ways. AMD is past the worst of its driver woes, but back then, it was bleak for AMD’s offerings. They chose to fight more in the mid-range market. The RX 580 was a well-positioned card, and one for which we unfortunately have no modern like-for-like replacement at the price.", "Looking back, that was an era we all probably took for granted. The 1080 Ti made for amazing performance at the high-end and the RX 580 made for a powerful card at the $200-$250 mark. The whole market was covered pretty well.", "Let’s do a quick look at the pricing and adjust for inflation.", "The GTX 1080 Ti was often $700, like the MSI Armor card, and ran up to $800. There were more expensive cards as always, but these two price points covered the vast majority of options.", "Today, a $700 purchase of the 1080 Ti would be equivalent to spending $880.73, according to US inflation data. An $800 purchase would be equivalent to $1,006.55. If you look at GPUs available right now, that $880 adjusted price would be an ", " from NVIDIA or an RX 7900 XTX from AMD, flanking each end. The $1,000 inflation-adjusted 1080 Ti price would be an ", "’s MSRP, if you can find one at MSRP, or again, a ", ". ", "Back to the inflation table, the GTX 1080 was $600 to $700 commonly. And again, remember that NVIDIA made this all very messy with its FE pricing of the time. That’d be $766 to $894 today.", "Equivalents would again include the ", " from NVIDIA and the ", " to 7900 XTX (watch ", ") from AMD.", "What’s wild is the ", " price of the GTX 1080 Ti. In a quick look around, they seem to commonly be selling for $150 to $200, or sometimes cheaper if you buy one with a broken fan. That’d be easy to fix.", "That makes a used GTX 1080 Ti a better option than NVIDIA’s modern $150 to $200 cards -- or sometimes even its $300 card. NVIDIA’s own masterpiece remains a thorn in its side for new sales and for expectations.", "The 3080 (watch ", ") did well to reset from the 20 series, but its limited availability at the strong launch price quickly evaporated its hopes of having a similar long-term reception as the 1080 Ti. ", "It’s time to get into some numbers.", "We’ll start with re-establishing our bearings for how the GTX 1080 and GTX 1080 Ti compare to each other today. This factors-in the latest drivers for each, Windows updates, and modernized changes to the BIOS and OS (such as ReBAR and hardware-accelerated GPU scheduling).", "Here’s the chart. This shows the percent improvement from a GTX 1080 to a GTX 1080 Ti in various games we test in 2024. It’s remarkably consistent from game-to-game in this era, even across resolutions. That’s a big difference from what we see between the cards today, where NVIDIA plays with memory bandwidth in ways that create less predictable scaling across resolutions.", "The GTX 1080 Ti is generally about 35% better than the GTX 1080 in AVG FPS for today’s benchmarks. If you had waited until the 1080 Ti launched and spent about $100 more, max around $200 more, then that money stretched pretty well and could have been a deciding factor in stretching the card out for one more generation.", "As a side note, it’s rare that we see 38% uplift for $100 these days. That doesn’t really happen anymore, but the fact that NVIDIA priced the 1080 Ti at $100 to $200 above the GTX 1080 (broadly speaking) seems like it will never happen again with such consistency when looking at the performance improvement. It almost seems like a mistake.", "Since we’ve revisited the GTX 1080 Ti so much, we’re going to do something different this time. We’ll start with a new style of simple table that we haven’t used before: It recaps several games we’ve tested and shows the most immediate better and worse cards in any modern generation. The table also shows the closest equal of any generation. As usual, the disclaimer “of what we’ve tested recently” applies. There are other equals or flanks, but we’re looking at recent benchmarks.", "The intended use of the table is to help you understand your baseline. If you know the most immediately better and worse cards, you can start to approximate where a 1080 Ti would fall on any chart (even if that chart lacks the 1080 Ti). Likewise, you can also figure out your baseline if you want to improve with an upgrade, not sidegrade to something similar.", "Here it is.", "The most immediately behind, modern architecture GPU is generally the ", ", ", ", or NVIDIA’s 60-class cards like the RTX 3060 (watch ", ") and ", ". Intel Arc also makes a few appearances. This tells you that if you wanted to upgrade, you need to buy at least better than these cards in the modern lineup to get any meaningful improvement at all -- and ideally, a couple steps up from them to ensure it is actually meaningful and not just a sidegrade with ray tracing capabilities.", "The closest of any generation we’ve recently tested is variable. We see the 2070 Super (watch ", ") appear a few times and the ", ", but it really depends on the game tested. The RTX 2080 (watch ", ") also makes an appearance.", "For the most immediately advantaged modern generation card, the 1080 Ti is commonly beaten most immediately by the same cards as were immediately behind it. This makes sense. When a card is +/- a few percentage points, it can swing either way. The ", " appears the most here. If you’re not buying at least a ", " or ", " as a replacement, generally speaking, we don’t think it’d be worth buying a new card.", "Let’s look at this another way. Instead of the most immediate flanks, which can return largely similar results due to the nature of small changes, let’s look at the uplift offered by the most likely upgrade candidates. These are chosen assuming a buyer is hoping to get the most uplift but spend around the same money as they originally did. We think the most relevant by these standards would be the RTX 4070 Ti Super (read ", ") and ", ", followed by the ", " and RX 7900 XTX for those who may want to spend more than they did years ago. This also helps you understand what spending another $150-$300 will get you for uplift.", "Here it is against a bunch of games. The 1080 Ti itself is not shown. That’s because it’s the left axis, or baseline. We are looking at percent improvement over baseline in average FPS.", "This is one of those scenarios where anything would be an upgrade. Generally speaking, you can expect somewhere around a 120-150% uplift with a 4070 Ti Super across these suite of games. The 4080 Super (read ", "), roughly speaking, would give you around 170-190% uplift. The XT is around the 140-160% for uplift, with the XTX at 190-210% or so broadly speaking. Each of these has several break-outs, including the ", " spiking upwards of 300% improvement in Starfield. At that point, percentages don’t feel like they mean anything anymore. Suffice to say, it’s an entirely different experience. You should basically be choosing between the modern cards that you're considering rather than necessarily comparing them to the 1080 Ti because all of these are going to be massive changes in the experience but it's still fun to look back and get a feel for it this way.", "The next recap is for the GTX 1080. For this one, we’re comparing against the RTX ", ", the RTX 4070 Ti Super, the ", " that just got a global launch, and the RX 7900 XT (read ", "). The ", " is the same price that the 1080 launched when ignoring inflation, or would be the equivalent of $470 at launch back then. The ", " is a similar price today, or including inflation, would be about $431 back at launch. That gives us two cards priced similarly with inflation and two priced below.", "Here’s the chart.", "The 1080 Ti doesn’t appear here since we already showed a summary chart for that, but as a reminder, that’d generally be around 35% uplift from the 1080. For the rest, you can get increases in average FPS in the multiples even with something at an equal price today when ignoring inflation. Even if your buying power hasn’t kept up with inflation, you can at least get a 2-3x increase in many scenarios with a 4070 Super (read ", "). The 4070 Ti Super (read ", ") is better enough that it may help pull you forward another year than the 4070 Super, though that depends so much on how much you’re willing to lower graphics settings that it’s hard to make estimates like that. You’re paying for that theoretical longevity. The 7900 GRE also provides significant uplift while being cheaper than $600 and is one of the more relevant cards at that price point right now.", "The 7900 XT is just in another class of rasterization performance altogether. It blows these away; the biggest difference though would be in ray tracing.", "We're about to get into the individual game test just to give some foundational data with more charts. There aren’t ray tracing charts here because the 1080 Ti does not natively or meaningfully support realtime ray tracing in modern games. Because of that, there's not really anything to test. For ray tracing results, just look at the RT charts in our ", " or any other recent GPU review.", "We’ll quickly run through a few game charts. Because we’ve already covered the major comparisons, these will mostly be to focus on key highlights or to provide a wider scope of cards to compare against. There are a lot on here, so feel free to pause at any point for the ones you care about.", "In Final Fantasy 14 at 4K, the GTX 1080 Ti still manages to hold a 62 FPS AVG. No problems here. That has it at 3060 Ti (read ", ") levels of performance and actually surpassing the 2080, somewhat embarrassingly for the Turing card. The 1080 FTW ran at about ", " levels of performance, flanked by the two available models. This chart actually also contains an overclock we ran for the 1080 Ti last year for our revisit (and that data is still valid -- this game’s results don’t change in our test approach). That OC had it up at ", " average FPS, surpassing the ", ".", "In Dying Light 2 at 1080p, the GTX 1080 sat below the ", " in our most recent round of testing. The 3060 also leads it somewhat significantly. The 1080 Ti has done excellently to hang-on here, but in some heavier modern games, it is beginning to fall to the bottom of the charts. Of note, even Intel’s ", " is outdoing the 1080 Ti in this one. The RTX 3080 is a good reference point, at 151 FPS average to the 1080 Ti’s 74, or the 1080’s 55.", "One last note: You can see the 1% lows dip down on the 1080, indicative of where some of the generational improvements have been invested over the years.", "1440p stretches the scale to the point that the 1080 Ti now falls below 60 FPS. If we choose 60 FPS as a somewhat arbitrary line of scrimmage, the first card that passes it is the A770 on this chart, with the ", " and 2080 close enough. For non-Intel, you might consider the ", " or ", " as meaningfully improved over the 1080 Ti, but probably with less staying power than you benefited from on the 1080 Ti.", "We tested Starfield at 1440p mostly because it helps us avoid non-GPU limitations higher up the stack, the GTX 1080’s performance had it about tied with an ", " GPU. Intel struggles in Starfield, so it’s not the best comparison. The RX 6600 (watch ", ") and RTX 3060 both post large gains over the 1080, despite neither being a recommended path forward from the card. This and the 1080 Ti alike would be hugely improved upon by nearly anything in the chart. 1440p is heavy with this game on these cards. They were capable 1440p players at the time, and even some 4K, but games have also gotten heavier in the years since Pascal.", "At 4K, the Pascal cards can’t handle the game and are clearly struggling. Their results are less consistent as a result of the load. To get to a meaningful uplift might mean a jump to a ", ", a used RTX 3080 as a great option, or the 4070 Super.", "In Rainbow Six Siege at 1080p, we’re served a reminder that both of these cards can still be objectively capable performers for the right title. This combination of resolution and game still puts the GOAT 1080 Ti into the hundreds of FPS, approaching 300 for the average, with even its slower 1080 counterpart still surpassing 200 FPS AVG. If you’re not playing the heaviest games at higher resolutions and if you don’t always need max settings, then in an objective sense, these are still good enough. Anyone ultra competitive might notice a latency difference between the 1080 Ti and a 4070 Super here, but generally speaking, if you’re not noticing the performance of your 10-series card as being bad, there’s no shame in sticking with it. To us, it’s a sense of pride. That’s why Steve still has a GTX 1080 Ti in his home machine.", "At 1440p, the GTX 1080 still holds 130 FPS AVG in Rainbow Six Siege, with the GTX 1080 Ti continuing to impress and earn its GOAT title, all 7 years later, with a performance equivalent to the 2070 Super and besting the modern A750 (read ", "). Noteworthy entries on this one remain the RTX 3080, which would still give a huge upgrade pathway while potentially running cheap if you’re willing to trust a used listing. The new RX 7900 GRE also jaunts ahead for something at a balanced price.", "At 4K, the Pascal cards both manage to keep their framerate above 60 FPS: The 1080 Ti FTW3 held an impressive 83, tying it with the 2070 Super and ", ", and the 1080 FTW ran at 62, about the same as the ", ". They’re still hanging in there. Another option we haven’t discussed is a potential used 3070 (watch ", "), but it’d really have to be cheap enough to be worthwhile. Other cards probably feel a lot better to move to than a 3070 if you’re a current 1080 or 1080 Ti owner, if only from the psychological association with the name. If you can get a 6950 XT (watch ", ") for $500 or so, that’s one that people are probably sleeping on these days.", "Resident Evil 4 at 1080p is up now, another of the relatively new titles in the suite. This one has the 1080 Ti at 101 FPS AVG and the 1080 at 74. That’s not bad. The 1080 Ti puts up a performance not distant from the RTX 2080 and just ahead of the 2070 Super. The 1080 trails the 3060. This is still playable on both.", "At 1440p, the 1080 FTW slips to about 50 FPS AVG. Still playable, but less enjoyably. The 1080 Ti maintains an overall good framerate and is effectively tied with the RTX 4060. You’d want to buy into a higher class of card if upgrading, otherwise it’ll just be the same in rasterization except with RT support for less intensive RT titles. On the AMD side, the 6950 XT remains worth paying attention to in the used market, as does the RTX 3080 for used. For new cards, the 7900 XT remains hard to beat for value with its $700 to $720 pricing lately. And for NVIDIA, the 4070 Super might be one of the stronger modern values.", "At 4K, both cards struggle. They fall off more as resolution increases in modern titles. The 1080 Ti manages to hang onto the 2080 equivalence, reminding us of exactly why our RTX 2080 launch-day review conclusion was to just go buy a 1080 Ti. Remember, at that time, there were literally 0 RTX games. The first RTX game wouldn’t launch for another 2 months, and because we’re not in the business of reviewing promises, the 1080 Ti made way more sense. It was comparatively cheap back then. It’s incredible how many generations this card has managed to survive, and matching the 2080 really proves that.", "Finally, in GTA V, the 1080 held a 56 FPS AVG and was between the 5700 XT (watch ", ") and 3060 at 4K. The 1080 Ti continues to impress and outmatches the ", ". It’s a hell of a show from Pascal. ", "Finally, just for fun, here’s some power consumption numbers. In a total 100% workload, we had the 1080 Ti at about 283W. That has it more power hungry than the 7900 GRE, so if nothing else, cards have definitely gotten way more efficient over the years in terms of FPS. It’s similar to the ", " non-Super.", "With an overclock, we had the 1080 Ti at 325W. That’s another aspect that GOATed the card: Its OC headroom was often enormous, with board partners more enabled to expand the total power budget than you’ll often find today. This has it around the 7900 XT and 3080.", "To recap some of the pricing, the ", " is similar in price if you ignore inflation. It's cheaper if you factor it in, at around $470. The ", " is the same price back then with inflation, meaning if you spent that amount of money today and then you got in a time machine and went back, you'd be buying a 1080 Ti with roughly the same money. The ", " is cheaper when you ignore inflation. It would be about $431 in 2016 while the ", " is similar price with inflation now. ", "These inflation numbers come from US Government data. For the numbers, we compared the precise launch date for the 1080 Ti against December of 2023 as they didn't have 2024 data available yet. Those are kind of the numbers to consider ultimately if you feel like your buying power is about the same as it was back in that era then you're looking at something like maybe the ", ", ", ", or something in that range. ", "The 1080 Ti holds on to its crown as the GOAT and at this point, it's not going to let go of it. The card will go down as completely legendary when it eventually gets retired from our benches but until we can't really run things anymore, we're going to keep it in as many charts as we can because it's just fun to see how well it's holding up.", "If you're looking to buy something new, viable options include the ", " and ", ". The ", " has also come down in price to $900 to $950 these days. In the used space, the 6950 XT and the 3080 are starting points. The ", " is also a more affordable option that will still provide a meaningful uplift along with some ray tracing.", "If you're looking for the next 1080 Ti, there doesn't really seem to be one right now. The 3080 was lined up for it but couldn't quite take that title. The ", " is definitely the closest contender but its price just takes away a lot of the power that it would have in terms of that association. It's got to be a combination of the two together that make something as special as the 1080 Ti was, which still plays games if you're not into RT or don't care yet. If you can get by on either older titles or playing at 1080p and don’t feel like the card is underperforming, then perhaps you don’t need to upgrade or can just wait until the next generation."]},
{"title": " 12VHPWR is a Dumpster Fire | Investigation into Contradicting Specs & Corner Cutting", "paragraph": ["12VHPWR is a Dumpster Fire | Investigation into Contradicting Specs & Corner Cutting", "Last Updated: ", "The Highlights", "12VHPWR doesn't exist anymore -- technically; it's transitioned to 12V-2x6, and NVIDIA has been using it for months, except technically not. 12VHPWR is also different from the 12-pin 30 series connector, but also different from 12V-2x6. ", "You apparently need a ", ", or maybe a ", " is fine, or maybe tulips or square plugs are best, or you can ", ", actually. Design oversights mixed with improper insertion cause an initial wave of problems.", "Steve Burke", "Patrick Lathan", "Vitalii Makhnovets", "Andrew Coleman", "Jimmy Thang", "Aris Mpitziopoulos (Cybenetics & HW Busters)", "Roman 'Der8auer Hartung (Thermal Grizzly)", "'Elmor' (Elmor Labs)", "Anonymous Engineers (Formerly at GPU Manfs)", "CableMod markets its solutions as superior on the back of this, says there is zero risk, then later royally screwed its own design and ", " of all its angled adapters. ", "A lot of people got the wrong idea that 12V-2x6 cables are intended to be used at 675 W, but they’re not. Wccftech reported that “", ",” except PCI-SIG mentioned neither Non-ATX 3.0 PSUs nor Gen 5 adapters in that very post.", "And Corsair... is mailing out ", " ", ". ", "12VHPWR is a mess. ", "Our story here started out as a cut-and-dry failure analysis of the CableMod angled adapters. We paid a third-party failure analysis lab to help us investigate CableMod’s specific failures as a post-mortem since no official cause was ever released, but as we went further, we realized we needed to start from the beginning.", "For this story, we did something we’ve been doing more recently, which is we sent our ", " to a number of peer reviewers and fact checkers to ensure accuracy of our research and statements. That’s because this topic is complex and spans several years of messy developments. These reviewers include Aris Mpitziopoulos, the engineer who runs Cybenetics, (a power supply validation lab that created the modern PSU rating system), Roman Hartung, aka der8auer, who reviewed our video for accuracy of statements (particularly related to engineering and electrical topics). He also runs Thermal Grizzly. Other reviewers include Elmor of ElmorLabs, who’s the brilliant engineer behind some of the most useful testing tools in the industry and a few anonymous engineers in the industry who were formerly involved in dealing with these specifications. ", "We've all been using 6- and 8-pin PCIe power connectors on GPUs for a couple of decades without major controversy. ", "We ran a survey that many of you participated in: out of approximately 23,000 responses, 3.3% of users that had ever used the old PCIe connectors had had a failure, and 4.0% that had ever used a 12VHPWR connector had had a failure. ", "For purposes of this story, we may colloquially use the term PCIe connector to refer to PCI Express 2x4 Auxiliary Power Connector, aka PCIe 6 and 8 pin, although technically, all of the connectors we're discussing today are PCIe. That’s just to make it a little shorter. There's some sample bias there with all the attention on 12VHPWR, but even assuming some error in here, that’s a similar failure rate over a shorter time span. ", "A lot of the 12VHPWR reports were of the CableMod adapters, which we already knew were problematic. ", "With the recent-ish CableMod adapter failures and recall, we're coming back to organize and conclude this story. ", "First, though, let's look at some CableMod adapters and try to understand what went so wrong that they issued a government-level recall -- something must have been different.", "A lot of this content in this article is sort of a historical look back at a massive timeline of the whole saga. We’re going to be stepping through a lot of materials and documents.", "We have some additional failed cards and connectors from CableMod so credit to them for at least being involved in the investigation, but ultimately, we found three that were really representative or otherwise good samples and sent those in. We did a cross-section on one of them and we've got some pretty interesting stuff.", "We sent three CableMod angled adapters to a failure analysis lab: one 90 degree variant B (#1), one 90 degree variant A (#2), and one 180 degree variant B (#3). ", "All three adapters melted around the GPU-side 12V terminals, specifically the thinner part inserted into the GPU. This implies that the area of high resistance was between the GPU pins and the male terminals, which matches the original partial insertion failures ", ". ", "On #1, there are no obvious markings. ", "On #3's ground pins, there's a wear mark that indicates a gap of about 0.8mm, which is small enough that it could have been created even with the retention clip in place. ", "On #2, we know the connector was 100% fully seated because it melted off with the adapter, so this one should be a clearer indicator as to what CableMod specifically screwed up with its adapters. We have two other pairs of GPUs and adapters that we didn't send out from CableMod, and the angled adapters on those appear to have been seated at least enough to fasten the retention clips.", "So, we have five melted and later recalled CableMod adapters, and some (if not all) of them were installed correctly.", "The adapters commonly had inadequate solder fill, although #2 specifically had gotten so hot that the solder reflowed away from joints. CableMod and its factory used 100% tin solder; manufacturing often requires using a lead-free solder, but it has the disadvantage of a significantly higher melting point (232C) versus tin/lead solder (183C), although it depends on a few other factors like the specific alloy composition and there’s a bit of a range. ", "The extra-thick copper layers on the PCB combined with excessive vias and big copper bars would have made it very hard to heat the angled adapters enough to flow tin solder and wet the mating surfaces. ", "This may explain the excessive flux that the failure analysis lab we hired identified on #1, which could cause electrical issues depending on the flux used and the amount, according to the lab. Bad solder fill and flux are problems, but as we concluded during the ", ", the point of failure wasn't at a solder joint.", "The clearances between the solder pads for the sideband pins and 12V pins on CableMod’s adapter are not adequate. The pads practically overlap here. You can see it pretty clearly. This combined with manufacturing variance or tolerances could lead to disaster and may have contributed to the CableMod recall. In the instance of our units though, this isn't good design, but it also didn't lead to our specific failures. ", "The lab also observed that the male connector lacks the proper H+ stamp that would signify a 9.2A per pin rating as laid out by the spec, but so do the NVIDIA adapter dongles that shipped with our ASUS 4090s. Having a letter and a plus sign obviously doesn’t change the characteristics, but may indicate process control or communication issues.", "The failed adapters we sent in left too much space between the male connector and the PCB, allowing the connector ", " which is the issue that CableMod tried to address with later 1.1 adapters by staking the connectors. ", "Flexing pins could lead to fatigue and work hardening over time. In #1, a sideband pin was visibly bent at the PCB. In fact, the CT scan of #1 shows dramatic bending of most of the pins inside the connector housing. This is bad. This is also visible in the epoxied cross-section that the lab performed. Some of this may have happened when prying the melted connector out of the GPU, but the fact that it could happen at all is telling.", "Thermal Grizzly produces ", ". CEO Der8auer ran a video on New Year's Day 2024 entitled ", " where he stated that Nobody that is selling any kind of product that comes with any kind of 12VHPWR adapter can guarantee anything. That's just how it is. You are always left with a risk that something goes wrong as long as you use this connector.", "We checked with Thermal Grizzly and, at the time of posting, the company has had 4 RMAs. Der8auer noted that of those, two customers were unable to fully seat the connector due to backplate and water block obstructions. There’s also a new WireView pro, which has some relevant changes to it. ", "The one pictured above will have detection of the sideband pins to determine if the 12VHPWR connectors are fully plugged in. It also has temperature sensing at the power connectors and it has hookups for external temperature sensors; further, they’ve added an audible alarm that’ll sound when an incorrect cable is installed, there’s improper insertion, or when user designated current or temperature limits are exceeded. ", "The original WireView completely skips soldering the sense pins and just jumps them internally, and on the male connector, the 12V and ground pins are soldered to two common bars that project out from the PCB. Pad spacing and solder fillet concerns are minimized because of this.", "Corsair sells a ", " and we've seen no reported malfunctions. We ordered one, and the connectors on the one we got were more flush with the PCB than on the failed CableMod adapters.", "Our understanding is that CableMod outsold Corsair and Thermal Grizzly's angled adapters combined, so although we can speculate, we can't draw firm conclusions based on a lack of failures for lower volume adapters.", "And this is a good time to remind everyone (including ourselves): Cables and PCB adapters are different. Angled PCB adapters predictably use a PCB, for which the spec has no official guidance. ", "None of these points we’ve discussed are cables other than the prior partial insertion ", ".", "As for the CableMod adapters, the failure analysis lab stopped at observations, leaving some of the speculation to us. ", "We believe the lack of solder fill and the space between the PCB and the connector may have encouraged the terminals to flex in their housing, worsened by the leverage that's placed on angled adapters by taut cables. In combination with this, anchoring the terminals to the PCB prevented them from twisting to conform to the pins on the GPU side. ", "We don't entirely agree with ", ", but we do on that last, concluding point. ", "The spec for 12V-2x6 cables requires 25mm of free wire behind the male connector without anything that repositions them from their natural relaxed state or location where they enter the housing, and wires are to be dressed in such a manner to allow the terminals to float freely in the pocket. ", "From what we've seen in the specs, this specific side of the connector (shown in the image above) is designed to be installed on a cable and is not shown mounted on a PCB in the specs. It seems possible to do so by circumventing the problem (like Thermal Grizzly), or perhaps seating the connector flush with the PCB (like with Corsair’s adapter). We're never going to guarantee that anything involving 12VHPWR is risk-free, though; we're with der8auer on that. The design oversights make that impossible. To be clear though, we also wouldn’t guarantee that PCIe 6/8-pin is risk-free -- but statistically, its risk factor appears to be at least slightly lower\\ partially due to more overhead in the spec. Let’s get into that.", "Connectors melt because something causes high resistance and dumps energy as heat. In the case of the original 12VHPWR connectors, working with a failure analysis lab highlighted two factors: (1) partial connection in combination with cable tension and (2) foreign object debris. Failures with poor connection were repeatable in a lab setting and were a widespread root cause for the first wave of melting. ", "This was hinted at as early as August 2022, when NVIDIA ", ".", ". Heat loss increases with both current and resistance. Current should theoretically have a flat limit across all pins, but as the CEM says, due to variations in contact resistance, an individual pin may see more than 9.2A of current depending on cable contact resistance nonuniformity. ", "Larger normal forces (a tighter squeeze) and metal-on-metal wipe area means lower electrical resistance and lower heat, but it also makes it physically harder to seat the plug.", "There are a few disadvantages to 12VHPWR versus PCIe 8-pin. PCIe 6/8-pin power connectors are comparatively big, and they slide into place easily and with a noticeable click. As ", " have ", ", the 150W spec for 8-pin PCIe connectors is usually well below the rated maximum capacity, whereas 600W is closer to the rated capacity of 12VHPWR connectors, reducing the margin of safety. ", "Providing 600W requires four big eight-pin connectors with 12x 12V wires, providing redundancy and spreading out heat, or a single 12VHPWR connector densely packed with only 6x 12V wires. ", "If one 12VHPWR pin heats up, it may soften the plastic housing and cause a cascading failure, especially on the cable side where the plastic is what holds the metal pieces in place. ", "Checking with der8auer on this concept of softening plastic housing and cascading failures, he noted: If there is significant contact resistance on the connector side this could increase drastically to maybe 10W-20W. And 10W-20W on such a small part will heat up over time which can then cause the connector to melt or at least become soft in regard to the plastic. If the plastic becomes a little softer, an already slightly bent pin can bend even more. Again increasing the contact resistance and then leading to the failure. ", "Also, because of the tighter safety margin, factors like alloys, tolerances, structures, and contact areas all require more standardization and diligence from every random manufacturer. ", "A quick note here about the 30C threshold that ", ". Seeing a connector rise 30C above the metal and air literally around the connector, NOT room ambient, is an indication that the connector can't keep up with heat dissipation, and could indicate the beginning of thermal runaway. It doesn't have to do with the safe temperature of the connector or the rated power delivery at a given temperature. It also doesn’t have to do with the greater room temperature, as those who worked on the spec told us. It is about the immediate ambient of the connector and what surrounds it directly.", "The older connectors can and do fail. As examples, we found the two most recent viewer emails we'd gotten about melted 8-pin PCIe cables and connectors and bought both PSUs and their associated cables. ", "Both viewers had used stock daisy-chain PCIe connectors included with their PSUs to power 300W+ GPUs. ", " sheds some light on the issue: the company doesn't cover connector overuse, which it defines as damages or malfunction resulting from the use of a graphics card or expansion card with a single PCIe 8pin connector that exceeds standard 225W total power draw (150W from PCIe 8pin connector + 75W from PCIe motherboard slot). Similarly, a graphics card or expansion card with dual PCIe 8pin connectors that exceed 375W total power draw (300W from two PCIe 8pin connectors + 75W from PCIe motherboard slot) will also not be covered under warranty. Basically, using SilverStone's daisy-chain connectors almost always voids the warranty.", "Edit: since the video accompanying this article was published, SilverStone stated to us that The use of PCIe daisy chain cables included with our power supply does not void warranty if it was used in manner within the limit of our overuse definition. So technically we used an 8pin PCIe on our power supply’s modular interface, but that connector is capable of supporting 300W.", "If you ever have a failed component, you can email ", " and let us know what the failure is. If it’s in the warranty window, that’s even better because then we can buy it from you and we can use it to test the manufacturer’s warranty. ", "This chapter covers why 12VHPWR even came to exist.", "So, PCIe 8-pin connectors and cables are generally overbuilt, but not always, and not to a consistent standard - but because there is more room in the spec, it is more likely they are overbuilt even if accidentally. It's known that running more than 150W over an 8-pin PCIe cable can cause melting in edge cases, as shown by SilverStone's ", ". GPU power consumption requirements have increased, though, and they’re not really showing any signs of slowing down. To reliably get more than 450W of auxiliary power into cards in a small package required a new cable. The 12VHPWR connector is smaller, enables better cooling on the card by reducing PCB length and therefore enabling flow-through, reduces cable clutter, and allows for more flexibility in PCB design.", "Full-size PCIe x16 devices can draw 75W of power through the PCIe slot. Modern GPUs require more than that, and for years that additional power has been delivered by 6- or 8-pin connectors. ", "Both styles of connector carry the same three 12V power lines, but 6-pin connectors are rated for 75W, while the extra two pins indicate a higher standard that can carry up to 150W. ", "On September 17th 2020, the ", " with a new 12-pin connector. It was a big change in form factor, but electrically nothing new: six 12V lines and six grounds numerically matched dual PCIe 8-pin connectors, which you can find in many other cards. Some dedicated power cables for these cards ", " but, for the most part, everyone used the included adapter dongles. We're now aware that NVIDIA had been considering PCIe power replacements for years beforehand, some of them exotic, but the 12-pin design was an off-the-shelf part from Molex (like ", "). Behind the scenes, both 30 and 40 series went through multiple connector revisions before shipping—but we're getting ahead of ourselves.", "The Peripheral Component Interconnect Special Interest Group (or PCI-SIG)'s PCI Express Card Electromechanical Specification (PCIe CEM) Revision 5.0, Version 1.0 was released on June 9th 2021. This was the first time that the 16-pin 12VHPWR connector was officially defined, but there were no GPUs with 12VHPWR connectors. ", "Un-cynically, the 12VHPWR connector was smaller; therefore it obstructed airflow less, reduced cable clutter, and allowed for more flexibility in PCB design. Cynically, pushing for a new connector allowed NVIDIA to lead the industry and pull its competitor(s) along, like RTX and DLSS, and, to some extent, now AI.", ", and it lacked the four sideband connections that would be added to make 12VHPWR. ", ", NVIDIA and Dell Corporation were listed as co-sponsors of the sideband addition. PCI-SIG is a consortium: NVIDIA is a member, as are Dell, Intel, AMD, and dozens of others. To paraphrase an insider that we spoke to: there was no reason to think that adding four signal pins to a tried-and-true design would cause any problems.", "The four sideband pins were SENSE0/SENSE1, CARD_PWR_STABLE, and CARD_CBL_PRES#. At this point, the PCIe CEM said that the Add-in Card, high-power auxiliary cable, and power supply may optionally implement all, any, or none of the three features. CARD_PWR_STABLE and CARD_CABLE_PRES# were data signals that were intended for enterprise, Sense1 was unused, and Sense0 signaled whether 450W or 600W was available. Grounding Sense0 meant 600W; opening Sense0 meant 450W. ", "One troubling thing that you may not have known is that there’s really no required validation process for this stuff. A manufacturer could feasibly do whatever they want without actually ensuring that the cable can meet these various loads. Even though PCI-SIG sets the specification, it doesn't step in and validate and stamp cables. It’s not part of the scope of what PCI-SIG does as it’s up to the manufacturers to police themselves. They could also do whatever they wanted with PCIe 6/8-pin, it’s just that there’s more overhead there and the cable has been refined over decades.", "The ", " was ", " on February 1st, 2022. ", ". As you may have guessed based on that mess of a name, Intel curates the ATX spec, but it's really a collaborative set of guidelines to keep hardware compatible. ", ", and third parties like ", ", but the spec wasn't and isn't law. The first release focused heavily on power excursions, which ", " from the ", ", but it also included the as-of-yet-unused 12VHPWR connector, which was marked as ", ". ", "The 12VHPWR section referred readers to PCI-SIG for details.", "Most importantly, this release included updates to the two sense pins. According to the ATX 3.0 spec, PSUs with native 12VHPWR ", " and use them to signal whether the PSU itself could deliver a given wattage. The four possible open/ground combinations of the two pins were used to signal four sustained power tiers, not two: 150W, 300W, 450W, and 600W. Leaving both pins open signaled the lowest power capability of 150W, and if the Add-In-Card does not monitor these signals, it must default to the lowest value in this table [150W]. This conflicted with the PCIe CEM: the sense pins were required on the PSU side, and the GPU was required to monitor them.", "In March 2022, ", ". It was released only a couple of weeks after the ATX 3.0 spec, but it already included a mechanical change to the connector to protect the sideband wires. This change wouldn't be reflected in the PCIe CEM for months, and it would ", " for manufacturers to catch up.", "Immediately afterwards, on March 29th 2022, the RTX 3090 Ti (watch ", ") launched. This was the first card that used a 16-pin 12VHPWR connector, but the adapter cables that shipped with these cards were the existing 12-pin style. Connectors were keyed so that 12VHPWR plugs could fit into any 30-series card, but 12-pin plugs couldn't fit into any 12VHPWR sockets except for the 3090 Ti's. Like we said: It was a mess from the start. The 3090 Ti was functionally a test platform for the upcoming 40 series. The 3090 Ti didn't comply with the Intel spec from February of that year before it, which stated that leaving both sense pins open should actually signal 150W, not 450W.", "On August 25th 2022, it began. PCI-SIG showed a grim internal ", " from NVIDIA about CEM 5 16pin 12VHPWR. Failures have been observed [in testing] in certain cable routing conditions from PSUs and test boards that generate side load on the interface. This was a call to action for the WG to ensure the CEM specification is sufficient to prevent failures in the field. [...] Time to failure observed from 10-30hrs. All samples made with copper alloy terminals and 14-16AWG wire. Samples tested were both discrete wire and internally bussed with solder terminations. 3 different manufacturers have been tested. At least 10 sample assemblies have been observed to either melt or generate hot spots. ", "The cables shown in this presentation were real 16-pin 12VHPWR cables, which were still rare in the wild as no GPUs required them.", "NVIDIA tested non-adapter cables, it tested 14AWG cables, it tested both discrete wires and a soldered bus, and it tested multiple manufacturers. The implied conclusion was that none of it mattered. These tests were mostly concerned with bending and sideloading under high load. ", "This was the source of the bend radius recommendations ", " ", ".", "On September 10th, ", " an email that had been sent to PCI-SIG members in the wake of that presentation, which stated that PCI-SIG has become aware that some implementations of the 12VHPWR connectors and assemblies have demonstrated thermal variance, which could result in safety issues under certain conditions and we recommend members work closely with their connector vendors and exercise due diligence in using high-power connections, particularly where safety concerns may exist. ", "Wccftech ran this under the headline PCI-SIG Warns of Potential Overcurrent/Overpower Risk With 12VHPWR Connectors Using Non-ATX 3.0 PSU & Gen 5 Adapter Plugs. ", "Neither Non-ATX 3.0 PSUs nor Gen 5 Adapter Plugs were mentioned by PCI-SIG in that memo -- that was inserted by Wccftech. We have no idea why Wccftech ran with that headline, but for months after this reporting, the conversation would revolve around adapter cables specifically.", "For NVIDIA, this was nightmarish timing with 40 series on the horizon. ", "As ", " reported on the story, NVIDIA ", " to say that I think you're worrying about issues that don't exist. We have thoroughly tested our power adapters and expect no issues. Potential customers who are concerned can use the RTX 40 Series connector solution with confidence.", "On October 12th 2022, the RTX ", " (beware of scalped prices) launched. This was the first time a true 16-pin 12VHPWR connector was required, but all cards shipped with adapter dongles. NVIDIA's adapters were able to “intelligently” ground or open sense pins based on how many 8-pin cables were connected. This meant that, as we saw in our ", ", connecting just 3 of the 4 cables would reduce the overpower provisioning permitted through overclocking software at the time.", "The 4090 (watch ", ") launched alone for its first month, so at first, all 12VHPWR problems occurred with 4090s because that’s all there was.", "Less than two weeks later, on October 24th, the first report of a burned-out adapter ", ". By the 25th, there were two, and NVIDIA ", " that it was investigating the reports.", "Starting on the 27th, igor'sLAB took the wheel with a rapidfire series of articles, starting with the headline, ", ". At this point, Igor operated under the assumption that it’s the adapter solution exclusively provided by NVIDIA to all board partners, which has fire-dangerous flaws in its inner construction! and the native 12VHPWR cables of the better power supplies show that it can be done differently. He speculated that the solder bus within the adapters was fragile and inadequate, and that if any connections were to break, the inner bridge between the pins is too thin (resulting cross section) to compensate the current flow on two or three instead of four connected 12V lines. He ", ", a vendor for the connectors, and ", " would fix the issue.", "On the 30th, we ", " of our first-party investigation of the issue. We tested adapters with many combinations of broken solder, cut cables, and overclocked GPUs, but didn't come close to melting anything. Our conclusion was that although failures were clearly happening, it wasn't due to inadequacy of the bus bar on at least our units, and we requested melted cables from viewers for further investigation.", "Speculation about the solder joints and bus bars ", " at this point, and ", " the ", " of the adapters. ", "The design used in NVIDIA's Astron-manufactured adapters would be termed 3 dimple, versus the supposedly superior 4 spring design from NTK and subcontractor 3con. Theories were being created and discarded almost literally hour-by-hour at times, so we went dark as we gathered information.", " was filed with the goal of starting a class action suit against NVIDIA, filed in the Northern District of California by New York resident Lucas Genova, largely leveraging New York laws. Genova v. NVIDIA Corporation stated that the melting has affected both the 12VHPWR adapter and the native 12VHPWR cable, and claimed that 23 reports of melting had been posted on r/nvidia on Reddit by the 7th, just two weeks after the first report. ", "By November 14th, ", " ", " had ", " a mechanical change as “new” that had actually been in the public ATX12VO spec since March. NVIDIA separately ", ", though: that the sideband connections would be shortened so that the sense pins only become contactable when the plug has been fully inserted. ", "That's called foreshadowing.", "On November 16th, we melted a connector. Actually, we got pretty good at melting them", "—if you've never seen that video, it's ", " for at least the reaction. ", "To start, we worked with Buildzoid to eliminate popular theories. ", "We manually spread the split terminals in an Astron adapter as far apart as possible, but saw no significant change. We cut four 12V terminals off of an adapter and ran a 600W load through the two remaining pins, but still saw no significant change. ", "We then sent several viewers' failed adapters to a failure analysis lab, which found debris molded into the housing (called “Foreign Object Debris”), metal burrs on the terminals, and scraped-off plating. These were all problems, and similar problems may have led to some adapters melting, but they didn't melt ours.", "Most of the failures known to us up to this point happened with partially inserted connectors, which is what we were able to replicate twice in one night. ", "We're aware that this doesn't account for every single melted connector. We want to be as clear as possible here, because we used the phrase user error a lot. To ", ", even if it is user error, at some point it's like, if the design is so bad that it encourages user error with any amount of regularity, then it is a combination of user error plus design error. ", "“Improper insertion” may be softer phrasing for the same concept: Our conclusion was that it was a mix of bad design of a new standard, and of improper insertion caused by both of these. The lack of additional power headroom means lower tolerance, plus the stricter requirement for quality metals and highly-rated plastics means that corner-cutting manufacturers wouldn’t be able to cut the same corners with the same success as with PCIe 6/8-pin.", "The tight 12VHPWR connector with its four additional sideband connections and no tactile click, hidden deep inside the shroud of a gigantic 4090, could easily be left partially unplugged. ", "We found specifically that not fully seating the connector and then pulling it to the side would reliably melt it, and we also clearly identified markings on some adapters that indicated that they melted while partially inserted. To quote ourselves again, ", ". ", "This isn't a get-out-of-jail free card for manufacturers to do blanket RMA denials. In fact, there was a leak that NVIDIA allegedly told manufacturers to just approve all of those related RMAs.", "Immediately following our video, ", " that we are aware of about 50 cases globally and our findings to date suggest that a common issue is that connectors are not fully plugged into the graphics card. ", "Based on this, there was a 0.04%-0.05% failure rate relative to approximately 125,000 RTX 4090s sold in the first month. ", "Also, NVIDIA stated that we are investigating additional ways to ensure that the connector is secure before powering on the graphics card. As NVIDIA stated in an internal document afterwards, testing of impedance vs gap spacing between the receptacle and the adapter showed that an increase in gap spacing corresponds to an increase in impedance and the impedance increases significantly after 1.5mm of gap spacing, and some pins violate the 6mΩ PCIe CEM5 electrical spec.", "After this, things slowed down. In December, PCI-SIG sent an email to members saying that when implementing a PCI-SIG specification, Members are responsible for the design, manufacturing, and testing, including safety testing, of their products, but it's unclear to us whether that was directed from or at NVIDIA.", "In February, months after we melted a 4 spring connector, ", " stated that crimp contacts inside of the cable plug are recommended to use the 4 Spring design instead of 3 dimple design [...] which will increase the contact area for electrical current flow inside the 12VHPWR connector and reduce the temperature rise of each contact. ", "This statement was later altered, and ", " Crimp Contacts inside of the cable plug are can [sic] either use the 4-Spring design, 3-dimple design [...] or equivalent design. Without any explanation we could find, they removed the text about increasing the contact area for electrical flow and for temperature reduction.", "In March, ", " was voluntarily dismissed with prejudice by Genova, meaning it can’t be brought back to court. A reason was never officially disclosed. It is possible it was due to a personal settlement, but there is no evidence of this at this time. We don’t know why it was dismissed. ", "That brings us to Part 6: The Melting, CableMod Edition.", "During all the fuss over adapter cables, bend radii, and toasted GPUs, CableMod consulted with Igor from igor´sLAB to develop rigid 90-degree and 180-degree adapters, with the final form ", " by Igor in March of 2023 and on sale by the end of the month.", "These were small PCB-based extensions (not really adapters) designed to enable a sharp bend away from the GPU. This was pitched as a safety feature, not just a cosmetic one, since it had been known for nearly a year that 12VHPWR cables ", ". CableMod wrote: ", ".", "These adapters incorporated what were supposed to be several improvements based on the ongoing controversy. ", " as recommended by the ATX spec at that time (although again, the spec would change later). ", "They had a ", " within the PCB (reportedly double the usual), they had three massive copper bars soldered to the PCB as reinforcement for pairs of 12V traces, they had an aluminum housing mated to the PCB with a thermal pad for heatsinking, they used PCB rather than plastic as a cover plate for additional heat resistance, and they used the shorter sense pins that NVIDIA had been considering in the female connector.", "Except that doesn’t appear to have been true.", "As far as we can tell with our units, the 4 spring terminals and shorter sense pins didn't make it into production for these CableMod adapters.", "Igor ", " of the terminal pins in a prototype adapter, which clearly don't match the ones in our failed 1.0 adapters. The sense pins on the female connectors weren't any different from contemporary pre-revision connectors on GPUs. ", "Finally, the claimed three additional copper bridges that reinforce the three 12V strands on the board (3 x 2 pins) where two pins are electrically combined in each case for safety reasons, in case one of the six 12V strings should fail externally are not actually connected like that, at least not in ours. In our CableMod 90-degree adapters, the two outer bridges are connected to all six ground pins and the inner one is connected to all six 12V pins. While at one point it may have been that way, it wasn’t in our production units. ", "The 180 degree adapters are the same, but with twice as many bridges. We don't believe these factors were directly to blame for the failures, but it wasn't a good sign that the 1.0 retail adapters didn't match the exclusive first review of them by someone who was so close to their design and seemingly, at least in some way, consulting on it.", "Two months later, on May 18th, NorthridgeFix posted a video called ", ". It was later established that part of this initial batch were eight damaged units sent by CableMod to NorthridgeFix as part of its RMA process. The shop has continued to receive damaged cards to this date.", " that at this point, it had had eight reported failures out of ", " (a .016% failure rate if that’s true), and that four of those were confirmed to be due to partial insertion. ", "We now know that 50,000 number possibly included all 12VHPWR products sold by CableMod at that time, not just adapters, so the true failure rate of the adapters would have been higher. This was within two months of the product launch, and on adapters that were specifically designed to resist this exact issue. ", "Worse still, at least one of the adapters had ", " melted into place while fully seated, indicating a new problem -- and that problem would lead to CableMod’s recall of its faulty adapters.", "In July 2023, ", " that the 12VHPWR connector would be replaced with the compatible-but-revised 12V-2x6 connector in the upcoming PCIe CEM 5.1. ", " that newer NVIDIA cards had silently rolled out an early variant of this connector as early as April of 2023.", "By August, CableMod was working on the ", " to replace the original 1.0 adapters with an updated 1.1 version. It stressed that the issues seen with our V1 adapters can't be pinned on NVIDIA and the new 12VHPWR standard directly, accepting the blame and responsibility for what was at this point a growing but ", " failure rate, according to the company. ", "The new 1.1 adapters incorporated these changes. First, they used the 12V-2x6 connector. Secondly, the connector was made to fit more tightly following a suggestion from JayzTwoCents. Third, the connectors were staked to the PCB to prevent wiggling. CableMod remained confident in its other non-PCB-based 12VHPWR products.", "Finally, on August 7th 2023, the current PCIe CEM Revision 5.1 version 1.0 rolled out, incorporating a full year's worth of ECNs (Engineering Change Notices) that mostly revolve around the ", ", with the original 12VHPWR definition bumped down to an appendix. Both sense pins are marked as required and Add-In Card partners are required to monitor both in order to draw any power. ", "The Open/Open condition has changed from 150W to 0W, with 150W now signaled by shorting the two pins together. AICs (but not PSUs) are also required to support the primary function of the previously optional CARD_CBL_PRES signal to provide a signal from the Add-in Card to the power supply that the Add-in Card has detected the Auxiliary Power connector is correctly attached. Power and ground pins are extended by 0.25mm and sideband pins shortened by 1.25mm. There are other numbers online cited for these mechanical changes, but these are the correct ones defined officially by the spec. Exact terminal length isn't part of the CEM (plug pwr and gnd pins must be fully engaged prior to sense pins making contact in a worst case tolerance condition), but we've seen NVIDIA documents showing that the terminals are lengthened by 0.6mm in its own adapters. Several tolerances are also tighter. All of these changes are intended to keep cards from drawing power without being fully plugged in or properly inserted.", "As a side note, the CEM Increased maximum Add-in Card total power to 675 W, but that includes slot power. This is confusing for them to state in this way because the 12V-2x6 connector is rated to deliver 600W of additional power, just like the 12VHPWR cable, ", " ", " ", " ", " ", ". ", "Here's what the spec says: The 12V-2x6 power connector delivers up to 55 A of continuous current to provide a maximum of 600 W of additional power to the Add-in Card on a 12 V rail. So in other words, please ", " ", " ", " unless you’re also going to start talking about the slot.", "Extensive sections to the CEM were added to describe cable assembly best practices, warn that individual pins could see more than 9.2A, warn about low-level contact resistance and side-loading, and discuss environmental durability. At least 25mm of untwisted or bent wire past the plug is now required, and designs intended to get a smaller bend radius (like right angle cables) are outside the scope of this specification.", ". To this day, the newest ", " 12V-2x6 connector spec is basically the same as the original 12VHPWR one.", "Even the newest revision isn't perfect. For example, as Aris pointed out to us, the spec says that for modular power supplies an additional 12V-2x6 PCB Header connector will be ", " in the housing of the power supply, but it also says the PCB Header [...] is mounted on the Add-in Card and, ", ", within a modular power supply,” furthering the contradictions of the spec documents.", "With that in mind, let's revisit CableMod's proposed changes to v1.1 of the angled adapters. First, CEM 5.1. CableMod said that V1.1 adapters will include a CEM 5.1 female connector, but that wasn't the side of the adapters that melted, so that was unlikely to help. ", "Second, Connector tightness. The connectors did need to be tighter, but connectors melting in place while fully seated hinted at a separate problem for CableMod. ", "Finally, Connector wiggle. CableMod used plastic stakes to fasten down the male connector to the PCB, but the company ", " that this didn't affect performance in our tests and was done for the sake of user experience. ", "The ", " also later claimed improved terminals. The 1.1 adapter wasn't a fix, but that was the clear implication of the replacement program.", "It didn't help. On February 8th 2024, CableMod threw in the towel with a voluntary recall for all angled adapters through the US CPSC government agency.", "According to ", ", which is a government agency in the US for consumer safety, there were 272 reported failures out of approximately 25,300 affected units, a failure rate slightly over 1% in one year and an order of magnitude higher than it had been in August. The phrasing used by the CPSC was that CableMod had determined that the male connector in the angled adapter could become loose during cable management and system use, overheat, and melt into the graphic processing unit, posing fire and burn risks. ", "As far as we understand, we don't believe CableMod ever conclusively identified a root cause for the failure of its specific adapters, but in the absence of a clear answer, it still deserves credit for the replacement and recall programs. That much is good, and most companies wouldn’t go that far. We also want to give CableMod credit for actively purchasing, fixing, or reimbursing customers for cards that were damaged as a result of use of their solutions. While this should be expected of any company, it’s rare.", "The failure analysis lab we hired also could not come to a firm conclusion as to the specific common cause of failure of CableMod’s adapters. It did, however, have some key indicators for potential causes of failure for the ones that we sent in. As we stated in the beginning, the key indicators of failure included bad soldering work, choice of solder material, potential fractures in the pins as a result of the design, and general workmanship issues.", "As we reach the conclusion here, a quick note that these kinds of deep-dives truly require community support. We have over 300 hours invested into this piece, with most of that being research and validation. To support our efforts, please visit ", " and consider grabbing one of our PC building ", " with wiring diagrams, ", " that are excellent for not only high heat tasks like soldering, but also for model building, painting, and crafting projects, or our other items, like our ", " that include common PC component theming to provide you with high-quality coasters that represent this enthusiast hobby. You can also throw us a few bucks per month on ", ".", "Thanks for your patience with these promotions as we continue to ramp our in-depth coverage the past few months for true deep-dives. Your support makes this possible. Back to the conclusion.", "After all this, we don't really “like” 12VHPWR or 12V-2x6, but it's here to stay.", "Right now, we recommend a native 12VHPWR/12V-2x6 cable, if for no other reason than it eliminates additional points of failure: simpler is better. Opinions may differ on this. For instance, Aris of Cybenetics thinks 2x8 pins on the power supply is the best. Here’s what he sent to us when we were talking about this: “The best way to reduce problems is to use 2x 8pin on the PSU’s modular board instead of a native 12V-2x6 since the former allow for more cable flexibility and are more tolerant to abuse in general. I advise PSU manufacturers to do this, but in some PSUs, due to a lack of space in the PCB, this can be an issue, so they are forced to use 12V-2x6 socket(s).”", "We agree with der8auer that NVIDIA using 2x 12V-2x6 connections on high wattage cards would restore some of the redundancy and safety margin that the PCIe 8-pin connectors had developed. We wouldn’t want or expect them to try to fully utilize those connectors the way they do a single one though, as it will start approaching US 15A breaker limits for the typical household. ", "As for adapters, adapters ", ". If you're using an ATX 3.0 PSU with 12VHPWR or 12V-2x6 but it doesn't have that plug ", " specifically, it's using an adapter by this definition. There's no simple way to connect the sense pins with an adapter; for example, Corsair runs 12VHPWR connections out of two 8-pin connections on the PSU side with one sense pin grounded to each, which means that if only one 8-pin is plugged in, the GPU will be signaled that either 300W or 450W is available arbitrarily, depending on which one is plugged in.", "Some adapter cables don't connect the sense pins to the PSU at all, like CableMod Stealthsense. On paper, the most correct adapters are the dongles that ship with NVIDIA GPUs which intelligently ground the sense pins based on how many connections are detected. Obviously that didn't prevent them from melting to start with, but it is important to remember that those failures, when they happened, were much different from CableMod's. We’d also recommend continuing to always avoid sharp angles or pulling tightly on cables in general, but 12VHPWR and 12V-2x6 cables in particular. This has been a known issue since before day one. If at all possible, follow bend radius guidelines from the PSU or cable manufacturer.", "If you're using a male-male double ended 12V-2x6 cable with your PSU, strictly speaking, the cable should have at least two visible sideband connections that run all the way from the PSU to the card. Since the CARD_CBL_PRES signal is now supported on the GPU side, up to three wires may be used. If a native 12VHPWR PSU meets spec, it handles sideband signals internally.", "PSUs don't always set those signals properly, though. As Aris from Cybenetics told us, nobody follows Intel’s recommendations, and you can see 600W [shown as available with] 12V-2x6 on a 650W PSU! This is ridiculous and I am so tired of writing this down on our Cybenetics reports. These recommendations aren't in the ATX spec itself, but they are in the Intel-published ", ". ", "Aris continued: Many ATX v3.x PSUs ignore this Intel guideline and have a 600W setting on their 12V-2x6 connectors. Remember this setting should NOT be applied on the cable, but within the PSU.", "Some third-party double-ended cables like ", " ignore the PSU and signals to the GPU that a full 600W is available to be used. This isn't ideal, but it's intended to avoid another common issue which manifests with a black screen and GPU fans running at max speed. Many of you reported having this problem in our survey that we ran. This is likely due to sense pins losing connection, whether that's from fragile sense pins that can easily be dislodged as CableMod suggests, or just vibration and thermal expansion. Since 12V-2x6 intentionally makes the sideband connections more tenuous, we expect this to become more common. If you experience this problem, it can be worked around by using a different cable.", "One last recommendation we have here is to make sure the cable is fully seated. That still matters a lot. It might be one of the things that matters the most after choosing a cable that's not designed with some kind of fault in it, like the CableMod adapters were, because there isn’t a ton of headroom. Also, be mindful that pulling one side can loosen contacts. ", "And finally, the ", " (beware of scalped prices) gets a mention: At the time of this writing, the card isn’t yet out, and at the time we’re publishing this, there are conflicting rumors about the device. In the past, leakers have gotten the power specs wildly wrong about GPUs, so we’re unable to make any firm recommendations or commentary until the true specs are known. Currently, the leak indicates a 600W TDP on the ", " (beware of scalped prices); however, last time leakers suggested 800W and 600W GPUs in consumer, it turned out that these were simply the recommended design guide for the cooling solution, not the actual power consumption. For sake of discussion, if we momentarily assume 600W is truly the “TDP” of this card, then our concern would be regarding running a single 12V-2x6 connector for the card. The cable itself is not rated for 675W, as we said earlier, and this is a common misconception. Between the cable, its limited overhead, and the PCIe slot, we would feel uncomfortable with how close these limits are to the power consumption. Der8auer felt the same way when we discussed it with him. If NVIDIA goes with two connectors, they’d have plenty of headroom. For now though, until those specs are finalized, there’s no point discussing this further. We’ll comment on it once we know more."]},
{"title": " Intel Arc B580 'Battlemage' GPU Review & Benchmarks vs. NVIDIA RTX 4060, AMD RX 7600, & More", "paragraph": ["Intel Arc B580 'Battlemage' GPU Review & Benchmarks vs. NVIDIA RTX 4060, AMD RX 7600, & More", "Last Updated: ", "The Highlights", "Intel’s Battlemage ", " GPU launches at $250. In our testing, the card has improved massively over the company’s original Alchemist GPU launch, so it’s already in a better spot than previously. By price, the B580 is positioned to compete with the ", " $300 GPU and the ", " at $250. Both NVIDIA and AMD have new GPUs launching in early January, but until they’re out, we can’t evaluate their performance.", "What we can say is that, out of the gate, the ", " is far more reliable than the Alchemist cards were at launch. Intel has definitely improved. It still has issues and it was still shipping driver updates until the last minute of testing, but the company has objectively improved.", "Steve Burke", "Patrick Lathan", "Mike Gaglione", "Jeremy Clayton", "Tim Phetdara", "Andrew Coleman", "Jimmy Thang", "Frametimes have largely been smoothed over, but remain a potential pain point for Intel in some games. Idle power consumption is also a pain point; however, overall value and throughput are competitive, and ray tracing performance is particularly competitive, especially against AMD.", "We also found that the B580 scales extremely well with higher resolutions, seeing the most uplift over the ", " or ", " at 4K and 1440p, and often losing that ground at 1080p.", "It’s an interesting review packed with a ton of new information, including a complete overhaul of our GPU test bench to an overclocked ", " platform.", "Let’s get started.", "Here’s a quick refresher on the current market for GPU prices, but remember that the RTX 50 series is rumored to launch next month, followed by rumors of new AMD GPUs. ", "For today: The B580 has an MSRP of $250 and was available for preorder on Newegg at this price. The prior Intel ", " is available for $230 to $280 for the 16GB model, with the ", " at $200 to $240 and ", " at $170. NVIDIA’s ", " is a main competitor, typically at $300, alongside the ", " at price parity with the B580. These will be the two key comparisons.", "One step up, the ", " and ", " are both around $400 to $420 right now, making them primary upgrade options another class up.", "We already covered the B580 specs in a ", ", but here are the basics again:", "The card launches ahead of the ", " (watch ", "), which launches next month. The B580 is a relatively small 20 Xe2 core configuration on the Battlemage architecture, making it smaller than the ", " or ", " in configuration size. Intel hasn’t yet announced 700-series cards in the Battlemage series.", "The B580 has a 190W default TDP, runs on 1x 8-pin power connector, and is cut down to PCIe 4.0 x8, which is a potential downside for anyone on old platforms. We’d have to look at that separately in the future.", "We have a brand new test bench for all of this. We’ve moved from an overclocked ", " to an AMD ", ", which marks the first time we’ve used an AMD CPU as our permanent GPU test bench solution in the nearly 16 years we’ve been running now. The 9800X3D gives us far better headroom and scaling to see the impact of high-end GPUs that should be coming out soon. We have it overclocked to 5.4GHz all-core and under a ", ".", "Our games list includes these. Not all of these will be shown in each review, but they are all tested. We’ve added Dragon’s Dogma 2 from 2024, Black Myth: Wukong from 2024, Baldur’s Gate 3 from 2023 -- which will be too easy for high-end GPUs, but is a good match for the B580, Starfield from 2023, Final Fantasy 14: Dawntrail from 2024, Cyberpunk: Phantom Liberty from 2023, and all the others you see above.", "We’ve tested about 25 GPUs for this launch. That list does not include the ", ", ", ", ", " or ", ", ", " or GRE, and similar high-end cards. You can find scaling data in our prior benchmarks for those.", "We added the ", " and ", " for a ceiling. ", "The reason for the cuts is time -- rolling into the end of year with team scheduling and our own travel, we wanted to allocate more testing time to older hardware or lower-end stuff to represent users considering an upgrade. That means we cut the high-end stuff for the GTX 1060 (watch ", "), 1070 (watch ", "), RTX 2060 (watch ", "), GTX 1650 (watch ", "), and similar cards. We’ll add higher-end GPUs in for the January launches, but they’re out of the price range of the B580.", "As far as cards with multiple VRAM configurations, we ran the “default” or first-launched VRAM configuration wherever an option was present. ", "Finally on the test bench side, we’ve added power efficiency testing and idle power consumption testing with calibrated tools.", "We have a lot more to test, but this article is huge already and we have a busy time ahead of us with some travel.", "Let’s get into the benchmarks.", "Final Fantasy 14: Dawntrail is up now at 4K first.", "At 4K, the Intel Arc B580 ran at 47 FPS AVG, with lows exceptionally close to the average. The B580 has a staggering lead of 28.6% over the ", ", which is elevated as compared to its lead at 1440p and 1080p. The RTX 4060 (watch ", ") is behind in lows also; although they remain consistent with its average.", "The B580 also leads the ", " at 15% ahead, the A770 by 16.5%, A750 by an impressive 27.9%. The ", " is around the same price as the B580, but struggles at 4K in this test at 31.5 FPS AVG.", "Users of the GTX 1060 6GB card would experience an uplift of about 193% moving to the B580, with the 1070 seeing 110% and the 3050 similar.", "As we saw in our ", ", the 3060 Ti (watch ", ") has a massive memory bandwidth advantage over its successors and embarrasses the 4060 and 4060 Ti cards here.", "From what we’ve tested lately that’s better than the B580. That list includes the $450-$480 ", " at 22% better and the ", " non-Super at 27% better, among the flagships.", "At 1440p, the gap narrows in some places. The B580 is running at a completely playable 86 FPS AVG with good lows. Its lead over lower cards has decreased: 3.4% against the 4060 Ti (watch ", "), 9% against the A770 (down from 16.5%), 19% over the A750 and RTX 4060 (from around 28% before), and 31% over the RX 7600 (watch ", ").", "The ", " jumps to 40% from 22% and the ", " jumps to 36% from 27%. The $400 RX 7700 XT (watch ", ") leads at 98 FPS to 86 FPS AVG on the B580, but is more expensive.", "The B580 looks good here despite a reduction in its lead from 4K.", "1080p squishes everything together and reduces the B580’s advantage.", "The B580 at 124 FPS AVG is now just 10 FPS ahead of the A770 and RTX 4060, or about 10%. The B580 went from a 28.6% lead at 4K to 19% at 1440p to 10% over the RTX 4060. ", "At 1440p, the RX 6700 XT (watch ", ") was marginally below the B580 and is now ahead at 1080p. The B580 also had nearly a 15% lead over the RTX 4060 Ti at 4K, but now is behind. The 4060 Ti leads at 133 FPS, or an advantage of 7.6%. That’s a huge swing.", "Starfield is up now, tested at 1440p.", "The B580 isn’t as strong in this one as it was elsewhere. Starfield is also a game that was not functional on Arc at its launch, so running at all is already better than last time -- though that’s a low bar.", "The B580 ends up behind the RX 7600, RTX 4060, and 4060 Ti in this benchmark. It’s beating the A770, A750, and A580 cards from Intel’s last gen.", "The 4060 leads by about 17%, with the 4060 Ti in an insurmountable 42% lead. The 7600 is closer, at 5% ahead. ", "The biggest downside here is the frametime pacing. Intel’s B580 struggles with 0.1% lows and 1% lows, which are indicative of a deeper per-frame problem that requires a frametime plot to investigate. We’ll explore that later in this review, closer to the conclusion.", "At 1080p, the B580 ran at 51 FPS AVG, giving the RTX 4060 a 10 FPS AVG lead, but an even bigger lead in lows. Although the 4060 has an advantage of 21% in average framerate, the real difference is in frametime pacing that we’ll see closer at the end of this review.", "The RX 7600’s lead is now 4%, with the 4060 Ti at 44%.", "Intel’s B580 leads the A770 by an impressive generational 16%, despite a lower core count configuration. That’s a huge win for Intel over its own hardware. Its lead over the A750 is 27%. Despite these gains, the B580 is not that competitive in Starfield.", "Resident Evil at 4K is pretty interesting. The B580 roughly matches the 4060 Ti, with a marginal deficit on 0.1% lows. The lead over the 4060 is massive, benefiting the B580 by 31% in average FPS. It also holds an advantage in lows. The lead over the 7600 is 24%, with the generational lead over the A580 and A750 alike impressive.", "This is a strong showing for Intel’s B580.", "At 1440p, the B580 maintains a competitive position: The card is fully playable at 85 FPS AVG with overall OK lows, albeit lower proportionally versus the neighboring A770 and RTX 3060 Ti. With the resolution drop, the 4060 Ti now leads the B580 by 7% from its rough equivalence before. B580 benefits from its memory bandwidth at 4K.", "The lead over the RTX 4060 is reduced to a still-noteworthy 22.5%, down from 31%. The 7600 lead is reduced from 24% at 4K to 18% at 1440p.", "1080p weakens the B580’s position overall. The 4060 Ti now moves to 10% ahead. The B580’s lead over the 4060 is reduced to 19%, although this is still a big lead. Most notably though, we see the frametimes deviate more from the average: The 128 FPS AVG is accompanied by 74 FPS and 63 FPS 1% and 0.1% lows with the B580, whereas proportionally and based on neighbors, these figures should be in the 100-110 territory. The drop jumps out as different from the rest.", "Baldur’s Gate 3 is up now, one of the most played games in the last year. Intel needs to do well in these types of critically acclaimed titles. Last round, we saw that Intel did better with Vulkan in Baldur’s Gate 3 than it did with Dx11, but was still disadvantaged in both APIs.", "With Dx11 and 4K/Ultra, the B580 ran at 45 FPS AVG. The lows are reduced versus its immediate neighbors in the 4060 and 7600, both of which would be better experiences by frametimes alone, despite all looking approximately equal in average FPS. This is another for our frametime charts list at the end.", "The B580 improves on the A750 by 6% and the A580 by 21%, falling behind the A770 in this one. The Arc cards are generally less competitive in frametime consistency in this game; however, they have significantly improved in their performance from a year ago.", "Here’s 1440p.", "The B580 ran at 74 FPS AVG, which is completely playable in this game. The lows are also acceptable in an objective sense -- it’s not a “bad” experience, but it’s also not as good as you’d get for frametime pacing from the RTX 3060 (watch ", "), RTX 4060, or RX 6600 XT (watch our ", ").", "The 6600 XT’s average framerate holds a 14% lead, with the 4060 at 8% ahead, breaking rank from a roughly tied average at 4K. The 7600 also climbs ahead, now matching the 6600 XT rather than the B580 AVG FPS as we saw at 4K. The 4060 Ti is 35% ahead of the B580 with its 100 FPS AVG.", "Generationally, Intel improves over the Alchemist A750 by 7%, with a notable leap over the 62 FPS AVG of the A580.", "In Cyberpunk: Phantom Liberty at 1440p, the B580 performs overall well. This is one of Intel’s strongest titles. ", "At 1440p and with Ultra settings, without RT, the B580 lands at 53 FPS AVG in our in-game test within one of the cities. The B580 roughly matches the RTX 3070, although is lower in 0.1% lows and frametime consistency. The B580 leads the RTX 4060 in AVG FPS by 36%, the RX 7600 by a similarly large gulf, and the RTX 4060 Ti 8GB model by 12%. The 4060 Ti has stronger 0.1% lows, but not in a way which we think is worth the cost tradeoff.", "At 1080p, the B580 slips in the ranks below the 4060 Ti, which also carries a large advantage in 0.1% lows. ", "The B580 technically leads the RTX 4060 in AVG FPS by 18%, but the 4060 pulls ahead in overall frametime consistency. The RX 7600 is in a similar boat.", "Black Myth: Wukong is next. This is one of the few games where we use the built-in benchmark. It’s new to our test suite and it’s been pretty consistent. Dropping settings would obviously increase framerate, but we’re interested in this from a scaling standpoint.", "At High settings, broadly speaking, the B580 still has a slight deficit in lows, but a far less noticeable one than some other games. It’s close enough to the RX 7600 and RTX 3060 that the experience would feel overall similar, although technically worse by measurement.", "The RTX 4060 holds a significant lead in this test, up at 19% and 54 FPS AVG to the 46 FPS on the B580. Frametime consistency is also better. The 3060 Ti leads the 4060 and B580, with the 4060 Ti at 65 FPS AVG, or 42% ahead of the B580.", "The B580 at least improved on the last generation, at 29% over the A750, and 38% over the A580. Intel is making big generational strides against itself here.", "At 1440p, we’re bordering on synthetic test territory for the B580. But what matters most to us is the scaling, not the raw FPS.", "At 35 FPS AVG, the B580 allows the 4060 a lead of 6.6%, down from 19% at 1080p. This is a huge swing in favor of the B580, which continues to scale more favorably at higher resolutions.", "The 7600 falls below the B580 in average FPS and is roughly the same in lows. The B580 also leads the prior generation flagship from Intel, the A770, which was at 30 FPS AVG. We’re going to pick up the speed here now that patterns are establishing.", "Dragon’s Dogma 2 is up next. For our CPU testing, we benchmark inside the city to create an NPC workload on the CPU. For GPU testing, we test outside of the city and in a GPU-heavy area with fields, water, and structures.", "At 1440p, the B580 ran at 44 FPS AVG with good lows. The GPU does much better here than in some of the prior tests and ends up keeping pace with the RTX 4060. The 7600, 4060, and B580 are all functionally equivalent. The 3060 Ti (watch ", ") benefits from its memory bandwidth and leads this grouping.", "This is a much better positioning for the B580 than the prior games.", "At 1080p, things shake-up to knock the B580 loose from its rough equivalence with the RX 7600 and RTX 4060. Now, the RTX 4060 holds a 13% lead, with the RX 7600 in an 11% lead. The B580 retains overall typical frametime pacing, which is good for Arc. It manages to hang in there, but it’s seen some losses as the resolution comes down.", "Dying Light 2 is next. This one looks good for Intel Arc, including frametime consistency: The B580 runs at 63 FPS AVG, which has it ahead of the 4060 Ti, 4060, and 7600. It’s also ahead of all of these devices in 1% and 0.1% lows, in what’s a major victory for Intel considering its challenges in some other games.", "The B580 ends up between the RTX 3070 and RX 6700 XT. The $400 7700 XT holds a lead in AVG FPS of 12%, despite being 60% more expensive. This is one of the stronger showings for Intel.", "At 1080p, the B580 continues its good performance by outmatching the A770 and RTX 4060; however, it loses ground to the 4060 Ti that it had outperformed at 1440p. The 87 FPS AVG is well into playable territory and carries good lows. The die size is much smaller than an A770, so outperforming it is key here: Intel may be able to reduce some of its cost per card, which will help it compete long-term.", "We’re moving on to ray tracing benchmarks. These are not comparable to the rasterized charts.", "Resident Evil 4 is up first. This is a relatively light workload for ray tracing and isn’t as distorted for one vendor or another as some other games.", "This first chart is at 4K with Max RT, but with FSR set to quality for all devices. We have validated other upscaling solutions and found their performance to be roughly identical, so matching for just FSR agnostically allows us to control for image quality as well. Because we are using FSR, it is not native resolution. We don’t use FSR in our rasterized tests.", "Here’s the 4K chart. The B580 ends up directly competing with the RTX 4060 Ti in the average framerate and in frametime consistency, with lows overall indicative of a comparable frame-to-frame interval to the 4060 Ti. It’s not far off from the RTX 3070. Intel’s B580 leads the RTX 4060 by 21%, at 50 FPS to 41 FPS AVG. The improvement over the A750 is similar. We need to run the 7600 back through this one still, but the 7700 XT and 6600 XT give an idea for AMD’s positioning.", "In this test, the Intel B580 runs at 75 FPS AVG with overall good lows. The 1% and 0.1% metrics are similar to what we see on the 3060 Ti, which outperforms the B580. Intel’s B580 manages to outperform the RTX 4060 by 6%, including proportional frametimes. It also outperforms the A770’s 71 FPS AVG, which was already relatively good for RT. AMD’s RX 7600 ran at 65 FPS AVG, giving the B580 nearly a 16% advantage while costing about the same.", "The 4060 Ti’s 91 FPS result outdoes the B580’s 75 FPS by 21%, including scaling in the lows. The 7700 XT pushes further ahead, up to 106 FPS AVG. Both devices cost about 60% more than the B580, at around $400 for the 4060 Ti 8GB and 7700 XT alike.", "At 1080p and with the same FSR and RT settings, Resident Evil 4 positions the B580 now below the RTX 4060 -- though they’re functionally tied. It’s losing the advantage that we’ve now proven it typically has at higher resolutions. These two and the RX 7600 are closest in price, with the 7600 down at 85 FPS AVG and allowing the B580 a slight lead of 9%.", "The 4060 Ti leads the B580 by 29%, with the 7700 XT 40% ahead of Battlemage.", "Overall, Intel’s performance in this lighter RT test is competitive, especially for the price and in comparison to AMD. ", "Dying Light 2 is a heavier RT workload and is tested with FSR Quality. ", "At 1080p, the B580 ran at 65 FPS AVG and held consistent frametimes. It’s a little better than the A770 and similar in average to the 3060 Ti. The 4060 Ti leads the B580 with its 73 FPS AVG result, a gain of 12%. The B580 leads the 4060 by 13%. AMD falls behind in this test, with the 6700 XT now below the B580 and RTX 4060. The B580 ends up with nearly a 30% lead over the 6700 XT, which is a precarious spot for AMD. The lead over the RX 7600’s 45 FPS AVG is 44%.", "In Dragon’s Dogma 2 with Max RT and no upscaling, the B580 ran at 44 FPS AVG with lows slightly lower than where they should be. The A770 leads the B580 in lows and ties in the average. ", "AMD’s RX 7600 does better here than in Cyberpunk and Black Myth, up at 53 FPS AVG and outranking the B580 by 20%. The RTX 4060 also outdoes the B580 (and also outperforms the 7600’s frametime pacing), landing at 54 FPS AVG.", "Battlemage is doing OK, but does not have the same advantage it has elsewhere.", "At 1440p and RT with Dragon’s Dogma 2, the B580 ran at 36 FPS AVG and had dips in lows compared to the neighboring prior-generation A-series GPUs. The 7600 leads the card now by about 10%, reducing its lead from at 1080p. The RTX 4060 is in a similar position, but with better lows.", "Cyberpunk with Medium RT settings is less brutal on AMD than Ultra, something we showed in our last round of reviews, but remains one of the heaviest RT loads and disproportionately hard on AMD devices. This is tested without any upscaling.", "The B580 did overall well here: Its average framerate was competitive with the RTX 3060 Ti, despite lower 0.1% lows than it. The 4060 struggles in this one with frametime pacing and is erratic and unpredictable with these settings. The B580 is a much better experience, with the 3060 Ti and up better still. The 4060 Ti also struggles with frametime consistency, illustrated by the 0.1% lows that draw our attention to the problem. This appears to be an issue with memory bandwidth, especially as contrasted to the 3060 Ti, which likely compounds with the VRAM capacity.", "In a massive loss for AMD, the B580 runs 62% ahead of its RX 7600 in average framerate while also maintaining superior lows and frametime pacing. AMD’s closest card is the RX 7700 XT, which is significantly more expensive. This is a repeat of what we saw with the Alchemist cards last time, where the A770 and A750 alike outperformed AMD’s 6700 XT and 7600.", "We tried testing RT Ultra for Cyberpunk, but unfortunately, the system hard locked with the B580 card. This behavior did not occur on any of the other 18 plus devices we tested with these settings and appears to be related to Battlemage.", "Black Myth: Wukong is up next. ", "This is an experimental chart, which means we are still researching the performance and vetting it. Our confidence is lower in data for experimental charts, which means they should be weighted less; however, we publish them when we feel we are ready to begin sharing, as this allows us to continue learning and advancing. We just like to be clear in our disclosures of data confidence.", "This one is brutal on anything that isn’t NVIDIA. Intel also had a last-minute driver update for RT performance in this game.", "At 1080p and with FSR set to quality, using high raster settings and medium RT settings, the B580 ran at 34 FPS AVG, with lows where they should be. Intel’s last-minute driver change did nothing to our results -- they were nearly identical, so we’re just showing one set here. The B580 ranks alongside the RX 7800 XT (watch ", "), as AMD has serious difficulties with this game. Wukong is similar in performance to Cyberpunk in its performance characteristics on AMD, where even a 4060 outperforms a ", ".", "For Intel, it at least is doing better comparatively than AMD, but NVIDIA has a stranglehold here.", "We’ll move to some quick zoomed-in shots of the frametime charts for some good and bad scenarios for the B580.", "We’ll start with Baldur’s Gate 3 at 4K. This chart shows the frame-to-frame interval on the vertical axis and the frame on the horizontal axis.", "Lower is better, more consistent is best. Although the B580 is at times lower than the RTX 4060, the card experiences occasional but massive excursions from the previous frame. We’re seeing some jumps upwards of 20ms, which is noticeable, but not necessarily game-breaking -- it depends on the frequency of them. In this case, you’d notice. Arc has improved substantially from Alchemist in this specific regard, but it’s clear that Intel still has some work to do in at least Dx11 with this game.", "Dying Light 2 rasterized is one of the better scenarios for Arc, so we’ll balance by also looking at that as well.", "In this one, the B580 had better frametimes across the entire bench pass. It’s lower overall, but also doesn’t experience any major unexpected deviations. Unlike the Baldur’s Gate chart, the B580 GPU is exceptionally consistent in its frametime pacing here. The 4060 ends up the worse of the two tested devices.", "In this next one, NVIDIA and its RTX 4060 are a victim of its own creation. In Cyberpunk with RT Medium, the RTX 4060’s framebuffer and memory bandwidth cause it to struggle, resulting in frametime spikes that, in one case in this chart, exceed 120ms. That’s 1/10th a second that you’re looking at the same frame. This massive spike would result in a stutter in-game. These stutters were repeatable during play. There’s another large spike later in the run. They also happen frequently in our later runs. ", "The B580 did not exhibit this behavior in this test and would be a better experience. Intel’s memory choices benefit the company here; bandwidth is one of them but capacity also contributes.", "Starfield had some major consistency issues run-to-run for Intel so we’re actually only showing Intel here.", "This shows 2 test passes from Starfield at 1080p for the B580. In this one, you’re seeing wildly inconsistent frame pacing with a total range from 13ms to 53ms. There’s no pattern to it and frame delivery is overall erratic, making the experience less consistent and allowing more microstutter behaviors to emerge. Dying Light 2 looked much better for Battlemage.", "Final Fantasy 14 is next. In this one, B580 did well overall but had slightly reduced 0.1% lows versus the 3060 Ti and 6700 XT; however, it did better than the RTX 4060 across the board. In the frametime chart for Final Fantasy, we see an incredibly flat line with only one major spike that would hardly be noticeable since it isn’t repeating.", "Let’s move on to efficiency.", "Now, we’re getting into power consumption and power efficiency measurements. For this testing, we’re using a PMD2 hooked into a PCIe slot interposer and the PCIe cables. This PMD2 has been personally calibrated by Elmor, from ElmorLabs, for our work upon request and has been validated against other measurement devices, including current clamps. We are isolating for just GPU power, eliminating other test bench power draw. This allows us a clean and isolated feed of GPU behavior.", "We haven’t yet tested our full lineup of GPUs as this is all brand new testing, so we only have some of the most relevant cards. You’ll have to check back as we add more.", "This chart is for idle power draw on Windows desktop and without any GPU tasks active.", "The Intel B580 pulled about 35W when idle at desktop, which is a lot less than the Alchemist GPUs pulled (up at 46W, 45W, and 43W), but it’s still more than everything else. Intel still has an idle power consumption challenge to overcome.", "The RX 6600 (watch ", "), for example, pulled only 5W through the PCIe slot and PCIe cables when idle, which is impressive. The 6600 XT was similar, at 6.2W. The 4060 is a relevant comparison and far lower in power consumption idle, down at 11W to the B580’s 35W or so.", "This is an area Intel will eventually need to improve, but no one will care about its idle power draw if the performance isn’t good enough to warrant a purchase first, so we’ll see if this improves subsequently.", "Idle GPU power has been requested by our audience for years, so we’re happy to finally start delivering it with this first look.", "The next chart is for Baldur’s Gate 3 efficiency at 1440p, looking at rasterization performance. This is measured in FPS/W, which can be thought of as frames per joule since it’s just frames per second per joules per second. Higher is more efficient here.", "FPS/W is easier to understand for most people. In this test, the RTX 4060 Ti has the best FPS/W performance, up at 0.71. The 4060 Ti is about 37% more efficient, meaning its FPS/W score is 37% higher than the Intel B580. This is still a massive generational improvement for Intel, where its A580 previously was way down at 0.31. The B580 scores 68% higher in FPS/W than the A580 and A750. Its total power draw is about 141W here, the same as the 4060 Ti, and so the reason its FPS/W is lower is because its framerate is simply lower. ", "The 4060 pulls 126W in this test and has a slightly higher framerate, benefiting on both sides of the equation. We don’t yet have the RX 7600 in this lineup.", "Now we’ll look at one of the B580’s best case scenarios to balance the last two.", "This chart is for Final Fantasy 14 at 1440p, where it did well. The B580 ends up 4th on our list so far at 0.51 FPS/W, ahead of the 7800 XT and behind the 4060.", "The RTX 4060 pulled 124W here, putting it at 0.58 FPS/W and almost 14% more efficient than the B580. That’s a good spot for the B580, despite being less efficient and pulling more power at 170W.", "The 4060 Ti pulled just 129W, so it didn’t leverage its total power budget, and was 27% more efficient than the B580.", "Against the last generation, the B580 is significantly more efficient than the RX 6600 XT, RX 6600, RTX 3060 Ti, and Intel’s own Arc cards. The jump over the A750 is huge, especially since the Titan model has a boosted power budget.", "At 1080p, the ", " and 4060 Ti appear the same because the 4090 (watch ", ") is completely CPU-bound. It can’t perform any better, but remains in a higher power draw state.", "The B580 again ranks as less efficient than the 4060 and more efficient than the 7800 XT and below. The B580 pulled 161W here.", "In Black Myth: Wukong at 1080p and without ray tracing, the B580 scored 0.3 FPS/W and pulled 146W, which has it significantly behind the RTX 4060 at 0.4 FPS/W and 121W. The 4090 would rank higher if it could fully stretch its legs.", "The B580 is about equal to the 7800 XT again.", "In Phantom Liberty with Ray Tracing and at 1080p, the B580 manages to hold onto its 4th place positioning in our current limited lineup. The lead over the 7800 XT is now a massive 29%, thanks to AMD’s performance issues in this title. The 4060 maintains an advantage of 15% over the B580. What’s clear is that Intel has drastically improved on its A-series performance.", "Intel Battlemage is way better than our experiences with Alchemist. The launch of the ", " and subsequent ", " and ", " cards was plagued with experience-ruining bugs that were unfixable in many cases. This time around, we ran into a couple driver issues, but the only one that completely prevented play was an issue with Cyberpunk and RT Ultra settings, where it’d hard crash. Everything else ran more or less without issue.", "This review is long already, so we’ll keep it simple. Here are the key points:", "As the ", " went on massive fire sales previously, we’d sometimes recommend it with heavy caveating. The main one was that we never felt comfortable recommending it for the general mainstream audience as we feared users without troubleshooting experience (or even those who have it, but don’t have secondary GPUs) would find it frustrating when encountering games that simply don’t work. Starfield, for example, just didn’t work at launch on Arc. ", "Battlemage has improved on this front. We feel much more comfortable recommending at large. However, we still have one major caveat, which is that this is still only the second true generation of Intel’s modern dGPUs. We fully anticipate that Battlemage will have issues given the thousands of games and millions of hardware and software combinations, and we can’t possibly vet them all. That’s why it’s important to check other reviews. We can only speak for our experiences: In the games we tested and with our software, we encountered only one game-breaking bug, and that was RT Ultra in Cyberpunk, which is likely not particularly playable anyway. It is a valid issue, though. We also had one system hard reset at some point.", "Now, on NVIDIA and AMD, such issues would almost never happen at this point. On Intel, this is an improvement from dozens of problems with the Alchemist launch. The issues were so many that we published a bug report detailing over 30 major problems. ", "The ", " poses considerable value as compared to the ", " and ", ". It is not always the best and trades with these cards, but is a serious competitor. You have all the numbers. We’d recommend looking through our results and determining if it’s a good fit for your games, but overall, Intel’s improvement is obvious.", "The next big thing will be seeing what happens in January with Intel’s competitors."]},
{"title": " Intel Arc Goes Where NVIDIA Won't: A580 GPU Benchmarks & Review vs. A750, RX 6600, & More", "paragraph": ["Intel Arc Goes Where NVIDIA Won't: A580 GPU Benchmarks & Review vs. A750, RX 6600, & More", "Last Updated: ", "The Highlights", "Intel Arc has ", ", but it’s ", " over the past year. Intel has managed to resolve many of its broken driver issues and has picked up the performance overall. Despite shedding staff, which concerns us for its longevity, the company has managed to turn the Arc launch around in a big way. But it’s competing with large players who have mountains of last-gen GPUs that they can dump for cheap, and that’s a challenge. But the ", " is going to try and make its mark in the budget class.", "The Intel Arc A580 is a new $180 GPU -- one of the only sub-$200 GPUs to hit the market in a long time. There is one problem here, however, and it comes from within: the A750 is now around $190 at times. A $10 price gap in real-world pricing is going to be a tough one for the weaker card to win, and the ", " has recently become a recommendation of ours in its price class (although, only for enthusiasts who can tolerate drivers that are late for new games and occasional crashes).", "Steve Burke", "Mike Gaglione", "Jeremy Clayton", " Vitalii Makhnovets", "Jimmy Thang", "The A580 is an interesting card: It applies some pressure to the existing stack, but likewise, its steepest competition comes from the older ", " and Intel’s own ", ". The RX 6600 is often around $200 these days, making it one of the fiercest nearby competitors and alternatives to the Arc A580.", "NVIDIA has functionally abandoned this market -- they seem to want you to pay for game streaming indefinitely if you’re in this price class. In fact, only NVIDIA’s ", " is worth mention here, but it’s not relevant enough to re-test. Although if rumors of a 6GB 3050 are true, maybe that’ll change.", "Today, we’re looking at the ", ". Given it's an Orc, we expect to find bonuses to its constitution and strength.", "The Intel Arc A580 GPU runs 3072 shading units, an 8MB cache, and has a TDP of 175W. Memory capacity and type come out to 8GB GDDR6 on a 256-bit memory bus. ", "Compared to the A750, that’s a lower TDP, a reduction in shader count from 3584 units, and likewise a drop in ROPs and TMUs.", "This testing will make use of our standardized GPU test platform that we deploy for all reviews. You can learn about our test benches and the games we run in this ", ", with large parts of our ", " (although the games have changed).", "Baldur’s Gate 3 is up first. This is one of the newest games to our test suite, and it works great for cards that are below the $400 price mark.", "As we settle into this chart, remember that Intel had difficulty running Baldur’s Gate 3 with the DirectX API. We talked about this in our ", ". Vulkan is significantly better on Arc and in ways which weren’t replicated on other cards. Arc had serious frame pacing problems with DirectX.", "We’ll start with a like-for-like comparison: The A580 with Vulkan -- its best and most appropriate use case -- allowed the A750 with Vulkan a lead of about 5-6%. We also retested this with the newest drivers and had the same result.", "Also like-for-like, the DirectX result for the A580 had it below the RTX 2060 and ", ", with the 6600 carrying a significant lead in low performance. ", "Everything in the 80s for FPS is hitting a CPU bind at some point.", "In Baldur’s Gate 3 at 1440p, the ", " ran at 56FPS AVG with Vulkan. That has the A580 ahead of the ", ". The lead is mostly a technicality in AVG FPS, but the lows are better -- but this is Vulkan. In Dx11, a truer like-for-like, the 6600 leads the A580 by 9%. ", "Let’s stick to a like-for-like with Vulkan: The A750 ran at 64FPS AVG, leading the A580’s 56FPS AVG result by 15%. That’s a more significant gap than we saw at 1080p, which is because the A750 was occasionally brushing against a CPU limit.", "Starfield went terribly for Intel. We used the drivers that claimed triple-digit uplift for Arc, but considering the baseline was literally not working at all, maybe that’s an easy uplift to hit. In our testing, we observed 18FPS AVG and lows that were completely unplayable. The game was a stuttery disaster. Comparisons don’t matter here - it’s just broken right now. Maybe it’ll work better soon, as Intel has noted it is still working on improvements here.", "In Total War: Warhammer 3 -- just before we move to PHARAOH soon -- the game ran at 85FPS AVG on the A580. That has the ", " about 8.5% ahead of the new A580. Lows are scaling as we’d expect with the average. Depending on the price at the time you’re buying, if they’re further apart, it may be worth going for the A580. But if these cards are within $10-$20 of each other, the A750 appears worthwhile.", "The A580 is ahead of the older RTX 2060, but given the importance of the 2060’s former $300 positioning for the KO model, that’s a good spot for the A580 to be in. Compared to the RX 6600, the A580 leads by 16% in AVG FPS, with lows similar.", "To look at one price class up, the RX 7600 -- these days $230-$250 -- is at 101FPS AVG. That has it leading the A580 by 18% while costing about 33% more on average. The ", " is in a different class for performance in general.", "At 1440p, what we want to know is whether the scaling remains the same. The A580 leads the RTX 2060 by 14% here, almost identical to the 1080p lead. Against the RX 6600, it’s 25% ahead -- a larger gap than the 16% lead at 1080p. The Intel Arc card is doing relatively well scaling as resolution increases, although it’s still ultimately more of a 1080p card. But that’s useful information to have.", "The A750 Titan meanwhile leads by about 13%, up at 62FPS AVG. The 1080 Ti remains a familiar face here, except with significantly improved lows over some of its immediate neighbors. Looking between the A580 and A750 Titan, we land on the RX 7600 at about 62FPS AVG -- the same 13% lead over the A580.", "In Shadow of the Tomb Raider at 1080p, the A580 ran at 98FPS AVG, allowing the A750 Titan to establish a 5% lead over the newer A580. If this were more consistently the gap, then the cheaper card would be the clear winner. The RX 6600 leads both, with its result at 125FPS AVG, gapping the A580 by 28%. As long as there’s price proximity between the two, at least in this game, the 6600 would be the clear choice.", "For more expensive comparisons, the RX 7600 pushes further ahead with a 54% advantage. The RTX 4060’s 157FPS AVG result is a little further ahead still.", "Please note that everything at or above 230FPS AVG is CPU-bound since we’re at 1080p, so those results aren’t comparable. We’ve removed cards like the 7900 XTX, 7900 XT, 4070 Ti, and similar.", "At 1440p, the A580’s 74FPS AVG had it about 5FPS behind the A750, giving the A750 a 6.5% lead. That’s more than we saw at 1080p, so they’re getting more distant -- but not in a relevant way. The RX 6600’s 83FPS AVG has it 12% ahead of the A580 here, so if they’re the same price, the 6600 would be the better buy. The $20 gap gives us more to consider and we’ll need the full picture of all games to make a determination at the end.", "Spending around $100 more would put you 35% ahead with the RX 7600, which also pulls up its lows -- although the A580’s lows in this game aren’t a problem. Going to the 4060 would increase that gap by a couple percentage points, but increase the dollar amount more significantly.", "In Final Fantasy XIV at 1080p, the A580 finds its place at a high framerate in a less intensive game. The 154FPS AVG result positions it about 5.5% ahead of the RTX 2060. You shouldn’t change from the 2060 to the A580, but it gives us a good idea of industry trends in this price class.", "The RX 6600 is about tied with the A580 in this one, although the A580 pushes better lows -- we’ve noticed that AMD cards, in general, run disproportionately low for 1% in this game. It’s not bad or particularly stuttery, but definitely worse than what we measured on Intel.", "The A750 leads the A580 by almost 8% here, a little more than we’ve seen in some of these games. As for the 7600, its 20% leadership puts it in an entirely different class of card -- but so does the price tag. That or the 4060 would be the next logical major step-up.", "We’re CPU-bound at 1080p starting at the 4070, so we removed everything else.", "1440p is next. The A580 can still play Final Fantasy at this resolution, landing at 93FPS AVG. That has it just barely ahead of the 6600 in AVG, more in lows, and still about 7% ahead of the RTX 2060. Spending more for the A750 would get you an increase of 14%, with the 7600 reducing its lead to about 19% -- not much of a change and mostly within error.", "Horizon Zero Dawn is next. At 1440p, the A580’s 73FPS AVG allowed the A750 Titan a lead of about 7-8% in AVG FPS. The RX 6600 is technically behind the A580, but they’re well within run-to-run variance. Even the lows are about the same, rendering the RX 6600 and A580 functionally equivalent in our benchmarking here. The A580’s lead over the 2060 is 8-9% here, again showing that it’s positioned as one of the more proper successors given the price reduction and slight performance boost -- but it’s a generation later than we’d like to see, and the same goes for Intel, which famously got stalled for its Arc launch.", "In F1 2022 at 1080p, the Intel A580 ran at 120FPS AVG, with the freshly retested RX 6600 at 126FPS AVG -- a lead of 5% in AVG FPS, although a bit behind in 1% lows. The A750 was 12% ahead in this test, with the RX 7600 22% ahead of the A580.", "At 1440p, the A580 falls to 91FPS AVG, with the A750 now 9% ahead. The RX 6600 is behind the A580 here, allowing the new Intel GPU a lead of 4.8%. They’ve flipped spots with the resolution increase.", "We’ll look at some quick ray tracing numbers to close things out on the gaming side.", "In Tomb Raider with RT Shadows, the Arc A580 managed about 60FPS AVG at 1080p with the highest RT settings. Considering the equivalence with the 6600 -- and close proximity to the recently re-tested ", " -- we’d say this is great relative positioning for the A580. It allows the A750 Titan (again, with new data) a lead of 9% -- but that’s similar to what we saw in rasterization, so given the A580’s cut-down spec, that’s not bad.", "At 1440p, the A580 led the RX 6600 once again. It’s proving itself here as compared to earlier results. The A750 Titan manages a 5FPS AVG lead, but overall, the A580 is doing relatively well.", "In F1 2022 with RT enabled, the A580 once again performed relatively well: It’s encroaching on the RX 7600. The A750 has a 14% lead, similar to what we saw in some rasterization tests. The RX 6600 remains behind the A580, giving it an advantage in this particular test with RT on.", "Intel's Arc frequency logging is still unreliable, but we can at least focus on thermals and power. We'll use external logging utilities for many aspects of this, although GPU-Z is reliable for thermals.", "Finally, we’ll run some thermal tests. This is contingent first on the power that the silicon pulls, and second on how good the cooler from the board partner is -- that’d be Sparkle’s job.", "The A580 Orc ended up at about 68 degrees for the GPU core temperature when at steady state. There’s no problem with that. Even if your ambient were significantly higher than our 21C test environment, that’d still leave plenty of room. These lower-end GPUs tend to run relatively cool. Even in spite of the inefficient performance-to-power consumption we saw, the total power consumption remains more than manageable from a thermal perspective.", "Thermals were about 78 degrees Celsius for the memory temperature. That’s well within spec. It’s warmer than we’d like to see on something like a 4090, which often has a massive heatsink, but that’s fine on a card like this one.", "Testing the A580 for power consumption, we found that the card pulls 218W from the PCIe cables and the PCIe slot combined, making it one of the least power efficient cards we’ve tested anytime recently. The ", " blows it away for power-to-performance, as does Intel’s own Arc A750 card, which itself pulled 234W. The ", " only pulled 136W in the same test, making it significantly more power efficient.", "Intel has a lot of work to do on this front - it seems Intel is in AMD’s old habit from generations past, where it’s blasting power to keep up with competing hardware. Fortunately for Intel, at the lower-end, that’s not as limiting as at the high-end. But this is still Intel’s next most important area of improvement after driver support; as evidenced by Starfield, drivers are still a point of concern.", "We normally don’t report on idle power draw, but that’s because it’s typically not interesting. In this truncated chart, we see the A580 was pulling 43W when idle on desktop. The A750 was at 45W. That’s a lot of heat for a passive computer. By comparison, the 4070 was around 11W here, with the RX 6600 at 8W.", "For those wondering, this is a single-monitor setup. Multi-monitor setups sometimes cause different issues.", "If it’s really a $10 difference and you’re set on Arc, definitely just go for ", ". It’s worth it over the ", ", but both cards ultimately maintain the same disclaimer as noted at launch: Intel’s drivers. They’re getting better, and Intel is showing promise, but we still wouldn’t recommend one of these cards if you’re going to give it to someone who might not be able to troubleshoot independently. For alternatives, the ", " is a close competitor and the only one really strongly worth considering at the same price. NVIDIA presently has no meaningful options at this price range. Its last-gen RTX 3050 would ", ", and an RTX 4050 hasn't yet been announced. The ", " is its closest modern option, but it's in a different price class. That card ends up around $300 currently, at which point you should also start considering the ", " (which is often cheaper by $50 or so).", "At least as far as Sparkle's execution of this card, the Orc model of the A580 is competent enough. It's fine for thermals, which is most of what they control. The card also doesn't pull that much power (in an absolute sense), so it's easy to keep cool. The power consumption in a relative sense, though, is wildly inefficient."]},
{"title": " Dell Made an Impressive RTX 4090: Relatively Small, Large Flow-Through, & Good Cooling", "paragraph": ["Dell Made an Impressive RTX 4090: Relatively Small, Large Flow-Through, & Good Cooling", "Last Updated: ", "The Highlights", "Back in July 2021, we took a look at ", " and thought it was surprisingly good. Fast forward more than two years and we’re reviewing ", " GPU, which we stripped out of an ", " build we previously reviewed.", "Dell’s RTX 4090 is based off of a reference PCB, which is actually different from NVIDIA’s Founder Edition card, and generally has the best compatibility with water blocks. There are multiple reference PCBs this generation, but the Dell one matches a prior Inno3D design.", "In terms of the card’s design, it uses a simple black-and-plastic shroud. The GPU is coupled with a large fin stack, and because the PCB stops short of it, there’s a lot of space for flow-through cooling where the air comes in the front of the third fan and is pushed out the end.", "Steve Burke", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "One big downside to the card is that it does not allow over-power provisioning for overclocking. The VBIOS is somewhat sadly power restrained and overclocking software doesn’t let us set over 100% power target so there’s no room to do any overclocking.", "In our review, we will be stacking Dell’s RTX 4090 against Asus’ RTX 4090 Strix as a point of comparison, which is a more premium card. Asus’ variant has much more stable power delivery, a higher power target with overclocking options, and also has multi-VBIOS compared to the Dell’s single VBIOS equivalent.", "Dell’s card features three fans, one extending beyond the PCB. At the top of the card, the shroud is completely out of the way of the exhaust. The bottom is covered by the shroud, but has little ducts for air to escape. The back of the card also has a big opening coupled with a perforated IO plate, which you can remove with 2 screws. One nice thing about the card’s design is that it has two fan connectors that are externally accessible, making it easier to disassemble without ripping a connector out accidentally (and easier for block installation).", "Removing the metal backplate of the card, you’ll notice that the thermal pads on it contact the back of the PCB’s memory modules. We rarely see the backplate leveraged for its additional surface area, so this is one of the stronger points of Dell's design (or at least, its partner's design -- whoever that is). They've done well to make use of the backplate. Pulling the PCB and cooler apart reveal a black aluminum baseplate for structural rigidity and some VRM cooling. This joins with the nickel-plated copper coldplate that contacts the GPU and memory modules. ", "Dell is using a heat sink mixing heat pipes and a vapor chamber, which contacts the GPU directly. The company combines the vapor chamber with five heat pipes, which collectively do a good job providing as much GPU coverage as possible (the larger 10mm heatpipes in particular provide high surface area through the cold plate, opposite the GPU core). These extends through the massive fin stack to make use of the surface area provided by the aluminum fins.", "On the PCB, we noticed that there’s room to populate more capacitors, MOSFETs, inductors, and build additional VRM phases. This suggests there is headroom for a more powerful card like a 4090 Ti -- or they just down-costed it. On the GPU itself, we noticed that the thermal paste on it looks spread across in an oddly manual way. Cleaning off the thermal paste reveals the AD102-300-A1 die, which is to be expected for a 4090.", "Overall, disassembly was pretty straightforward and accessible with 17 screws that allowed us to get down to the PCB. Another little thing that we appreciated seeing, or in this case not seeing, were any warranty void stickers. This is great because they’re not really enforceable anyways and are anti-consumer. ", "Up next, we'll look at thermal performance and acoustics. ", "For our thermal performance benchmarks, we’ve only included the ", " as an ultra high-end comparison. The point is to just offer a reference, not to determine which of these two cards is better. They’re obviously very different.", "The chart above shows the steady state averages: At equilibrium, the Dell 4090 held a 73 degrees Celsius GPU Core with its auto setting, which stabilized at 52% fan speed for 1980RPM. The hot spot was 86C, which really isn’t bad. The memory temperature was 78 degrees -- that’s not great, but it’s still well within spec. This might only become problematic in a very high ambient case with non-stop load on the memory, like a former mining use case.", "With auto, the Strix card was about 10 degrees cooler in the core metric, about 7 degrees cooler in the hot spot, and a significant 13 degrees cooler for the memory. But this comparison isn’t good enough: the Strix runs significantly lower RPM, and is therefore quieter when left to auto.", "Normalizing for noise levels though required ", "the Strix’s fan speed. We went from 1495RPM to 1871RPM, which equalized the noise levels with Dell card's 1978RPM.", "The noise-normalized Strix was another 2-3 degrees cooler in most metrics.", "Again, the point isn’t to determine whether the Strix card is better -- it obviously is, and Dell wouldn’t disagree -- but just to provide a reference point for a barebones design versus one of the better partner models on the market. The most important factor though is that the Dell 4090 passed our thermal torture test, which is the most we seek from a barebones OEM design.", "As for power consumption, we found that these two cards were within 10W of each other -- remarkably close, meaning we were also power-normalized within variance.", "Purely as a curiosity, we decided to cover up the flow-through area of the card. This is something we’ve been wondering about, so it’s just an academic exercise -- there’s no practical value. We used 2 layers of heavy-duty gorilla tape to cover the hole in the backplate. We also controlled the fan speed and the power target, so all variables were fixed except for the presence of the flow-through hole.", "Taping it over increased temperature by about 5 degrees Celsius across the board, plus or minus a little bit. The large flow-through area that Dell included does actually do something, and does clearly help the GPU thermals.", "Again, this card came from our Alienware R15, although the same concept would apply to the R16 that we’re working on reviewing now: The card will pull air in through the front intake fan and the lower ventilation in the side panel, then anything passed through the flow-through hole will hit the top exhaust from the CPU cooler. Although this increases the effective ambient of the CPU cooler intake, these larger 240mm liquid coolers are more capable of handling it and the GPU will benefit more than the CPU will lose -- especially given Dell’s clamping-down on power budget.", "Noise levels were tested in our new ", ", which is a special testing environment for hyper-accurate acoustics analysis -- it eliminates as much background noise as possible, allowing us to ensure data isn’t interfered with by other office or world noise. To support our continued purchase of equipment like this, please head over to ", "and throw a few bucks our way. Our Patreon supporters have been enabling this type of work for a long time now, and you can be part of our next big equipment use. We’ve been getting a ton of use out of the acoustic chamber, as it’s already popped-up in our ", ", our ", " and ", " case reviews, and now this one.", "Let’s take a look at some data.", "Starting with the frequency spectrum analysis, Dell’s auto profile tends to settle at 1978RPM under our test conditions. The frequency spectrum has some stronger levels towards the low-end, particularly at 200-800Hz. The last few devices we’ve tested have been at the higher-pitched end of this, mostly because they’ve been handheld gaming PCs.", "The Dell card falls off gradually after 2000Hz, decaying without any abrupt frequency changes that might be more annoying to a human listener.", "Plotting the ASUS card at auto, this configuration is overall much quieter across the spectrum. Its behavior tends to have a sooner fall-off at around 1200Hz, where we see our final spike before it begins the decay. It levels-out briefly at 2500-4000Hz before falling further.", "Finally, a roughly noise-normalized dBA SPL Strix at 1870RPM followed a similar frequency spectrum to the Dell 4090. The Dell card had higher levels at 200-400Hz, but otherwise, they’re very similar noise profiles.", "Looking at noise levels now, also measured in our hemi-anechoic chamber, we end up with the chart above. ", "The Dell card runs a higher RPM at a given percent and has less overall range, so its noise level is higher per percentage increase. Like-for-like RPM, they are often within 1dBA of each other -- but the Strix is favored for cooling, as we saw earlier.", "The Dell card’s progression of noise is similar to the Strix here. We’re not seeing any sudden spikes or flattening. The card tends to stay within the 35-35.5 dBA range when set to auto, tested at 1m and with a noise floor of 13.7dBA.", "And here’s the next most important plot: Frequency. This looks at the sustained frequency in megahertz over a prolonged workload. The Dell 4090 fluctuates a lot for core clock, with a range of +/- about 100MHz. That’s relatively high point-to-point for a 4090, as most partner models now will hold a steadier, flat frequency.", "Adding the Strix to the plot demonstrates that: It’s at a flat 2730MHz, whereas the Dell card ranges from 2650 to about 2745MHz. Dell is hitting a power perfcap limit, whereas the Strix is hitting a voltage reliability limit. To flatten this frequency and boost higher, Dell would need to allow VBIOS to pull more power. We could do that ourselves, but it’s locked to 100% in OC software.", "Alienware and Dell prebuilt PCs have historically had lots of problems but some of their ", " and GPUs are surprisingly well put together, which made us curious to take a deeper dive into the company’s RTX 4090. After putting it through its paces, Dell’s card performs well overall. ", "The GPU core temperature is honestly lower than we had expected, especially considering its relatively small size. This is impressive for an OEM-made card that uses a reference design. The cooler does well and we weren’t running into thermal throttling with it. We also didn’t have any major acoustic complaints.", "The tear-down is also straightforward. We’re not sure how many different water blocks will fit on this reference design PCB, but our Alphacool did fit on it, for what that's worth. ", "At the end of the day, if you buy an Alienware or Dell pre-built, at least you’ll know that the GPU should be good enough."]},
{"title": " NVIDIA RTX 4080 Super, 4070 Ti Super, & 4070 Super Official Specs, Price, & Release Dates", "paragraph": ["NVIDIA RTX 4080 Super, 4070 Ti Super, & 4070 Super Official Specs, Price, & Release Dates", "Last Updated: ", "The Highlights", "NVIDIA today officially announced its long-rumored “Super” series GPUs. We won’t waste any time: The 3 GPUs are the ", " at $600, ", " at $800, and RTX 4080 Super at $1,000. The biggest change is in the 4080 Super, which brings MSRP of the prior 4080 down by $200. As for the lineup, NVIDIA is discontinuing the original ", ", now replaced by the full die 4080 Super, and it is also discontinuing the ", ". The original ", " will remain.", "We’ll start with the specs and the breakdown of the rest of NVIDIA’s pricing.", "Steve Burke", "Tim Phetdara", "Jimmy Thang", "Here’s a table with some prices we just pulled from spot-checking Newegg and Amazon.", "The only card that’s increased in price in a big way is the ", ", which is $2200 and up. They’re all over the place. We’ve seen them up to $3,000, but couldn’t find any trustworthy sources at MSRP at the time of writing this.", "The 4080 Super slots in below that in terms of capabilities. The 4080 is currently available at prices similar to its $1,200 launch price, plus or minus a bit. The 4070 Ti is currently around $770 to $820, which are prices before these announcements. ", "The 4070 Super is around MSRP for the 4070, but the 4070 itself is around $550 today.", "Finally, the 4060 Ti 16GB has also come down by $50, now at $450.", "For relevant AMD alternatives around the same prices as the new cards, the ", " is around $780 now, up $60 from the ", ". The ", " is about $950-$970, which is close to its original MSRP.", "Release dates are staggered: The RTX 4070 Super launches first. That’s the $600 card and it launches on January 17th. The 4070 Ti Super is next at $800 and on January 24th. The 4080 Super launches January 31st for $1,000.", "The prices are mostly moving down, so that’s a good start. One of our concerns leading into this was if NVIDIA would use the 4080 Super to push a higher price now that the 4090 has exited its MSRP, but coming down is a relief. Whether it’s enough to support good value will be something we evaluate in our review. We’ll hold judgment on that until we can see the performance.", "Let’s get into the simplified spec sheet from NVIDIA.", "The 4080 Super uses a full AD103 die with 10,240 CUDA cores, a bump of 5.3% from the original 9728 CUDA of the 4080. The 4080 Super also upgrades the memory to 23Gbps, up from an effective 22.4Gbps of the 4080 -- so about a 2.7% increase. The total graphics power remains the same for the Super and original 4080s. ", "Moving on to the 4070 Ti Super, NVIDIA told us that this uses the AD103 die from the ", ", but with 8,448 CUDA cores. That’s up from 7680 on the ", ", or obviously down from the 9728 of the original ", ". It sits right in between the two, so you can expect it’ll likely be between the existing ", " and ", " for performance -- no surprise there. The name tells us that much.", "The larger change is to the memory: The 4070 Ti Super will have 16GB of VRAM, up from 12GB on the ", ". It also gets a big memory bandwidth bump by moving to a 256-bit interface from 192-bit. This is a huge increase in memory bandwidth that will have a theoretically large impact on high-resolution performance.", "The ", " is last. The ", "’s CUDA core count is 7168, up from 5888 on the 4070. That’s about a 22% increase. NVIDIA said the 4070 Super uses a “nearly perfect” AD104 die, which would max out at 7680 cores if perfect.", "For a brief explainer on why that's relevant for those of you who might be new to all of this, each GPU SKU has different pieces of silicon. They’re different sizes. As you go down the stack, they get smaller. Larger silicon costs a lot more to make. It’s not only in materials but it’s also much harder to get the yield high. You have a lot more area, and in terms of the fab process, it’s more expensive. When companies talk about a perfect die, in the case of a GPU, that would mean all of the SMs are there so every component of the die came out without any meaningful defects. GPUs with more defects can get relegated to a lower tier, which results in a cheaper model SKU. To learn more about this, make sure you check out our ", ".", "Finally, the 4070 Super also gets a 20W increase to default power target, which is meant to support the frequency and higher core count. This pushes it lower on the efficiency part of the curve, but should allow higher extraction of performance in a part of the market where there’s a lot more competitive pressure for raw performance from AMD’s side.", "That mostly covers the specs. NVIDIA provided some relative performance comparisons, but with a weird mix of DLSS 3 and 2. We’ll just wait to run the benchmarks ourselves before talking more about performance. ", "Speculatively, the 4080 Super is interesting mostly for its price reduction. The 4070 Super is interesting for its larger swing in core count. The 4070 Ti Super’s bandwidth increase is its big change. Each of these three has a different angle that makes it interesting, so we’ll have a lot to test and talk about soon.", "NVIDIA also featured a number of other smaller announcements, at least as far as our coverage goes.", "The most relevant to this audience would be the Alienware AW3225QF 4K OLED monitor with a 240Hz refresh rate and 0.1ms response.", "The company also talked about a new G-Sync feature called “G-Sync Pulsar,” which is meant to reduce motion blur. Not the kind that game engines apply, but the kind you get intrinsic to the monitor.", "The rest of the announcements in our pre-briefing pertained to generative AI or RTX Remix, which is the modding kit. RTX Remix is moving to a new major version revision and is worth exploring for modders and NVIDIA has updated its ramen shop owner AI, but we’ll save that for another time.", "We’re rerunning a lot of the GPUs through our test benches now, so check back for the reviews as data comes in. Those will be going live likely sometime near the release date for the cards."]},
{"title": " AMD Radeon RX 7900 XT vs. RTX 4070 Ti Revisit in 2023: Benchmarks & Price Drops", "paragraph": ["AMD Radeon RX 7900 XT vs. RTX 4070 Ti Revisit in 2023: Benchmarks & Price Drops", "Last Updated: ", "The Highlights", "AMD’s ", " has finally become the competitor it should have been -- sort of. It’s time to do a revisit, because the new pricing makes this card a lot more competitive than it was at launch. ", " and said that AMD was out of touch, especially with its own 6950 XT pricing that killed the 7900 XT’s worth (and against ", ").", "The cheapest SKU we could find was the ", ". The pricing has been ", " lately, unfortunately. We purchased it when it was $720, which was a $30 instant promo stacked on top of a seemingly new $750 baseline price. Apparently that was an incredibly narrow window though, because by the time we finished our in-depth testing of the card and writing the review, the price had changed again. And not just the promo price, but the entire price: On all US retailers we had checked, the price climbed from $720 discounted and $750 baseline to a new $800 baseline.", "That took us by surprise, because every retail listing we saw gave us the impression that $750 was the new baseline. We’re skeptical whether the price might have just risen to drop once we hit Black Friday in a few weeks.", "(Editor's note: As of 11/12/23, when we're entering this as an article, the price has slightly dropped again -- now $780 -- aligning with our above suspicions).", "Steve Burke", "Mike Gaglione", "Jeremy Clayton", "Vitalii Makhnovets", "Tim Phetdara", "Either way, that means we bought it at a $180 decline from the launch MSRP of $900, or if you were to buy it right now, it’d be a $100 drop from launch MSRP. Both are a big shift from the launch price.", "Despite our immeasurable disappointment of the rug being pulled on us, we’ll forge ahead with a rewrite of this article to accommodate both the illusive $720 price and the $800 one.", "Either price would put the 7900 XT in close competition with NVIDIA’s ", ". Regardless, the price ", "been generally trending down. The focus today will be on head-to-head value comparisons between the most relevant competition that can be bought new. This is meant to be more of a convenient buyer’s guide and recap.", "This review will specifically test the PowerColor RX 7900 XT 20GB Hellhound model, which is one of the cheaper ones regularly available in the US. The Hellhound uses a 3-fan cooling solution, has a dual VBIOS switch, and has a physical toggle for LED control (with three pre-programmed options: purple, blue, or off - the rest is done via software). Testing largely focuses on value today of an RX 7900 XT in general, but we also included frequency analysis for the clock, thermals, and power consumption.", "We’ll start with the prices as of October 30th, then briefly look at the prices from a couple weeks ago when we bought the card.", "First off, looking at ", ", a price comparison engine, we happened to buy the cards right in the narrow dip above. It didn’t last long. The $850 baseline seems to be vanishing though, so that’s moving in the right direction. ", "Doing a quick Newegg search for new-in-box and ", " cards, factoring in instant promos but ignoring mail-in rebates and gifts, we ended up with these prices.", "Most recently, the 7900 XT on Newegg seems to land at around $800. That’s unfortunate. It’s still better, but it was commonly available for $720-$750 a few weeks ago. The same is true of ", ", and you can find the ", ".", "Looking at the 4070 Ti, prices are largely unchanged this past month. Overall, the 4070 Ti can commonly be found for around $800 -- so the 7900 XT at its new price is a direct competitor and, as of October 30th, doesn’t currently have a big pricing advantage. If it drops back to $720, it will. The few $770 4070 Tis that are out there would have an advantage.", "Next, we looked at the ", ". You can definitely get it for under 600 dollars in the US. With a little timing, you should be able to get it for around $550 with relative ease. But there’s a more important alternative at this price class -- and it’s a close competitor to AMD’s 7900 XT.", "The 6950 XT is almost completely gone at this point. We found 4 total first-party listings between Newegg and Amazon (update, 2/9/24 - some of these are no longer available and have been de-linked):", "But AMD is almost definitely not making this card anymore. It’s on its way out. That’s unfortunate, because at $600, it’s a killer price as compared to the 7900 XT. But we still need to look at how the 7900 XT is today, especially since these cards will soon be gone and it’ll replace them.", "We also pulled-up the ", " -- and were shocked at how expensive it has remained. ", "We also found it poetic that Newegg confused an RTX 4070 Ti with an RTX 4080, considering that’s what it ", ".", "But we know all of you aren’t in the US, so we did our best to aggregate some data for Europe.", " caters to Germany, Austria, and Switzerland and provides mountains of pricing data and trend-line information. We asked Geizhals to utilize its price trend data to help us show the price reduction since launch, and they were awesome to quickly get us this chart. This chart includes 19% VAT, plus European pricing and being in Euros, so for our Americans in the audience: Europe has the bigger number.", "It’s leveled-off, and is lower than launch.", "Geizhals shared data with us that showed the best-priced 7900 XTs in its region include the XFX MERC, with 32 offers, and the Sapphire Pulse. PowerColor might not have the same distribution advantages in Europe, as its Hellhound is currently 20 Euros over the XFX card there.", "This testing was performed with our standardized GPU test bench (unless otherwise noted). You can learn more about our ", ".", "Let’s go over the quick competitive comparisons before we get into the detailed charts.", "This chart shows a top-level recap of AVG FPS scaling across several recently tested scenarios. A bar to the right is improvement ", ", a bar to the left is percentage performance reduction against ", ". If the bar goes left, the 4070 Ti wins.", "The RX 7900 XT has the majority of victories, and most of them are double-digit victories. The Skylines 2 test was particularly wild, although that game is ", " in a long time. But it’s still a valid lead.", "In ray tracing tests, the 7900 XT runs 3% to 9% worse. The lower NVIDIA advantages are at 4K, where NVIDIA’s architectural choices have limited the 4070 Ti’s ability to continue scaling. The 4070 Ti also had two break-outs in rasterization: In Final Fantasy at 1080p and 1440p, the card scaled further before hitting the CPU limit. The 7900 XT seemed to encounter a mixture of a driver overhead limitation and CPU limitation. It appears there’s a driver overhead advantage in this particular title with this CPU for NVIDIA.", "In Counter-Strike 2, NVIDIA just has a legitimate advantage.", "This re-establishes that NVIDIA maintains a ray tracing advantage, but that AMD holds a strong advantage in both rasterization performance and overall capabilities at higher resolutions like 4K. The biggest disadvantage was its price, which WAS resolved when it was $720-$750, as that had the 7900 XT consistently cheaper than the 4070 Ti. Right now, they’re about the same price. The 7900 XT is still advantaged in these charts, but if you went heavy on the ray traced games, NVIDIA would be the advantaged card.", "Let’s look at ", " vs. the 7900 XT. We’re adding this so that you know what you’d gain by spending an extra $270 or so. ", "The 7900 XT maintains an advantage in the 40-50% range for many of these games when at 4K. The 1080p results are often CPU-bound, hence lower scaling. ", "In ray tracing, we’re seeing a maximum of 29% advantage for the 7900 XT. ", " holds a 6% lead in Final Fantasy 14 for our testing, indicating the same CPU-bound behavioral advantage that we saw in the 4070 Ti.", "Overall then, whether we look at the cheapest or the average cost from our earlier tables, the price increase to $720-$750 is about 35-38% for the 7900 XT for a 40-50% increase in 4K and 1440p performance, or if we look at the new-new pricing of $800, the 7900 XT is about 45% more expensive.", "We’ll next look at the ", " against the 7900 XT.", "The pricing here was as low as $890, with general availability at $900. Now it’s generally available at $950, with several cards boosting over $1,000. We’re not sure what happened, but everything jumped for AMD’s card prices. ", "Here’s a comparison chart. The bar represents the percent uplift of ", " over the XT.", "Generally speaking, we’re seeing about a 20% uplift at 4K from the upgrade. 1440p tends to be around 15%, with 1080p less reliable since several of these games can start truncating the results.", "At the October 13th pricing, that would have been a $170 increase to buy the XTX, or 24% more money cheapest-to-cheapest in exchange for 20% more 4K performance. Now, at $800 baseline against $950 baseline, that’s a 19% cost increase.", "That’s not as linear as we see lower down the stack, so you’re starting to pay the “just the best” premium for ", ". Remember that you’d also need to begin ", ", as it begins to pop-up nearer the XTX than the XT.", "Overall, we’d say the value of the RX 7900 XT is stronger than that of the 7900 XTX if at those $720-$750 prices, evidenced by the more linear performance scaling than shown here. But as they draw closer, the upsell scenario reappears.", "That’s a better spot than the XT was in at launch for relative value against competitors, but it was nearly an undeniable victory at the price two weeks ago -- other than the 6950 XT as an alternative.", "But we want to make sure the cheapest options are actually any good, so we ran some basic thermal, power, and frequency tests of the Hellhound.", "GPU performance in games is largely the same between cards. Typically, the difference between something like a Sapphire Nitro, PowerColor Hellhound, Gigabyte Windforce, or other add-in board partner card (board partners or AIBs) comes down to what we'd classify as quality of life features. These are things like thermals, noise, VBIOS options, overclocking features, power consumption, and visuals.", "Strictly speaking to gaming performance, it's rare to see more than a 1-3% swing from one partner model to the next. The better place to focus is on these quality of life features when weighing alternatives.", "The next section will specifically look at the Hellhound in these departments. Again, we bought this particular model because it was the cheapest one, so we want to make sure that (aside from hitting the basics of gaming performance targets) it still runs well.", "This card has dual VBIOS, which is typically a feature associated with more expensive cards. That’s great to see, especially because it gives you a backup in case the firmware ever gets bricked.", "Quickly evaluating the frequency, we found the OC VBIOS ran at about 2484MHz when at steady state, so it drops around 90MHz from start due to heat gain. The Silent VBIOS appears to work this time -- we’ve had issues with PowerColor messing that up in the past -- and the clocks drop to 2390MHz. This is a big reduction, but is intended to reduce fan speed by reducing heat load from the GPU. We’d strongly recommend starting with OC, which is default from the factory. If it bothers you, you can always set it to silent (just reboot in between).", "Thermal performance has long been a challenge for partner models with AMD’s more recent generations -- mostly for hotspot thermals.", "In this test, the OC VBIOS had the card running at about 70 degrees Celsius edge temperature, with hotspot at about 84 degrees. That’s well within spec -- far better than we’ve seen on some of the reference designs. It’s not the best performer we’ve encountered and is less capable than the ", ", but it’s also the cheapest we’ve tested so far and it’s still performing in a way that doesn’t concern us when it comes to thermals.", "The silent VBIOS doesn’t change the temperature much, but that’s because PowerColor dropped frequency. Fan speed actually only came down by 3% here as well, so there’s more they could do to properly capitalize on the word “silent” in their VBIOS naming.", "For power consumption, the RX 7900 XT reference card was at about 313W, with an overclock on it landing at 362W. The Hellhound ran at 309W for the silent VBIOS and 330W on the default OC VBIOS (without overclocking though, that’d naturally increase further).", "The RTX 4070 Ti ran at 290W in the TUF’s default Performance VBIOS, significantly lower than the 330W we’re seeing on the default Hellhound -- but that’s part of the exchange for the price advantage of the XT. As for the XTX, the reference model pulled about 351W when stock.", "We know a lot of you like a flood of data, so we’ll briefly look at some full gaming charts. To get these in full depth, check our recent ", " or our previous ", ". We’ll just speed through some here.", "We’ll look at Starfield first, a game we ran full standalone ", ". We also published an ", ". This one has had an overall AMD advantage for GPUs.", "In Starfield at 4K/High, we ", " at 74 FPS AVG and the 7900 XT at 64 FPS AVG. That’s a 15% improvement with the XTX. ", " is left in the dust by the 7900 XTX, which has a 27% lead. The XT has an 11% lead.", "The XT shows that it can definitely be a 4K gaming card, especially without ray tracing. Against something cheaper, like ", ", we’re seeing a 32% lead for the 7900 XT for about $300 more. That’s a sharp loss in performance-per-dollar with the 7900 XT, but it also moves performance into a different category.", "At 1440p, the 7900 XT and XTX are about the same. That’s because we’re now CPU-bound in this title. ", "Let’s briefly look at the impressively buggy Cities: Skylines 2, which has bugs as bad as inverse graphics settings at higher presets. We just ran a full benchmark test and graphics comparison for this game that you can check out ", ". ", "This starts at 1080p -- and don’t get us wrong: It won’t go up from here. The game is functionally unplayable at higher resolutions. It’s like 2009 all over again.", "Before the patch, the 7900 XT was around 60 FPS AVG with these settings. Lows are all over the place, but that’s the game and it’s universally true for the cards. The XTX is about 11% better here. The lead over the 4070 Ti is about 30%, as we showed earlier. The 7800 XT gap is similar: $300 less would land you at 46 FPS AVG with these settings instead. The 4080 is down at 57 FPS AVG.", "We’ll look at F1 2022 now, but using ray tracing for the testing.", "At 1440p ultra with ray tracing, the 7900 XT ran at about 85-86FPS AVG. That has ", " just behind the 4070 Ti here, so we’re seeing the ranks flip. As expected, ", " holds an advantage with RT tests. That’s about 5% for the 4070 Ti. The XTX is about 14% ahead of the XT here.", "In Shadow of the Tomb Raider at 4K/High, the RX 7900 XT ran at about 123-127FPS AVG. That has the XTX about 17% ahead. The RTX 4080 is roughly tied with that, with the 4090 establishing a ceiling. The 4070 Ti isn’t too far back, with the 7900 XT ahead by 5% to 8.5%, depending which card it is. The 6950 XT remains compelling value here, with nearly equal performance to the 4070 Ti but a $200 cheaper price.", "We’ll quickly look at Baldur’s Gate 3 now. This game isn’t intensive enough for a card like the 7900 XT to be fully leveraged, but that’s the point -- that’s why we’re showing this game.", "At 4K/Ultra, the 7900 XT is CPU-bound and ranked alongside the 7900 XTX, RTX 4080, ", ". The 4070 Ti and 6950 XT are nearby. We wanted to show this chart because it helps put into perspective what you really need: If you’re playing less intensive games like this primarily, you could save a lot of money by dropping down to something like a 6800 XT, 7800 XT, or RTX 4070. All of these are still relatively high-end cards, but with massive cost reductions.", "When we purchased the ", ", it was one of the best values for a high-end, current-generation card you could buy. We were excited about the card at that price point, but that didn’t last. It quickly rose from $720 to $800. The only reason it’s worth repeatedly mentioning is because we’re highly suspicious of the price climb in such close proximity to Black Friday, which is, of course, America’s most sacred holiday when we celebrate consumerism. We wouldn’t be surprised if the cards drop again. If they do, and if the competition doesn’t similarly drop, then ", " would become the best value in its price class.", "Currently, that award remains with the 6950 XT at $600, but those won’t last. There are ", " at major US retailers at the time of this writing, so we’ll operate under the assumption it’s functionally gone. But if you can get an RX 6950 XT, they're a great deal: If you do happen to grab one, the differences are often +/- 5% from the 7900 XT, with the max range at around 10%.", "The recent price increase has tempered our enthusiasm around the 7900 XT’s value and put it in more direct alignment with the ", "’s price. The 4070 Ti has advantages in ray tracing, particularly when at lower resolutions like 1080p. Those evaporate as you approach higher resolutions. The 4070 Ti might also have a feature set advantage, but that’d depend on whether you view frame generation and Reflex as a value-add (or things like ray reconstruction, ", "). AMD’s FSR3 Fluid Motion should help compete here, but for now, NVIDIA has a wider spread of its DLSS technologies.", "Our original thoughts on the 7900 XT were clear: We called it a “greedy upsell,” which at the original launch positioning, it absolutely was. Unfortunately, the price changes have contracted the ", " and XT close to one another once again, but it's going in the right direction. Back then, we also noted that the 6950 XT and 6900 XT were far better values. That’s still true if you can find them around $600, but the 6900 XT is basically gone in new-in-box fashion, and the 6950 XT will follow."]},
{"title": " Best & Worst GPUs of 2023 for Gaming: $100 to $2000 Video Cards", "paragraph": ["Best & Worst GPUs of 2023 for Gaming: $100 to $2000 Video Cards", "Last Updated: ", "The Highlights", "First up, we just published our ", " as well, and this will follow the same format. To set the expectations first: Like we said in the last one, our “best of” series runs at the end of each year and serves as a fun way to rapidly recap some of the high points (and low points) and try to refamiliarize ourselves and the audience with options. These pieces are less dense with charts by design, as we know a lot of people build a system, peace out for a few years, and then land on these when they check back in. If this article helps point you toward any one of these cards and you want to learn more about it, you can find links to each of our individual reviews below, alongside links to Amazon and Newegg.", "For pricing, it’s all over the place right now due to sales coming up fast. Each table contains the lowest price we found the card for from a first-party seller at time of writing, with the upper bound being within the common pricing range.", "That should get everyone up to speed on how these pieces work. Basically, if you’re seeking more data, check out the full reviews. But let’s fly through these GPUs today.", "Steve Burke", "Vitalii Makhnovets", "Jeremy Clayton", "For the formatting, we're breaking this up into categories based on price. The categories will include:", "We'll be listing each available card (by GPU SKU, not by board partner model) in each price range, eliminating anything we think is unreasonable or pointless (like old, heavily marked-up inventory). With that list, we'll walk through the best options and note anything that's particularly bad value.", "Each of these has been reviewed at one point or another as well, sometimes with revisits later in its lifecycle. Of course, visiting our most recent reviews will get you the vast majority of the relevant and most up-to-date data. Our ", " is available as an article as well and contains numerous cards in its price class.", "| ", " | ", "| ", "| ", " (same as above) | ", " | ", "This first category is a disaster as compared to previous years. The $100-$200 price class has long been one of the most popular, just after the $200-$300 range (which, according to our view retention stats, is the most popular range).", "But today, this is our list of options:", "Before even looking at the prices, take a look at the release year column above. There is a single entry from 2023. A GPU being from this year doesn’t make it necessarily good or bad, but it does affect pricing and what else is available. NVIDIA and AMD overbought at the tail-end of the pandemic supply race and got stuck with inventory, leading to a delay in more affordable, new cards.", "The 2022 round-up column shows prices we wrote down for our Best Of summary last year for cards that we talked about. The 1630 was about the same price, the 1660 Super was higher -- so that’s come down, and the 6600 is about the same.", "The newest cards on this list would be the ", " -- which just came out -- and the ", ", alongside the ", ", ", ", and ", ". But being the newest doesn’t necessarily make them the most relevant for price-to-performance.", "If you've been out of the game a little while, it's important that you understand several of these newer cards cut the PCIe lanes down, which will primarily affect you if upgrading an older system with a more dated PCIe generation on the motherboard. It won't matter in a modern PCIe slot.", "The ", " might actually be one of the best values here right now. Our recent A580 benchmarks help give some perspective: ", "In Baldur’s Gate 3 running 1080p/Ultra, the A580 held a 64FPS AVG with DirectX and the ", " was just ahead of it at 66FPS AVG. The Vulkan results are more appropriate for Intel, where they ranked at 79 and 75FPS AVG. The ", " is the most relevant competition -- both in price and performance -- and ran at 74FPS AVG. The 1660 Super, currently around $165 at time of writing, runs far enough below these two options that we’d skip it. ", "In Total War: Warhammer 3 at 1080p, the A580 ran at 85FPS AVG, putting it ahead of the RX 6600 by 16%. The ", " did even better, at 94FPS AVG and nearly GTX 1080 Ti performance levels. ", "Tomb Raider had the A750 at 103FPS AVG, allowing the RX 6600 a lead of 22%. In Final Fantasy XIV, we had the 6600 about tied with the A580 and behind the A750 GPU entries. In the same game at 1440p, the A750 pulls ahead of the 6600 by upwards of 22%.", "Intel’s Arc ", " might be one of the best values right now at its new -- and maybe temporary -- $180 price point we’ve been seeing. The ", " is close enough that you should make the $10 jump to the A750. It’s worth it. The biggest problem with Intel remains its general reliability: Arc has massively improved specifically this year, but it still can have problems with new games as it often needs hand-tuning. This is particularly problematic for anything that isn’t DirectX 12 or Vulkan. As such, we’ve been recommending that only enthusiasts who have troubleshooting skills, patience, and/or a backup GPU buy Arc. Despite its big value uplift, it’s still not guaranteed that you can run a game well at launch. Starfield is a good example of that for Arc, and that’s outside of the game’s other issues. Intel has been working on this one, but it definitely wasn’t a week-1 title for Arc.", "So, if all of that sounds like too much hassle or if you don’t want to be in the IT role for whomever you’re buying a card for, consider the ", " as one of the best competitors in performance. It’s similar in price, sometimes it’s better than ", ", and most times, it’s about the same. NVIDIA is sitting this price class out right now, probably rolling hundred dollar bills into cigars and smoking them while watching the peasantly A750 and RX 6600 fight.", "| ", "(times have changed!) | ", "| ", "| ", "| ", "| ", "| ", "| ", "The next section is for $200-$300 cards, which have historically been the most popular.", "Here’s the options list. The release year column at least looks a little healthier.", "The RTX 3050 is priced at $215, down from $270-$300 when we did this round-up last year. ", " as compared to options from both AMD and NVIDIA, so we can eliminate it.", "The ", " and RX 6600 XT went up against ", " in last year’s comparison. Even today, the 6650 XT remains relevant and available, typically around $220 at time of filming. That’ll probably drop with sales in a day or two.", " is one of the two most relevant GPUs in this price category, currently around $240-$270. It’s already dropped in price twice since launch. The ", " is still somehow around and hanging in there at $300. ", " is the most modern NVIDIA GPU to show up so far, at $300 still. And finally, the ", " remains at $300.", "The RX 6700 XT is the most powerful in this listing, with ", " refresh currently in the next price class. We’ll start by focusing on the 6700 XT, 3060 Ti, and 4060 since they’re all $300.", "In our ", ", we had the ", " outperforming the 4060 in Final Fantasy 14 at 1080p, at 6.3% better. The 6700 XT was further ahead still. At 1440p, the ", " held 141FPS AVG to the 3060 Ti’s 135, with the 4060 getting embarrassed at 119FPS AVG. At least it wasn’t a 4060 Ti.", "In Cyberpunk at 1080p, we saw the 4060 run at 86FPS AVG, behind the 3060 Ti again (which itself roughly tied the 6700 XT).", "F1 2022 at 4K had the 4060 behind the 3060 Ti again -- the 3060 Ti has bandwidth advantages here. The 6700 XT led even the 4060 Ti in this one.", "In our A580 review and using Baldur’s Gate 3 at 1440p, the 6700 XT was nearly at the CPU limit, with the 4060 trailing. The ", " was technically ahead of the ", ", but functionally, they were tied.", "From this set of results, the 4060 appears less relevant than it probably should be: The 3060 Ti and ", " are better options if price is identical. The 6700 XT is particularly strong. Looking at Starfield 1080p/High before the biggest patch, the 6700 XT led the 4060 by 17% or more -- some games are better than others.", "At $300, assuming you absolutely cannot spend more, we’d go for the ", " or ", ". The ", " is one of the best value 40-series cards, but it objectively isn’t as powerful as these equal price options.", "The lower-end of the $200-$300 range is pretty healthy. We’d go for the ", " or the ", ". The 6650 XT is basically an overclocked 6600 XT, so you can check the 6600 XT in our charts and estimate a couple percent higher. At $220, that’s the best deal in its price class. The RX 7600 fluctuates and trades places with the 6600 XT regularly, sometimes with leads that are noticeable. It’s not a bad option at $240 today.", "| ", "| ", "| ", "| ", "Now for the $300-$400 category.", "This one is somewhat empty: We get reappearances from the RX 6700 XT, 3060 Ti, and 4060, but didn’t include them on this table since they’re available one tier down. ", " pops-up around $320 at the cheapest we saw it, or commonly $330. That’s basically an overclocked 6700 XT. ", " also makes an appearance now, down from its $400 launch price for the 8GB model. It’s weird to still see the ", " around, but it is. The same goes for the RX 6800, which is a 2020 card but has become surprisingly relevant with its new pricing.", " of the RTX 4060 Ti was simply titled: ", ". Now, some months later and with a price drop from $400, we still think it’s a hard sell. The 4060 Ti’s price didn’t fall in a vacuum: The ", " and 6700 XT came down alongside it and are close competitors, with most of our tests showing them head-to-head with the 4060 Ti. If you’re not going to leverage features like NVIDIA’s Ray Reconstruction in Cyberpunk, Reflex, or its RT featureset, the 6700 XT and 6750 XT make more sense for rasterization performance at the value. That’s even truer at higher resolutions, where the 4060 Ti struggles. Our original 4060 Ti review showed several cases where the 3060 Ti outmatched it in higher resolution testing, leading to NVIDIA making a mockery of itself.", "The ", " is also worth consideration at the $370 price point. Back when we originally reviewed the card, we found the 6800 XT was commonly 10-15% ahead of the 6800, with some larger boosts in scenarios like ray tracing.", "NVIDIA will have a compelling card eventually here, but the ", " isn’t high-end enough to survive on merits of features like DLSS and ray reconstruction alone.", "Ultimately, at the top-end of the $200-$300 range and bottom-end of the $300-$400 range, the 6700 XT remains a relevant pick. That’s a big role reversal from when it launched at $480 MSRP. ", " would be another great option if you have a little extra to spend. After those, we think the ", " might make more sense than ", " in some of the scenarios where its pricing is driven so far down. You can find our ", ".", "| ", "| ", "| ", "| ", "| ", "| ", "| ", "| ", "For updates on the 6950 XT, 7900 XT, and RTX 4070, check our ", ".", "Time to speed this up. We’re widening the range and now looking at the $400 to $750 price category, which makes this a lot more interesting. This is where it’s been the most exciting recently.", "This table gives an idea for common options. We saw the 7700 XTs (", ") start appearing at $430, with most of them at the MSRP of $450. ", " also began popping-up around $430, a sharp fall-off from the original launch price. It’s still not worth buying. It’s not fast enough to benefit from the memory capacity increase.", " at $470 is compelling, especially as it’s cheaper than the 7800 XT and often trades places with it. We saw the 6800 XT outperform the 7800 XT in several tests thanks to its higher CU count, among other changes.", " runs $515 to $550. ", ", which is a great price for that card, and the ", " has finally fallen back down to $740-$750.", "Let’s start with the ", ". A few weeks ago, we ran a revisit of this GPU using the Powercolor Hellhound as our test platform. We bought the card for $720 or so, which was a $180 reduction from the original MSRP. We were thrilled about the find and excited to share it, but within days, the price shot back up to $800. When we posted that video, we said we expected it’d come down again just in time for “sales” for Black Friday. Well, it did. It’s currently at $740, which leaves just enough room for a doorbuster sale in 1-2 days for $720 again. We wouldn’t be surprised. Manipulative retail practices aside -- and this is shared across all major retailers -- the card itself is actually a great pickup at $720-$740. We were lukewarm on it at $800 as it was in direct competition with ", ". But ", " might outshine it at $590. Those are headed into extinction, but are close performers to the 7900 XT.", "We have a few charts from our ", " revisit you can look at to see how close they sometimes are. If you want the full details on these cards and how they compare to the 4070 Ti, check out the revisit. These are strong performers in rasterization, especially at higher resolutions, and compete closely enough in ray tracing to be worth considering at this price class.", "Coming down in price, the ", " enters the fold in competition with the 7800 XT and 7700 XT. The easiest way to look at the 4070 vs. 7800 XT will be in our two charts from the review conclusion:", "The 7800 XT had advantages anywhere from a couple percentage points to 23% over the 4070 in non-ray traced workloads, with a few losses here.", "In ray tracing, ", " was ahead from 5% to 15%. If you really care about ray tracing performance, and especially if you might like features like ray reconstruction, the 4070 becomes much more relevant than in pure rasterization. We’d choose the ", " at this price-class for anyone eying games that are RT-heavy.", "| ", "| ", "| ", "The $750 and up class is wild and also shows you where NVIDIA is focusing its new generation. We're hesitant to make any recommendations on the RTX 4070 Ti or RTX 4080 right now as there are refreshes due in first quarter of 2024. The refreshes will specifically target the 4080 and 4070 Ti, if rumors are to be believed.", "Options are slim: The 4070 Ti somewhat appears one step down, with a lot of options in the $750 to $850 range. ", " also remains in this upper pricing, although reduced from its $1000 launch price. It’s around $920-$950 commonly. The 4080 is around $1105 at the cheapest to $1200. And then the ", " has gone ", "in price, and is the only one in this entire list of GPUs that has gone in the wrong direction.", "Maybe that’s because of ", ", or maybe they just have the market cornered, but the cards are rarely in stock right now and also have somehow appreciated in value. These used to be around $1600.", "In terms of performance, the ", "definitely distances itself from the rest of the pack in ways that were previously unheard of for NVIDIA’s product lineup. Traditionally, the best card to the second-best card were much closer together -- especially if you’re talking about the range between a Titan and the highest-end non-Titan card. With the 40 series, that gap is wide enough to fit a mid-range GPU through. This is also true in ray tracing performance, where the 4090 is commonly 50% ahead of the 4080", "So the 4090 does its best to establish value by providing actual scaling over the 4080, but we can live without higher framerate to save a lot of money. The bigger place it provides value is the memory: For our workloads, with rendering videos in Premiere, we’ve actually found that our renders complete ", "on an ", " than on an RTX 3090. That’s because the 3090’s 24GB of VRAM gets fully leveraged in our rendering workloads, whereas the 4080’s 16GB limits us severely and can slow render times down upwards of 50%. The 4090 works around this with the 24GB VRAM capacity. One of our render machines uses a 4090 for this reason, and we’d bet a lot of professional users -- even though they may wince at it -- are willing to pay the price to increase speed of work.", "As for the cards below this, ", " is difficult to justify against ", " new and low price. We’d generally opt for the 7900 XT over the XTX with a gap that large. The 4070 Ti remains worth consideration for heavy RT users especially. The 4080 we’re still not big fans of. The pricing is just too far out of bounds, yet it lacks the professional advantages offered by the ", ". We tried a 4080 as a cheaper alternative to the 4090 for rendering and it just wasn’t good for our workload.", "Remember, NVIDIA will soon be refreshing its 4080 and 4070 Ti cards, maybe among others, so these categories will soon change.", "The Biggest Disappointment category is hard. There are just so many options this year. For us, it’s more of a trend that’s disappointing: As part of its cost saving measures, AMD and NVIDIA both have made cuts to hardware while retaining old naming schema.", "Despite a name being semi-arbitrary, it still sets a customer expectation. We’ve been the most disappointed in last-generation parts beating or equaling parts of a new generation with the same naming (just incremented). The RX 7800 XT is a great example of this, where the reduced CU count and other changes allowed the 6800 XT to best it in many scenarios. Despite a price drop with that, it’s just confusing for the average consumer. The same is true for NVIDIA’s RTX 4060 Ti, which was embarrassingly beaten by its own 3060 Ti at higher resolutions largely due to memory bandwidth reductions. We’d like to see the manufacturers keep the naming more in-line with what consumers already understand.", "That wraps up our list of the best GPUs for 2023. If you jumped to this section, go back to the price category that best aligns with what you're looking for -- each one is a self-contained guide for each price bracket. If you're looking for roundup-style information on other components, we also already published our ", " article, and our Best CPU Coolers of 2023 piece is on the way soon.", "HARDWARE NEWS", "PC BUILDS", "PC BUILDS"]},
{"title": " ONE YEAR LATER: Intel Arc GPU Drivers, Bugs, & Huge Improvements", "paragraph": ["ONE YEAR LATER: Intel Arc GPU Drivers, Bugs, & Huge Improvements", "Last Updated: ", "The Highlights", "It’s been a little over a year since Intel Arc discrete GPUs launched, and the launch was... ", ". ", "And to Intel’s credit, ", " and even named us in a blog post where it promised to fix its issues. But a lot has changed, so we’re revisiting our punch list of driver issues to see how much our recommendation has changed with the improvements.", "There was a point in time, in the midst of pandemic-related shortages and with everyone trapped indoors playing video games, when Intel was primed to eat NVIDIA and AMD's lunch. All Arc had to do was exist and cost less than $1,000. It missed the mark on launch and was late, but did manage to land below $1,000 -- far below it, and that's the biggest advantage Intel has held.", "Steve Burke", "Patrick Lathan", "Vialii Makhnovets", "Jimmy Thang", "After Arc's official ", ", delays followed, as did several launches that seemed designed to satisfy legal language. ", " on the next-to-last day of Q1 2022, but only in laptops, and the ", " at the end of Q2, but only in China. ", " the real cards everyone was waiting for, showed up in Q4 2022. By that point, Intel was allegedly ", " as prizes for the Xe-HPG scavenger hunt. That's not to mention the ", " that preceded all of this back in November 2020.", "All that is to say that Arc had more time in the oven than anyone could have predicted, and yet judging by ", ", it needed every minute. ", "And now it’s time to see if it’s ready for prime time. Again.", "The driver and Arc Control software were plagued by bugs, many of which were minor, but the combined experience made testing hell. Intel jumped in at the deepest possible end: yes, it had been shipping IGPs and accompanying software for years, but it hadn't shipped a consumer AIC GPU since a halfhearted attempt in 1998. And we covered that story arc in our ", ". You should check it out.", "In spite of this, Intel has been trying to immediately replicate every NVIDIA and AMD feature: first-party recording and streaming functions, XeSS, ray tracing, overlays, performance controls, and integer scaling, to name a random handful. This shotgun approach to software features when the hardware itself is still brand new ended up spreading Intel’s focus in too many directions, leading in a lot of half-working things.", "As a result of that ", " coverage, Intel immediately began posting updates, and noted in its", " that it had filed 43 issues with our engineering team from a ", " by GamersNexus and corrected 4 of those issues by the end of July. We checked back in to ", " and then again at the beginning of this year to ", ". But the biggest area we’ve seen improvement is simply in performance. DirectX 9 got a big overhaul, as did Dx11. We’ll revisit that at the end here.", "We won't re-explain all the many challenges that any GPU manufacturer would face trying to enter this market, but the important ones are software and drivers. Making the hardware is difficult enough. Intel did pretty well there; they made hardware that, when the software, the drivers, and the games all mesh together and work, actually runs competitively. With recent price drops for things like the ", ", where we've seen them as low as $190, just $10 over the ", ", the A750 genuinely is a very strong competitor in the games where it runs well.", "All of our tests of Arc have been caveated with the note that enthusiasts should be the ones buying it: people who have the troubleshooting experience and the patience to deal with the card, and ideally, have a backup GPU from Nvidia or AMD. That's been the line that we've been drawing in our recommendations, and Intel needs to fix that. Part of fixing that is improving a lot of the bugs it's had and usability issues. Some of this will be ongoing, though.", "Let’s start with the problems.", "We won't claim to have found every bug, and we haven't written down every single known issue in Intel's patch notes, but we do have a list of things that we've personally encountered.", "Starting with unfixed problems: We ", " with ", " back when the A380 launched, but our recap of what the feature is supposed to do was cut for time. Here's a summary: Smooth Sync and Speed Sync are both tearing mitigation modes buried in the Frame Delivery submenu of Arc Control. As for the other options, Application Choice respects in-game settings, VSync delivers frames in sync with the display refresh rate, and Smart VSync automatically enables VSync when the application's render rate exceeds the displays refresh rate and disables VSync when the render rate falls below the displays refresh rate. Other than Application Choice, each of these driver-level settings requires VSync to be turned off in-game in order to take effect.", "All of these options are designed to mitigate tearing, which happens when the GPU delivers frames out of sync with the display, primarily on displays without variable refresh capability (FreeSync, G-Sync, Adaptive Sync, VRR). VSync delays frame delivery to eliminate tears. Speed Sync allows the game engine to run ahead uncapped, then delivers the newest whole frame to eliminate tears (but it may lead to perceived stuttering). Smooth Sync allows tearing, but it dithers tears over exactly 32 scanlines. This is handled by a hardware block inside the display engine and had no measurable performance impact in our testing.", "The problem we noted back in August 2022 was that enabling Smooth Sync caused serious artifacting in several of the games we benched, specifically non-DX12 games like Total War: Three Kingdoms, Tom Clancy's Rainbow Six Siege, and Grand Theft Auto V. ", " later that month stated that we corrected 21 UI issues in our driver release on August 19th, and it also includes [...] fixes on SmoothSync corruptions, and the (no longer publicly hosted) ", " for that driver release lists Enabling 'Smooth Sync' may exhibit display corruption in certain game titles under the FIXED ISSUES header.", "Those aren't lies per se, but we tried Smooth Sync again a couple months later, and the results made us suspicious. We confirmed those suspicions for this piece: Smooth Sync is simply turned off for Rainbow Six Siege and GTA V, and presumably any other games that had reported issues. It still works as expected in games that we originally saw it working in, like Strange Brigade, so at least 1 person will be happy, but then again, it also requires players to have an Intel Arc GPU, so that number may be closer to 0… As far as we know, Intel never copped to the fact that its fix was to just turn off Smooth Sync.", "As for Speed Sync, it's just gone. There's no mention of it in the Arc Control menu. Rest in peace, Speed Sync. That’s one way to fix a bug. You can’t have bugs if you don’t have features.", "When Arc launched, not only would the Arc Control app be installed as part of the driver install process, but the Intel Graphics Command Center would also automatically download afterwards. That's not true anymore, which may be an improvement, but Command Center does offer different variable refresh settings than Arc Control does when a compatible display is connected.", "Intel Arc Control contains these settings (all in separate sub menus):", "Intel Graphics Command Center contains this setting:", "And on top of that, Windows contains this setting:", "None of these settings are linked to each other, except that VRR can't be enabled in Arc Control unless it's enabled in Graphics Command Center first, but not vice versa. It's just confusing, and there needs to at least be some explanation.", "But Intel ", "remove the duplicated Smart VSync setting from Command Center, so someone's listening.", "Intel's Driver & Support Assistant tool is still forcibly installed alongside Arc Control. You can install the bare driver, or you can install the driver and Arc Control AND the Assistant, but you can't install just the driver and Arc Control. ", "It's especially annoying for us, since we'd like to avoid installing auto-driver-update bloatware on vital test benches. Even though it's part of the GPU driver install, DSA isn't handled by Wagnardsoft's DDU cleanup like Arc Control and Graphics Command Center are, because it's a random piece of non-GPU-related software. DSA can be manually uninstalled immediately with no consequences.", "Next up is HDCP.", "Because of how Smooth Sync works, we needed to use an external capture system to record it in action, and it was a massive pain. HDCP blocked us from recording anything. AMD includes an option in its control panel to explicitly disable HDCP, and although NVIDIA doesn't, we've successfully used this capture system with NVIDIA cards in the past.", "In order to capture Intel, we had to use the old-school janky HDMI splitter workaround. HDCP is already annoying, and this is a poor implementation.", "At launch, Intel blasted a ton of annoying notifications from the system tray that would pop-up with notes of varying usefulness. ", "Intel may have cut down on the number of notifications from Arc Control, but the ones that show up (before they're turned off) are still pretty annoying. The toast isn't delivered through Windows notifications, it comes from the app itself, and the notifications can't be interacted with or dismissed until they time out on their own. That’s the most annoying part. You have to sit there and stare at them until they go away. Also, the DPI scaling is screwed up on old 1280x1024 monitors.", "But, despite the fact that we still find them useful, most people probably don’t. No big loss there.", "Time to get into the problems that were at least partially resolved by Intel. This section is a mix of resolved and unresolved: It’s Schrodinger’s driver bug. Until you install the driver, it is both broken and not broken.", "Monitor compatibility was one of the most serious complaints from our original batch. We saw issues with two different display types -- one new and one a high-end 4K display from 2014 -- where Intel struggled with display out despite competing cards working with both monitors. ", "At launch, the A380 completely failed to work with them. Later, during our ", ", we found that Arc cards could output to those displays using updated drivers, but only after the driver loaded. That means no output in BIOS or Windows Safe Mode. We observed the same behavior on at least one other monitor in the office, but to be fair to Intel, we've seen a similar issue (as it stands now) with some non-Intel monitors and GPU combos.", "If you're getting a black screen with a new Arc card, try swapping to another monitor to install the driver, then swapping back.", "In our Arc A770 LE review, we saw the fans on our GPU spun constantly, never turning off even at idle. We have occasionally seen the fans spin down with updated drivers and firmware, but the heat generated (and power drawn) by the A770 LE at idle remains high enough to keep the fans spinning the majority of the time, so we're not counting this as a full fix.", "As a general rule, games don't run as well on Arc when using DX9 or DX11. That's in comparison to other vendors on DX9 or DX11, and to Arc cards using DX12 or Vulkan. ", " It's just going to be a labor of love for forever making DX11 titles get better and better and better, and DX9 as well.", "DX12 and Vulkan are thin APIs that shift responsibility for memory management and optimization to applications (game engines), while previously DX11 and DX9 shifted responsibility to GPU drivers. ", "DX11 and DX9 create more work for GPU vendors, and NVIDIA and AMD have a head start, while Intel is stuck playing catch-up supporting software that's already on its way out. ", "This has contributed to Arc's subpar record for day-one game support, especially for DX11 games. If Intel were to slow or halt software support for Arc, game compatibility would likely rapidly go downhill.", "Also, ", " That means that Arc DX9 performance depends on the ongoing development and optimization of this layer. ", "We think Intel made the right choice by focusing its efforts on newer API support, but it means that Arc isn't a reliable platform for playing older games, which is unfortunate given the mid- to budget-range price and performance of the A-series cards. That was true at launch and remains true now: Although support has significantly improved, it will be a continual, ongoing effort to update games on older APIs (whether or not those games are new). Baldur’s Gate was an easy, recent example, although its Vulkan option gives Arc users an alternative.", "This one wasn’t an issue. It was a design choice: Arc needs ReBAR. It works without ReBAR enabled, but performance can be massively worse depending on the application. This issue is inherent to the memory controller used by Intel. Intel's memory controller doesn't perform well with small transactions; it prefers the large transactions enabled by ReBAR. Again, this is an area where we think Intel compromised well by focusing on newer platforms, which usually support ReBAR and enable it by default. It may hurt Arc's ability to fit in the ultra-budget space, though, since old hardware is less likely to support ReBAR.", "That’s all still true now. But again, we think you should be enabling ReBAR on everything these days unless you have a very specific use case.", "Now we’ll move to the fixes and the positive side.", "On a more positive note, there are many issues that have been fully solved. One in particular that we're cautiously optimistic about is Windows Update repeatedly overwriting driver installs. ", "Formerly, if you installed Intel drivers with clean install selected (especially after running DDU), Windows Update would immediately downgrade the driver to whatever ancient LTS version it had on hand. Intel's ", " back then was to make sure not to enable the Execute a clean installation check box, which is completely unacceptable as a fix.", "We can't promise that this problem is gone permanently, but we tried a clean install on our test bench and Windows Update left us alone. That’s a good thing.", "Many of the other complaints that we called out have simply been resolved, with no further discussion needed. But we do want to list them and give acknowledgement and credit. For perspective, here are some of the things that Intel has crossed off its list over the past year:", "We covered Intel’s severely bugged ", ". The game was wildly inconsistent on Arc, where frametimes would sporadically double, or in other words, the framerate ", ". ", "Intel resolved this issue when we covered it back in February of this year. The net result was a significant improvement to the frametimes and the average framerate. ", "In this chart from our original coverage of the fix, you can see that the ", " and ", " went from the bottom of the chart toward the middle. That’s a big uplift.", "As we mentioned, before CS2 replaced it, ", " was also resolved. The frametimes were some of the worst consistency we’d seen in a long time, and Intel fixed that early this year. The game has since been replaced, but the groundwork for the fix remains in the drivers.", "One of the big ones was Arc Control’s existence only as an overlay. This was incredibly frustrating: Arc Control would act as if it were a Steam overlay, making it impossible to interact with the rest of the desktop. This overlay behavior persisted even when it was the only application open. Rather than being a window, you’d have to alt-tab out of it to access other applications (including notepad). This was a big UX oversight. Intel has fixed this behavior and greatly improved usability as a result. We’re happy to see this improvement. ", "Another one was a fix to the Arc Control Center. Previously, this series of actions would completely break the overlay: Opening the Arc Control overlay in a lower-res application (e.g. 1080p) on a higher-res display (e.g. 4K), then exiting, then opening the overlay on the native-res desktop. This specific problem has been fixed.", "We complained heavily about the non-dismissible notifications. Some of these annoying behaviors still exist, but one critical one has been resolved: On display wake, not even system wake, Control used to pop-up multiple notifications every single time the display woke up. This was particularly annoying because they could not be dismissed. Intel has resolved this on our test monitors, at least.", "ReBAR was previously incorrectly listed as not supported in Arc Control even when it's enabled and working. This has been resolved. We have not seen this issue again.", "This was another big oversight: Driver installation weirdly required an internet connection. This was a big issue because Windows could take over and hijack the install and install an older driver version prior to the user completing their own install. This has been resolved.", "This was a small one. The driver installer would previously minimize itself during install and would not restore. This was resolved.", "Previously, rerunning the driver package installer would only give the option to repair the current install, without options to change what features are installed or reinstalled. Intel has improved this behavior.", "Another fix: Previously, using the “reset” button on the overclock screen to reset OC values would throw an unexpected error, as if no one had ever used that page before shipping. Intel fixed this following our review.", "The next is a series of fixes for performance slider changes, voltage control, and fan control. Previously, the performance slider would throw errors when adjusted. That’s fixed. Also, the voltage control was oddly in decimal mV, so microvolts instead of millivolts. The changes either didn’t actually do anything because they were too small or it just presented improperly. Also fixed. And finally, fan control did not work or exist. That appears to be mostly fixed.", "There was another issue where Intel Arc Control would just inevitably break. We didn’t have any explanation for it, but with 100% consistency, it would stop working on all systems. After this happened, it couldn’t be reinstalled on that system AT ALL. It was a critical fault. We actually nuked an OS over it. That’s been fixed.", "Additionally but related, Arc Control would open multiple instances at times -- for reasons also unknown to us. It’d also sometimes just fail to install for seemingly no reason.", "Finally, Intel DSA would report an update available for Arc Control, but trying to download it permanently broke DSA. This appears to be fixed.", "Overall, Intel Arc software has improved dramatically but remains a largely manual effort. The hardware has always been good when it works.", "We are concerned about Intel’s driver team after the company’s recent round of layoffs, as this manual effort means a high manpower requirement. ", "Arc has been a strong value recently, especially the ", ", and for it to move from a recommendation of “this is good for patient enthusiasts with troubleshooting experience” to “this is good to recommend to your family member for whom you don’t want to provide tech support,” they’ll need to continue improving the day-1 support for games. There are still multiple games that we’ve tested like Starfield and GTA V that have been broken at various times.", "But overall, Intel has in fact resolved many issues. Some of the remaining ones are disruptive for casual users (or users without a second GPU, or users who are playing brand new games right when they launch), but at least the drivers are moving in the right direction."]},
{"title": " Back from the Dead: 3dfx's Unreleased Voodoo5 6000 Quad-GPU Card", "paragraph": ["Back from the Dead: 3dfx's Unreleased Voodoo5 6000 Quad-GPU Card", "Last Updated: ", "The Highlights", "This is an unreleased 3dfx Voodoo5 6000 GPU—or set of GPUs—built on a custom 80-Watt Strange God board with four 166MHz 3dfx VSA-100 Napalm chips in double SLI, a 66MHz AGP 1.0 interface, 6-pin PCIe power input, 16x16MiB SDR SDRAM chips for a total of ~256MB of onboard memory, and dual VBIOS (128MB or 256MB memory modes). The card was doomed when it was being made by 3dfx: it was one of their last products.", "This card shouldn't exist, but we have two. There’s no such thing as a retail 3dfx Voodoo5 6000; ", " Instead, these cards were created by Anthony ZXCLXIV (ZXC-64). As a hobby, he hand-assembles and sells custom cards, including 3dfx's lost crown jewel. He designs and orders PCBs, then populates them with new old stock 3dfx chips purchased in bulk, usually taking three days to assemble each card. No one has produced a Voodoo5 6000 for over 20 years, and the last people who did never shipped it. Today, we finally get to tell you about this card that we bought from ZXC-64 for about $1500 US.", "Steve Burke", "Patrick Lathan", "Vitalii Makhnovets", "That's a vast oversimplification of the work that's gone into this project, though. In order to make new cards, Anthony first had to get his hands on a prototype. To give you some idea of their rarity, it took three years from the card's canceled launch for Extremetech's Joel Hruska to find one and write what he called ", " back ", ". With the help of a collector, Anthony was able to borrow a damaged and non-functional unit, and from there managed to non-destructively reverse engineer it and build a new card from scratch. It could have been emulated instead, something that 3dfx’s own founders acknowledged.", "I have no idea [laughs]. They...yeah, it's, it's interesting. But, because they can.", "In ", ", Anthony stated that Making the PCB wasn’t very complicated—I placed all the design blocks around the board and solved the puzzle that way—there were no other available variations. We get the feeling he's underselling himself: he's gone as far as to make multiple revisions of a card left abandoned, including extended memory, PCI interfaces, different power inputs to replace the original DC barrel jack, and VGA pass-through. This is real engineering.", "The ", " dual-chip ", " was the first and only 250nm VSA-100 (Voodoo Scalable Architecture)-based Voodoo5 to market in June of 2000, followed by the budget single-chip ", " in October.", "The Voodoo5 6000 had ", " GPUs on one card. Some prototype Voodoo5 6000s used a supplementary ", ", but the retail product would have had a barrel jack to take power from an external AC Voodoo Volts 50W power adapter.", "The first thing to note about the card is that it is big. Very big. In fact, it's about a foot long [...]. And it has a price tag to match - the expected US launch price is $600 [...] which begs the question, who on earth would spend that much money on a graphics card?", "3dfx was showing off a prototype Voodoo5 6000 as late as September 2000, with Eurogamer remarking on the obscene size (~12 inches), crazy MSRP ($600, ~$1000 adjusted), and power requirements (60W). ", " to our 500W, $1600, 14” cards.", "3dfx Interactive was ", " by former SiliconGraphics Incorporated staff at a point where enterprise 3D had been dominated by SGI for years and PC 3D didn't exist outside of CAD hardware. For more on SGI, check out our ", " and ", " videos made with the help of ", " ", "SGI developed the groundbreaking IrisVision 3D accelerator add-in card for PCs—not just SGI workstations—", ", but didn't know what to do with it. Pellucid, a new startup, was spun off with the IrisVision IP. Media Vision Technology ", " in 1993, then ", " in 1994, with FBI investigations and legal proceedings dragging on for years afterwards. 3dfx was founded by a core group, Scott Sellers, Ross Smith, and Gary Tarolli, that had followed IrisVision from SGI to Media Vision (soon joined by investor/CEO/chairman Gordon Campbell).", "3dfx dabbled in some government and ", " ", " to start with, but its goal was always the console-dominated home gaming market that SGI had intentionally avoided: SGI believed the market incapable of supporting expensive GPU development. There was some internal debate over whether 3dfx's first boxed product should be an add-in card ", ", but in 1996, 3dfx ", " to ", " the ", " powered by the original Voodoo Graphics 3D chip. 3dfx managed to convince Orchid to sell the 3dfx product without any physical prototype, purely off the strength of prerendering demos on SGI hardware and saying that the final product would look like that.", "People would look at it and they'd say 'Well, isn't that what it looks like when you run it on the SiliconGraphics RealityEngine?' and we said 'Yeah!'", "For that matter, there weren't any existing PC games that could leverage the chips; 3dfx had to ", ". 3dfx developed its own API as well, ", " since SGI's OpenGL wasn't initially built for gaming.", "The Orchid Righteous 3D is the card that famously ", " when the 3D hardware activated and closed relays, enabling the VGA passthrough. ", "As the box states: Other 3D solutions replace your existing 2D adapter and may compromise performance. Righteous 3D is a dedicated 3D accelerator that works transparently with your 2D adapter. In other words, ", " in conjunction with a separate 2D graphics card. This ", " over contemporary 3D/2D combo cards, and it also allowed 3dfx to brush past the existing legacy of 2D graphics cards and make something entirely new. The timing was perfect: Windows 95 had just launched, everyone was buying new PCs with PCI slots, and PC gaming was about to ", ".", "This was a period where software and hardware development were racing forward hand-in-hand: Quake ", " with software rendering, but in 1997 GLQuake was launched with OpenGL support (which at the time just meant Voodoo support), and John Carmack joined 3dfx's advisory board.", "3dfx was on fire at this time, and it was just getting started. Voodoo cards were must-have hardware for early 3D games like ", ", especially so for Glide-enabled titles like Unreal and Unreal Tournament. ", "3dfx ", ". There were some minor stumbles that year, like the ill-fated ", " as well as ", " and torpedoing a potentially profitable contract with SEGA, but things were still trending upwards. ", " and ", " marked the peak of 3dfx's success, with ", " (sourced from PC Data) that the top five GPUs sold in 4Q98 were all Voodoo-based. 73% of performance/gaming graphics'' market share was held by 3dfx by early 1999. That’s almost exactly like NVIDIA's current position, including the market share percentage, and it's a reminder of just how fickle the graphics market is.", "The Voodoo2 was the first consumer card to utilize 3dfx's scalable scan-line interleave tech to link multiple cards together (original Voodoo chips had that capability, but it was unused). The abbreviation SLI was notoriously later purchased by NVIDIA and ", ".", "You can't take a high-flying, high-multiple, high-technology, sexy 3D graphics chip company and marry it with a marginal, piece-of-crap board company and come out of it with anything that's good.", "Through the release of the Banshee (3dfx's first 2D/3D combo card), 3dfx relied entirely on board partners like Diamond, Creative Labs, and STB Systems, doing zero first-party hardware production. In late 1998, 3dfx's board decided it was ready to live the dream by ", " (~$243 million in 2022) on major partner STB, based in Texas with manufacturing capability in Mexico.", "Buying a manufacturer allowed 3dfx to immediately shift from 0% to 100% in-house manufacturing (not including the TSMC-manufactured silicon) and push out its partners, who all promptly turned to the competitor: NVIDIA. If that sounds familiar to you, it did to us, too. It’s amazing how rapidly a “too big to fail” company can instantaneously implode when it ", ".", "There isn't a person out there that wouldn't mind having a 3D accelerator that would remain at the head of the pack for the next year, instead of finding him/herself wanting an upgrade after about 6 months.", "As the ", " scrambling to keep up in an oversaturated market ballooned, 3dfx's designs fell into a rut of recycling old hardware and repeatedly diverting short-term resources ", " which was delayed past relevance. ", "DirectX became increasingly dominant in games, and adoption of 3dfx's Glide API was limited. As ", ", 3dfx is back with the third installment in the Voodoo trilogy, but unlike George Lucas' award winning creation, this sequel isn't something to get your hopes too high for. That was written before Episode 1, so maybe don't get your hopes up for The Phantom Menace either, Anand.", "3dfx's lead continued to shrink with the launch of NVIDIA's GeForce 2 in May 2000; NVIDIA focused on sales to OEMs, while 3dfx stuck to the relatively small high-end enthusiast market. The wheels ", " with 3dfx ", " just two years after its acquisition, then dumping ", " after creditors started bankruptcy proceedings.", "The final physical prototypes produced by 3dfx were of the ", " and eventually canceled Voodoo5 6000, as well as some number of ", " which started initial testing days before the company ceased to exist. If you've got a Spectre, email us.", "Given the larger-than-life impression that 3dfx made on everyone—we know, we've seen your comments—it's bizarre to think that it only took four years to go from the release of the first Voodoo card to total collapse.", "Our original plan was to build a system worthy of ZXC-64's ", ", with the baseline requirements being a Windows 9x install and an AGP 1.0 compatible slot. After some discussion with Anthony and perusal of ", ", we settled on an MSI KT3 Ultra motherboard, which Anand Shimpi himself awarded an Editor's Choice Award. We paired that with an Athlon XP 2600+ Thoroughbred from 2002, from the classic AMD era where 2600+ meant 2133MHz.", "The motherboard was DOA, but our friends at the Kramden Institute were generous enough to send us an extremely beige 1999-vintage Dell Dimension XPS T600 as backup, and they even waived the $4 scrap price. Out of the box, it came with a 600MHz Pentium III, 128MB of RAM, a Cirrus Logic PCI GPU, a 10/100 NIC, and a 10GB hard drive, all of which was still functional. We upgraded it with a viewer-donated e-waste 800MHz CPU and some memory harvested from a crumbling homemade RAM Christmas wreath.", "We confirmed that the Voodoo5 6000 worked with viewer-donated hardware, then bought a new EPoX 8K3A motherboard with a VIA KT333 chipset, reportedly the most stable platform for these tests.", "The system was a complete nightmare to get running–we've been working on this piece between reviews for something like three years on-and-off. The sweet spot for compatibility with the Voodoo5 6000 is Windows 9x, so we installed Windows 98 SE with the unofficial Service Pack 3.66 on our test bench. We had constant resource conflict problems on the 8K3A (due to the unusually high amount of VRAM) that we eventually worked around by booting in and out of DOS mode, but the permanent fix was to carefully desolder and move one of the SMDs on the Snow-White in order to reduce the required AGP aperture size. After days (weeks) of troubleshooting, we narrowed down our remaining problems with artifacting and crashes in multi-GPU mode to a defective card, and Anthony swapped us a Strange God AGP so we could complete our testing. In fairness to him, we've seen exactly the ", " ", " reported with retail Voodoo5 5500s, so it looks like his card is a true reproduction—even down to the bugs.", "For comparison, we're testing a couple of roughly contemporary AGP cards sent to us by viewers: the ", " (one of the cards that 3dfx helped to kill) and the 2000 NVIDIA GeForce 2 GTS (one of the cards that helped to kill 3dfx).", "Real3D was a spinoff of Lockheed Martin—yes, that Lockheed Martin—that", " the i740 as Project Auburn with Intel and CHIPS & Technologies, Inc (coincidentally also co-founded by Gordon Campbell), making this the only consumer Intel dGPU until Arc (other than technically Xe and the elusive ", "). And yes, Intel ", " card after the notoriously accident-prone F-104 widowmaker. ", "The i740 was meant to ", " in opposition to the widespread PCI standard, but as a mediocre budget card it was immediately stomped by the release of the PCI Voodoo2. As Anand Shimpi said in his ", ", the Voodoo2 remains the king of the 3D world by a considerable margin. Real3D was shuttered in October 1999 and Intel shifted to integrated graphics for the next two decades, with the arguable exception of Larrabee.", "The GeForce 2 series would have been NVIDIA's direct competitor to the last generation of Voodoo cards, but with the fall of 3dfx, it was up against ATI's first gen Radeon cards instead. Our GeForce 2 GTS (GigaTexel Shader) is the original 32MB launch model.", "This is normally where we'd tell you why our testing is accurate, but in this instance, we're working with cards and hardware that are outside our direct area of expertise (they predate GN by a decade), and we're working with community-developed drivers and an unofficial service pack for Windows 98. We're also testing software that favors Voodoo: this is a fun showcase, not a competitive review. In every test, performance and stability of the card varied based on drivers and whether Anthony's experimental extra VRAM was enabled. We tried drivers from Amigamerlin (2.9), Raziel64 (1.01.16), and the Voodoo5 6000 Resource Group (1.05.04). Overclocking is supported through the 3dfx tools, but we're not going to push our luck on antique hardware. We did one test pass in Single Chip mode, utilizing only one of the four VSA-100s and effectively turning the card into a Voodoo4.", "We'll start with Quake III Arena, a game strongly associated with Voodoo. Despite that association, none of the 90s Quake trilogy natively support the Glide API—instead, they use OpenGL with an optional Glide wrapper. As a result, there are a quarter-century's worth of opinions about the best way to run Quake III. We just installed the game, patched it, used the vanilla 3dfxVGL.dll for the Voodoo card, and maxed out the settings. We used id's FOUR demo for testing.", "Our best stable result for the Voodoo card was with a driver downloaded from the Voodoo5 6000 Resource Group. There was minor scaling with VRAM on this driver, with a 4% uplift going from 128MB to 256MB mode. Switching to single chip mode massively downgraded performance, which helps illustrate how the GeForce 2 was able to outperform single chip Voodoo4s. NVIDIA's card averaged 81FPS, which is 154% ahead of single chip mode, while the full-performance Voodoo5 6000 outperforms the GeForce 2 in turn by 42%.", "We had to switch to Kramden's old Pentium III system to get the i740 to work properly, and even then it couldn't handle rendering the 2D 1280x1024 desktop at 32bpp. Our Starfighter is the 8MB model with no slot for extra memory, which was a feature on some variants. Quake III refused to even launch with the i740 installed.", "Unreal Tournament 1999 was Glide's killer app. Unreal Tournament has true native Glide support, as well as Direct3D for the NVIDIA and Intel cards. Theoretically, we could just slap a NIC in our bench and join a server, but we used the cityintro scene for benchmarking instead, patched up to game version 436.", "We saw heavy texture artifacting in Unreal Tournament on our Voodoo5, which correlated directly with the texture detail setting. The Raziel64 driver didn't offer the best average framerates, but it did sidestep most of the artifacting issues (while introducing others). ", "Using the VRG driver, we saw a 62% performance increase from 41FPS single chip Voodoo to 66FPS NVIDIA GeForce 2, a smaller gap than in Quake III. This is 3dfx's home turf. With all four Voodoo GPUs working together, the stable Razeil64 result is 69% ahead of NVIDIA's card, while the artifact-y VRG result is 77% ahead at 117FPS average.", "Moving on to 1024x768, the Starfighter did actually manage to run Unreal Tournament -- but only at this resolution. The launcher recommends software (i.e. CPU) rendering for older cards, explicitly mentioning the i740, but we used Direct3D to load the GPU. Intel averaged 23FPS, with the Voodoo5 170% ahead at 63FPS average. The Voodoo card is hugely restricted by the old Pentium III, which is the reason we invested in a new motherboard and CPU. Bottlenecking in benchmarks is just as much a problem with these tests as in modern configurations.", " of legacy Futuremark suites going all the way back to the original 3DMark99 DirectX 6 benchmark. 3DMark has been a DirectX-only benchmark since its inception, so this test doesn't favor Voodoo as much as the games we selected.", "We found the Amigamerlin Voodoo driver offered the best performance, but again, each driver had its own quirks. The trilinear filtering test didn't render correctly on Amigamerlin, while the NVIDIA card had consistent problems with misshapen polygons in the 3D tests. ", "This test does provide the best example of Anthony's 256MB memory mode actually helping, as the 32MB texture test ran extremely poorly in 128MB mode. In 256MB mode, though, one edge of the texture consistently showed corruption–we may have a bad memory chip, or it may be a software issue. Amigamerlin 128MB scored 11043 3DMarks, still 53% ahead of the GeForce 2 GTS even in this DirectX application. The GeForce 2's 7219 point average in turn outperformed the single-chip Voodoo by 156%.", "On the older Pentium III platform and at 1024x768, the CPU score is less than a third of what it is with the Athlon, giving us a better picture of the bottleneck. Still, the Voodoo managed a 342% advantage over the i740's overall score at 5924 points versus 1339, with the Voodoo winning in every category except trilinear filtering. The i740 was incapable of running the bump mapping tests, but those aren't factored into the overall score. ", "The Voodoo5 6000 couldn't have saved 3dfx, and neither could Rampage. The company was doomed, and one product launch wouldn't have changed anything. NVIDIA's slow-and-steady strategy of building a solid OEM customer base with cheaper, less exciting cards while 3dfx pursued the tiny enthusiast market gave NVIDIA an advantage (although they", "), and nearly everyone agrees that 3dfx's fate was sealed the moment it decided to acquire STB. Based on the Computer History Museum's interview, it sounds like everyone includes the three co-founders and the chairman (formerly CEO), who were obligated to go along with the board's vote.", "If 3dfx had played nice with board partners and moved more quickly on Rampage, it may have been a different story–or it may not have, with the imminent ", ". This is an example where going where the money is first gave NVIDIA a resource advantage.", "Anthony ZXCLXIV can be reached through ", " for purchase inquiries."]},
{"title": " NVIDIA GeForce RTX 4070 Ti Super GPU Review & Benchmarks: Power Efficiency & Gaming", "paragraph": ["NVIDIA GeForce RTX 4070 Ti Super GPU Review & Benchmarks: Power Efficiency & Gaming", "Last Updated: ", "The Highlights", "We’ve got a lot of cool benchmarks in our ", " review. We’re adding GPU power efficiency testing where we’ll go over FPS per watt, marking the debut of this testing (for us) for GPUs, which isn’t anywhere near final but will soon help reveal more of power characteristics that are often overlooked for video card reviews -- and we've been guilty of that. We’re also adding Cyberpunk 2077 ray tracing benchmarks back in, alongside a couple dozen cards benchmarked through the gaming comparisons today.", "To provide an overview, we’re reviewing ", " in this article, but there’s also the $600 ", ", which we ", ". That card will sit alongside the original ", ", which has dropped about $50. There’s also the ", ". That’s 4 4070 cards, which makes things confusing. NVIDIA is helping to streamline things a bit by getting rid of the ", " moving forward. This isn’t to mention the new ", " (find ", "), which is what many commenters seem to be most excited about due to its $1,000 price, which is $200 less than what the original ", " launched at.", "Steve Burke", "Patrick Lathan", "Mike Gaglione", "Jimmy Thang", "The 4070 Ti Super is sandwiched between the ", " and ", " and comes out to be a solid “meh.” Some interesting findings out of the gate: the 4070 Ti Super skews higher compared to the 4070 Ti (", ") in 4K because of its memory subsystem change. The 4070 Ti Super has increased memory capacity, moving up from the 4070 Ti’s 12GB to 16GB, and changes its memory bandwidth from 192-bit to 256-bit.", "You can find additional test methodology notes in our ", ".", "Power efficiency testing was something we debuted in our ", ", which looked primarily at FPS per watt. In keeping with that, we’ll be looking at FPS per watt here as well. ", "FPS per watt with GPUs produces mostly sub 1.0 numbers, and that’s because power consumption is typically higher than the typical frame rate is in terms of pure numerical value. You might ask, “Why not do watts per FPS to get a nice positive number then?” Our only real answer to that is consistency. We’re going with FPS per watt because we already used it in our CPU story, which people seemed to like. FPS per watt also allows us to go for “bigger number better.”", "Starfield at 4K starts us off for efficiency. In this one, the most efficient card in the test was the ", ", at 0.27FPS/W. Or if you want to look at it another way, about 3.7W per FPS. Or another way still, 0.27 frames per joule. ", "The 4070 Ti Super is about equal with the original 4070 Ti, the latter of which technically has a 2.1% improvement in efficiency here.", "Compared to the ", ", the 4070 Ti Super is about 4% more efficient in FPS/W.", "At 1440p, the ", " slips down the ranks a bit more as it approaches a CPU bind. This reveals interesting data that shows that, although the CPU may start limiting performance, that doesn’t necessarily make the GPU more efficient. It’s similar to the IO die baseline power requirement buffer we saw for AMD CPUs.", "Anyway, the 4070 Ti Super again allows the 4070 Ti a lead in efficiency, this time by about 4.1%. The 4070 Ti Super’s lead over the ", " is a relatively large 15% here, showing that AMD is trading power for performance.", "At 1080p, the 4080 (", ") remains the most efficient, while the ", " continues to slip down the ranks: Its baseline power requirement to maintain operation with its default card settings is reducing its efficiency as it gets increasingly tangled-up by other components. This is really interesting data and implies that the entire system will in fact be less efficient as CPU load increases, as we saw in our previous ", ".", "The 4070 Ti Super produced 0.57 FPS/W here, that has the 4070 Ti original card 4.4% more efficient, or the 4070 Ti Super as 25% more efficient than the ", ". The ", " (recent ", ") is also becoming limited, causing a further gulf.", "In Resident Evil 4 at 4K, without RT, we found the 4070 Ti to be the least efficient card, with the 4070 Ti Super improving by 6%. It could be the case that the uplift in this title comes from the memory subsystem change as opposed to frequency.", " is significantly more efficient here due to overall higher performance than previously, allowing it to roughly tie the RTX 4080. The ", " sits between the Ti Super and the original Ti.", "At 1440p, the 4070 Ti Super still leads the 4070 Ti, now by 2.7%, with the 7900 XT still relatively high up the chart. The ", " ends up striking the strongest balance overall in this one.", "At 1080p, the 4080 and ", " still have some scaling headroom for framerate. The ", " overall comparative efficiency has fallen, but it still pulls 357W and remains relatively heavily loaded despite being limited on total CPU scaling. The 4070 Ti Super is roughly tied with the 4070 Ti at this resolution, so its lead shrank with each resolution decrease. The 7900 XT allows the 4070 Ti Super a lead of 1.4%, so they’re also about tied. The 4070 Super strikes the best balance so far.", "In Rainbow Six Siege at 4K, the RTX 4080 remains the most efficient of the group, followed by ", " -- which is now establishing a trend -- and then the RTX 4090. The 4090 is slightly lower on the efficiency curve for volt-frequency tuning to maximize performance. ", " leads the 4070 Ti by 8.3% in this title, a result of a higher AVG FPS increase than we’ve seen in some other games. The 7900 XT ends up between the two Ti-class cards.", "Now we’re going to quickly look at some 10-point and 30-point non-consecutive highs from the entire test run, including loading screens.", "In this chart, we’re looking at just Watts. The RTX 4090 pulled 502W for its average of the highest 10 points of data, with 498W for the highest 30 points averaged. This won’t capture the smallest transients, which will spike higher, but that’s something ", ".", "The RX 7900 XT pulled 385W as its 10-point high, with the 4070 Ti Super at 330W to the Ti’s 321W.", "In Starfield at 1440p, that drops to 382W on the 7900 XT, 372W on the 4090 -- which is becoming CPU-constrained -- and 266W on the 4070 Ti Super. The 4080 shows why it was relatively power efficient here.", "That’s the foundation of our efficiency testing. We’re really excited about this and plan to add a ton more to it. We did this in just the past week alongside adding ray-traced Cyberpunk and starting our Alan Wake 2 methodology development, so there’s a ton going on here. But of all that, we think the GPU power efficiency testing is the most promising and has the most room for improvement. It was by no means final -- we’re open to changing all of it. ", "We’ll start the game benchmarks with some quick summary charts.", "Here’s a summary chart of the ", " vs. the RTX 4070 Ti. The bars indicate percent improvement by moving TO the 4070 Ti Super FROM the 4070 Ti. ", "In general, we’re seeing about a 10-11% uplift at 4K. Our testing tends to be at highly intensive settings to minimize CPU load, so especially when at 4K, this makes sense with the memory subsystem and framebuffer improvements. Two of the older games here -- Horizon Zero Dawn and Total War: Warhammer 3 -- posted gains higher than we saw elsewhere. ", "At 1440p, we saw about a 7% average uplift in the 4070 Ti Super vs. the 4070 Ti. That’s not particularly exciting and reduces from the 4K gains because the memory just isn’t as impactful. ", "At 1080p, we typically saw from 2% to 6% gains, with a few break-outs higher. Generally speaking, it’s around a 5% uplift at 1080p.", "We have two identical 4070 Ti Super cards, so to help validate these, we tested both for frequency in Port Royal. The brief test established an average frequency of 2746MHz for the unit we used for our review, with the more recently tested unit that wasn’t used in the review at 2725MHz on average. This is about a 20MHz delta. That’s within manufacturing variance, but the silicon quality on the unit we chose at random appears to be a little higher than the secondary model that we used for future latency testing.", "Now for the ", " vs. the RTX 4070 Ti. We broke this into RT and non-RT, as the scale slides opposing directions and we’d prefer to do as much of that math in a single direction (percent improvement) as possible, just to keep it clean. That said, even when it is negative, because the numbers are so tight, it’s typically within 0.5% whether you calculate in the direction of improvement or loss.", "Regardless, the RT performance strongly benefits the RTX 4070 Ti Super. We noticed that Cyberpunk scales more heavily in favor of NVIDIA as all graphics settings increase. With customized ultra settings and without upscaling, we found the 4070 Ti Super was typically in the 70+% range for its lead over the 7900 XT. ", "With Cyberpunk using medium settings instead, we saw halved gains down at 35% for the 4070 Ti Super over the 7900 XT. As RT workload amplifies, the favor for NVIDIA likewise seems to disproportionately amplify.", "In less intensive scenarios, the lead is below 20%. There’s one 4K upscaled result favoring the 7900 XT in Resident Evil 4, which progressively moves toward NVIDIA favor as resolution decreases.", "In non-RT workloads, switching the chart to show TO ", " FROM the 4070 Ti Super, we see the 7900 XT starts pulling ahead on average. Depending on resolution, it’s anywhere from equal to 14% ahead, with losses toward the bottom of the chart. ", "Time to move into the specific game benchmark charts. We have a lot of cards on here. Depending on which chart you look at, we go back to the ", ", the ", ", ", " variants, and more. Let’s get into those charts.", "Starfield is up next, another of our 2023 titles with 2024 patches to test.", "At 4K, the ", " landed at 62FPS AVG, with lows proportional and well-timed. That has it ahead of the 4070 Ti by a relatively uneventful 6.3%. The lead over the ", " is 18%, and compared to some cards you might upgrade from, it’s ordered as follows: 79% over the RTX 3070 and 161% over the RTX 2070.", "The ", " leads the 4070 Ti Super by 10%, so AMD is still leveraging its advantage in this particular game and has a wider lead than it does in some others. And just for reference, the 4090 leads the 4070 Ti Super by 47% here, at 92FPS AVG.", "At 1440p, the 4070 Ti Super still has full scaling in this benchmark. Its lead over the non-Super variant’s 95FPS AVG is just 4.4% now, down from the already low 6% at 4K. The Ti Super now only leads the 4070 Super by 14.7%, even less exciting than before. ", "Resident Evil 4 is another 2023 game that we’ve added recently. In this one, tested at 4K and rasterized first, the 4070 Ti Super ran at 87FPS AVG and led the 4070 Ti by 10.6%, with the 7900 XT leading the Ti Super by 12%. The 4080 is just ahead of that.", "Looking down the stack, the ", " remains one of the most powerful and viable options at the $500 mark -- assuming it’s still there when this goes up -- in certain games. On the NVIDIA side, the Ti Super leads the new RTX 4070 sans-Ti Super, at 71 FPS, by 23%. Over possible upgrade pathways, the lead over the ", ", 2070 non-Super, and ", " is significant, respectively at 86%, 190%, and 139%.", "Scaling is clean at 1440p. Lows are proportional, so since the 0.1% lows don’t indicate anything noteworthy here, we’ve removed them to instead accommodate more GPUs on this chart. That’s the trade-off.", "The 4070 Ti Super’s 172FPS AVG has it 7.8% ahead of the 4070 Ti, reduced from the 10.6% result at 4K. Scaling tightens as resolution falls.", "The 4070 Ti Super is still bested by the 7900 XT, this time by 6.8%. This chart added a bunch of mid-range cards from ages past, so for some potential pathways: The ", " at 58 FPS AVG, the ", " at 70 FPS AVG, the 3060 XC at 57 FPS, and the ", " at 78 FPS would see an improvement, respectively, of 200%, 147%, 201%, and 121%.", "At 1080p, the 4070 Ti Super is still scaling with the CPU. It’s at 253FPS AVG, leading the 4070 Ti by 5.1%, predictably less than at 1440p and 4K. The 7900 XT’s lead also reduces here, down to 3.4%.", "Dying Light 2 is a 2022 game. Tested at 4K first, the 4070 Ti Super leads the 4070 Ti by 12.6%, better than we saw in the last game. The 7900 XT is about equal with the 4070 Ti Super and can’t be told apart at a functional level. ", "Owners of the 2070 non-Super would see massive gains under these test conditions, at about 178% -- a lot of that is from the intensive 4K load that the 2070 is struggling with. The 2080 would likewise get multiples of uplift. Alternatives to the 4070 Ti Super might include the RX 7900 XT at equivalent performance or the 4070 Super at reduced performance, which achieves 83% of the performance of the Ti Super. The RX 6800 XT would be another option here and is one that has aged relatively well with its price drops.", "Up next is 1440p. 0.1% lows scaled perfectly fine with this, so we removed them to permit space for cards on the chart.", "This includes fresh retests of the ", ", ", ", and ", ". In this test, the 4070 Ti Super’s lead over the 4070 Ti is reduced to 8.4%, with gains against the 6600 XT and 6600 at 152% and 197%, respectively. Alternatives still include the 7900 XT, ahead by 3.1%, the 4080 more meaningfully ahead -- but we’d advise strongly against a 4080 given the 4080 Super’s inbound status and lower price -- and the 4070 Super at 85% of the performance of the 4070 Ti Super.", "At 1080p, the 4070 Ti Super’s lead over the 4070 Ti is even lower, now at 5.8%. The 7900 XT is now tied, so its lead has also fallen. Scaling is clean from a test standpoint, but this isn’t particularly interesting, so we’ll just move forward.", "We’re moving on now to our set of benchmarks we keep around for reliability and long-term validation, as the numbers rarely change for these.", "In Tomb Raider at 4K, the 4070 Ti Super TUF leads the 4070 Ti by 12% and is roughly tied with the RX 7900 XT. For upgrade references: The lead over the 2070 XC is 167%, the same over the RX 6600 XT and RTX 3060 XC.", "At 1440p, the 4070 Ti Super led the 4070 Ti by 8.5%, posting full scaling, with the lead over the new 4070 Super at about 16.5%. Compared to older generation cards you might upgrade from, options include a doubling over the RTX 3060 Ti and RTX 2080, a 171% boost over the RX 6600 non-XT at 82FPS, and similar over the original RTX 3060.", "In F1 22 at 4K, the RTX 4070 Ti Super ran at 137FPS AVG, leading the 4070 Ti by 11%. That has the 7900 XT ahead of the 4070 Ti Super by 8.7%, with the 4080 past that. Compared to upgrade options, the lead of the 4070 Ti Super over the 2070 XC is 163% against the 52FPS AVG result. It’s about the same boost from the RX 6600 XT and RTX 3060 XC. ", "Alternatives might include the 4070 Super, which achieves 82% of the performance of the Ti Super for 75% of the price, or the 6800 XT, which achieves 84% of the performance for 63% of the price in this game -- though that changes with RT.", "At 1440p, the 4070 Ti Super posts full scaling at 228FPS AVG, leading the 4070 Ti by 6.3% -- a reduction against 4K, despite unbound scaling. The 7900 XT is closer to the 4080 than the Ti Super, meanwhile the 4070 Super gives the Ti Super a 15% lead. Bringing upgrades back into the picture, 1080 Ti users would gain more than double the framerate, although the 1080 Ti is still plenty good for a lot of rasterized games, and RX 6600 users would jump 167% from 86FPS AVG.", "We’re still not CPU-bound at 1080p for the 4070 Ti Super. The Ti Super leads the Ti by 5.8% now and the 4070 Super by 12%. The 7900 XT has climbed the ranks a little and established a 14% lead over the 4070 Ti Super.", "Revisiting those upgrade options: The 2070 was down at around 120FPS AVG, so there’d be a huge boost here, with the 3060 at 126FPS AVG, the 1080 Ti at 142, and the 6600 XT at 152FPS AVG. In any of these scenarios, the Ti Super would be a big jump, with RT jumping more. Whether or not that’s worth it really depends on the games you play. If you’re not playing heavier, newer games, then it’s less likely to be critical.", "Rainbow Six Siege is up now. We ran efficiency tests for this up above, but the FPS numbers weren't taken from this chart (they were taken separately since we had background tasks for efficiency).", "The 4070 Ti Super’s 184FPS AVG had it 10% ahead of the 4070 Ti and 21% ahead of the 4070 Super. AMD’s 7900 XT puts up a strong fight here, technically -- but not particularly noticeably -- outpacing the 4070 Ti Super. Price is what’ll matter there.", "Compared to the 2070 Super at 84 FPS AVG, we’re seeing a 120% improvement in the Ti Super. The 3060 isn’t distant from that math, down at 71FPS AVG.", "1440p reduces the Ti Super’s lead to just 3.5% over the 4070 Ti, an unexciting move. The 7900 XTX and 4090 indicate that we still have plenty of CPU headroom, so this is an unfortunately real, boring change from the 4070 Ti. There’s no point spending more time here: It does not meaningfully move the needle from the 4070 Ti, but certainly arrests its price.", "Final Fantasy 14 is up now. ", "The 4070 Ti Super ran at 129FPS AVG here, establishing a 15FPS lead over the 4070 Ti, or about 12.5%. The 7900 XT sits close to the Ti Super, but behind it -- and AMD has worse 0.1% lows in this game than would be proportional to the average.", "Against the 4070 Super, the Ti Super is 23% better, and against the baseline RTX 2070, it’s 178% improved. We haven’t retested it in a while, but the ", " is on this chart as a point of reference. Its framerate may have moved slightly in the past year, but we don’t see many meaningful gaps developing with this game, at this point. ", "Finally for the old reliable benchmarks, GTA V at 4K has the 4070 Ti Super at 140FPS AVG, leading the 4070 Ti by 11.6% and the 4070 Super by 19%. If you bought an RTX 2060 when it launched, an upgrade here would yield a 185% uplift. The 7900 XT is just behind the Ti Super here.", "We’ll open our ray tracing testing with Cyberpunk: Phantom Liberty, which was only just added to the test suite and therefore has fewer cards than the RT tests we’ll look at next. We’re iterating and adding to this each review. All of these tests were conducted in the last two days and were done across two groups of settings: The first batch uses RT Ultra with upscaling disabled, ray reconstruction disabled, and overdrive off. The second batch uses a much lighter RT Medium, which we found to have lower scaling impact overall and more favorable -- but still weak -- AMD performance. AMD’s performance deficit widens as RT load increases.", "Here’s the chart.", "At 4K first, the ", " ran at about 23 FPS AVG. This average is low, but the lows are spaced proportionally and well as compared to the average; despite being unplayable, this is good as an academic study of bandwidth and is why we included it. The 4070 Ti ran at 20.6 FPS AVG, allowing the Ti Super a lead of 13%. Critically, the original Ti has significantly worse lows here. You wouldn’t use these settings for either card, but it does show that the memory bandwidth and capacity change influenced the performance in some key areas.", "The closest AMD card here is the ", ", which underperformed against the 4070 Super but held stronger lows.", "At 1440p/Ultra, the 4070 Ti Super’s lead over the 4070 Ti drops to 8%. The cards diverge as load increases as a result of the memory subsystem changes, so it does in fact do something, but that impact becomes largely academic since we were in unplayable territory at 4K/Ultra.", "The 7900 XTX runs below the 4070 Super here. The 4090 posts a massive lead of 58% against the 4070 Ti Super.", "At 1080p/Ultra, the 4070 Ti Super’s lead was reduced to 6%. The memory subsystem overhaul doesn’t matter much here. The 4080 leads by 15% here, with the 7900 XTX still tied with the 4070.", "Let’s look at RT Medium briefly.", "Here, the 4070 Ti Super leads the Ti by 12%, at 57.7 to 51.6. The 7900 XTX is much more competitive here than it was at Ultra, now surpassing the 4070 Super and roughly tying with the 4070 Ti. It’s still not competitive on the whole in this test, but this illustrates that heavier RT loads disproportionately separate AMD and NVIDIA, favoring NVIDIA as RT workload goes higher.", "Finally, at 1080p/Medium, the 4070 Ti Super leads the 4070 Ti by 7%, the lowest of this game so far. The 7900 XTX is about equal with the 4070 Super here, with the XT about equal to the ", ". AMD’s relative rank overall has fallen at this resolution. It’s benefited by the higher resolution combination with lower ray tracing settings.", "In Resident Evil 4 with RT and at 4K, we’re using FSR as a test of both upscaling and RT impact.", "We measured the 4070 Ti Super at 101 FPS AVG, leading the 4070 Ti by 11%. The 7900 XT manages to outperform the 4070 Ti Super in this one, although that doesn’t persist to heavier RT games like Cyberpunk, as we saw earlier.", "Compared to the 4070 Super, the Ti Super is about 22% better, and compared to the older 2070, back when RTX was new, it’s about 150% better.", "At 1440p, the 4070 Ti Super runs at 165 FPS AVG with upscaling and RT. That has it just ahead of the 7900 XT and 7.7% ahead of the 4070 Ti.", "Finally for Resident Evil RT, 1080p has the 4070 Ti Super at 201 FPS AVG with FSR, reducing the lead over the Ti to 5.7%. The 7900 XT sits between the two of them and is closer to the original 4070 Ti than the 4070 Ti Super.", "In Dying Light 2 with RT and equivalent upscaling between all vendors, we saw the 4070 Ti Super at 51.8 FPS AVG, leading the 4070 Ti by just 9%. The 7900 XT trails the 4070 Super here, down at 38 FPS AVG and just ahead of the 4070 baseline card. The XT is not in a great spot competitively. NVIDIA is advantaged here. It’s not as extreme as in Cyberpunk, but definitely more than in Resident Evil 4.", "Generationally, the 4070 Ti Super leads the RTX 3070 by 86% and the RTX 2080 by 182%.", "At 1440p, we’ve added some mid-range past-gen cards to the list: The RTX 2070 now appears down at 30 FPS AVG, ahead of the 6600 XT’s 27 FPS result and behind the ", "’s 46 FPS AVG result.", "The 4070 Ti Super’s 96 FPS leads the 4070 Ti by about 7%. It’s dropping again. The 7900 XT is behind the RTX 3080 and RTX 4070 Super in this one and ahead of the RTX 4070. It’s not competing with the Ti-class cards directly.", "At 1080p, the 4070 Ti Super’s lead over the 4070 Ti is reduced to just 4.4%. The 7900 XT is about 5-6% ahead of the 4070 and continues to yield an advantage to NVIDIA. Not much has changed for these ranks.", "Although we looked at power efficiency earlier, now we’ll briefly look at our standardized total power consumption against more cards. The RTX 4070 Ti Super TUF card pulled 291W with the “quiet” BIOS, or 296W with the default performance VBIOS that ours shipped in. Overclocking allows a maximum power consumption of 321W with the OC on the performance BIOS.", "The 296W figure has it about the same as a 6800 XT and less than an RX 7900 XT by 10-25W, depending on what card you look at. The 4070 Ti was about 5W less, at 290W in our original testing. This contributes to some of the performance gap as well.", "Well, that’s a lot of numbers.", "First, on our side of things: The efficiency testing is exciting and there’s a lot of room for us to improve on it. The methodologies aren’t final nor are the choices of data presentation, so remember that when we add new tests, it’s sort of a living document. We’ll keep iterating on this until we land on something we feel like covers the hardware well. That’ll just mean a lot of trial and error on identifying the test cases and the scaling. It’s a cool start, though, and will give us some new insight into performance outside of elements like frame time, frame pacing, frame rate, and power. For latency, we’re actually already overhauling our next iteration on that and plan to re-introduce it for the 4080 Super review. ", " and liked how it turned out, but we want to fine-tune the testing and so made way for efficiency instead. This is just us experimenting with new types of data presentation.", "As for the cards, you have all the numbers and we’ll let you make your own decision. But for our stance on it, as briefly as possible, this ", " launch can largely be summed-up as “meh.” It’s really not particularly strong but it’s also not offensively bad. The price is locked, so maybe a downside is that we might traditionally have a price cut instead, but the average selling price (ASP) remains up as a result of this launch. But the performance also goes up a little bit, so we’re back to “meh.” It’s not the worst card we’ve reviewed. It’s just kind of in the middle. ", "It seems like NVIDIA has chosen to couch this card in between the ", " and the ", ", with the 4080 Super, in particular, potentially resetting the value scale for NVIDIA’s high-end with that $1,000 price.", "The ", " puts pressure on AMD’s ", ". If you care a lot about super heavy ray tracing, like ultra or high settings in games like Cyberpunk and Alan Wake, then the ", " falls behind in big ways. If you don’t care about RT or you play less RT-intensive titles, like games with a single RT feature, then the 7900 XT and ", " are less different.", "But we’ve been totally overhauling our testing one new benchmark at a time, so we’re going back to the lab to do it all again for the 4080 Super launch and we’ll leave you with this data to make your decisions."]},
{"title": " AMD Radeon RX 7800 XT GPU Review & Benchmarks vs. RX 6800 XT, RTX 4070, & More", "paragraph": ["AMD Radeon RX 7800 XT GPU Review & Benchmarks vs. RX 6800 XT, RTX 4070, & More", "Last Updated: ", "The Highlights", "Today, we're reviewing the ", ". We also have a review coming up for the ", " (update: ", "), but this one is focused on the new 7800 XT, a $500 MSRP card from AMD.", "For this benchmarking, a couple of things to consider:", "AMD believes that ", " is the true successor to the RX 6800, not the ", ". So by name, marketing, and signaling to the customer, AMD suggests this is the successor; however, by spec and MSRP, the company hints that the original 6800 is the predecessor. We don't really care about any of that marketing; what we care about is how it performs versus the 6800 XT, because it's the same price today. On Newegg and Amazon, there are a few listings for around $500. That makes the 6800 XT a direct competitor to the 7800 XT. If you're considering second-hand cards, platforms like eBay offer many options from both the 30-series and the 6000 series.", "Steve Burke", "Patrick Lathan", "Jeremy Clayton", "Mike Gaglione", "Vitalii Makhnovets", "You can see above that the RX 6800 XT is, in many ways, the better card. Architecturally, the 7800 XT is superior -- but the 6800 XT will be able to make-up for the differences with brute force in many locations. The direct NVIDIA competition would primarily include the likes of the ", " (the ", " is, and has been, a massive waste of money). The ", " would be the next price class up from NVIDIA.", "Here are some quick pricing numbers (all within +/- $20 based on a glance at Newegg and Amazon):", "These set up the key comparison points versus the 6800 XT. The main difference is the cut CU count from the 6800 XT: AMD's spec page lists it as 60 versus 72. This will play a role in situations where the architecture alone and frequency changes can't account for the 12CU difference. They're not directly comparable one-to-one, but there's an advantage to those CUs, especially for some of the 4K tests.", "That's enough setup. We have a lot of data to cover today, but we've compacted it more than usual. We'll start with Starfield.", "For testing on the RX 7800 XT, our focus will be on rasterization, ray tracing, and some power consumption. We have not conducted our usual acoustic tests for this particular review as we made cuts to accommodate other content this week (namely, the ", ", plus work on ", ").", "Our first set of benchmarks will look entirely at rasterization performance. Our ray tracing tests will follow toward the end. As an important note, be advised that any games which overlap in these two categories -- such as Shadow of the Tomb Raider -- are incomparable between the two charts. That means a 4K/High Tomb Raider result when rasterized cannot be compared to a ray traced result (unless your goal is to compare only the effect of the settings change).", "Our rasterization testing does not use any upscaling technology. All testing is done native. Some ray tracing testing uses upscaling technologies, but those are noted explicitly when used.", "We’ll start with Starfield, seeing as that’s what we’ve spent the last week testing.", "At 4K/High, the RX 7800 XT ran at 48.7FPS AVG, with lows at 37 and 27. Those are paced similarly to what we saw elsewhere -- this game is kind of a mess for performance, but it’s at least consistently a mess. That’s all that matters for benchmarking.", "For current generation flanks, the RTX 4060 Ti 8GB, about $100 cheaper, ran at 30.5FPS AVG. That allows the 7800 XT a lead of 60% -- a massive increase -- at a cost increase of about 25% MSRP-to-MSRP. The RTX 4070 is priced around $100 higher and lands at 39.5FPS AVG, giving the 7800 XT a lead of 23% while being more expensive than it. In at least Starfield, AMD is currently in a strong lead. We’ll revisit this as things patch and change to see if that remains, but for now at least, they’re in a better starting point than NVIDIA.", "As for more expensive options, in this particular title and with this game version, only the other AMD cards would be worth considering. The 7900 XT improves by 32% at 64FPS AVG while costing around $790-$820 today.", "Finally, as compared to the RX 6800 XT - which is a similar price - the 7800 XT holds a lead of about 10%.", "The game may be messy for performance, but AMD’s relative positioning is currently extremely competitive for the 7800 XT in this title.", "At 1440p/High, the RX 7800 XT ran at 79FPS AVG, with lows at 50 and 36. That has it ahead of the 6800 XT by 10% -- so that much remains the same. The 7900 XT leads the 7800 XT by 22.5% in this test, down from 32% previously. That’s because the 7900 XT is starting to hit a CPU bottleneck, so there’d be more room to scale if not for that limiter.", "Compared to NVIDIA price competitors, the 7800 XT leads the 4070 by 23% and the 4060 Ti by 62%. Scaling is similar to the 4K/High testing. AMD is incredibly strong with its 7800 XT as compared to the 4070 and 4060 Ti in this particular game. We have one more resolution before we see how it does in other games.", "At 1080p, the 7800 XT was nearing our CPU bind. The 7900 XT isn’t present because it’s irrelevant -- it’s also CPU-bound. So are the 4090 and 7900 XTX. There’s no room to scale here. Let’s move to the next one.", "Dying Light 2 is new to our benchmark suite. Starting at 4K and with a custom/high configuration, the 7800 XT ran at 45.7 FPS AVG with lows well-timed. That has the 7800 XT as about 9.6% higher framerate than the 4070, about 39% higher than the 6700 XT, and similarly ahead of the 4060 Ti. The 6800 XT ended up ahead of the 7800 XT, embarrassingly for AMD, with a 12% lead. That’s more than just a partner model difference. It looks like AMD’s choices on the CU count may have impacted it here.", "As for the 4070 Ti, that leads by 19%.", "Now for 1440p. Here, the 7800 XT ran at 85.5 FPS AVG, with frametimes again overall consistent and well-paced. The 3080 leads, followed by the 6800 XT, which itself holds a lead over the 7800 XT of 13%. These companies really all woke up and chose embarrassment with their naming scheme. It’s amazing how much less embarrassing the generational losses -- both for NVIDIA and AMD -- would be if they’d just stop trying to trick people into thinking the cards are worth more just by a name.", "At 1080p, the RX 7800 XT’s 117FPS AVG still afforded the 6800 XT a 12% lead. It’s also about tied with the RTX 4070, including the lows. Compared to the 4060 Ti, the lead is about 30% here. AMD’s biggest competition right now appears to be itself. From the company’s perspective, that’s probably not bad.", "Resident Evil 4 is up now, another new game in our test suite for this overhaul. At 4K, the 7800 XT ran at 72FPS AVG, with frametimes again consistent. This game appears to pace frames well on most of these cards. The RX 6800 XT leads the 7800 XT, this time by 6.2%. The 7800 XT ends up ahead of the 4070 and roughly tied with the 3080 this time.", "At 1440p, the 7800 XT’s 136FPS AVG has it again just below the 6800 XT, ahead of the 4070 by 9%, and ahead of the 6700 XT by 47%.", "Total Warhammer is up now. At 4K, the 7800 XT sits at 56FPS AVG with relatively low 1% lows compared to the GPUs ahead of it. The 7900 XT leads by 39% at 78FPS AVG, with the 7900 XTX about 70% ahead. As for other GPUs, the lead over the RTX 4060 Ti is 44%, establishing a strong position against NVIDIA’s recent launch. The 4070 is tied with the 7800 XT in all metrics for this one, with the 6800 XT a bit behind.", "But 4K is demanding for the 7800 XT. Moving to 1440p, the 7800 XT’s 116FPS AVG has it about 4% ahead of the RTX 4070 in AVG FPS. The RTX 4060 Ti is far behind, allowing a 44% lead to the 7800 XT. As for the 6950 XT, that one establishes itself as a strong alternative if you can grab one of the last remaining cheaper models, with a lead of 7% over the 7800 XT. The 7900 XT jumps 39% ahead with its 161FPS AVG.", "Compared to the flanking RTX 4070 Ti, the 7800 XT gives up a 20% lead to NVIDIA’s much more expensive $800 alternative.", "Users of an RTX 2060, RTX 3060, or RX 5700 XT might find value in an upgrade here.", "At 1080p, the 7800 XT still has plenty of CPU scaling headroom to take advantage of. The 7900 XT has a 37% lead over the 7800 XT, with the RTX 4070 about tied -- within 4% -- of the new AMD GPU. The 4060 Ti remains somewhat distant and will be a better comparison to the 7700 XT in our next video.", "Last generation’s 6800 XT managed nearly identical performance to the 7800 XT, with the 6950 XT pushing a little further ahead. If you’re wondering what an extra $300 gets you from the NVIDIA side, the 4070 Ti would again yield about a 20% uplift. Not great value comparatively.", "In Tomb Raider at 4K, the RX 7800 XT held a 93FPS AVG with frametimes highly consistent and well-paced at 83 and 79. That has it behind the RTX 4070 on a technicality, but in reality, they’re effectively tied. The 6800 XT also leads by a few percentage points, with the 6950 XT a more notable 23% ahead. The 4070 Ti holds a similar lead. Compared to cheaper options, the 6700 XT manages 74% of the performance of the 7800 XT, with the 4060 Ti around the same positioning. Moving to a 4070 Ti or 7900 XT would gain you between 26% and 36% more performance.", "We’re going to start going through these charts a lot faster now to just rip through some numbers.", "At 1440p, the 7800 XT moves to 167FPS AVG with frametimes again consistently timed. The 4070 has a technical lead of 2% here, with the 4070 Ti more noteworthy at 23% (again). While we’re up here, the 7900 XT keeps a 31% advantage over the new card.", "Cheaper options, like the 6700 XT or 4060 Ti, are outpaced by the 7800 XT by about 32%.", "Finally for this one, 1080p has the 7800 XT at 223FPS AVG, pushing the card close to the 7900 XT due to external bottlenecks -- the CPU is limiting the scaling room here, so everything north of 230FPS is bound. You can ignore all of those results. They’re not scaling properly. The growth over the 6700 XT was 25% here.", "Horizon Zero Dawn is in briefly now. In this one, the 7800 XT’s 85FPS AVG had it functionally tied with the 6800 XT and RTX 4070, including in frametime pacing. The lead over the 6700 XT was 51% generationally, with nearly a doubling of the 5700 XT’s framerate. As for the other direction, the 4070 Ti leads by 14%, with the 7900 XT ahead by 25%.", "At 1440p, the 7800 XT is about tied with the 6800 XT, ahead of the 4070 by 3.9%, ahead of the 6700 XT by 42%, and the 4060 Ti about the same. Once again, we’re seeing about an 84% lead over the 5700 XT. Users of that GPU or the older 3060 and 2060 cards may see an opening for an upgrade.", "1080p didn’t prove useful. We were CPU-bound.", "In Final Fantasy 14 at 4K, the RX 7800 XT posted an 85FPS AVG result, although with 0.1% lows behind where they should be. This has been true of AMD’s hardware in the current version of this testing process for this specific game, so it’s not unique to the 7800 XT.", "The 7800 XT manages to lead the 6700 XT by 31% -- similar to the 1080 Ti and the 4060 Ti, actually. The 4070 is ahead of the 7800 XT in this one by about 6.8%. The 6800 XT pushes a little higher still, gaining 15% over the 7800 XT. As a final reference point toward the top, the extra money spent on a 4070 Ti would gain you 37%, or 46% at the 7900 XT.", "At 1440p, the lows behave the same way as we saw at 4K -- that’s a specific frametime pacing behavior related to this game. The 7800 XT’s 184FPS AVG has it ahead of the 4060 Ti by 28% and has the 4070 non-Ti ahead by 5%. The cards are becoming limited at the top of this chart, allowing the 4070 Ti to pull ahead -- but we are bottlenecked on the CPU now, so let’s move on.", "Ray tracing is up now. We’re keeping this brief since we just added a bunch of games to our test suite for rasterization, but we’re adding more RT testing shortly to accompany those changes.", "Starting with F1 2022 at 4K with RT on, the RX 7800 XT ran about equal to the RX 6800 XT. That’s not great for AMD given some of the prices for the 6800 XT lately, especially if you go used. The 4070 has about a 5% lead here, so not much -- but our resolution is also high. Let’s move to 1440p.", "At 1440p with RT, the RX 7800 XT again roughly tied with the RX 6800 XT. It leads the 4060 Ti by 18%, with the 4070 leading the 7800 XT by 7%.", "Moving to Tomb Raider with RT shadows, first at 4K, the 7800 XT was tied with the 6800 XT. The lead over the 4060 Ti is massive due to the resolution here -- that reduces as resolution reduces. The 4070 maintains a 5% lead here.", "1440p brings the lower-end closer to the 7800 XT, but allows the 4070 to pull ahead and grow its lead to 10%. Otherwise, the 6800 XT again is about the same as the 7800 XT.", "Now for power consumption.", "The RX 7800 XT pulled 248W when stock in a full workload. Overclocking it gave us headroom up to 293W. That has the stock 248W 7800 XT as more efficient than Intel’s A750. NVIDIA’s 290W 4070 Ti TUF pulled more power but also ran a higher framerate. Compared to the 6800 XT, the 7800 XT consumed about 50W less power in this workload.", "We’ll defer to a new chart for some numbers. One important point with these summaries: In scenarios of a CPU bind, like some tests at 1080p, you’ll see little to no change. That’s expected. It’s because we were resource limited elsewhere in the system.", "Another point is that we're trying to keep the percent math all in one direction where possible. Percent math can be tricky, so we mostly aim for a percent improvement. This means in the title of the chart, it's going to say from A to B. That means from baseline card A, so let's say a 7800 XT to a 6800 XT, to B, we're looking at the percent improvement going in that direction.", "This first chart is for ", " versus ", ", and it shows the percent improvement from the 4070 to the 7800 XT. The 7800 XT generally bests the 4070, sometimes significantly. You see that especially at 4K. We already know the 40 series, like ", " versus the 3060 Ti, has issues with these higher resolutions.", "When ray-traced, the 4070 was a clear winner. It’s anywhere from 5% to 15% better in these charts with RT workloads.", "This summary chart looks at improvement from the 7800 XT to ", ", meaning that bars going in the positive direction, to the right, are the percentage advantage that the 6800 XT has over the new 7800 XT.", "In most of our tested scenarios, the 6800 XT bests the 7800 XT. That’s embarrassing. Fortunately for AMD, the 6800 XT had a higher initial MSRP. Unfortunately for AMD, it’s readily available for cheap if used, or in a couple places we checked, about the same price. Some of the improvements are drastic, like Strange Brigade Vulkan at 4K or Final Fantasy at 4K.", "Here’s the chart for the 4060 Ti to the 7800 XT. In this one, the 7800 XT has it by a mile.", "The 4060 Ti loses by a lot to the 7800 XT given the $100 price gap. NVIDIA’s 4060 Ti seems to be exactly where we left it, which is the trash.", "The ", " is compelling if you can find it, even as compared to the ", ". NVIDIA struggles in terms of pricing or value, especially when looking at the 4060 Ti or the 4070. We expect another card to slide in between the 7900 XT and the 7800 XT, perhaps the 7800 GRE. But that's not official yet. AMD still has a gap in its pricing, but they've stated they're done launching GPUs for this generation with new ASICs. This leaves room for a potential refresh, and if they do make one, it'd be here.", "Hopefully that helps you make a decision. We really wanted to package these results in a neater fashion to make it more approachable, especially because, frankly, it’s been a long week. You’ve got all the numbers, so you can make a decision now. Our main concern with the 7800 XT is the underperformance versus the 6800 XT in many cases, so we’d recommend that you check the remaining new stock. If you’re OK with used, that may be a good consideration (alongside the 3080).", "Otherwise, you’ve got the numbers. Our 7700 XT review will be next."]},
{"title": " AMD RX 7700 XT GPU Review & Benchmarks vs. 7800 XT, 6800 XT, RTX 4060 Ti, & More", "paragraph": [" AMD RX 7700 XT GPU Review & Benchmarks vs. 7800 XT, 6800 XT, RTX 4060 Ti, & More", "Last Updated: ", "The Highlights", "Now we're reviewing the ", ". We were sent an XFX AIB partner model, as reference models weren’t made for the RX 7700 XT series GPUs -- and the XFX model is comically large. We ", " the ", " in a separate piece, but found that, compared to an ", " (which are still available for competitive prices), it was overall lackluster. The 7700 XT stands to fill a gap in the middle.", "The 7700 XT is a $450 card, up against the $500 7800 XT. The 6800 XT proved to be a better buy than the 7800 XT (based on our testing) if you can still get one at the same price as the 7800 XT. As that card fades and disappears though, the 7800 XT is at least not bad value -- it’s far better than we’ve seen from the RTX 4070 or especially the RTX 4060 Ti. The 7800 XT at least helped prove that the 4060 Ti 16GB is a massively greedy waste, priced the same as the 7800 XT and 6800 XT, and that the 4060 Ti 8GB remains suspect. The 7700 XT will likely further threaten the 4060 Ti’s existence, but it may be close enough to the $500 cards to skip if you can afford it.", "Steve Burke", "Patrick Lathan", "Jeremy Clayton", "Mike Gaglione", "Vitalii Makhnovets", "Quick recap of the prices — we went over these in the last review as well, but if you missed it: The 4070 Ti is around $800, the 4070 is about $600, the 4060 Ti is between $400 to $500 with the larger capacity, and then the 4060 is $300. That's Nvidia's immediately relevant current-gen lineup. AMD's lineup has the 7900 XT at $800, and then they've got everything from a 6700 XT at $330 up to a 6950 XT at roughly $630, with the 6800 XT somewhere in the middle at $500.", "That's the setup. Now, let's get into the benchmark charts, and then we'll show you the summary chart at the end, just like with the 7800 XT.", "Just like with the 7800 XT review, we’ll start with Starfield. It’s new and it’s a very heavy workload, at least right now, and that makes it particularly relevant. To AMD’s benefit, Starfield is also currently running better on AMD cards price-to-price than NVIDIA cards.", "At 4K/High, the RX 7700 XT ran at 39FPS AVG, 31 1% lows, and 24FPS 0.1% lows. That has the RX 7800 XT about 24% ahead of the 7700 XT while costing 11% more. We’re wondering if this is a classic upsell. The performance gap between them is larger than the price gap might otherwise suggest, and considering companies normally have two options in this position -- either have a tiny gap that allows the cheaper card to be the best value or a larger gap that creates an upsell -- we’re not surprised to see the latter. ", "Either way, compared to the 6700 XT, the 7700 XT leads by 28%. It also leads the RTX 4060 Ti, which is currently about $380-$400. The gap there is a 29% advantage for the 7700 XT. The 4070 is about tied, including in lows, allowing AMD a value advantage in this current game version. The 7800 XT would be the most obvious step up in terms of value to price gap.", "At 1440p/High, the RX 7700 XT roughly ties the RTX 3080 and outpaces the 6700 XT by 24%. The lead over the 4060 Ti is about 28%, similar to before. The 7800 XT’s extra $50 boost it by 27% over the 7700 XT. It’s more of a lead than at 4K. For other options, you could consider a used 6800 XT if willing to put-up with second-hand cards. In that case, it’d outperform the 7700 XT by about 15%.", "Finally, at 1080p/High, we start seeing a CPU bind at the top of the charts where the 7900 XTX, 4090, 4080, and to some extent (but a lesser one), the 7800 XT are all bouncing off of the CPU’s capabilities. The 7900 XT would be the same, hence why it wasn’t included. The 7700 XT is still far from that ceiling. The 7800 XT leads it by 22% despite occasionally hitting a ceiling. The 6800 XT is about 14% ahead of the 7700 XT. Generationally, AMD’s new card is about 20% ahead of the 6700 XT.", "Dying Light 2 is new to our test suite, so the GPU list is more limited to what we could do between Starfield runs in the past two weeks. At 4K, the RX 7700 XT ran at about 38FPS AVG, allowing the RTX 4070 a lead of 11%. The 7800 XT had a lead of 21% over the 7700 XT. The 7700 XT improved by 15% over the 6700 XT, but the 7800 XT still manages to complicate the choice around the 7700 XT given its disproportionate improvement to price increase. The 4060 Ti is far enough down the stack to not be much of a consideration at this price range.", "At 1440p, the 7800 XT’s lead drops to about 17-18%, down from 21%. As we’ve seen in the past, increasing the resolution can illustrate advantages of a GPU that emerge from higher CU counts or ROP counts.", "The 4070’s lead also climbs, this time to about 13% from 11%. As for cheaper options, the improvement in the 7700 XT over the 6700 XT is 14%, or about the same against the 4060 Ti. Actually, Intel’s A770 is just below both of these. Intel still doesn’t have an Arc competitor in the upper ranks of GPU competition despite overall strengths in the more affordable market.", "We’re still not bound by the CPU on the 7700 XT at 1080p. Here, the card ran at about 100FPS AVG, putting the 4070 17% ahead. The 4070’s lead is gaining as resolution decreases for this game, whereas the 7800 XT -- now at a similar lead of about 17% -- is seeing less significance as opposed to the 4K result.", "Up next, in Resident Evil 4 at 4K, the RX 7700 XT ran at about 60FPS AVG. That lands it just under the RTX 4070 at 63FPS AVG, allowing NVIDIA’s more expensive 4070 a lead of about 4.7% in rasterization here. The 6800 XT might be better value than either of the two new cards, depending on if you can still get it at around or under $500, as it manages to outperform the 7800 XT by 6% and the 7700 XT by 27%.", "As for the 7800 XT, that’s ahead of the 7700 XT by 19.7%.", "1440p has the 7700 XT at 119 FPS, the 7800 XT at 136 FPS, the 6800 XT at 143FPS, and the 4070 Ti at 164FPS. Respectively, that means these GPUs lead the 7700 XT by 14%, 20%, and 38%. Compared against the last generation, the 7700 XT is 30% ahead of the 6700 XT.", "We won’t spend much time on 1080p. The 7800 XT led the 7700 XT by 15% here, with the rest of the GPUs scaling similarly to before.", "In Total Warhammer at 4K, the 7700 XT landed between the 6800 XT and 4060 Ti. It’s ahead of the 4060 Ti by about 13%, ahead of the 6700 XT generationally by about 27%, and ahead of the 4060 by 35% -- although pricing is a different story.", "In the opposite direction, moving to a 7800 XT would push performance up by 27% in exchange for the extra $50. The 4070 would post about the same performance gain here, although for an extra $100 over the 7800 XT. AMD definitely positioned these two to force a hard choice.", "At 1440p, the RX 7700 XT ran at 96FPS AVG, allowing the 7800 XT to establish an advantage of 20%. That’s not as much as at 4K, so for at least this test, the 7800 XT has a disproportional benefit at the higher resolution.", "Compared to other cards, the 7700 XT leads the 4060 Ti by 20% as well, with the lead over the last-gen 6700 XT at about 27%. Higher-end options could increase performance by 43% moving to the 4070 Ti and 66% at the 7900 XT level.", "At 1080p for this game, we’re most interested in scaling against the 7800 XT. The higher-end option ran at 177 FPS AVG, leading the 7700 XT by 16%. That’s another reduction against what we saw at 4K and 1440p, so the lead diminishes and becomes less significant as resolution decreases. That’ll be important to keep in mind as we look at the rest of the tests.", "For other comparisons, the scaling is more similar: The lead over the 6700 XT remains about 27%, with the lead over the 4060 Ti at about 18%. Not much has changed there.", "In Tomb Raider at 4K, the RX 7700 XT’s 74 FPS AVG has the 7800 XT 25% ahead. That’s pretty consistent with some of the previous games. Compared to the $400 4060 Ti 8GB, the lead is 12% by the 7700 XT, or 37% over the 4060 for 50% more money.", "At 1440p, the 7800 XT leads the 7700 XT by 17%. That’s not nearly as good as we saw at 4K and also matches some of the previous scaling reduction as resolution falls. This is one of the more interesting stories emerging from this particular review -- the 7800 XT is often disproportionately more interesting as an alternative as your interest in higher resolution gaming increases. As for other comparisons, the 7700 XT leads the 4060 Ti by just 11% here. The lead over the last-gen 6700 XT was 13%.", "At 1080p, the 7800 XT only leads the 7700 XT by 10%, making it appear much less worth the $50. Part of that is because we’re approaching a CPU bind around 240FPS AVG, so some spikes are truncated, but part of it is because of the already-shown reduction in advantage alongside reduction in resolution.", "In Horizon Zero Dawn, the 7800 XT is back to its 26% lead when at 4K, at 85FPS AVG to 67FPS AVG. Low are proportional. The 7700 XT is capable of 4K gaming in some scenarios, like this one, and as for its generational improvement, we saw a 19% improvement over the 6700 XT. The 4060 Ti sticks close to its prior gap, where the 7700 XT holds a 14% lead.", "At 1440p, the 7700 XT runs at 133FPS AVG against the 7800 XT’s 162FPS AVG, establishing a lead for the 7800 XT at 22%. That’s a reduction of about 4 percentage points compared to the 4K test, so the pattern remains.", "In Final Fantasy 14 at 4K, the 7700 XT runs at 68.9FPS AVG, putting it close to the old 1080 Ti and 7% ahead of the 6700 XT, or similar ahead of the 4060 Ti. The 7800 XT leads the 7700 XT by 23% here, similar to many of the other games now.", "Ray traced testing is up next.", "Starting with F1 22 with RT on, we found the 7700 XT to run at 29 FPS AVG without using any type of upscaling. Purely in the comparative, that has both the 6800 XT and 7800 XT about 11% ahead. The 4070 is now 17% ahead, so as usual, we see NVIDIA showing some more relative capability in its RT performance. The same shows up for the 4060 Ti, which closes the gap to 8% here. Let’s move to a more playable resolution.", "At 1440p, the 7700 XT runs at 57.6 FPS AVG. It’s still 8% ahead of the 4060 Ti, with the 7800 XT 9% ahead and 4070 still 17% ahead.", "In Tomb Raider at 4K and with ray tracing -- so these results aren’t comparable to earlier -- the RX 7700 XT ran at 40FPS AVG. All we really care about is the percent scaling. The 7800 XT was 29% ahead here, with the 6800 XT about the same. The RTX 4070 expanded its lead to 36% in this title, with the 4060 Ti not too distant.", "At 1440p, the 7700 XT moved to 81FPS AVG, reducing the 7800 XT’s lead to 18% and the 4070’s to 29%.", "Power consumption is up now. The RX 7700 XT that we have consumes more power than our RX 7800 XT. That’s a difference of model: The 7800 XT is a reference model from AMD, whereas our 7700 XT is an XFX unit with higher clocks and an increased power target. The 7700 XT ends up at 268W, or 308W when overclocked. That’s considerably less efficient than the 7800 XT reference model, given the lower performance in exchange for more power.", "We talked in our 7800 XT review about our thoughts regarding competing options and last-gen options, so once again, we’re going to focus this particular conclusion just on the 7700 XT vs. the 7800 XT and 6800 XT.", "We have some new charts. In the 7800 XT review, we showed a few % improvement charts that summarized the AVG FPS uplift from Card A to Card B. Percentage math can be unintentionally misleading if it goes both directions -- positive and negative -- so we try to present the cards in a way where it’s generally showing a positive uplift rather than mixing and matching. That said, as you approach 0 difference, the differences in the calculation become irrelevant.", "Generally speaking, moving to the ", " from the ", " would boost you by 20-30% at 4K, or 10-20% at 1080p, +/- a bit. Remember that CPU-bound scenarios, like Final Fantasy at 1080p, will show no difference. That’s not because there isn’t one, but because that scenario is limited by other components and can’t show the differences between the cards.", "$500 is about 11% more money than $450, if you want to look at it that way, and so gaining in the 20s-30% more performance seems like, in a vacuum of these 2 cards, a good trade. If you can afford the $50 extra, we do think it’s better value to step up to the 7800 XT. What’s even better value though is stepping up to the 6800 XT, which is currently about the same price.", "This is our 7800 XT to 6800 XT summary chart from the last review. In general, the 6800 XT is a better card when at the same price or similar. In this case, the jump from the 7700 XT to the 6800 XT would be even larger. You get more CUs for it too, which helps in some applications and some games.", "AMD has a history of launching cards like this that don’t make a ton of sense immediately with close-by options also from AMD, but what we’ve noticed is that AMD tends to cut prices fairly early. We wouldn’t be surprised to see the 7700 XT and 7800 XT differentiate by closer to $100 as things settle and age, and it’s possible that the value of the 7700 XT climbs if that happens. Past behavior doesn’t indicate the future, but for these massive companies, it’s normally a good tool to estimate it.", "What is clear is that, as we said in the 7800 XT review, the 4070 and 4060 Ti really just look bad here. The 4060 Ti in particular is an impressive abomination of bullshit at 16GB for $500 MSRP, and the fact that it’s already been cut in price in some places helps highlight that.", "But strictly speaking to the 7700 XT, we’d say go up a step if you can afford it. It’s an upsell, and that’s a classic trick -- but it seems to make sense. We think the 7700 XT will make more sense later as prices diverge."]},
{"title": " NVIDIA GeForce RTX 4070 Super Review & Benchmarks vs. RTX 4070, RX 7800 XT, & More", "paragraph": ["NVIDIA GeForce RTX 4070 Super Review & Benchmarks vs. RTX 4070, RX 7800 XT, & More", "Last Updated: ", "The Highlights", "We’re reviewing the ", " today. It joins the ", " in the stack. It costs $600, which is roughly $50 more than the 4070 (find ", "), which sometimes comes down to $530. The other new cards come out in a couple weeks, with the RTX 4080 Super (", ") launching on January 31 for $1,000 and the 4070 Ti Super launching on January 24 for $800. ", "The main changes with the ", " and the original ", " are in the core count: the 4070 Super will run 7168 CUDA cores, whereas the ", " has 7680 and the 4070 has 5888. ", "Based on the early community reaction, it seems like the 4080 Super might be the most awaited of these 3; however, each of the cards has a different area where it may establish itself as interesting: For the 4080 Super, that’s the price. For the 4070 Super, it’ll be the relatively large core count increase. And for the 4070 Ti Super, it’ll be the memory bandwidth and capacity, which both increase significantly over the ", ".", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Tim Phetdara", "This one is fairly straight-forward: We’ve refreshed a number of our tests and have added some new ray tracing and upscaling benchmarks. In addition to the gaming and power tests, we’ve also introduced latency testing for the first time as a part of our permanent and standard GPU review suite. We’ll be doing more with this going forward.", "We’ve been working toward this for a few months now, mostly because framerate has gotten so comically high in some FPS games that it starts to feel almost meaningless when you’re comparing, say, 700FPS vs 600FPS. Instead, normally what people want when they describe a high framerate experience in a shooter is to feel connected with the input, where higher framerate mostly goes to help reduce the total end-to-end system latency. ", "We’ll talk about this more in the latency section, but it gives us something new and provides a different number to look at for the charts. And there are a lot of charts in this review.", "The quick version of the data today is all upfront: The ", " is generally between 6 and 16% ahead of the 4070 Super in our testing, with many of the results clustering around 10%, depending on resolution. The 4070 Super often leads the 4070 by 13% to 17%, with a few break-outs to 21% and 23%. Against the 3070, the 4070 Super improves by around 30-60%, with most results clustered around 50%.", "On AMD’s side, the closest alternative is the ", " at $500, the ", " at $500, the ", ", where still available, for $600, or the ", " for about $750, plus or minus a bit on each of these prices. We wouldn’t be surprised if they drop another $20 between the time we’re writing about this and the time of embargo lift. Intel mostly occupies a lower price tier and won’t be in the discussion today, but is included in the charts.", "Let’s get straight into the games.", "You can find additional details about our game graphics settings, test choices, and methodology in this ", ".", "In Shadow of the Tomb Raider at 4K and rasterized, the RTX 4070 Super ran at 107 FPS AVG, with lows close behind. There are no meaningful excursions in any of the 1% or 0.1% lows for this chart -- everything is effectively perfectly cascaded from the average.", "The 4070 Super’s result has it roughly tied with the ", " and just behind the ", ". The outgoing 4070 Ti leads the Super by 8%, with the outgoing ", " leading by 38% with its 148 FPS AVG. Looking down the stack in descending order, the RTX 4070 ran at 93FPS AVG, and that gives the Super a 15% lead, the ", " ran at 72FPS AVG, giving the Super a 49% lead, and the ", " ran at 49 FPS AVG. The 2070’s result was hierarchically in about the same spot as years ago, with the ", "about 10% ahead of it.", "Compared to AMD, the 6950 XT at its $600 sale price was a good deal if you bought it in the last year. The closest competing alternative in rasterization would otherwise be the ", " or ", ", with the former being superior. The ", " is 16% ahead of the 4070 Super here but is also more expensive.", "At 1440p, the top 3 entries are CPU-bound. The 4070 Super is not, though: At 191 FPS AVG, the 4070 Ti leads it by 7.4%, similar to at 4K, with the 4070 Super leading the 4070 by 15% and the 3070 by 52%.", "AMD’s best competition would be the prior 6950 XT, which is just ahead of the 4070 Super, or the ", " if you’re spending more money, currently leading by 14%. Against the ", ", NVIDIA’s Super holds a lead of 12%.", "1080p is GPU-bound for these cards, so we’ll skip it.", "Starfield is up next. This has entirely new data because the game has recently had several major updates, so we have had to ditch our prior dataset to move forward with the most recent patch. There are fewer cards on these charts as a result.", "At 4K, the RTX 4070 Super ran at 53FPS AVG, so the 4070 Ti ends up about 11% ahead, with the 4070 Super ahead of the 4070 non-Super by 13.8% and the 3070 by 52%.", "AMD still has a strong position in Starfield for GPUs, even with all the recent patches. AMD’s cards ", " and they remain comparatively well positioned now. The 7900 XT leads the 4070 Ti by about 10FPS and the 4070 Super by 30%, but the 7900 XT also costs around $750 right now. At $500, the 7800 XT roughly ties the 4070 Super in these tests, positioned just ahead of the ", " and ", ".", "At 1440p, the RTX 4070 Super’s 86FPS AVG had it about tied with the 7800 XT and just behind the 6950 XT. The 4070 Ti leads by 10%, at 95 FPS to 86. Against the original 4070’s 79FPS AVG result, the Super’s improvement is about 10%, and over the 3070, it’s about 51%. Both of these results are about the same as we’ve seen elsewhere.", "An extra $150 or so on the 7900 XT would push you 26% ahead, with the ", " a bit ahead of that (and soon to be replaced by its own Super).", "At 1080p, we’re limited by other components on most of these devices. The 4070 Ti is pushing up against the boundary for this test. The 4070 Super is still within test bounds; however, some frames are ricocheting off of them, so we’ll just move on to a better comparison.", "In F1 22 benchmarks at 4K and without RT (that comes later), we tested the 4070 Super at 113 FPS AVG and with 1% and 0.1% lows predictably and properly spaced-out. That has it about 117% ahead of the RTX 2070, 41% over the RTX 3070, 15% over the RTX 4070 non-Super, and has the 4070 Ti ahead by about 10FPS, or 9%.", "AMD’s 6800 XT does well here and is still priced at about $500, making it a worthwhile consideration -- especially compared to the weaker 7800 XT in many comparisons. The 7900 XT posts a more meaningful increase with its price hike, at 32% uplift, and the ", " is a step beyond that.", "At 1440p, F1 had the 4070 Super at 198FPS AVG, with still plenty of headroom for higher framerate. That allows the 4070 Ti a lead of 8.5%, with the 6950 XT the next GPU beyond that. Compared down the stack, the 4070 Super leads the 4070 FE by 13% and the 3070 by 42%, with an improvement over the 2070 by 116%.", "The RTX 4070 Super would obviously not be worth upgrading from the original 4070. We also think owners of the 3070 should keep their cards unless really feeling limitations, as it’s still plenty capable. A multi-generational jump makes more sense here, like, say, from the 2070 or a ", ", the latter of which isn’t on this chart.", "At 1080p, the top few cards are starting to hit external limitations -- but we still have plenty of room to improve on the 4070-series. The 4070 Ti leads the Super by 6%, which itself leads the original 4070 by 8.8% and the 3070 by 31.6%.", "At 1080p, the 7800 XT pulls ahead of the RTX 4070 Super. AMD is scaling stronger here in some instances. Even the 3080 is right alongside the 4070 Super, with the 6800 XT ahead of both. The stack shuffled a bit at this resolution, which is one of the main reasons we test multiple resolutions: It can sometimes reveal architectural differences or an impact of difference choices the GPU manufacturers make, like in regards to memory bandwidth, for example.", "Rainbow Six Siege is next. This one will also appear for our latency testing.", "At 4K, the RTX 4070 Super held a 153 FPS AVG framerate, so the stack arranges like this for NVIDIA: The 4070 Ti is 9% ahead, the Super is ahead of the 4070 FE by 18%, and it’s ahead of the 3070 by 37%.", "The lead against the 3070 is reduced versus Tomb Raider and Starfield, whereas the lead against the 4070 is increased marginally compared to F1, Tomb Raider, and Starfield. AMD’s alternatives include the 6950 XT at a reduced framerate compared to the 4070 Super. The 7900 XT pushes beyond the 4070 Ti, with the 4080 ahead of that, predictably. The 7800 XT increased its framerate by about 5FPS as compared to launch testing for us, helping improve its positioning but not changing the stack in a major way.", "At 1440p, the RTX 4070 Ti’s 351 FPS AVG still has plenty of room before the ceiling, established at 490 FPS by the ", " -- and even that’s not the full limit. That has the 4070 Ti 10.5% ahead of the 4070 Super, about the same as we saw in previous tests. The 4070 Super led the 4070 by 15%, also about the same as we’ve seen, and the Super is 43% over the RTX 3070.", "Not much has moved here. The 4070 Super’s relative rank is similar in this test as before. It’s just ahead of the 3080 Ti and behind the 6950 XT.", "Up next, Resident Evil 4. We added this one within the past 6 months.", "At 4K, the RTX 4070 Super’s 71 FPS AVG has the card sandwiched between the 3080 and 7800 XT, with the 6800 XT ranking just ahead of that. The relative scaling has the 4070 Ti’s 79 FPS AVG about 11% over the 4070 Super, with the Super almost 16% improved from the original 4070 and 51% over the RTX 3070.", "AMD’s 7800 XT gives cheaper competition in this raster test, roughly tying the 4070 Super while costing $100 less. The 4080 Super will be a big competitor here though, potentially challenging the ", "’s position in price and performance once it launches.", "At 1440p, the ", " illustrates that we have plenty of room to measure the 70-class cards and establishes a large gap between itself and the next card down, which is the ", ".", "The RTX 4070 Ti’s 160 FPS AVG has it 12% ahead of the 4070 Super, which itself is 17% ahead of the 4070 and 59% improved over the 3070. ", "AMD’s 7800 XT is slower than the 4070 Super here, though not by a meaningful amount when rasterized, and the 7900 XT again outperforms the new Super card.", "At 1080p, the 7900 XTX sets our ceiling mark at almost 300 FPS AVG. The 4070 Ti has plenty of distance from that limiter, down at 241 FPS AVG and leading the 4070 Super’s 216 FPS result by 11.4%", "As for the Super, it’s ahead of the 7800 XT by 9.5% this time, the 4070 FE by 17%, and ahead of the 3070 by 62%.", "AMD’s 7800 XT ran below the 6800 XT in this one, as it does in a lot of games, at 198 FPS AVG. From the AMD side, the 7900 XT would offer a meaningful uplift, whereas the 6800 XT would come close, but doesn’t surpass the 4070 Super in this test.", "Now for Dying Light 2, another relatively new test addition. At 4K, the RTX 4070 Ti ran at about 60 FPS AVG, leading the 4070 Super by a reduced and uneventful 6.6%. The 4070 Super leads the 4070 FE by 22.5%, then the 3070 by 42.9%. That has the positioning against the 4070 a little higher than in other games, although still within a reasonable range.", "The RX 7800 XT and 6800 XT encroach on the 4070 Super, with the 6800 XT basically equating it and providing an indistinguishable experience, while the 7900 XT again leads. This game is fairly heavy on all these cards, helping illustrate clean scaling from one to the next. The 4080 is about 41% ahead of the 4070 Super, so we’re looking forward to seeing how close to the ", " the 4080 Super will be to each other.", "At 1440p, the RTX 4070 Super’s 111 FPS AVG result has it about tied with the 6800 XT again, or leading the 7800 XT by 8%. The 4070 Ti runs 8.2% ahead of the 4070 Super, with the Super ahead of the original 4070 by 22% and ahead of the 3070 by 40%.", "Again, AMD’s most direct price competitor would be the 800 XT class cards, with the 7900 XT being the next price and performance class up.  ", "At 1080p, scaling has slightly improved for the 4070 Ti, now at 9.2% ahead of the 4070 Super. That’s consistently increasing the gap as resolution decreases, although not meaningfully. The gap against the 4070, meanwhile, has diminished by about 1 percentage point per resolution change, now at 19.6%. As for the 3070, the 4070 Super is about 45% ahead of that. AMD’s 6950 XT and 6800 XT remain the closest flanks to the 4070 Super.", "For Final Fantasy 14, which has been one of the most reliable GPU benchmarks we’ve used in a while. At 4K, the RTX 4070 Ti’s 115 FPS AVG had it just behind the 7900 XT and 9.5% ahead of the 4070 Super. That’s right in-line with what we’ve seen in the other games. The 4070 Super leads the original 4070 by 16%, which is a relatively large gap if these cards are only within $50. NVIDIA establishes an upsell by keeping the 4070 on the market while perhaps putting some pressure on AMD’s $500 price class. The lead over the 3070 by the Super is 44%, again mostly in-line with what we’ve seen elsewhere. The pattern has formed.", "Compared to AMD, the 6800 XT remains one of the most competitive options at the price, with the 7800 XT dragging unfortunately behind it. The 6950 XT outperforms the 4070 Super, but is rarely available new these days. We saw a few first-party listings holding on for $600, but they’re dwindling.", "AMD’s lows remain slightly lower than the scaling set by NVIDIA here, although not in a way that ruins the experience.", "At 1440p, we’re CPU-bound on everything ranked 4070 Super and above. This isn’t a useful test, so let’s move on.", "We ran GTA V at 4K for old time’s sake. Somehow, there’s still scaling with our test settings. The 4070 Ti leads the 4070 Super by 6.6%, with the 4070 Super about 15% over the 4070 FE and 37% ahead of the 3070. The gap between these cards is slightly smaller in this game than some of the others.", "Now we're moving on to ray-tracing tests. These results aren't comparable to the previous non-RT charts unless, for some reason, you just wanted to compare RT to non-RT.", "In Dying Light 2 with high RT and DLSS quality or equivalent settings for FSR and XeSS, we end up with this chart. The RTX 4070 Super held 43 FPS AVG here, showing that these cards actually need upscaling to run with these settings. The 4070 Ti leads it by 12%, with the Super card leading the 4070 FE by 19% and the 3070 by 54%. These numbers are similar to what we saw when rasterized, painting no meaningful deviation between these NVIDIA devices with RT and DLSS. The AMD cards tumble down the stack some more, with the 7900 XTX now equivalent to the 4070 Ti and the 7900 XT closer to the 3080 when both are using upscaling.", "At 1440p, the RTX 4070 Ti climbs to 90 FPS AVG, now a much better framerate, leading the 4070 Super by 11%, which leads the 4070 FE by 18% and 3070 by 52%. Again, these are about the same as we saw in rasterization. Unlike in rasterization, AMD falls behind a little bit here: The 7900 XTX is about the same as the 4070 Ti for performance, with the 7900 XT closer to the 3080 again. The 6800 XT ends up closer to the forlorn ", ".", "Finally, at 1080p, the 4070 Ti runs at 130 FPS AVG, leading the 4070 Super by just 9.5%, The 4070 Super is 18% ahead of the 4070 and 51% ahead of the 3070 once again. AMD’s 7900 XTX runs just behind the 4070 Ti and ahead of the 4070 Super.", "This one uses FSR on all cards. The RTX 4070 Super ran at 83 FPS AVG here, about tied with the 7800 XT and 3080 Ti. AMD is doing a little better in this one. The 7900 XTX now leads the 4070 Ti, the latter of which runs at 91 FPS AVG and leads the 4070 Super by 9.5%. ", "The 4070 Ti leads the 4070 Super by 9% here, with the 6800 XT and 7800 XT closer to the 4070 baseline. They held more of a lead over it at upscaled 4K.", "At 1080p, we’re mostly interested in what trend emerges. Here, the 7900 XTX pushes further ahead, with the 7900 XT now about tied with the 4070 Ti. The 4070 Ti leads the 4070 Super by 8%, with the Super leading the 4070 by 14% and 3070 by 57%. The 7800 XT is about equal with the baseline RTX 4070.", "In F1 with ray tracing and without any upscaling, the RTX 4070 Super ran at 41 FPS AVG, or about tied with the 3080 Ti. The 4070 Ti’s 45FPS AVG doesn’t meaningfully distance these from an experience standpoint. Over the 4070 FE, it’s about a 21% advantage for the Super. AMD’s 7900 XT roughly equates the 4070 Ti, with the 6950 XT as AMD’s closest card to the 4070 Super. The 7800 XT is closer to a 4070 in 4K RT performance.", "At 1440p, the 4070 Super keeps its lead over the $500 7800 XT and the former 6950 XT flagship, with the 7900 XT posting-up between the 4070 Ti and 4070 Super. The lead over the other 70-series cards is about the same as everywhere else.", "Power consumption is quick. In a total card workload, we found the 4070 Super to pull 222W at the PCIe rails, which has it about the same as a 3070 and about 20W more than the original 4070. That’s where part of the performance boost is coming from. Overclocking the 4070 Super puts it at 240W, which is just below AMD’s 7800 XT stock power consumption. NVIDIA remains overall efficient, despite the 20W bump from the 4070.", "Our latency testing was conducted on a different test platform, which makes the framerate data incomparable to other tests in this suite. We tested using a 360Hz display at 1080p and using an LDAT, which is an external physical measurement device for total end-to-end system latency. We previously ", ". Testing was done with a 2-second shot delay and auto activation on 30 shots (and 100 passes). We attempted move-on-click and flick testing, but found it unreliable in this game. There are problems with muzzle flash detection, but we filtered the data for outliers and had other issues with flick testing.", "Here are the results. These numbers represent the total end-to-end system latency, represented in milliseconds. It’s not accurate to call this “input latency” or “input lag,” as this is the latency for the entire system. That’s from click to seeing the action. This will directly correlate with FPS in a lot of ways, but sometimes, it’s possible for the driver to break away from purely being related to framerate. It’s possible for a higher FPS device to perform worse than another in latency. It’s also the point to just show a new number.", "The 4070 Super combination had an end-to-end system latency of 19.3 ms in this test. The floor is set by the ", " for perspective, which was holding us back at 32 ms. Enabling Reflex boosted performance to 18.0 ms, a reduction in latency of almost 7% end-to-end. The RX 6800 XT is about tied with the Reflex-enabled 4070 Super. The 7900 XT had a 15.6-ms total end-to-end latency, with the 4090 at 11.7 and setting the performance cap.", "In Counter-Strike 2, we tested in Dust II on practice and with a closed lobby without bots visible.", "The 4070 Super and 4070 FE both appear in this test. They were about the same here, or within test error. The 6800 XT is also within run-to-run variance. The 7900 XT measured 11ms end-to-end here, with the 4090 at 9.7 ms. The 2060 KO set the floor at 22 ms. Just for reference here, too, the 4090 was running at 858FPS average in this test.  This is kind of the point and is exactly why we wanted to introduce the latency analysis because it helps reset the scale and gives us a number that's a little more meaningful as a human.", "This is something we’re still working on, so we have a lot to do here in the future for latency testing. We plan to continue overhauling and exploring this testing. Currently, the run-to-run deviation is higher than we’d like it to be. We'd also like to move to movement testing or flick testing rather than click to photon with the shots, so that’s our next place to try and narrow-down the responsiveness, but it does help put things into perspective for how the system feels to play on and isn’t just a framerate number.", "That pretty much sums it all up. To give a recap: The ", " is sticking around, the ", " is obviously the new GPU. The ", " is outgoing; they are not going to continue making those. The ", " is also outgoing, and so those two cards will be replaced by their new Super variants, and that'll define the new stack for NVIDIA at this sort of high end.", "Again, the quick version of the recap is that we’re seeing about a 10% advantage favoring the outgoing ", " vs the ", ", about a 15% advantage with some break-outs favoring the 4070 Super over the ", " original, and then about 50% against the 3070 (", "). There’s more nuance to those numbers, but that’s the most compacted version.", "AMD competes relatively closely in rasterization with the most relevant cards being the ", ", the ", ", ", ", and the ", " sort of in that order with the ", " representing a kind of step-up, and if you’re going up to that price point, you’ll need to look at NVIDIA’s more expensive options, too. For ray tracing, AMD falls behind. That’s not new, but it’s a repeat behavior. Using upscaling across both company’s cards doesn’t really change that picture too much.", "For value, it at least hasn’t gotten worse for the 4070 Super: The Super is better than the non-Super and is about $50 more on average, with the 4070 continuing to exist but at its newer price point. One of the larger considerations is that the power consumption does go up but it’s 20 watts, which isn’t a crazy power increase but does allow NVIDIA to push performance a little more and get higher clocks.", "If you’re considering this card, the things to really think about include ray tracing -- which still primarily favors NVIDIA for performance -- and total budget. If you don’t care about ray tracing at all, AMD’s cards become much more viable and often have strong value propositions. For example, we ", " and at the price we bought it for, we liked it a lot. You should check that out if you are considering going up a price class. ", "We’d recommend waiting around for the next two Super cards to drop to see how they change the stack, then we can all regroup in the 4080 Super review and talk about the value proposition across the market."]},
{"title": " Lame, But Cheaper: NVIDIA RTX 4080 Super Review, Benchmark Comparison, & Value Discussion", "paragraph": ["Lame, But Cheaper: NVIDIA RTX 4080 Super Review, Benchmark Comparison, & Value Discussion", "Last Updated: ", "The Highlights", "Unlike NVIDIA -- and AMD with the ", " launch -- we’re not wasting any time with BS today. The answer is 1 to 3%. That’s the percent improvement of the ", " over the original ", ". We spent 20 hours of testing to create a 1-sentence performance summary, so thanks everyone for reading. Remember to go to the ", " to support us!", "The only thing good about the launch of the ", " is the price reduction, because otherwise, it’s functionally the same performance as the ", ". The difference is largely just noise. If this were still $1,200, it’d easily be one of the biggest wastes of time as reviewers we could spend -- but the $200 price drop helps a little bit. The trouble is that the 4080 always should have been cheaper. It was never a $1,200 card, as we ", ", and unlike the modern “low-end” cards like the ", " 16GB, the VRAM difference on the 4080 against the ", " is actually meaningful. For us and many other workstation users, it’s the difference in viability as a workstation GPU. With enough VRAM to power an editing machine competently, maybe the story would be different. But as a gaming card, the 4080 never should have been $1,200.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "And that makes the price reduction feel like some kind of Stockholm syndrome: It’s kind of a good thing, and the value certainly improves, but it’s also difficult to praise something that has moved from complete insanity into just moderate derangement. Traditionally, many years ago, this card wouldn’t have existed: NVIDIA would have cut the prices instead, but today’s NVIDIA instead values the additional marketing push it gets from attaching a new sticker to the end of what performs like an old card. And it’s working, clearly, because instead of a line item in a news story, we’re talking about it here.", "This review won’t be like our other GPU reviews from the last few weeks. We do have all the same data, but sincerely, it’s 1-3%. Multiply 0.03 against any number in any chart and add it to the 4080 result and you’re at or above our 4080 Super result. Instead, we’ll spend some time running comparisons at the $800-$1,000 price point and will recap some of the current market options.", "We were originally planning to go HAM with this review and include more latency testing and all the other new tests we’ve been running, but upon seeing performance, it’s really just not warranted -- especially after the past few weeks of reviews. We’ll publish a full dataset on the site soon in our Mega Charts entries for GPUs, but for today, it’s not necessary and is just a waste of everyone’s time. There’s no real nuance here.", "The RTX 4080 Super has 10,240 CUDA cores and uses a perfect AD103 die. The original RTX 4080 was also AD103, but cut down to 9728 CUDA cores. This could be for yield reasons. The end result is that the new 4080 Super has 5.3% more CUDA cores, but it also has an advertised slight clock bump.", "You can find additional test methodology notes in our ", ".", "And here’s the chart to join the recap.", "We could spend the usual 30 minutes chart spamming to show our work, but this image summarizes it pretty well. And genuinely, you can multiply any of these percentages against ", " from last week and you’ll know where it lands.", "With the ", " launch and the relative lameness of the card, we said it seemed possible that NVIDIA was couching its weakest launch between the two better cards: The ", " and the 4080 Super. Well, other than the value improvement of the 4080 Super, we were definitely wrong about that one. The 4080 Super is a lot less exciting than we’d anticipated. We weren’t expecting the world with that specs change, but certainly better than an average uplift of 1.9%. ", "Here’s a quick comparison of the ", " vs. the RTX 4080 Super, first showing only ray tracing in isolation because the advantage flips. The favor is toward NVIDIA here, whereas the raster favor is toward AMD.", "In the chart above, we see the unbelievable lead NVIDIA holds in Cyberpunk ray tracing, which we just re-added, when running on Ultra RT settings. That disproportionate advantage falls as the RT settings are reduced, with medium going from a 60+% NVIDIA favor to about a 30% favor -- still huge at rough price equivalence. Dying Light 2 shares this behavior.", "Resident Evil favors AMD here and is a lighter RT workload, so that makes sense. Tomb Raider and F1 are also both medium to lighter-weight RT workloads. That gives us a fairly full picture of the types of RT games right now, where we have those which heavily leverage ray tracing and swing the performance toward NVIDIA in big ways and those which supplement less heavily.", "For the rasterization comparison between these two, AMD leads or is equal with the 4080 Super. Overall, it’s anywhere from about equal to 20% ahead in raster performance, with particular strengths in Starfield at 4K, Dying Light 2 at 4K, Resident Evil 4 at 4K, F1 at 4K and 1440p -- and actually not bad at 1080p, despite approaching bottlenecks. If you mostly play non-RT titles or you aren’t interested in using the feature in heavy RT games like Cyberpunk and Alan Wake 2, then the ", " might be better value, but it really depends on what games you intend to play.", "So let’s talk about that aspect: the value. That’s more interesting today, anyway.", "We don’t normally do FPS/$ (or $/FPS) charts just because they require a lot of caveating and aren’t quite as objective as we’d like them to be (just due to some inherent loss of nuance), but they definitely have their place. This is the place.", "The following charts don't take into things like power efficiency, professional workloads, frame pacing, and frame delivery, but they’re still useful. ", "Here’s 1440p in the battle of 4080 vs 4080 Super. If we were to draw a line at an approximate average, it’d be in the $8 to $9 per FPS range for the original RTX 4080, or $6.5 to $7.50 range for the RTX 4080 Super. Generally speaking, you can see that the gap from the 4080 to the 4080 Super, where lower is better, improves by a similar amount per card.", "For perspective, let’s look at these numbers as a percent reduction in cost per frame.", "This is just the percent improvement, where we are defining improvement as reduction in cost per frame, from the 4080 to the 4080 Super. The reduction in USD/FPS tends to be about 17%, so if you wanted an objective look at the change in “value,” which inherently has some subjectivity to it depending on the buyer’s situation, this is about as close as we can get between the two cards.", "So, depending on if you’re NVIDIA or a realist, you could say that they improved 1-3% or you could say they improved 17%. It just depends on if you’re getting paid to say it.", "As we said earlier, this entire launch is functionally just a price reduction of an existing product. It’s a good thing to reduce the price, but they’ve done it in a confusing way -- and we wonder whether the cost to fab a cut-down 4080 die is meaningfully lower than a 4080 Super die. If it is, and if we ignored NVIDIA’s desire for maintaining ASP and margin, then it might have been more exciting to cut MSRP further. But then that’d look like an admission of a bad launch price, so maybe that was never in the cards. As we said last year, NVIDIA had an RTX 4080 problem where no one was buying them for a while. It’s been the opposite for the ", ", which everyone seems to want. ", "The GPU market has definitely changed.", "Let’s look at some more numbers.", "The next one looks at the ", " also at 1440p. We’ll use some 4K numbers in a moment. For the 7900 XTX, we’re working off of an average of a selection of cards available at retailers. This table shows our work.", "Currently, the average RX 7900 XTX will cost about $985 in the US from the two largest retail options. The cheapest option yesterday was the Phantom Gaming at $940, which seems to be in good supply. It’s tough to know which price to use for the chart coming up since the instant promos are likely temporary to compete with this launch, so to simplify things, we’ll use the best price and the average price. That’s $940 and $985. Remember that the average 4080 Super is likely to trend above $1,000 as well.", "Here’s the price per frame chart. We have two values for the 7900 XTX to make comparison easier. The 4080 Super is assumed at $1,000, since we have no retail units to compare as of writing.", "First looking at RT performance, particularly in Cyberpunk with ultra settings, AMD is getting killed for value. But remember, this specific test produces massive, double-digit percentage point increases with NVIDIA over AMD. The medium results are less intensive for the ray tracing workload, and as a result, the numbers level-out. NVIDIA still produces better value per frame.", "In Dying Light 2, NVIDIA again maintains an advantage against both AMD price points. Resident Evil favors AMD, F1 with RT marginally favors NVIDIA, and Tomb Raider with RT has them about equal.", "For rasterization performance, AMD generally has an advantage. It is typically below or roughly equal to NVIDIA in the games in the bottom half of our chart for rasterization. AMD’s performance is typically higher here or very close. That’s benefitting it in value here compared to in RT benchmarks.  ", "Here’s the % reduction in cost per frame with RT, moving to the 4080 Super from the XTX. At $985 for the XTX, the reduction in cost per FPS for the 4080 Super, despite a higher base cost, is 38% for Cyberpunk with Ultra RT, 20% at medium or in Dying Light, 9% for F1, and 5% for Tomb Raider. AMD has an advantage in our Resident Evil tests.", "At $940, those numbers reduce to 35%, 16%, 4.5%, and equality in Tomb Raider.", "Let’s look at rasterization and flip the chart. Because the XTX tends to be better in these tests, the reduction in cost per FPS now favors the XTX. Buying AMD instead of NVIDIA here would give you a 15% lower cost per frame at $940 in Starfield and Resident Evil 4, 20% in our F1 test, and 17% in our Total War test. NVIDIA has a driver overhead advantage in our testing approach for Final Fantasy 14, so it levels out. The $985 options lose value, of course, but you’d need to determine if they have features you value more. They are still ahead of NVIDIA.", "The next section will just look at NVIDIA’s progress in value.", "A couple notes here: Price per frame value like this gets fuzzy when you exit direct head-to-head comparisons. Our main reservations about this kind of chart relate to how people actually shop: Generally speaking, people have a budget in mind or are determining it, then will buy roughly within a range. That means a head-to-head value chart can help. But very few people would say, “I only want to buy the best dollar per frame card” and ignore all other nuances. ", "These charts smooth over those nuances, including frame pacing, efficiency, latency, or even just the fact that again, most people don’t have an infinite range and then sort by best value for the purchase.", "And for one last thing, just a note that the dollar numbers aren’t cross comparable at all necessarily between reviews. The FPS values are different, so the dollar values per FPS are different. As a result, the only thing that actually matters is the ranking within any given singular chart. Also, because the resulting $/FPS number is totally arbitrary and has no baseline for some known-good value, unlike a threshold such as 60FPS, you end up just looking at the approximate size of a bar in comparison to others anyway. We’re doing this as a percent chart instead.", "Our pricing here was taken by averaging reasonable cards on first-party retailers. The ", " was about $2,000 on average at time of writing, so we did not use its $1,600 MSRP.", "One more thing: These charts skew HEAVILY based on whether you’re using 4K, 1440p, or 1080p results. That’s not just a bottlenecking consideration at the low-end, but because the cards scale differently depending on their capabilities. If people like this enough, we can play around with doing one for each resolution or something. That’s what you’d really need. But enough talk of the limitations -- you understand our reservations about it, let’s take a look.", "Anyway, here it is. This is new and we’re not sure if we like it, so that’s your disclaimer. No big claims for this one. Our commenters often ask for a value chart as an objective measure, but because of the hesitations explained, we don’t make them normally. This is a different approach for us.", "100% is baseline best value of the cards presented on the chart, where “value” is determined as the $/FPS number. The result has the ", " as the cheapest per FPS, so it’s at 100%. The 4090 is about half the “value,” if we want to make the decision as a community to phrase it like that and cut every single bit of nuance, like the fact that a ", " could never do some of the things a 4090 could do. Regardless, what this does tell us is the direction NVIDIA is going.", "By this chart, it would in fact appear that the 4080 Super’s new price drop has improved its “value.” The 4080 is among the worst on the chart and lacks some of those nuances that a 4090 provides. For instance, despite being a so-called “low value,” the 4090 is still the only card on this list we’d buy for our editing machines due to the VRAM, and that’s not something that gets measured in this way.", "But you get the idea. We’re not sure if we like that chart or not, but it is a commonly requested one from the audience and we’ve been trying to play around with ways to slightly de-arbitrary-ize it. If you’re just looking at relative bar size anyway, might as well strap a number to it that’s a little more intuitive.", "But at the end of the day, we come back to the ", " conclusion. None of the playing around with charts actually matters and all of this can be done with the normal approach, which is just plain old critical thinking.", "This review has been simple. Again, take our last round of charts and multiply the ", " results by about 1-3% and increment it, and that’s the new result. It’s not worth singular charts in the video. It’s weird because it’s a “lame” launch with regard to the performance, and again, without that price drop, this would be getting one of the biggest roasts we could give -- just like some of NVIDIA’s cards last year.", "But the price did come down, so that’s the only factor softening the ire. In this instance, the ", " has indeed improved in value over the 4080. You don’t need a chart to tell you that: If a product is the same but gets a $200 price cut, its value just went up.", "What’s more interesting is looking at things like the ", ", the ", ", and the ", " to try and gauge value there. Generally speaking, as you go up the stack, the value tends to get worse. At least that’s historically been true. The 4070 Super helped revive some of that. The ", ", unfortunately, was a bit of a dud. Meanwhile the ", " is cheaper. On the AMD side, the ", " is now effectively the direct alternative to the ", " and 4080 Super.   ", "In this case, we can’t praise NVIDIA as a savior for doing what should have been done a long time ago. We can, however, say that it is at least a better situation. But our hesitation to fully embrace this goes back to not getting suckered into encouraging a new method to keeping average prices high.", "All of that said, one thing we noted in our efficiency testing for the ", " was that the 4080’s appearance on those charts has made us at least somewhat more fond of it than previously. Before we had the FPS/W numbers, it wasn’t clear to us just how relatively efficient the base 4080 is and the 4080 Super is basically just a little better here. That’s something our review overhauls are helping with.", "Anyway, that’s it for now. You have enough to work with to make your decisions. We’ll publish as many of the raw FPS numbers as we can get together soon."]},
{"title": " AMD Radeon RX 9070 XT, Ryzen 9950X3D, Z2 Extreme SOC for Ally / Legion, & More", "paragraph": ["AMD Radeon RX 9070 XT, Ryzen 9950X3D, Z2 Extreme SOC for Ally / Legion, & More", "Last Updated: ", "The Highlights", "AMD announced a ton of CPUs, GPUs, and handheld hardware today. The announcements were for the 9950X3D, 9900X3D, Ryzen Z2 SOC for handhelds such as the ROG Ally, and RDNA 4 GPUs like the RX 9070 and RX 9070 XT. AMD also announced a number of mobile CPUs. Our focus will be on RDNA 4 and the new Zen 5 X3D parts alongside the handheld SOC.", "We’ll start with AMD’s GPU news since it’ll be the quickest.", "Steve Burke", "Vitalii Makhnovets", "Jimmy Thang", "AMD announced the existence of its Radeon RX 9070 and RX 9070 XT today, noting Q1 2025 availability.", "Specs are extremely limited right now. The company did picture several partner model cards in its announcement slide, including at least one that looks like a Yeston model, an ASRock model, XFX, and all the others listed. The cards pictured above are generally 3-slot coolers that are 2-3 slots thick.", "AMD says the GPUs will use its RDNA 4 architecture and will utilize a 4nm process from TSMC. AMD mostly described its specs with adjectives, which is unfortunately not particularly useful. Words like “optimized compute units,” “supercharged AI compute,” and “improved raytracing per CU” don’t tell us a whole lot. We’ll have to wait for that information.", "Likewise, AMD announced that FidelityFX Super Resolution, or FSR4, will be released and has been built for RDNA 4. It intends to re-launch its Anti-Lag software solution that was intended to compete with Reflex, now in its Anti-Lag 2 iteration. We were not pre-briefed with any further information than this at the time of briefing.", "The company is clearly self-aware, as it also presented a slide about its naming choices for the RX 9070 series. Go figure. The slide above shows that AMD intends to line-up the 9070 series, including both XT and non-XT models, with the ", " down to the middle of the ", " (read ", "), whatever that means. The worst 9070 is apparently half of one ", " -- or maybe that means 1.5 7800 XTs? All we’re missing is a note telling us that the image is not to scale.", "Anyway, against NVIDIA, this roughly positions the 9070 series as comparable, according to this image, to the ", " (watch ", ") and ", " (read ", "). We won’t get out our scrying stones for this hastily thrown-together image since it’s hard to judge without real numbers, but that’s at least how AMD seems to be positioning it.", "The company claims the change is to line-up with its Ryzen 9000 CPUs and says it will reserve 8000 naming for its mobile CPUs.", "On the CPU side, AMD’s two new desktop CPUs are predictable: The 9950X3D and the 9900X3D, which use the Zen 5 architecture that shipped at the end of last year and follow-up the wildly successful ", ". The ", " has been constantly out of stock due to the demand.", "The 9950X3D is a 16C/32T part that advertises a maximum boost frequency of “up to 5.7GHz,” noting a 144MB total cache size. At the time of writing this, AMD has not provided pricing details or a specific release date beyond sometime within the next few months. ", "For comparison, the 9800X3D (read ", ") has a total 104MB cache and $480 MSRP. The advertised boost of the 9800X3D is 5.2GHz, so the 9950X3D has a greater cache size and may benefit from higher boosting. The 144MB cache on the 9950X3D comes from the additional CCD in the configuration and could have some specific benefits that we’ll explore in our eventual review. ", "The 9900X3D is a 12C/24T component that advertises up to a 5.5 GHz boost max. It has a 140MB total cache. The 9950X3D runs a 170W TDP, with the 9900X3D at 120W. The 9800X3D is also 120W. Because of this, the 9800X3D may benefit from additional power available during fully loaded workloads. There could be some shuffling of the CPU stack in specific benchmarks due to the power budget differences.", "AMD’s updated chipset drivers should more intelligently park CCDs and, in theory, should make it easier to upgrade in-socket without needing to blow away the whole OS prior to moving from a single-CCD part to a dual-CCD part. We will still be using isolated SSDs for our reviews, but this should be a benefit for end users who may later seek to upgrade in-socket.", "AMD published some first-party claims. As usual, we’ll have our own numbers soon -- as will basically all other reviewers -- and so you should wait for those prior to making decisions. To set the stage for what we’re verifying against, AMD is claiming the following:", "AMD says this is “the world’s best gaming processor,” though note that they are comparing it to the ", " (watch ", "). The 9950X3D is shown as being on average 8% better across 40 games that AMD tested, with a range of no change to a 58% uplift over baseline compared to the ", ".", "AMD also claims that it outperforms the ", " (read ", ") by 20% on average across 40 games. We definitely believe this, based on numbers we ran for the 9800X3D and ", " already.", "Its first-party numbers also point to performance improvement in Blender, with lesser improvements in Photoshop and Premiere in PugetBench testing against AMD’s own prior processor.", "Historically, these CPUs do not necessarily provide significant improvements over the single-CCD X3D CPUs of the same generation. You might see rough equivalence or slight changes in specific games. The primary advantage would be for someone who does a lot of gaming but also wants the additional cores for production workloads. ", "The other historical challenge has been behavior with core parking, something we’ve now detailed extensively. While core parking is still a “thing,” AMD says its new chipset drivers should resolve a lot of the past issues.", "AMD’s Z2 SOC follows-up the Z1 and Z1 Extreme mobile solutions that were found on some handheld devices. AMD has also offered mobile chips like the 7840U and 8840U that have been in handheld devices and are comparable.", "The Z2 is light on information: AMD again defers to descriptors like ‘breathtaking” and “exhilarating speed,” which we assume is the next speed setting for a Back to the Future movie. ", "It also gets into some business-y stuff, like the addressable market and increase in competition in this market.", "As for actual news, the Z2 family comes in 3 variations currently known: The Z2 Extreme, Z2 Go, and the…Z2 non-Extreme, non-Go.", "The Z2 Extreme and Z2 are both 8C/16T parts with the same cache and a boost frequency separated only by 100 MHz. The actual change comes in the form of the integrated graphics. This is also where the Z1 and Z1 Extreme deviated most heavily. The configurable TDP allows up to 5W more driven to the Z2 Extreme, which will cost battery life but help power the GPU. The Z2 has a higher boost clock despite a lower cTDP, likely due to overall package budget allocation with the GPU change (and also density).", "The Z2 Go is new. This is a 4C/8T part that only boosts to 4.3 GHz maximum advertised, only has 10 MB of cache, keeps the 15-30W cTDP, and keeps the 12 CUs. This CPU is far weaker than the others listed here, especially with that clock drop, so we’re curious to see what types of devices make the best use of it. We’ll also be curious to see battery life and if it can stick closer to that 15W number while still providing meaningful performance.", "These are all listed for Q1 2025 availability, so we’ll be busy on our team running handheld benchmarks once again here soon. We ran several reviews last generation and will need to do a total refresh.", "We’d like to dedicate this next section to our ", ", who once joined us to ", ".", "AMD’s new mobile CPU is the FireRange AMD Ryzen 9 9955HX3D that’s releasing in 1H 2025, and it’s joining the 9955HX and 9850HX mobile parts.", "The 9955HX3D is advertised as what AMD claims is the best gaming and content creation part for mobile. We don’t really test mobile, but we certainly use high-end laptops for our travel and might try these out.", "The 9955HX3D is a 16C/32T part that boosts up to 5.4GHz. It has 144 MB of cache and a TDP of 54W. The 9955HX is the same, but with less cache. The 9850HX is a 12C/24T part with lower boost, no X3D cache by mercy of its easier name, and the same TDP.", "AMD also spent some time on its new “AI” brand name mobile processors, but we’ll leave that to someone else to cover as that’s not really our area of focus."]},
{"title": " NVIDIA RTX 5090 at 575 Watts, RTX 5080, 5070 Ti, & 5070 Specs", "paragraph": ["NVIDIA RTX 5090 at 575 Watts, RTX 5080, 5070 Ti, & 5070 Specs", "Last Updated: ", "The Highlights", "NVIDIA today announced its RTX Blackwell family of 50-series GPUs. These include its RTX 5090 at $2,000, the RTX 5080 at $1000, the 5070 Ti at $750, and the RTX 5070 at $550.", "NVIDIA claims that its RTX 5070 has “4090 performance at $549,” which is definitely something we will be inspecting. NVIDIA also stated that this is “impossible without AI,” also stating it is “impossible without GDDR7,” which the company is moving to for its 50-series video cards.", "Let’s get into the news.", "Steve Burke", "Jeremy Clayton", "Tim Phetdara", "Jimmy Thang", "NVIDIA spent a lot of time talking about AI, and we’ll get into some of that briefly at the end.", "We’ll start with the hard information that we have.", "NVIDIA announced its Blackwell GPU as it’ll arrive to the consumer market in January. The GPU, presumably the full Blackwell die, was noted as a 92 billion transistor solution (as compared to the ", "’s approximate 76 billion).", "Notably, the card CEO Jensen Huang showed off at the event appeared to be a 2-slot card, which he noted has 2 fans. This is a stark contrast to the huge prototype NVIDIA cooler ", ". This is a big swing from the 3-slot and 4-slot cards we’ve become used to, which were necessary for thermal and power management.", "NVIDIA also posted some of the hard specs to its ", ".", "We can start with the power, which is listed as 575W total graphics power for the 5090. ", "That’s a huge amount of load to put on a single 16-pin connector and we’re concerned about the strain on it. We also wonder if this will be coupled with a redesign of coolers to try and actively cool the area of the power connector.", "The RTX 5090 Blackwell GPU is ", " as having 21,760 CUDA cores, memory at 32 GB of GDDR7, clocks at 2.41 GHz boost and 2.01 GHz base, and a large 512-bit memory interface width. NVIDIA has iterated its Tensor core generation to 5 and its RT core generation to 4 for Blackwell, though we don’t yet have architectural details on what that actually means on the consumer side. We expect those details soon.", "The FE card is listed as 304mm by 137mm for dimensions, and 2 slots thick.", "Jumping over to the prior RTX 4090 (watch ", ") for ", ": The 4090 has 16,384 CUDA cores, down notably from the 21,760 of the 5090 -- but cores can’t be linearly compared, especially cross generation, so the real-world impact likely won’t track linearly. The 4090 also ran 24 GB of GDDR6X rather than the 32GB GDDR7 on the 5090. The 4090’s clocks are higher as advertised, though, at 2.52 GHz boost and 2.23 GHz base -- but clocks, like core count, aren’t everything.", "Zooming out to look at memory capacity, we see the 5090 at 32 GB, the 5080 at 16 GB, the 5070 Ti at 16 GB, and the 5070 at 12 GB. For perspective, the ", " (watch ", ") is also 12 GB, the ", " is 12GB, the ", " (read ", ") is 16GB, and the ", " is 16GB.", "Going to a ", ", the 5080 is listed at 10,752 CUDA Cores, which is slightly more than the RTX 4080’s 9,728 CUDA cores and not the same huge change we see with the 4090 to 5090. The 5070 Ti lists 8960, against 7680 on the 4070 Ti (watch ", "), and the 5070 lists 6144, up from 5888 on the ", " configuration. ", "Again, these aren’t directly comparable as they’re different generations, but are useful for establishing how NVIDIA is positioning the cards.", "The full specs page shows a 2.62 GHz max boost on the 5080, 2.45 GHz on the 5070 Ti, and 2.51 GHz on the 5070. We already said the 5090 has a larger memory bus. The 5080 and 5070 Ti both run a 256-bit bus, with the 5070 at 192 bits.", "Other than the 575W of the 5090, NVIDIA lists the other cards at 360W, 300W, and 250W for total board power. Broadly speaking, NVIDIA’s power consumption appears to be increasing. ", "This is good timing with our efficiency testing: It’s possible efficiency is up despite power draw also going up, but that’s what we’ll find out.", "We’ll have our own benchmarks soon enough and you should rely on those or the independent benchmarks of other trusted reviewers. We can still reference NVIDIA’s first-party claims to get an idea for where they stand.", "NVIDIA’s webpage has a relative performance chart that’s pretty hard to actually read, but we can get an idea. NVIDIA claims the 5090 outperforms the 4090 by over 2x in some situations, such as with Cyberpunk and Wukong, among others. In these tests, they list “DLSS+Full RT” as the settings. The footnote that’s nearly the same color as the page background says that the 40-series used frame generation in this testing, but the 50 series used MFG 4x mode. This makes the comparison not like-for-like.", "We consider this approach flawed, but we’ll look at their other claims for full perspective. Switching to the RTX 5080, NVIDIA shows it as outperforming the RTX 4080 (watch ", ") by, again, sometimes 2x -- this is tough to filter through differing settings tested, unfortunately.", "The 5070 Ti shows beyond 2x gains against the 4070 Ti in the same way and with the same settings difference, with the 5070 and ", " showing the same in NVIDIA’s first-party claims.", "Of all of these, the Plague Tale comparison is maybe the most fair since NVIDIA notes that it only has DLSS 3.", "As for what DLSS 4 actually is, NVIDIA ran this ", " to introduce it. Of MFG, or Multi-Frame Generation, the ", " reads, “DLSS Multi Frame Generation generates up to three additional frames per traditionally rendered frame, working in unison with the complete suite of DLSS technologies to multiply frame rates by up to 8X over traditional brute-force rendering.”", "The page continues to say, “Our new frame generation AI model is 40% faster, uses 30% less VRAM, and only needs to run once per rendered frame to generate multiple frames. For example, in Warhammer 40,000: Darktide, this model provided a 10% faster frame rate, while using 400MB less memory at 4K, max settings, using DLSS Frame Generation.”", "This section of the ", " also indicates that you’ll be able to override the DLSS model used in games that don’t get updates from devs, which is already possible to be done manually by some users who replace .dll files. This new approach looks like it will be more user-friendly.", "NVIDIA stated that its Blackwell GPUs will have 2x the memory bandwidth of Ada, at 1.8TB/s for the cited spec, it claimed 2x the the RT TFLOPS, and 1.5x Ada shader performance. ", "The PCB showcased was a relatively small square -- like a further cut-down version of the 4090 FE PCB if you were to chop the wings off -- that appears to be sandwiched between two full flow-through fans. ", "The design is shown in this explosion diagram where NVIDIA illustrates the PCB centrally with densely populated components on both sides of the board. The cooler also utilizes a vapor chamber cooling solution with what appears to be 5 heatpipes, assuming the render is accurate. The GPU directly contacts the vapor chamber as you would expect, with the flow through area handling the flanking heatsinks.", "Uniquely, that appears to take some learnings NVIDIA had from ", ", which is a full flow-through design. ", "NVIDIA also spent limited time talking about other AI features for gaming. Although it is publishing materials to its site, we’ll wait for the full architectural briefing to get into more depth. For now, the company highlighted these:", "NVIDIA’s keynote was lengthy and covered topics outside of our typical coverage scope. For now, we’re just focusing on getting these basics out to you and will revisit the other announcements in more depth as we have time to adequately read through all the released materials.", "As for release dates: NVIDIA cited January in its keynote, but its website specifically lists January 30th for the RTX 5090 and 5080. It says the 5070 Ti and 5070 will arrive in February."]},
{"title": " AMD Radeon RX 9070 XT GPU Review & Benchmarks vs. 5070 Ti, 5070, 7900 XT (Sapphire Pulse)", "paragraph": ["AMD Radeon RX 9070 XT GPU Review & Benchmarks vs. 5070 Ti, 5070, 7900 XT (Sapphire Pulse)", "Last Updated: ", "The Highlights", "There’s real competition now. The answer you’re here for is that the ", " and ", " go back-and-forth a lot (depending on the game). ", "At 4K and rasterized (without RT), the ", " and ", " were within 6% of each other (on either side) in F1, Cyberpunk, Resident Evil 4, Starfield, Total War: Warhammer 3, and Dragon’s Dogma 2. At 1440p and 1080p, we saw similar results depending on the game. Sometimes the 9070 XT can close the gap a little bit if it’s behind; sometimes it’s able to pull ahead a little bit. It depends on the situation. Because the 5070 Ti (read ", ") is basically an ", " in a lot of games, which is basically an ", ", that means the 9070 XT is often close to the 4080 Super (read ", ") in these games as well.", "Steve Burke", "Mike Gaglione", "Jeremy Clayton", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "In ray tracing, it’s all over the place. This is sort of the downside to the card. AMD has got some real strengths, but it’s also got some real downsides. The 9070 XT improves massively on AMD’s prior generation, but NVIDIA remains fiercely competitive still. AMD gets crushed in tests like Black Myth: Wukong with RT, but is actually competitive now in more mixed load RT games (AKA more medium-weight RT). ", "NVIDIA’s biggest strengths remain in its feature set generally, ray tracing, and efficiency in particular. Its power consumption is pretty effective for what’s output. The features get difficult to measure. For example, do we measure MFG as multi-frame generation or as…multi-failure generation… ", "That’s the fastest possible version of the recap. NVIDIA has had a busy 3 months destroying the hype it built for the 50 series. They’ve had ups and downs -- actually, it’s mostly been downs. Not that many, though. Just the ", " burning. And the ", ". And the ", ", even from first-party partners. And the ", ". And the missing ROPs on the card they didn’t initially disclose them on. And the ", " about the ", " vs. the 4090. And, well, we’ll be here all day if we keep listing all of the issues.", "Let’s just move on to the 9070 XT review.", "AMD’s RX 9070 and 9070 XT launch the day after this story goes up. We already posted a ", " going into the specs and architecture of the cards, but the quick recap is this:", "AMD has made major changes architecturally for the RDNA 4 generation, which the 9070 XT uses. There are 2 cards: the 9070 and 9070 XT. There’s probably going to be another card later that's at the lower end. The basic specs of the cards today might feel familiar to the Vega era, though: The cards are divided by a 56 compute unit (CU) model and 64 CU model with today’s review focusing on the 64. No, ", ". We’ll also have the 9070 review up shortly.", "For TDP, AMD markets them at 220W and 304W, with board partners having room to scale higher. We’ll test this in our review. AMD is using GDDR6 memory at 16GB capacity at 20 Gbps and on a 256-bit bus for both cards. The VRAM alone will be advantageous in heavier RT workloads, which is something we talked about in our ", ".", "The architecture’s biggest overhaul that we’re aware of has been in ray tracing. AMD has doubled the ray intersection rate, moved to two RT accelerator blocks with a shared 128KB memory, moved to BVH8, and introduced oriented bounding boxes to reduce or eliminate false positives in ray-triangle and ray-box intersections. AMD also introduced a dedicated ray transform block to help with transformation. This is all stuff that AMD needs to improve upon because NVIDIA has successfully sort of manufactured a category it’s really good at, which is real-time ray tracing.", "All of this helps with ray tracing performance, where AMD had fallen behind not only NVIDIA, but even Intel Arc in some situations last generation. ", "For our review of the ", ", the RTX 5070, we showed that Newegg only had a single GPU model in stock, sold by Newegg, that wasn’t refurbished when searching from $450 to $650. It was the ", ". ", "This is madness.", "There’s just nothing there. The 9070 XT and 9070 both should be within this range, but they are also likely to get scalped. What may help is that there are rumors of greater supply than the 50-series, and likewise, they may be less desirable by the AI-at-home segment than the upper-end 50-series cards, like the ", ". ", "Because these reviews go up before the cards launch, we can’t know where the pricing will land. We do intend on following it up immediately though with a report on how the launch shook-out. ", "Either way, we’d normally dedicate an entire section talking about all the various alternatives at the same price, but the reality is just that there aren’t any other than used cards. ", "We’re trying to keep this one simple today, so let’s just get straight into the numbers.", "Dragon’s Dogma 2 at 4K is a remarkably strong showing for the RX 9070 XT. In this benchmark, the 9070 XT ran at 70 FPS AVG, landing it between the RTX 4080 (read ", ") and RTX 3090 Ti. That means that even taking MSRP at face value for both cards, the $600 9070 XT is achieving 95% of the performance of the $750 RTX 5070 Ti Prime, but at 80% of its MSRP. We want to caution that this result doesn’t always happen -- sometimes a 9070 XT is worse than a 5070, so it depends on the game. But this is a great start.", "The frametime pacing is also comparable, meaning that the frame-to-frame interval is not noticeably different to a human player.", "The 9070 XT leads the ", " by 14.8% here. The lead over the 5070 is 24%, at 70 FPS to 56 FPS.", "At 1440p, the RX 9070 XT nearly ties the NVIDIA RTX 5070 Ti, the latter of which only leads by 3%. It’s measurable, but you’d never notice this difference. The lows are also within variance. Because a 5070 Ti is basically an RTX 4080 V3 or V4, that means the 9070 XT is also punching close to RTX 4080 Super levels. The 4080 Super was a $1,000 MSRP card that replaced a clinically insane $1,200 MSRP card before it, giving us some perspective.", "The last-gen flagship makes us wish AMD had something one step higher as well: The ", " still leads the new 9070 XT, holding an 8% advantage here.", "Against the new RTX 5070, the 9070 XT leads by 21%. The ", " posts an even larger gap to the 9070 XT. As for owners on cards like the 2070 or 2070 Super here, this might be a good upgrade.", "At 1080p, the RX 9070 XT maintained its relative positioning against the 5070 Ti. It’s now at 145 FPS AVG to the 151 result on the $750 MSRP NVIDIA model, available on sale for only $150 more. We’ve never seen an inverse sale where the price goes up…", "The 7900 XT ran at 134 FPS average in this benchmark at 1080p, giving the 9070 XT an uplift of 8%. As for the ", ", it’s still technically ahead of the new flagship RDNA 4 card, but only by 8%.", "FFXIV is up now. A quick disclaimer: The results here appear to be outliers in our dataset. They are repeatable and we re-tested both cards multiple times, ultimately coming to the same data set. They are lower than AMD’s own findings; however, we’re not sure if AMD is using the Dawntrail test like we are, and it’s also possible that the test area is different (as we capture a specific scene). Regardless, we’ll continue looking into these and wanted to disclaim that they are outliers from the rest of the rasterized data set, but the results did repeat in our testing. ", "At 4K, the 9070 XT landed at 68 FPS AVG. Unfortunately for AMD, that means that the 9070 XT is worse than the RTX 5070 here. The 5070 leads the 9070 XT by 13.6% with its 78 FPS AVG; the 5070 Ti leads by a staggering 43%, at 97 FPS to 68. Whereas Dragon’s Dogma 2 was a strong position for AMD, it’s weak in this game. It all depends on the game itself.", "At 1440p, the 9070 XT ended up only 2 FPS above the 7900 GRE (read ", "). Architecturally, the improvements just aren’t helping it here. The 5070 Ti ends up at 187 FPS AVG, leading the 9070 XT by 34%. The 5070 leads it by 10%. ", "Let’s show how much of a tennis match this really is.", "Resident Evil 4 swings it back the other way: At 4K, the RX 9070 XT now holds a 103 FPS AVG, landing it nearly tied with the RTX 4080 Super. That’s a great spot for AMD’s card, which it needs after that Final Fantasy showing we just saw.", "The 9070 XT leads the 7900 XT marginally and leads the 5070 by 31%. The 5070 Ti leads the 9070 XT by 3.5%, with the 7900 XTX (read ", ") 23% ahead.", "At 1440p, the 9070 XT continues to rank alongside NVIDIA: The 9070 XT is about 5 FPS short of the 5070 Ti, making for a measurable but undetectable difference to a human; that is, assuming the 5070 Ti has all the ROPs. If it doesn’t, we’d see anywhere from 6-12% more of a performance swing. ", "The RTX 4080 Super leads the 9070 XT by 5% here. The 7900 XTX was also once a $1,000 card and itself leads the 9070 XT by 20% with its 232 FPS result.", "Against the new RTX 5070, the 9070 XT holds a 27% advantage.", "At 1080p, the RX 9070 XT clocked higher framerate than the 7900 XT and landed just below the 5070 Ti. The ", " leads the 9070 XT by 15%, which isn’t all that much when considering we’ve all been gaslit into thinking a ", " takes the place of a 1080 Ti or something. ", "Since we just alternated to a title where the XT looked better, let’s bring it back maybe the other way.", "Black Myth: Wukong tends to favor NVIDIA, both with and without RT enabled. We’ll see if that remains true on the new architecture.", "At 4K, the 5070 Ti leads the 9070 XT by 12% here. That’s not as big of a gap as it could be. Against the 5070, the 9070 XT is at least ahead by 14%. Compared to the prior generation, the 9070 XT is about the same as a ", ". The 7900 XTX is a few percent higher framerate than the 9070 XT.", "At 1440p, the 9070 XT’s 83 FPS AVG result is matched with good pacing on the 1% and 0.1% lows. It’s not better than its neighbors in a meaningful way, but is keeping pace properly.", "The 5070 Ti leads the 9070 XT by 5% and the 5080 (read ", ") leads it by 17%, probably calling the 5080’s existence into question more than anything -- and again, that’s one with all the ROPs.", "The 5070 ran at 72 FPS AVG, so the 9070 XT is about 10 FPS higher. That also had the 5070 above the 7900 XT, which the 9070 XT has now vaulted past.", "At 1080p, the scaling shifts the 9070 XT closer to the 7900 XTX. The two are functionally equal in all 3 metrics. The 5070 Ti outranks the 9070 XT on a technicality, but not in an observable way. 1080p seems to squish all of these together. ", "Starfield is up now. This one flips it again: At 4K, the 9070 XT leads the 5070 Ti by about 2 FPS. Just like we’ve said elsewhere, this is a measurable but irrelevant difference. You wouldn’t notice the 2 FPS. You probably would notice the cost difference, though.", "The 9070 XT actually roughly equals the 4080 Super here and isn’t that distant from the 5080. Both the 5070 Ti and the 9070 XT are a threat to the 5080’s already questionable existence.", "At 1440p, the 9070 XT is again between the 5070 Ti and 4080 Super, roughly tying the latter. The 7900 XTX has a 6% lead over the 9070 XT here. The 5070 non-Ti, which is still not equivalent to an RTX 4090, continues to not be equivalent to a 4090. Truly wondrous technology. We never could have predicted that…", "At 1080p, the 9070 XT now holds a 127 FPS AVG with lows at 68 and 46. That plants it right between the 7900 XTX and 5070 Ti. There’s not much difference between these three in this test. The 4080 Super isn’t that different, either, and the 5090 (read ", ") shows that we do have a little more CPU headroom.", "So does the 4090, for that matter, which continues to not be a 5070.", "Dying Light 2 is up next. This is one of the heavier games in our test suite.", "At 4K, the 9070 XT ran at 62 FPS AVG, which has it just ahead of the 3090 Ti. It’s also 11% ahead of the 5070. The 5070 Ti leads the 9070 XT by 12% in this test, which matches its gain in other tests where it held an advantage.", "In other words, the 9070 XT achieves 89% of the performance at 80% of the listed MSRP. We’re reviewing this before the 9070 XTs go on sale, so we can’t know how much to adjust for street price yet.", "At 1440p, the 5070 Ti beats the 9070 XT at 130 FPS to 118, or about a 10% uplift to the 5070 Ti. The 4080 Super is a few frames above that. The 5070 is down at 106 FPS AVG, resulting in an advantage for the 9070 XT of 11%. It’s equidistant between them.", "AMD has also improved on its 7900 XT model. The 6700 XT is way down at 61 FPS AVG, so users on that tier of hardware could experience nearly a doubling in framerate in some tests.", "We’ve been rerunning Cyberpunk: Phantom Liberty on a newer version for all tests, so this chart is sparse.", "The 9070 XT ran at 53 FPS AVG, giving it a lead over the 5070 Ti’s 50 FPS result of 5.8%. Against the 5070, the 9070 XT is ahead by 29%. Maybe more noteworthy is that the 9070 XT technically is ahead of the 4080. The 7900 XTX remains about 9% higher framerate than the 9070 XT.", "At 1440p, the 9070 XT climbs to a playable 109 FPS AVG. This is without upscaling or frame generation -- just organic, farm fresh frames. The 9070 XT ends up basically tied with the 5070 Ti, slightly leading the 4080, and notably leading the 5070. We haven’t re-run AMD’s older stuff in this one yet.", "Time for ray tracing. This is where AMD will really need to prove itself. AMD spent a lot of time talking about its improvements to ray tracing blocks in its recent press briefings, so they’re clearly aware of the deficit.", "We’ll start with the worst-case scenario. Black Myth: Wukong has worked best on NVIDIA hardware since its launch, especially in ray tracing. At 4K with upscaling and ray traced, the 9070 XT ran, with our settings, at 29 FPS AVG. Playability doesn’t matter right now, just the relative scaling. We’ll get to lower resolutions down below.", "With these settings, the RTX 5070 ends up ahead by a large 38% at 40 FPS to 29. The 5070 Ti is 78% ahead of the 9070 XT. This is AMD’s absolute worst-case scenario. Against last generation, AMD is posting large gains: The 9070 XT outperforms the 7900 XTX by 45%, climbing from 20 FPS to 29. That is a substantial gain, especially considering the XTX was often slightly ahead of the 9070 XT in raster but obviously, there are situations like this where you’ll have to just heavily weigh NVIDIA if RT and this type of game matters a lot to you. Against the 7900 XT, there was an enormous 84% uplift in performance. It’s undeniable that AMD is improving in RT.", "At 1440p upscaled, the 9070 XT ran at about the levels of the RTX 3090. The 5070 now is 37% ahead, so about the same as the previous resolution, with the 5070 Ti 66% ahead, reduced from before. The gain in the 9070 XT over the 7900 XTX is 45%, so the same.", "At 1080p upscaled, the 9070 XT held 73 FPS AVG and climbed past the 3090. It’s now approaching the 3090 Ti, which came out 3 years ago and had no formal MSRP at launch. It just sold for whatever in that period, which typically was close to $2,000, but occasionally $1,500.", "The 5070 is now 33% ahead, down from 37% before. The 5070 Ti is down to 53% ahead -- still huge, but a gradual reduction from the 4K upscaled gains of 78%.", "Let’s look at something more balanced. Dragon’s Dogma 2 is a game that we’d play with ray tracing enabled, as we do think it looks better, but it’s not nearly as heavy an implementation as Cyberpunk or Black Myth.", "In Dragon’s Dogma 2 with ray tracing and at 4K, the RX 9070 XT ran at 61 FPS AVG.  This has it ahead of the RTX 5070’s 49 FPS result by 26%. The 5070 Ti leads the 9070 XT marginally and by 2 FPS, or 3.6%. The 7900 XTX is about 5 FPS ahead of the 9070 XT.", "Definitely a healthier position than Black Myth, but also not as impressively heavy.", "At 1440p, the 9070 XT ran at 103 FPS AVG and tied the 5070 Ti almost exactly. Again, this is heavier on raster than RT, but this is a better result than historically for AMD. Previously, the 7900 GRE was below the new 5070, with the 7900 XT about the same as a 4070 Ti Super (read ", ").", "1080p puts the 9070 XT as still right around the 5070 Ti and 4070 Ti Super.", "Dying Light 2 is up next, tested at 4K with upscaling as the game is relatively heavy.", "The 9070 XT landed at 46 FPS AVG, which puts it tied with the 7900 XTX and just behind the 3090 Ti. AMD still has a deficit in RT as compared to its NVIDIA competition, with the 5070 Ti leading by 24%. That’s not as obscene as the gap in Black Myth, but it’s still an undeniable victory for NVIDIA. The RTX 5070 ran at 44 FPS AVG here, so the 9070 XT is about 6% ahead. ", "At 1440p, the 9070 XT ran at 89 FPS AVG and tied the 4070 Ti Super and 3090 Ti. It’s marginally ahead of the 7900 XTX, though they’re functionally equal. The RTX 5070 Ti leads the 9070 XT by 16% now, down from 24% at the higher resolution. The 4080 Super and FE were tied with each other and aren’t distant from the 5070 Ti.", "At 1080p, the 9070 XT ran at 129 FPS AVG. The 5070 Ti maintains a lead here, but it’s now reduced to 9.4%. Those are some huge reductions in its advantage as the resolution comes down. NVIDIA is still ahead but has lost significant ground here.", "Resident Evil 4 is up now. At 4K with ray tracing and upscaling, the 9070 XT performs at parity with the 5070 Ti. This is another of the lighter-weight RT titles, so broadly speaking, thus far, games with fewer RT features implemented that lean more heavily on raster allow AMD to compete better.", "The 9070 XT leads the 5070 by 27%, with the 7900 XTX leading the 9070 XT in this one by 16%.", "At 1440p upscaled, the RX 9070 XT ran at 180 FPS AVG and allowed the 5070 Ti a marginal victory. The 9070 XT improved upon the 7900 XT, but not the 7900 XTX. ", "Cyberpunk is up next. We’ll start with the heaviest workload and scale down from there.", "4K and RT Ultra tends to destroy cards with lower VRAM capacity, like the 5070 with its 0.1% lows. Cards like the 2070 (watch ", ") and 2070 Super (watch", ") have been removed this time since they were unplayable and their results were just noise anyway. One could be better than the other just because neither can play the game.", "The 9070 XT landed at 22 FPS AVG. In a relative sense, what matters is the 5070 Ti’s lead of 23.5%. The 9070 XT leads the 5070 by 26% in average FPS, but the 5070 has massive stuttering problems due to insufficient VRAM as it depletes.", "Bringing RT down to Medium but still at 4K, the 9070 XT runs at 28 FPS AVG and lands between the 7900 XTX and 4080. That’s a much better spot to be in. This puts the 5070 Ti ahead by 10%, down from 24% at Ultra. You could then get to a playable framerate with upscaling or by dropping resolution.", "You can see NVIDIA getting embarrassed by its own choices again: The 4070 Ti (read ", ") and 5070 are both crumbling in the 0.1% lows, which is a direct result of the low VRAM capacity. This low 0.1% value manifests as stuttery frame delivery and inconsistent frametime pacing.", "At 1080p but back to RT Ultra, the 9070 XT ran at 71 FPS AVG, 61 1% low, and 58 0.1% lows. The 5070 encroaches on this result at 64 FPS AVG, although the 9070 XT has a slight advantage in 0.1% lows.", "The 5070 Ti leads the 9070 XT by 20%.", "Finally for Cyberpunk, 1080p at RT Medium, the 9070 XT ran at 92 FPS AVG. That reduces the 5070 Ti’s lead back down to 12% from the 20% we saw with RT Ultra and the same resolution.", "We’re getting into efficiency testing now. Efficiency benchmarks are a combination of power consumption and performance, so you’ll get to see both in this testing. We perform the testing with a PMD2 sitting as an interposer between the PCIe slot and the power cables, capturing just GPU power consumption in isolation.", "We’ll start with Final Fantasy 14 as usual; however, this won’t reflect well on the 9070 XT due to its overall low performance in this title. The 9070 XT ends up toward the bottom of this chart. Its power draw was 310W here, pulling less than the 430W of the 7900 XTX, but also producing a lower framerate. This drags down the efficiency, planting it between the XTX and the 3090 Ti. The 7900 XT was more efficient in this particular test, with the 5070 likewise significantly improved on the 9070 XT.", "NVIDIA remains advantaged in efficiency.", "1440p has more cards on the chart. The 9070 XT ends up improved upon the efficiency of the 6600 XT and 6700 XT, up at 0.45 FPS/W, but still worse than the prior XTX, 7900 XT, and NVIDIA’s entire modern lineup. The 5070 Ti is 62% more efficient than the 9070 XT here, up at 0.73 FPS/W. This is not a good result for AMD. It’s burning a lot of power to produce the output.", "Here’s a better test for the 9070 XT. In F1 24 at 4K and with ray tracing, the 9070 XT ran at 0.18 FPS/W. These results round to the second place, so differing bar sizes for the same numbers is normal -- it just means the hidden digits are separating them.", "Anyway, the 9070 XT is more efficient than the 5070 and significantly more efficient than AMD’s prior 7900 XT. This massive uplift and flip over the prior raster Final Fantasy charts comes as a combination of improved performance for the power with the large ray tracing uplift that AMD saw generationally. NVIDIA’s 5070 Ti remains more efficient than the 9070 XT at 0.20 FPS/W, but this is much closer than it was previously and now only has an 11% uplift. That’s more normal.", "At 1080p but still in F1 24 with RT, the 9070 XT ran at 311W and scored 0.51 FPS/W. That puts it ahead of the RTX 4060, the Intel B580, and 42% improved on the prior 7900 XT. NVIDIA’s 5070 Ti maintains an advantage at 266W and 0.62 FPS/W, or a 22% improvement in FPS/W. That benefit mostly comes from its lower power draw to produce comparable performance.", "Dragon’s Dogma 2 with RT and at 1440p is up now.", "The 9070 XT consumed 311W during the course of this testing and calculated to a 0.33 FPS/W result, which makes it better than the 7900 XT and worse than the 5070 Ti. Despite AMD’s gains overall, NVIDIA retains its advantage in efficiency and output for the power used. AMD had to get performance before it could get efficiency though, as these two are part of the same formula. We think their focus should remain on pumping performance with the hope to balance-out the efficiency calculation on that side of the formula.", "Starfield at 1440p is up now. This is without ray tracing. The 9070 XT pulled 310W again here, landing at 0.34 FPS/W and just ahead of the B570 and ", ". The 5070 and 5070 Ti are both more efficient, with the 5070 Ti in particular keeping a massive improvement at 0.48 FPS/W. The performance is comparable on the 9070 XT and the 5070 Ti here, meaning that most of that efficiency benefit comes from the NVIDIA card pulling just 209W to produce almost the same amount of work. This is a good comparison because they’re effectively iso work, or controlled for a nearly fixed output, and so we’ve eliminated the last variable of performance. NVIDIA is simply more effective per Watt consumed. Whether that matters is up to you. ", "AMD is definitely winning in the cost per frame department -- but it has often done this, so now it’s a question of whether it wins by enough.", "NVIDIA currently has 90% of the discrete GPU market share. AMD has 10% with Intel at around 0% still. That’s why it’s so important for consumers that AMD -- and one day Intel -- are able to really compete with NVIDIA. At the same time, AMD and Intel shouldn’t get pity purchases if they haven’t earned it. ", "We’ll see how street prices shake-out for the ", ". The ", " has a problem where its partners aren’t even hitting MSRP, so consumers are getting scalped by the likes of MSI. ", "As a quick recap of performance:", "In rasterization performance and at 4K, AMD's ", " is commonly within the range of 5-6% of the ", ", with a few break-outs like Dying Light 2 and Black Myth non-RT where the 5070 Ti has a 12% advantage over the 9070 XT. As we said earlier, our Final Fantasy 14 results just don't match what AMD presented, but we also run the newest version of the benchmark. Across all resolutions, performance of the 9070 XT approaches levels of the ", " in some benchmarks and is commonly around ", " levels, but often between them. Broadly speaking, the 9070 XT beats the ", " non-Ti and these charts show the summary of some of the 4K and 1440p results we have against the 5070 Ti. These charts illustrate the percent improvement from a 9070 XT to a 5070 Ti. In other words, if the bar is positive and going to the right, then that’s a 5070 Ti victory. ", "As for ray tracing performance, NVIDIA is ahead almost universally in our testing. In Black Myth, it's not even a competition. If you really wanted to play this game and you decided you needed RT for it with heavy settings, you'd basically need NVIDIA. In Cyberpunk, AMD narrows the gap from previous generations, but NVIDIA maintains a large advantage. In games like Dragon's Dogma 2 with RT, the 9070 XT looks much more competitive. The extra VRAM is useful in some heavy situations, such as in Cyberpunk RT with ultra settings where the 5070 starts to struggle under VRAM load.", "In our efficiency testing, NVIDIA maintains an advantage overall. This is derived from both FPS and power, and in many of these cases, the lower power draw serves as the stronger part of NVIDIA's side of the equation (rather than performance). We think AMD's focus on performance before power is the right move. Power is OK for them. It can obviously be better, but running lower power wouldn't be worth losing potentially everywhere on performance. We think they made the right decision on this balancing act and can refine it later.", "And this back-and-forth we’re describing is why it’s been so critical for AMD to get its pricing right. In situations where a purchasing decision between AMD and NVIDIA is unclear for the average consumer -- not most people reading this, but we’re talking about the mass market who don’t even know Gamers Nexus exists -- NVIDIA will remain the “default” choice in the minds of those consumers unless AMD really gives them a reason to pay attention to. For AMD to really get noticed, it has to either win in large ways or be much cheaper, but ideally both.", "With the 9070 XT, we think the $600 MSRP is the minimum that AMD had to do to get some positive groundswell and attention. And it achieved that: there has been a lot of enthusiasm over the last few days, in no small part thanks to NVIDIA continually f***ing everything up. We wish AMD would have come in slightly cheaper on the 9070 XT to really kick in the doors to the mass market, even though that’d hurt short-term margin, just to make sure it can generate some momentum and keep developers integrating its own technologies."]},
{"title": " Incredibly Efficient: AMD RX 9070 GPU Review & Benchmarks vs. 9070 XT, RTX 5070", "paragraph": ["Incredibly Efficient: AMD RX 9070 GPU Review & Benchmarks vs. 9070 XT, RTX 5070", "Last Updated: ", "The Highlights", "The ", " non-XT’s MSRP is $550, with the XT 9% higher at $600 MSRP. That makes the XT version just 9% more expensive. Despite the similar pricing, the 9070 actually remains really interesting on its own.", "First of all, in some of our efficiency tests when looking at performance per watt, it nearly tied for the most efficient GPU. This seems to be in the so-called “sweet spot” of power and performance in what would be a huge upset favoring AMD. The fact that it’s starting to chip away at one of NVIDIA’s key areas of competition is huge. The reason for that is simply because the ", " pulls a lot less power than the ", " by percentage but most of the performance remains.", "Steve Burke", "Mike Gaglione", "Jeremy Clayton", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "The quickest possible version is this: For the ", " vs. the 9070, the XT model is in the range of 9% to 16% better at 4K and 1440p rasterized, but typically is about 11-13% better than the 9070 in our suite of tested games. At 1080p, it’s 6% to 15% better, with most cases around 9% to 11% for the games we tested.", "As for the ", ", it’s not looking good for ", ": At 4K and rasterized, the 9070 leads the 5070 by 0% to 18%, depending on game. It has one loss in Final Fantasy and it has losses in some ray tracing tests, but not all of them, which is interesting.", "The 5070 is basically out of the conversation, so we’re left with the 9070 XT or the 9070 at this price point -- which is what AMD probably wants, because the 9070 is priced in a way that the 9070 XT becomes an easy upsell. That might be to do with yields. If they’re yielding enough XTs that they don’t really want to sell non-XTs, maybe that’s the strategy. ", "We’re not going to spend much time on the specs and architecture today. We’re also going to speedrun the charts and shorten the comparisons. If you want the full depth, check out our ", ". That contains some more discussion of results and some more architectural information. Our ", " about the 9070 series has even more architecture background than that.", "The RX 9070 has 56 Compute Units, with the 9070 XT running 64 CUs. Both are 16 GB cards with GDDR6 on a 256-bit bus. The GPUs have slightly different clocks. Both GPUs get the architectural overhauls of RDNA 4 and there’s no difference there, so the same ray tracing changes apply to the 9070 as the XT. The only real main difference is the move to 56 CUs.", "And that’s sort of it. ", "We’ll save the pricing recap for post-launch -- we want to monitor launch for the next day or two to get an idea of availability of both the 5070 and 9070 series, plus the pricing they land at.", "Let’s just get straight into the data.", "Dragon’s Dogma 2 is up first and at 4K initially.", "In this test, the RX 9070 non-XT ran at 64 FPS AVG, with lows at 54 and 53. The 9070 XT’s 70 FPS result positions it 9% ahead, which is exactly how much higher the base MSRP is.", "Against the equivalently priced RTX 5070, this is one of AMD’s stronger titles: The 9070 Pulse leads the 5070 FE’s 56 FPS AVG by 14% here, with 1% and 0.1% lows improved in-step with the average. The 9070 is achieving 87% of the performance of the ", ", but at 73% of the base MSRP.", "The RX 9070 leads the ", " (watch ", ") by 37% here as well. We’ll look at the 6700 XT elsewhere.", "At 1440p, the RX 9070 ran at 106 FPS AVG, with the 9070 XT leading it at 116 FPS (or 9.3%). The ", " is only a few FPS higher than the 9070 XT, with the 4080 Super (read ", ") just beyond that. In short, the 9070 is achieving 88% of the 4080 Super’s performance, which was a $1,000 card, but at 55% of the original MSRP. Despite our wishes that the 9070 were $50 cheaper, this at least helps to slowly reset the runaway pricing that NVIDIA set in motion. This gives everyone some perspective.", "For some comparisons against prior generations: The 9070 improves on the 67 FPS result of the ", " (watch ", ") by 59%, the 53 FPS result of the 6700 XT by 100%, and the 42 FPS of the 6600 XT by 152%.", "Here’s 1080p. The old GTX 1060 and 1070 also appear on this chart to give some insight into upgrades, though anything modern would be better. There’s no point getting into percentages for those: They go from unplayable to playable.", "The RX 9070 is about tied with the ", ". The 9070 XT still leads by around 8%, with the 5070 Ti (read ", ") ahead of the 9070 by 13%. The 9070 leads the RTX 5070 DOA edition by 6%. The lead over the 6700 XT is 96%, with the improvement on the 6600 non-XT’s 49 FPS result at 173%.", "Final Fantasy 14: Dawntrail is up now. We included this same disclaimer and disclosure in our ", ", but to recap: We’ve noticed lower performance for the 9070 series specifically in Final Fantasy XIV: Dawntrail, including lower results than AMD’s own claims. We’ve had highly reliable results in this benchmark and our RX 9070 series data has been repeatable across multiple retests, so we’re publishing it, but we just want to highlight that there is disproportionately low performance for the 9070s and that it is something we’re investigating. It’s possible it could be the specific scene, benchmark version, or just the architecture’s behavior here. But the results are repeatable, so we’re running them.", "At 4K, the RX 9070 continues the scaling pattern set by the 9070 XT. The XT is again 9% ahead. ", "The 5070 FE leads both of the cards in this test, running at 78 FPS AVG and improving upon the 9070’s result of 63 FPS by 24%. Against the prior generation, the 9070 XT sees a smaller improvement on the 6700 XT of 53%. ", "At 1440p, the 9070 ran at 126 FPS AVG. The 9070 XT is 10% ahead here, with the 5070 ahead by 21%. Improvement over last generation is non-existent, with the ", " right next to the 9070.", "Resident Evil 4 is up next, tested at 4K first.", "The 9070 ran at 91 FPS AVG here, creating a 13% lead for the 9070 XT and its 103 FPS result. The 9070 XT was excitingly right next to the 4080 Super’s 105 FPS in this game, meaning that the same $1,000 4080 Super result leads the $550 MSRP 9070 by only 16%. That’s a paltry gain for such a huge price difference, especially given how new the 4080 Super is.", "AMD’s 9070 exceeds the performance of the same-MSRP RTX 5070’s 78 FPS by 16%. If NVIDIA would stop remaking ", "s (read ", ") and 4080s, they might actually make some progress here.", "At 1440p, the RX 9070 ran at 172 FPS AVG and outperformed the 3090 Ti. ", "The 9070 XT outperforms the 9070 by 13%, with the 5070 Ti only slightly beyond that result.", "Against the 5070’s 152 FPS AVG, the 9070 runs 13% ahead. The 5070 really does look even more DOA than previously in some of these tests. If it were a dead horse, it’d be getting kicked right now.", "1080p is up now. The 9070 ran at 247 FPS AVG here, which had it between the ", " (watch ", ") and ", ". The 5070 still trails, now giving the 9070 a lead of 10%.", "The XT model maintains about a 12% advantage over the non-XT.", "Black Myth: Wukong is a much more challenging title for AMD to run, but mostly with ray tracing. Either way, there should be some more favor for NVIDIA here. Even without RT, it’s a heavy game. The ray tracing tests will come later.", "At 4K and rasterized, the RX 9070 ran at 41 FPS AVG against the 9070 XT’s 46, giving the latter a lead of 11%. The ", " sits ahead of the 9070 XT. The 9070 ends up still leading the RTX 5070, albeit on a technicality, which is actually a huge victory for AMD in this particular title. That’ll change with RT, but this is a good position overall in raster.", "At 1440p, the RX 9070 held 75 FPS AVG with well-paced lows, sitting at 65 and 60 FPS for 1% and 0.1%. This is consistent (and good) frametime pacing, but it’s about the same as all of its neighbors, so nothing exceptional.", "The 5070 ran at 72.1 FPS AVG. The difference between the two cards is imperceptible and shows up in measurements, but would not be noticeable to an end user. ", "The 9070 XT’s 83 FPS result has it again about 11% ahead of the 9070, so that’s pretty predictable now.", "To just highlight some landmarks: The 2060 ran at 25 FPS and tied the RX 6600, the 6600 XT ran at 29 FPS AVG, and the 3060 ran at 31 FPS AVG.", "At 1080p, the 9070’s 104 FPS AVG allowed it to finally start gaining some distance on the 5070. It’s not a meaningful swing at 6% improved, but is in favor of the 9070. If AMD were $50 cheaper, it’d be a clear victory. Unfortunately for AMD, a tie will often be decided in NVIDIA’s favor by most buyers, especially with the complications of RT and software suites. But still, beating the 5070 in this game is an achievement for the 9070.", "Starfield is up now, tested at 4K. In this one, the RX 9070 ran at 63 FPS AVG and roughly tied the RTX 4070 Ti Super. The 9070 outperforms the RTX 5070’s 54 FPS AVG by 17%, which is starting to be wide enough that NVIDIA needs to be concerned…if they basically weren’t a monopoly. The 5070 Ti falls below the 9070 XT in this one and only leads the non-XT by about 6 FPS. Hardly enough to spend $200 more for. The proximity to the 4080 (watch ", ") and 4080 Super also isn’t great news for NVIDIA.", "At 1440p, the RX 9070 ran at 96 FPS AVG and nearly tied the 4070 Ti Super again. The 5070 Ti outperforms the 9070 by a lame 5.4%, with the 9070 XT outperforming the 9070 by 10%. ", "Against the 5070’s 83 FPS AVG, the 9070 leads by 15%. If the 5070 weren’t already in the grave, we’d pronounce its impending demise. We might want the 9070 to be a bit cheaper just to see that balance for the times it loses or is tied, but even without that, we can’t deny that AMD is putting up its best fight against NVIDIA in years.", "At 1080p, the 9070 runs at 118 FPS AVG. The relative rank hasn’t moved much. It leads the RTX 5070 by 14% here, so the lead has slightly reduced, but it’s still ahead. The 9070 XT leads the 9070 by 8%.", "In Dying Light 2 at 4K, the RX 9070 ran at 56 FPS AVG and kept lows remarkably close by, at 50 and 41 -- but not in any more remarkable way than all of its neighbors. This game is just consistent.", "The 9070 ends up tied with the 5070. There is no difference between these two and, in these situations, NVIDIA will generally be viewed more favorably by a mainstream audience. That’s where the price would come in, or hopefully awareness of the other results.", "The 9070 XT leads the 9070 by 11%, so you’d be paying 9% more at MSRP for about 11% more performance.", "This is one of the games where the 5070 Ti pulled ahead of the 9070 XT in a noteworthy way, so we see some of that apply to the 9070 and 5070.", "At 1440p, the 9070 runs at 106 FPS AVG and ties the 5070 again. They’re within error of each other. The 9070 XT outperforms the 9070 by 11%, with the 5070 Ti still ahead of the XT. Generationally, we’ll just briefly highlight the RX 6600 (watch ", "), RTX 2060 (watch ", "), and RTX 3060 (watch ", ") as reference points to some of the most common GPUs of past generations. Those should give you an idea of the performance gains.", "Cyberpunk is up now. This one has generally been tough for AMD in the past, but is harder for it with ray tracing. We’ll start with rasterized testing and at 4K.", "The results are thus far positive: We already knew that the 9070 XT outmatched the 5070 Ti, but now the 9070 is nearly tying the RTX 4080. That’s just embarrassing for NVIDIA’s last-gen mid-range-posed-as-a-flagship GPU as compared to a $550 card. The 9070 technically outperforms the ", " as well, though is basically tied, and the lead over the 5070 is 15% again. ", "At 1440p, the 9070 now falls slightly below the 7900 XT, so they’ve traded places as resolution came down, and the 5070 has also gotten closer. The 9070 is now about 11% ahead of the 5070 rather than 15% before. The 9070 XT leads the 9070 by 11% and the 5070 Ti slightly.", "In Phantom Liberty at 1080p now, the 9070 landed at 148 FPS AVG, allowing the 7900 XT (watch ", ") to maintain its slight lead. The improvement in the 9070 over the 5070 is now down to 7% from 15% at 4K originally. If we dropped it down to 360p, based on this trend, NVIDIA might actually pull ahead. Great. Just like they’ve wanted -- maybe that’s the push for DLSS.", "Ray tracing is up. This is where AMD has invested heavy effort with its architecture but all of it has been to try and catch up. NVIDIA was so far ahead in some games that AMD won’t be able to catch them in all scenarios. The real question is how much closer do they get this time.", "We’ll start with AMD’s worst case: Black Myth - Wukong, but now with ray tracing and at 4K with upscaling.", "The 9070 ran at 26 FPS AVG here, so outdoing the 3070 Ti (watch ", ") but below the 3080 (watch ", ") from 2020. The 3080’s original MSRP was around $700, although that really only held for a week or two before COVID-era scalping went crazy.", "The 9070 XT outdoes the 9070 by 14% here. This is too low of a framerate to be playable, but we do the test for relative scaling and percent scaling.", "The RTX 5070 crushes the 9070 here, holding a 57% lead over the AMD GPU. The 5070 Ti’s scaling over the 9070 XT was better and nearly 80%, but 57% is still huge for the 5070 over the 9070. If you want to play Black Myth with ray tracing, like we said in the ", ", you basically only buy NVIDIA.", "Lows are where NVIDIA will struggle the most for 5070 VRAM capacity. In this particular test, we aren’t hitting VRAM saturation; however, we have shown instances where the 5070 hits saturation with heavy workloads and higher resolutions, leading to heavy stutter like in the Cyberpunk RT 4K scenario.", "At 1440p upscaled, the 9070 pushed 47 FPS. This gave the 9070 XT about a 6 FPS lead, nearly tied the 3080, and outperformed the 3070 Ti and ", " notably. The improvement over the 7900 XTX (watch ", ") shows that AMD has actually executed on its RT performance uplifts.", "But unfortunately for AMD, the 5070 remains superior with a 73 FPS AVG. It leads the 9070 by 55%.", "At 1080p, the 9070 measured at 67 FPS AVG and pushed past the 3080. The 9070 XT leads by 9%. The 5070 leads the 9070 by 46%, so it’s slightly reduced, but still has an unbeatable lead.", "Dragon’s Dogma 2 with ray tracing is next, tested at 4K first. We measured the 9070 at 56 FPS AVG, giving the 9070 XT a lead of 9%. The 4080 isn’t much past that, so for as close as these cards are, they’re also very close to the 4080 and 4080 Super. The 5070 trails in this one, giving the 9070 a lead of 15%.", "At 1440p, the 9070 gets dangerously close to NVIDIA’s 5070 Ti, which failed to pass the 9070 XT in the ", ". The 5070 Ti leads the 9070 by 9%, the same lead as the 9070 XT has against it. The 5070 non-Ti is down at 83 FPS AVG, creating a 13% lead for the 9070.", "This chart has entries for the 6700 XT (watch ", ") and other prior GPUs.", "At 1080p, the 9070 ran at 119 FPS AVG and led the 7900 XT by a few frames per second. The lead over the 5070’s 107 FPS AVG was 11%. The 9070 XT has a reduced lead over the non-XT at this resolution, now just 6% ahead of the cheaper card.", "Dying Light 2 with upscaling at 4K is up now, this time with ray tracing. The 9070 XT leads the 9070 by a higher-than-average lead of 16% here. The 9070 ends up below the 5070 in this one also, with the 5070 producing a lead of 9% over AMD’s most relevant card. ", "At 1440p, the 9070 runs at 78 FPS AVG and gives the 9070 XT a lead of about 10-11 FPS. The 9070 XT’s prior 16% lead is now reduced to 14%. The 5070 is also reduced to a 4% lead from a 9% lead at 4K. The 9070 was really struggling with the 4K resolution.", "Finally for this game, 1080p puts the 5070 at just 1 FPS ahead now, so basically margin of error. The 9070 XT leads the 9070 by 13%.", "In Resident Evil 4 with ray tracing and at 4K upscaled, the 9070 held a 104 FPS AVG and outperformed the 4070 Ti Super and 5070. The boost over the 5070 is 14% here. The 9070 XT ran 12% higher framerate than the non-XT, with the 5070 Ti basically tied with that.", "This chart has a lot of cards lower down the stack, like the 2060 (watch ", "), 3060 (watch ", "), 2070 (watch ", "), and 6700 XT for past generation comparisons.", "At 1440p upscaled, the 9070 ran at 162 FPS AVG and roughly tied the prior 7900 XT. The 9070 XT was 11% ahead of the non-XT here, with the non-XT ahead of the 5070 by 9%.", "Cyberpunk is up now, one of the two heavier titles we test for RT. We test this one at two groups of settings: Ultra and Medium, chosen because NVIDIA gains a disproportionate advantage at Ultra, while Medium pushes them closer together. That gives us the full picture.", "At 4K and RT Ultra just to stress test it for relative scaling, the RX 9070 ran at 18 FPS AVG. Obviously this is unplayable, but this makes the point we made in our ", ": The 0.1% lows suffer on the 5070 in a big way. That’s because they’re indicating to us that underneath those lows, which really are just meant to be an indicator of a problem, there’s spiky and erratic frametime performance. This is caused by exceeding VRAM limitations on the 5070, which simply isn’t equipped enough to deal with these problems.", "At 4K Medium, the 9070 boosted up to 24 FPS. No change in how playable it is, but even this lighter-weight workload is too much for the 5070 FE’s capacity, which you can again see in its lows.", "The 9070 XT leads the 9070 by 15% here, one of the higher percent increases.", "Reducing the resolution helps reach playable framerates. At 1080p and RT Ultra, the 9070 held 61 FPS AVG against the 9070 XT’s 71. That’s a relatively large advantage of 16% for the 9070 XT.", "The RTX 5070 ran at 64 FPS here, outdoing the 9070 by just 5.7%.", "Finally for games, the Cyberpunk 1080p/Medium results put the 9070 at 81 FPS AVG, roughly tying the 7900 XTX. This also puts it above the 3080. The 5070 ran at 81.9 FPS AVG and lows were within error of the 9070. There is no distinct advantage in lows for the 9070 here. Average is the same, which is a major positive for AMD when considering its previous RT deficit.", "We’re moving on to power and efficiency testing now, which looks at both the total power consumption of the device during the test and the frame rate. The end result is that we can calculate the efficiency in performance per Watt. It’s actually a really exciting test for the 9070. ", "In F1 24 at 4K and with RT, AMD has exceptional performance. These are only showing two decimals, but more are processed for the bar width. The 9070 roughly tied with the 4080 Super and ", " (beware of scalped prices) as the most efficient GPU in our test suite.", "The 5070 was at 0.17 FPS/W, giving the 9070 an advantage of 24%. That’s a huge swing in its favor. The 9070 XT was closer to the 5070.", "At 1080p but with the same settings and game, the 9070 again ends up just behind first place. It’s tied with the 5070 Ti and just behind the 0.64 result of the ", " (read ", "). The 9070 XT burns more power and, although its performance is better, the tradeoff favors the 9070 here. The 5070 ends up way down the ranks, at 0.55 here.", "Final Fantasy 4K is up next. This is one of AMD’s weaker showings given its limited performance scaling in Final Fantasy 14.", "The 9070 pulled 224W during this test when measured at the PCIe cables and the slot. The 5070 pulled 10W more, but had better efficiency from its higher performance. The end result is that the 9070 outdid the 7900 XT for efficiency, but gave the 5070 a lead of about 18%. For reference, the 9070 XT pulled 310W here, roughly matching their TDPs.", "At 1440p, the 9070 ranked at 0.56 FPS/W with a 224W draw. That has the 4060 as more efficient, the ", " slightly less efficient, and the 7900 XT also slightly less efficient. The NVIDIA 5070’s 0.65 FPS/W result outdoes the 9070 again here, but we’ll see if that persists outside of AMD’s weakest rasterization title.", "Dragon’s Dogma 2 with RT shows exceptional efficiency for the RX 9070, at 224W again and 0.42 FPS/W, it’s looking pretty good overall. The performance is slightly lower than that of the 9070 XT, but the reduction in power really puts it in a better spot on the efficiency curve. It seems like this is more of the so-called “sweet spot” for power to performance. The 5070 is down at 0.36 FPS/W, despite pulling 231W.", "In Starfield at 1440p, the 9070 is less impressive than in F1 and Dragon’s Dogma 2, but still overall good. Its result was 0.43 FPS/W, a large improvement on the 9070 XT’s 0.34. The 9070 ties the RTX 5070, which is a problem for NVIDIA because efficiency was one of NVIDIA’s main benefits with the 5070 Ti against the 9070 XT so if AMD is starting to chip that away, that’s bad news for NVIDIA. That’s kind of one of the key things the company has stood upon for being more expensive in the past. ", "First, the ", " gets credit for being relatively power efficient. It’s basically tied at the top in a few of our charts, though not all of them, but it’s looking better there. In our ", ", we said that AMD’s decision to favor performance over cutting power was the right move for the company right now. We think that remains true for the card that’s supposed to be its flagship, but for the ", ", the power cut helps create the difference between the cards to begin with, but the baseline performance is high enough that it ends up in a great efficiency position.", "The ", " ends up ahead of the 9070 by about 9-12% in most of the games we tested, with the ", " generally giving the 9070 a lead in several games. Dragon’s Dogma 2 at 4K was playable on both, but the 9070 had about a 14% advantage over the 5070. The 9070 also led the 5070 by about 15% in Cyberpunk rasterized at 4K, with the ", " ahead of the 9070 by 12%. There remains the one break-out for the 5070 in Final Fantasy, something we talked about in our ", ", but beyond that, for rasterization, the 9070 is ahead in basically every scenario.", "Baldur’s Gate 3 even showed a large benefit at 4K for the 9070 versus the 5070 since we’re far enough away from the CPU bottleneck.", "In ray tracing at 4K, the 9070 XT ended up around 9% to 19% higher framerate than the 9070, though that 19% number is based on low framerate, but even still, 17 is the next highest percentage. 1440p and 1080p weren’t that different and can be found in the charts section earlier. As for the 5070 in RT and 4K, the 9070 beat it by 15% in Dragon’s Dogma 2, 8% in F1 24, 6-7% in Cyberpunk, and 14% in Resident Evil 4. The 9070 lost in Black Myth and Dying Light 2 with RT. At 1440p and RT, the same losses exist. This points non XT and XT in a similar position to what we saw with the ", " and the ", " or the ", " and ", ". The gap is small enough that most people will upsell themselves to the XT model. ", "Weirdly, NVIDIA’s own fumbles have sort of made the proximity of the two cards less of a problem than they otherwise might have been. Because from AMD’s perspective, it’s either AMD or AMD. They probably don’t really care that much which version you buy, but the XT makes more sense than a ", " does. The 5070 is already mostly irrelevant. NVIDIA’s strengths like DLSS, ray reconstruction, and Reflex all remain, of course, but we don’t think the bells and whistles are good enough on the 5070 to outweigh the 9070 or the 9070 XT. The biggest strength it probably has is CUDA, which we personally leverage for things like video editing. But for gaming, the 9070 and 9070 XT have really kicked the 5070’s ass (though it really kicked its own ass)."]},
{"title": " RIP Intel: AMD Ryzen 7 9800X3D CPU Review & Benchmarks vs. 7800X3D, 285K, 14900K, & More", "paragraph": ["RIP Intel: AMD Ryzen 7 9800X3D CPU Review & Benchmarks vs. 7800X3D, 285K, 14900K, & More", "Last Updated: ", "The Highlights", "AMD’s ", " review embargo lifts today. The 9800X3D is a Zen 5 CPU with extra cache, but with critical changes to the location of the cache within the die stack. ", "As we talked about in a ", ", the 9800X3D has shifted the extra cache under the core complex, leading to more direct contact from the CPU cores to the IHS lid underside. AMD has also eliminated some of its bonding layers within the CPU, which reduces insulation further, and it has removed the structural silicon that leveled the top of the cache die to better mate the IHS in prior X3D designs. That’s because the extra cache die and the core complex die are now the same physical dimensions.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "The 9800X3D is a $480 MSRP part for the AM5 platform. Let’s get into the review.", "The only way AMD could screw up this launch would be with the price, so let’s start with a price comparison and update. This was all collected in the days leading up to review publication.", "The 9800X3D’s MSRP is $480. It’s not listed as we write this.", "Assuming that price is accurate, some of its direct neighbors and competitors include the others on this list. The ", " is about $476 now and is out of stock with a listed former price of $450 on Newegg. The 7800X3D (watch ", ") has previously been as low as $300 to $330, with drops in August to around $360. Lately, its price has stabilized higher. We have a policy of making comparisons against pricing at the time of the review, so we’ll use the $476-$480 figure today.", "The ", " is priced at $187 to $230. The 7950X (watch ", ") is a similar price to the 9800X3D, landing at about $500. That’d be one to pay attention to for non-gaming workloads.", "Intel’s competition includes the ", ", to the extent you can even call it “competition,” seeing as it barely competes with Intel’s own parts on value. The 285K(read ", ") is $630 where it can be found, and you shouldn’t buy it, with the ", "(watch ", ") at $400. The prior generation parts, like the ", ", have fallen in price lately. That’s at $440, with the ", " at $347.", "We have a lot to get through, so let’s get into the benchmarks. We’ll have frequency, gaming, efficiency, and production tests.", "We’ll start with a comparison of frequency against the ", ". This will help explain the performance differences we’re going to see today.", "In an all-core workload with Blender, we observed the 9800X3D maintaining an average all-core frequency at a fixed 5225 MHz without any dropping. The stability and flatness of this frequency is a result of the higher power limit, which is allowing the core all the power it needs to maintain this boost.", "The 7800X3D averaged between 4800 and 4890 MHz during the original review cycle for this same test. It’s significantly lower and less fixed, shown by the line’s variability.", "In a single-thread comparison with Cinebench, the 9800X3D also held a maximum single-core boost of 5225 MHz throughout the duration of the test. The 7800X3D held at 5050 MHz in the same test as a maximum single-core frequency.", "Between these two tests, the 9800X3D holds a significant frequency advantage over its predecessor in both all-core and single-core loads.", "We also ran a voltage ID comparison just with software. In Blender, the 9800X3D held a VID of 1.18V on average, with the 7800X3D at about 1.07V. The 7800X3D is power limited and also running at lower clocks, which combine to yield a lower VID.", "Using the same Blender all-core workload, we measured a Tdie CPU temperature of approximately 77 degrees Celsius in a 21-degree Celsius environment when using a 360mm Liquid Freezer II at 100% pump and fan speeds. CPU die average was similar.", "The L3 cache plotted just over 50 degrees Celsius, with the CPU IOD temperatures around 41 degrees with hotspot readings at about 50 degrees.", "The 9800X3D cannot be directly compared to the 7800X3D thermally by using internal sensors picked up by software. It would be erroneous without accounting for the changes AMD has made in its sensors. The AMD temperature sensors have been relocated within the silicon and moved to cooler locations to prevent clock dropping too early. We talked about this in our ", " and provided a controlled comparison so you can better understand why the sensor readout isn't directly comparable between the architectures.", "It can be directly compared to the ", ", though. The ", " pulls less power in this test and so will be cooler, but it’ll still help to compare. The 9700X (read ", ") ran a Tdie of about 52 degrees Celsius under the same test conditions and with the same cooler.", "With PBO maxed-out on the 9700X, we saw about a 13W higher power draw than the 9800X3D stock. This landed the 9700X at about 86 degrees Celsius. It isn’t perfectly comparable because the power isn’t exactly matched and we ultimately don’t have an easy way to directly compare the 7800X3D’s thermals from the cache change without solutions that require more time than AMD gives in a review cycle. Even still, the key takeaway is that the 9800X3D is not burning the cores at excessive temperatures even with the stacked solution.", "Let’s get into gaming benchmarks.", "Stellaris is a 4X game that we test for simulation time rather than framerate. Lower is better, with the result measured in seconds.", "Zen 5 has already shown advantages in this test, with the 9700X previously scoring the new top rank in the benchmark and outmatching all prior CPUs. Core count has limited benefit in this beyond 8 cores for AMD, but IPC and clocks seem to matter.", "The 9800X3D absolutely crushes the prior top result, with a 25.8-second result against the 9700X’s already barrier-breaking 30.3-second result. This previously appeared to be a limitation of the memory, which we can see reinforced by the 31.1-second 285K result at DDR5-8600 vs. the stock result at 32.5. ", "The original X3D CPU with the 5800X3D (watch ", ") posted a 35.4-second result against the 40.7 result of the ", ", so we’re seeing a repeat of that era, which was also impressive. ", "The 9800X3D also reduces the 7800X3D’s simulation time by 17.6%.", "Intel’s best showing is the 285K with faster memory, but that’s not a like-for-like comparison as we could boost memory on AMD also. The 285K stock required 32.5 seconds to complete the simulation, meaning the 9800X3D reduces time required by 21%. The ", " shows why we haven’t retested it, underperforming overall for reasons explained in our ", " of the part. Even with the new data, it underperforms vs. the 7800X3D.", "The ", " and ", " are effectively tied and within error of each other, and removing any limits wouldn’t change that much.", "This is a great showing for the 9800X3D.", "Dragon’s Dogma 2 is up now, another of our 2024 titles. This game, even with all its updates to improve CPU performance, is still heavy on CPUs. The 9800X3D distances itself from the 7800X3D with a 16.2% uplift, gaining on the original 111 FPS AVG to an impressive 129 FPS AVG. We reran this one multiple times to ensure the result was right, but it ended up not even being our biggest gain in the suite.", "The gain on the 14900K (read ", ")was about 17%, up from 109.6 FPS AVG. The same is true of the prior 5800X3D. Over the 285K, we saw a 23% uplift. ", "Frametimes were improved in this game, but not as much as we saw in some other games. The improvement is more or less proportional to the average framerate, so there is no particularly impressive divergence in lows. In other words, it tracks with what we’d expect of a 129 FPS AVG.", "Final Fantasy 14: Dawntrail is up now, released this year. The 9800X3D breaks the previous upper bound of the chart. ", "Let’s run through the flagships: The 9800X3D CPU ran at 373 FPS AVG, which has it at 5.6% higher framerate than the 7800X3D while costing the same as the current 7800X3D pricing at time of writing. The 14900K ran at 310.3 FPS AVG, giving the 9800X3D a massive lead of 20.2%. This is one of the games where the new Arrow Lake CPUs are hugely regressive and impressively bad value, so the 285K’s 270 FPS AVG gives the 9800X3D an overwhelming lead of 38.3% higher average framerate. As for the 5800X3D, the lead is 11.8% over the prior AMD gaming flagship’s 334 FPS AVG.", "For some anchors to older parts: The R7 2700 (read ", ") and 2600 (read ", ") were around 145 to 150 FPS AVG, with the 2600 benefiting from a frequency advantage. The 3600 (read ", ") was at 170 FPS AVG. The Intel ", " is down at 186 FPS.", "For frametimes, we observed overall similar frame-to-frame intervals for the 9800X3D and 7800X3D. Typically, they oscillate between 2ms and 4ms intervals, where 16.667ms would be 60 FPS. The spikes are what matter: The 9800X3D in this title has slightly shorter excursions from the mean than the 7800X3D. The difference is hardly perceptible, but on a technicality, the 9800X3D does deliver more consistent frametimes in this title.", "Baldur’s Gate 3 from 2023 is up next. We want to caveat this one with a disclaimer: We saw a larger than typical gain in the 9800X3D versus the 7800X3D for this. After we spent a day troubleshooting it, we have come to the conclusion that there is no evidence to suggest any testing errors or uncharacteristic issues caused by the test or game itself, so we’re going to run the data because it’s interesting. We’d pull it if we had any substantiated concerns. We checked with two other reviewers in peer review, ran HWINFO logging, reran the tests multiple times on both the 9800X3D and 7800X3D, and came to the same conclusions.", "The game has the 9800X3D way up at 160 FPS AVG, leading the 7800X3D by an obscene 26.9%. The 7800X3D in both our shown dataset and our unshown additional tests have it in the 124-126 FPS range. This was one of the games we double-checked and got the same results each time.", "The 14900K ran at 105 FPS AVG, giving the 9800X3D a crushing advantage of 53.2%; the 7800X3D already had a lead over the 14900K of around 21%, depending on which data set we looked at. ", "The 9800X3D leads the 285K’s 100 FPS AVG by 60%. Against the 5800X3D, we’re seeing a boost of 33.3% from the prior 120 FPS AVG.", "Baldur’s Gate 3 frametimes for the 9800X3D also improved over the 7800X3D, and this time, it wasn’t just proportional to the average uplift. Here, you can see the 9800X3D maintained a tighter frame-to-frame interval with reduced amplitude of excursions from any given prior frame.", "Because this was such an outlier, we ran HWINFO logging against the test as a separate run. ", "In this test, the 9800X3D average all-core frequency was about 5225 MHz, which is impressive for all-core. We think this is why the performance is so disproportionately good: There’s a much higher power budget, so we’re not trimming the frequency peaks, and the power consumption itself overall isn’t excessive in this game. The two combine for full boosting.", "Plotting the 7800X3D, we see a much spikier, less predictable average all-core frequency that bounces between 4500 MHz and about 5050 MHz under load. The highest single-core frequency is also variable. This is contributing to the behaviors discovered in this test. ", "In Rainbow Six Siege, the 9800X3D landed at 643 FPS AVG and led the 7800X3D’s 622 FPS result by 3.4%. There are limited gains to be found in a game already over 600 FPS. We’d have to re-evaluate this with whatever flagship NVIDIA puts out next to try and find the true CPU ceiling. It at least gives perspective that you may not see big differences in heavily bound scenarios.", "The 14900K ran at 586 FPS AVG here, so the 9800X3D has a 10% improvement. The new X3D part is also about 10% over the 285K. Compared to the 5800X3D, the 9800X3D gains 12% in AVG FPS.", "We removed some other CPUs from this one to make space for APO on results. As a reminder, APO is now doing little for performance in any of our tests. This includes Rainbow Six, which previously saw larger impact. The 14900K is about 10 FPS different with APO on. The 285K saw change only within error and run-to-run variance so it’s irrelevant.", "Starfield is up now, a 2023 title.", "In this game, the 9800X3D leads the 7800X3D by 16%, impressing once again generationally. The new result is 169 FPS AVG to the 145 FPS of the 7800X3D.", "The 14900K is led by 24.6% with its 135 FPS result. The new 285K did a little better than the 14900K in this game, at 143 FPS AVG. That’s still an 18% higher average framerate for the 9800X3D. Even with the DDR5-8600 memory in Gear 2 with the 285K, it still caps-out at 152 FPS AVG. That was a great result, but the 9800X3D puts things into a new perspective.", "Against the prior AMD 5800X3D flagship and its 128 FPS result, the new 9800X3D has a 31.4% uplift.", "Some quick reference older parts include the 2600 at 59 FPS AVG, the 2700 at 66, the 3600 at 70, and the ", " at 71 FPS.", "F1 24 is another of the games with a lower boost over the 7800X3D. The 9800X3D ran at 464 FPS AVG here, a 5.8% improvement on the 438 FPS result of the 7800X3D. The 14900K ran at 385 FPS AVG, so that’s about a 21% uplift for the 9800X3D. The 285K was massively regressive in this game and was down at 344 FPS, giving the 9800X3D a 35% advantage. ", "Against AMD’s flagship from the 5000 era, the lead is 18.6% over the 391 FPS result of the 5800X3D.", "Total War: Warhammer 3 is one of the older games we test, but is important for perspective on GPU and memory bottlenecks.", "The 9800X3D ran at 490 FPS AVG, which is within error of the 7800X3D. These two are bound by the same bottleneck, which is the GPU in this situation.", "There’s only a 5% lead over the 14900K due to the same limitation, with an 8% advantage over the regressive 285K. The 5800X3D ran at 457 FPS AVG, so a 7% gain for the 9800X3D. The ", " with its recent rerun we ran landed it up alongside the 14700K (read ", "), with both encountering the same bottleneck as the ", " and the 7800X3D. Sometimes people ask why a 13700K could be better than a 14700K. It isn’t: It’s just that we can’t actually see unbound scaling, limiting the usefulness of this test. ", "This game has 0.1% low issues with the i9 CPUs due to their thread count. We don’t test community FPS mods, so it’s up to the devs to fix this.", "We’ll now get into efficiency testing, then production benchmarks. This testing looks at CPU performance per Watt, typically presented as FPS/W for games (which would be frames per joule). We’ll start with MIPS/W for 7-Zip, though.", "These tests look at a simple formula of the power in Watts drawn versus the performance of the task. Adjusting either of the two parameters has an impact on results.", "In 7-Zip compression, the 9800X3D computed to 1298 MIPS/W, or millions of instructions per joule, putting it barely ahead of the ", ". The increased power consumption of the 9800X3D reduces its efficiency as compared to the lower power 9700X, at 81.6W to 98.4W. The 9700X scored 1389 MIPS/W.", "The 9800X3D ends up relatively efficient in compression, but less efficient than the prior 7800X3D. The 7800X3D was not a higher performer, but because this is a calculation of both power and performance, either one can help to counterbalance a deficit in the other.", "Meanwhile, Intel’s 285K measured at 1051 MIPS/W, which is improved upon its prior efficiency performance in the 14900K, which was way down at 672 MIPS/W. That’s with the EPS12V and ATX12V line measured on the 285K. The AMD CPUs do not pull from ATX12V in any meaningful way in our testing. The PCIe slot is isolated, as are fans and RGB LEDs. 5V from I/O is also isolated. This means there is some overhead in ATX12V on Intel from the RAM and other small devices, but nowhere near enough to meaningfully move that needle closer to AMD.", "Decompression efficiency is up now.", "In this one, the 9800X3D ends up at 1482 MIPS/W, just under the 5600X (which is benefitted by its 60W power reading) and above the 7950X at 183W. The 7950X in ECO mode is more efficient for its trade outperformance, down to 133W and now at 1936 MIPS/W. The ", " boosts higher, mostly because its power draw drops even more -- now at 124W for 16 cores. The 7950X could also be limited to 124W and would achieve a similar score.", "The 7800X3D is more efficient than the 9800X3D due to its lower power consumption, but its performance is also lower. The 9800X3D trades efficiency for more boosting headroom. This benefits it in the gaming tests we saw earlier, despite costing more power.", "Intel’s closest CPU is the 285K toward the bottom of the chart, at 162W in the same test and 1194 MIPS/W.", "Moving on to games, we’ll start with Baldur’s Gate 3.", "Baldur’s Gate 3 positions the 9800X3D as the new king of efficiency in the test, with a 2.4 FPS/W result that has it just above the 2.3 FPS/W result of the 7800X3D. The 7800X3D utilizes about 13W lower power as averaged, resulting in a smaller gap than we might otherwise see. The 9800X3D at least maintains AMD’s trend of X3D parts becoming new efficiency leaders in gaming.", "Intel’s CPUs first appear with the ", " at 1.3 FPS/W. The 285K is below that, at 1.1 FPS/W, followed by Intel’s last generation parts.", "Starfield efficiency is up now.", "The 9800X3D is almost at the top, but not quite. Its performance gains were relatively high in this game, but the power consumption increased significantly. The 9800X3D averaged at 98.7W, with the 7800X3D at 69W. This is what leads the 7800X3D to a victory in this test, despite the performance uplift. AMD has lost efficiency here.", "Intel’s CPUs first appear at the 285K, down at 1 FPS/W. The 14900K is at about 0.7 FPS/W.", "Stellaris is something of a repeat of that: The 9800X3D pulled 54W on average, leading it to a 2.6 simulations per Watt-hour score. The 7800X3D ended up at 2.7, or about a 4% advantage in efficiency despite a reduction in performance compared to the 9800X3D. The 12W lower power leads to this discrepancy.", "Intel’s closest part is the ", " at 1.9 simulations per Watt-hour, with the 285K at 1.5.", "Final Fantasy 14 is last for efficiency comparisons in gaming.", "For this one, the 9800X3D ranked at 7 FPS/W, which has it below the 5700X3D (read ", ") and 7800X3D. The CPU pulls just under 54W on average, while the 7800X3D ran at about 43W and the 5700X3D ran at an impressive average of just 39W. Despite higher performance, the higher power tips the scale away from the extreme efficiency we’ve seen in previous X3D parts.", "It’s still relatively high in the ranks, above everything Intel and above AMD’s non-X3D parts, but it’s clear that AMD favored an increase in power for an increase in performance as it tries to balance between.", "Production benchmarks are next. These tests look at a suite of applications outside of gaming. The 9800X3D is ultimately a gaming CPU. Our non-gaming tests do not regularly show advantages for extra cache.", "Blender is up first for a 3D rendering pass of our intro animation.", "The 9800X3D completed the frame render in 12.5 minutes, about tied with the Intel 245K (read ", "). Although we don’t recommend the part, the 245K is cheaper at $320. AMD’s 9800X3D manages to at least outperform the 9700X, with an atypical render time reduction of 16%. It’s atypical because prior X3D parts do not necessarily see such gains, such as the 7800X3D at 15.9 minutes to the better results from both the ", " (watch ", ")and ", ". The reason for the atypical gain is largely the power budget, where the 9800X3D has more power available out-of-box to clock up.", "The ", " also requires less time. The 9800X3D is improved, which is better than we’ve seen in past X3D parts in this test, but there are still far better performers and value options from Intel and AMD alike if applications similar to this test are your daily use case.", "7-Zip can be one of the more sensitive to cache, but it depends on whether it’s compression or decompression.", "In compression testing, the 9800X3D completed 128K MIPS, which puts it within error of the ", " and ", " (watch ", "). It at least posts a 13% jump over the more power-constrained 9700X. The lead over the 7800X3D is similar. 7950X3D (watch ", ") performance is about the same as the ", " and within about 1%. ", "Intel’s 285K has a large lead here, up at 170K MIPS with DDR5-6000. The gain in our DDR5-8600 test was massive in this benchmark, putting it at nearly 202K MIPS. The ", " approaches that result, meaning an upgrade to its memory as well would leapfrog the 285K.", "Decompression has the 9800X3D at 146K MIPS. It’s between the ", " and 7700X (watch ", "). The 9700X was regressive in this test against both the 7700X and the more like-for-like power 7700.", "The 9800X3D leads the 7800X3D by 10.2% and the 9700X by similar.", "Again though, if you’re heavily represented by this test, you’d be better off with a different CPU. The 16-core AMD CPUs lead this chart and set that example. The ", " has been below $500 lately, so it’d be a price comparable alternative to the 9800X3D that’s more suited to this.", "Chromium compile is up now. ", "The 9800X3D requires 130 minutes to complete the compile with our settings, putting it at the same level as the 14600K (read ", ") and Intel 245K. The ", " non-X (read ", ")leads the 9800X3D here and benefits from the extra threads.", "The 9800X3D also benefits from an 18% reduction in time requirement against the 7800X3D’s 160-minute result. Likewise, it leads the 149-minute result of the 9700X. Still, the ", ", 13700K (watch ", "), and 285K are all advantaged over the 9800X3D, as are AMD’s own ", " and ", " (read ", ")parts.", "Adobe Premiere testing is done with the Puget Suite.", "This testing lands the 9800X3D at 10,050 points in aggregate for the extended test, which includes RAW, intraframe, and effects performance. The result is between the 13700K and ", " above it and 12900K (watch ", ") and 7900X below it. ", "The 9800X3D does actually improve on both the 9700X and 7800X3D, though, both of which are around 9100 points in aggregate.", "Intel’s ", " outperforms the 9800X3D by 6.6%, with the 7950X (watch ", ") a bit above that. The 285K does impressively well in this specific test, with the 14900K alongside it.", "Photoshop also uses the Puget Suite.", "The 9800X3D does impressively well in this benchmark, with its averaged score landing ahead of the 9950X (read ", ") and 9700X alike. The 7800X3D’s 10,162 point result gives the 9800X3D a lead of 17%.", "AMD does well in this specific Photoshop test right now. Intel’s first CPUs show up way down the chart, at around the ", " (watch ", ")and ", " levels of performance with the 14900K and 14700K. The 285K does about the same as the 13700K here.", "This is one where the 9800X3D manages to boost itself even in a non-gaming scenario, benefitted by the extra power available for clock boosting as compared to the 9700X.", "This chart is an experiment. We don’t want you to place too much usefulness in this particular chart because it is experimental, but we also can’t try new things if we always try to perfect them first.", "This chart shows the delta in USD per FPS at various simulated prices for the 7800X3D. The 9800X3D is fixed at $480 in all of these simulations, with the 7800X3D variable based on the number you see in the chart legend on the right. A negative value means that the 9800X3D is that amount cheaper per FPS than the 7800X3D, while a positive value means the 9800X3D is that amount more expensive per FPS than the 7800X3D.", "At near price parity, the 9800X3D has significant value advantages in Dragon’s Dogma 2, Baldur’s Gate 3, Starfield, and even Phantom Liberty. Value is functionally the same in F1, Rainbow Six, and Final Fantasy. ", "It isn’t until a $420 price for the 7800X3D that the Starfield value gains are mostly eliminated. At $400 7800X3D versus $480 9800X3D, the 7800X3D starts to make a ton of sense as a better value, assuming that’s how you shop. ", "This is also an experimental chart. ", "In this one, we’re showing the percent increase in power consumption for the application in the left axis vs. the percent increase in performance. The best result would be a larger performance increase than the power increase by percent, although linearity is also good.", "In Baldur’s Gate and Stellaris, with the latter converted to simulations per hour so that higher is better, the percent performance increase is either improved or nearly linear with the percent power increase. In Starfield, the performance increase costs a substantial power increase. We saw the same in Phantom Liberty. These are our two most power-hungry games in the suite and fully leverage the power budget. 7-Zip also saw this swing. Dawntrail is bottlenecked, so can’t reliably be used. Even limited though, power is higher.", "AMD might be past the most efficient point in the curve, but results like Stellaris support that it is still relatively balanced. ", "Intel’s", " was already lowered into its grave, but the ", " just contributed a significant aqueous mixture of hydroxide, chloride, potassium, and about 95% water onto it. After this impromptu hydrolysis reaction, there aren’t many compelling reasons to pick one up.", "To recap some key points quickly:", "The 9800X3D is definitely the new gaming king, and this time, it’s priced similarly to the ", ". The original launch price of the 7800X3D was $450. Even at that price, the 9800X3D is a worthwhile improvement and doesn’t feel like stagnation. ", "There are some big boosts to performance over the ", ": Stellaris saw the 9800X3D break through a glass ceiling and propel to new heights against the already-dominant 7800X3D; Starfield saw about a 16% improvement; Dragon’s Dogma 2 saw a 16% uplift, also breaking through what seemed like a ceiling; Baldur’s Gate 3 had a 26-27% improvement, which was such a big swing that we re-ran the tests on both CPUs, collected HWINFO logs during execution, and closely inspected the graphics to ensure equal renders. We also checked with another reviewer who saw a 17% uplift in the game while testing in a different area and under different settings, which is close enough when considering those changes.", "Even without that, the CPU is just overall competitive in gaming.", "For efficiency, the 9800X3D doesn’t manage to hold onto AMD’s multi-generation history of its new X3D CPU becoming the most efficient in our charts. The CPU is still good, and we’d still classify it as “efficient” overall when considering everything else on the charts.", "Production isn’t as competitive as other parts, so if you’re not building a gaming-first system, you should just buy a different CPU. But it’s good enough for a mix of work and high-end gaming, and likewise, it uncharacteristically improves upon the ", ". We haven’t always seen this with X3D, as frequency is typically sacrificed for power as a result of the thermal limiters imposed by the heat sandwich AMD previously had with the stack.", "Intel isn’t anywhere close on the gaming charts. It isn’t only beaten, its new 285K flagship -- which is, for some completely insane reason, $630 -- is sometimes beaten by 40-60%. Typically, we’re seeing 25-35% when unbound by the GPU. ", "Intel does better in the production benchmarks, but we still wouldn’t recommend the Ultra 200 series broadly. The ", " and ", " remain competitive, with the ", " and ", " also somewhat competitive here. There are some very limited use cases, such as the buzzworded “creation” scenarios, where the 285K makes some sense. But Intel is marketing the 285K on efficiency, and AMD is more efficient in every test we’ve run.", "The entire last few months have been wild: We watched AMD open it up with Zen 5, where it drunkenly fumbled the football back 5 yards on the field. Intel then picked up the ball and proceeded to run towards its own goal, at which point it tripped over its shoe laces that came unglued. AMD then picked the ball up and walked it the rest of the way with the 9800X3D.", "And somehow, it worked. AMD was set up for a slam dunk on this launch with both its own and Intel’s fumbles, and by under-marketing the performance, it was in a position where only the price could screw the launch.", "This launch was also the most organized out of the last several months, including AMD’s own Zen 5 launch. An organized launch is important: With about 2 weeks of testing time rather than the few days we’ve had, plus a mature platform without mid-testing reworks, it is clear that AMD really sat down and planned the launch rather than shoving it out the door in a panic to respond to something else. This gives us some additional confidence that there won’t be any unexpected, major problems with issues like BSODs or BIOS.", "That’s it for the 9800X3D review. You have all the numbers to make decisions. The 7800X3D may make more sense in the event its price falls significantly, but overall and all things totaled, we’re positive on this one."]},
{"title": " Intel Core Ultra 7 265K CPU Review & Benchmarks vs. 285K, 245K, 7800X3D, 7900X, & More", "paragraph": ["Intel Core Ultra 7 265K CPU Review & Benchmarks vs. 285K, 245K, 7800X3D, 7900X, & More", "Last Updated: ", "The Highlights", "Now we’re reviewing the ", " - Core Ultra 7 (Series 2) Arrow Lake 20-core 8P+12E LGA1851 125W Desktop Processor.", "We initially found the “Series 2” on the product box to be confusing, but then we realized that this is the Core 200 Series, and since 2 is sort of like 200, it all makes sense. These names won’t cause any problems and are very clear…", "This is going to be the simplest and shortest of our 3 reviews for this CPU lineup. If you want the full depth and technical detail, check out the ", " for the deep-dive into efficiency, gaming, and production. This one is going to focus on just the charts and conveying information quickly for you all as we wrap this series (for now).", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "The ", " is currently available for $404 on Newegg and Amazon right now. That puts it predictably between the $630 ", " and $320-$330 ", ". As a recap, thus far, the 245K has made the least sense since it’s more gaming-oriented and less focused on potential workstation applications, whereas the 285K could maybe make an argument in some workstation or production use cases. The 265K theoretically balances between.", "We’ll start with a quick pricing recap of what’s available around the time we’re writing this review.", "The 265K is about $404 right now, which is fitting, because…Error Lake value can’t be found.", "The price has it similar to the ", ", which is currently $400. The ", " non-X is $370 or so, with the ", " at $330. The ", " is $430. AMD has this territory encircled with similarly priced options. The ", " comes in 19% more expensive at $480 and would also be less viable in most production use cases we test, but far more viable in gaming scenarios. If you’re only doing one of those, that allows you to either ignore or focus on the 7800X3D (watch ", "). If you’re doing both, that’d be where the 265K might make sense -- if it’s not beaten by Intel’s own ", " at $350 and ", " at $290. ", "And AMD has announced that its ", " will be arriving on November 7th. We’re not sure what it’ll cost yet, so it’s possible it’s not a direct comparison here.", "As a reminder, other considerations for Arrow Lake are that it requires an entirely new platform and Z890 boards are some of the most expensive we’ve seen in a given class. It also benefits from faster, more expensive RAM in ways that other CPUs can cut costs and corners. As a positive though, the reduced power consumption means reduced cooler requirements as compared to the prior Intel generations, so that can reduce some cost.", "That’s it for the basics and positioning. If you want more, check out the prior two reviews or the ", ". Let’s just get right into it.", "Our efficiency testing has been explained in-depth in two pieces now and briefly introduced in a third. To learn more about what we’re doing here, check out our ", " and our ", " where we set up our monstrous test bench.", "We’ll start with 7-Zip compression efficiency. We’re just going with the ATX12V and EPS12V rails for now, as we still think these are the closest to accurate on our setup.", "The 265K ended up at 163W in this test, which has the efficiency at 968 MIPS/W. That has the CPU as less efficient than the ", ", which pulled 162W on the same ATX12V and EPS12V rails, but produced a higher throughput, yielding a 1051 MIPS/W result.", "AMD’s ", ", ", ", ", ", and everything else, including the 3700X (read ", ") from 2019, ranks above the 265K as a result. The 265K really is only better than the ", ", 2700 (read ", "), ", ", and Intel’s own lineup here.", "In decompression efficiency, the 265K repeats its rank and falls below the 1194.9 MIPS/W result of the 285K. The power drawn is the same since this test suite runs both consecutively and at about the same power level. The end result is that the 265K is marginally less efficient than the ", ", more meaningfully behind the 285K, and is otherwise mostly just ahead of the prior Intel CPUs. Generationally, the improvement on the ", " is actually good. It’s 47%. It’s a real uplift, and Intel does deserve credit for that; however, again, the entire top half of the chart is AMD-dominated. It’s just not even close. The ", " in Eco Mode leads the 265K in efficiency with an advantage of 87%. The 9700X (read ", ") is cheaper and also holds a substantial lead, up at 1624 MIPS/W. The 9700X won’t produce as high of a result in this test as the 265K for raw performance, but in efficiency, it is more efficient.", "Even the ", ", which is AMD’s highest power draw non-HEDT part we’re testing right now, is more efficient than the 265K. This is partly because its performance is so much higher in this test.", "Here’s gaming with Baldur’s Gate 3. Here, the 265K pulled 89W when measuring both the ATX12V and EPS12V rails. That has it similar to the 285K. We noticed during this testing an initially higher reading on the 265K by almost 10W exactly, but after troubleshooting Vcore and CPU Package Power, we were able to isolate that 10W as being from a measurement tool difference on the 265K platform. We were able to make adjustments to effectively calibrate it for the data we had from all other tests on this chart. As we’ve stated, this is all brand new methodology and is more complicated because of ASUS’ decisions to split the rails for the CPU, but we’re staying on top of hunting down these deviations and accounting for them. This also means we’re going to continue studying the measurements and tools to refine the readings.", "With the 89W measurement, the 265K ends up just below the 285K for efficiency (tied when rounded). Its performance is lower, but power is similar, so the two are effectively equal. The TDP is the same on these CPUs, so if they’re drawing up to the power limit, then this is expected.", "Neither of these is particularly impressive when considering the 7800X3D or ", ", both of which have higher framerate and lower power consumption, resulting in higher efficiency. The 245K (read ", ") is more efficient than the 285K and 265K, up at 1.3 FPS/W and tied with the ", " and 9700X.", "In Final Fantasy 14, the 265K calibrated to prior tests pulled 65.5W during our testing. We didn’t add a line item for ATX5V in this one since we’ve been saying that we don’t think its impact on the CPU is significant in any way.", "This lands the 265K at around the same power consumption as the 285K for the same two rails. The efficiency is lower because the framerate is lower. The 245K is more efficient, up at 4.3 FPS/W. ", "The 265K is the least efficient of these three parts so far on this chart. It’s still improved on the 14700K (read ", "), but because the performance is regressive in this particular title -- and by a lot -- the efficiency struggles to take off despite the reduction in power consumption from what was 98.2W.", "The 7800X3D has an efficiency lead at 8.3 FPS/W, or a 131% improvement. This is actual insanity. The large framerate boost combined with the steep power reduction gives AMD a big lead here. Again, whether you’re talking outright efficiency or environmental stewardship and absolute power consumption, the answer to both of these would be AMD as the most efficient. Intel cannot fight on these grounds, despite improvements over its own prior architecture.", "Stellaris is up.", "In this one, we have the 265K at 1.5 simulations per watt-hour, about the same as the ", ", especially considering rounding. ", "If we look for a performance-normalized comparison, the closest would be Intel’s own 14700K. The uplift over the predecessor is 50%. AMD’s ", " is somewhat close in performance as well, yet holds an advantage at 1.7 simulations per watt-hour.", "We didn’t capture power data for the 245K in Starfield, but we have the 265K and 285K.", "The 265K here pulled 144W, putting it around the same as the 285K. Because the performance declines and the power is the same, the efficiency is worse than the 285K once again. The 285K appears to be a better bin in combination with higher efficiency.", "The 265K ends up about the same as the 14600K. Fortunately, it improves on the 14700K’s 0.6 FPS/W result. The ", " has a lower power consumption than the 14700K as a result of an external bottleneck limiting CPU utilization and also the binning. It can’t be fully leveraged. The 285K and 265K are both fully engaged though.", "Dragon’s Dogma 2 is up. In this one, the 265K ran at 99 FPS AVG, which has it 4.6% ahead of the 245K and means the 285K is about 4-5 FPS ahead of the 265K. The 14700K leads the 265K by 8.6%, with the ", " about the same. The AMD 7800X3D is ahead by 11%, with the cheaper ", " also ahead of the 265K while running on an older, cheaper platform.", "The 265K is worse value than even the 245K in this particular game, and we wouldn’t recommend that one, either. Its low performance here is fine, with no particularly meaningful deviation from the expectation, but overall, the 265K is just not impressive in this test even against its already unimpressive brethren of the same 200 Series. Or Series 2. Or whatever Intel is calling it.", "F1 24 is up now. In the very least, the gap is wider against the 245K, now with a 7.5% uplift in framerate. Lows increased proportionally with the average.", "This positions the 265K as equivalent to the AMD ", " and a bit ahead of the 7700 (watch ", ") and 7900 non-X parts. The ", " is functionally tied with the 265K, making it both performance and price matched in this test -- at least, at the prices right around launch.", "The 285K’s 343.5 FPS AVG has it just 4% ahead of the 265K. It wouldn’t be worth buying the $630 285K regardless, and especially not for gaming, but it’s especially not worth it here. Even the 265K makes more sense, and it still doesn’t make a ton of sense.", "The 5700X3D (read ", ") further establishes that storyline with its 355 FPS result, led further by the once-upon-a-time cheaper ", " (when it was briefly available at Micro Center). That one has a lead because its frequency is higher.", "At 1440p, we see some drop in performance from the resolution change, but a similar hierarchy overall. The 265K ends up sandwiched between the 14600K and ", " as we bounce off of occasional framerate limits. The entire top of the chart is brushing against external bottlenecks at least occasionally, so let’s move on.", "Final Fantasy 14: Dawntrail is up now, first at 1080p.", "AMD holds a domineering lead over this chart and keeps a stranglehold on the top 3 entries, with 4th held closely against the ", " with APO on. ", "The 265K landed at 236 FPS AVG here, which has the ", " ahead of it by 4%. The ", " non-X also leads, up at 253FPS AVG and holding an advantage of 7.4%. Even the ", " leads. The 14700K’s 287 FPS AVG result has it 21.7% ahead of the 265K, establishing, without a doubt, that the 265K has gotten thoroughly “wrekt” in this test against its predecessor. The 285K also did poorly in this game; in fact, this is one of the games Intel openly stated it has regressive performance in, and we can definitely confirm that. Almost anything else makes more sense than Arrow Lake in this benchmark.", "Baldur’s Gate 3 had the 265K at 96 FPS AVG, which ties it almost perfectly with the ", ". That includes tying the 1% lows, with 0.1% close to the usual wider error range. The 265K only leads the 245K by a few FPS on average, rendering it relatively uninteresting. The 245K was already terrible value against alternatives here, and that includes not just the clearly dominant X3D CPUs -- where we have 4, and soon to be 5, topping the chart -- but also Intel’s own prior CPUs. The 14700K leads the 265K by 6%, and for perspective, the 7800X3D leads it by 32%. The 5800X3D (watch ", ") isn’t far below that, at 120 FPS AVG. The 5700X3D, which is around $200 to $230 lately (but has been cheaper), has an advantage over the 265K of 16.4%.", "For the 265K, we’re just not seeing it in this one.", "Stellaris is up now. This one uses a late game save file and tests for simulation time rather than framerate. Players of 4X games are likely aware of how bogged-down the CPU can get in late game stages. ", "The 265K required an average of 33.9 seconds for its simulation. The ", " averaged 33.5 seconds, with the 7700 non-X at 34.2. The 14700K predecessor is indistinguishable from the 14900K (read ", ") here, with both exhibiting a 2% simulation time reduction from the 265K.", "The ", " is also improved, with a simulation time reduction of 1.2 seconds. Zen 5 generally does well in this test, shown also with the 9700X at the top.", "The 285K with our default settings did better in this one relative to the 14 series than other tests, but was still beaten by AMD’s 7800X3D and 9700X.", "Rainbow Six Siege is up now. In this test, the 265K ran at 519 FPS AVG. We observed that the 285K had frametime pacing issues in this game as compared to the 14 series, which persist here. Our ", " remarked that we think this may be related to specific optimizations made by the Rainbow Six team, as APO’s benefit has been reduced to effectively nothing.", "By average FPS, the 265K is behind the 5700X3D, and further behind the higher clocked ", ". Both of these AMD CPUs have better 0.1% lows; however, the 14600K has far superior 0.1% lows than all 3 of these and is functionally tied in average FPS with the 265K. It’s within error for average, but better in low performance. The same goes for the ", ", embarrassingly for the 265K.", "Here’s how it stacks up: The 7800X3D leads the 265K by 20%, the 9600X leads it by 19%, the 14900K with APO off by 13%, and the 285K with APO off by 12%. Even the 7900X (read ", ") leads here, and that’s not explicitly been branded as a gaming part, yet competes in both production workloads and price.", "Starfield is up now. This one has the 265K at 134 FPS AVG, just ahead of the 5800X3D and behind the 13700K (watch ", ") and 14700K. These two CPUs (and the 14900K) are all bouncing off of another limit, and the 285K with DDR5-8600 makes it appear as if that limit is memory. This is also reinforced by the cache-boosted 7800X3D propelling to the top here.", "The 265K has an improvement on the 245K’s average FPS of 120.5 of 11%. It also leads the 5700X3D here by 13%.", "AMD has historically had issues with Starfield, despite being the GPU sponsor for the game. The 9600X is less competitive in this gaming test than some of the others, down at 101 FPS AVG.", "Time to move on to production benchmarks. This testing will look at a shortened list of workstation applications.", "Blender is up now for a 3D rendering benchmark.", "In this one, the 265K required 8.7 minutes to complete the render. That has it near the 14900K. Against the 14700K, the 265K also benefits from a render time reduction of 8%, meaning 8% less time required to complete the work. The reduction in time required against the 13700K is 20%, down from almost 11 minutes. AMD’s ", " in ECO mode leads the 265K with an 8% reduction in render time needed, with the non-ECO result at 7.4 minutes and in line behind the 285K. ", "The 265K beats the 7900X, which at least helps its positioning against similarly priced AMD competition. That isn’t always the case.", "The 265K also benefits from a 31% reduction in render time requirement against the 245K.", "7-Zip Compression is up now. In this test, the 265K ran at 158K MIPS, which puts it roughly tied with AMD’s R9 7900X and behind the ", ". The 265K improves on the 245K by 29% in throughput, with the 285K leading the 265K by 8%. This is a test where we saw a large improvement from the memory upgrade in our 285K test with DDR5-8600. We might revisit that topic if we can find some time.", "The 9900X (read ", ") is about 6% more expensive than the 265K right now and performs about 3.5% better. The 14700K is cheaper than the 265K, but uses more power to score 8% better. The 7950X (watch ", ") is one of the more interesting CPUs still, but it depends heavily on price. It’s listed at $500 as we write this, or about 24% more than the $405 listing for the 265K on Newegg. The 7950X performs 18% better without Eco Mode on and similarly with it enabled.", "In Decompression, the 265K ran at 168K MIPS and landed just behind the two-generation-old 13700K. The refreshed version of that, the 14700K, is up at 195K MIPS, landing the 14700K ahead of both the 285K and the 265K. The 285K only topples it when upgraded with faster memory, but of course, giving the same treatment to the 14700K would also leapfrog it ahead.", "The 14700K leads the 265K by 15.7%. The 265K leads AMD’s ", " by 19%. X3D doesn’t really help here, so the 7800X3D and 5700X3D fall down the stack comparatively, despite strong gaming performance and really good efficiency.", "AMD’s production-oriented 7900X leads the 265K by a staggering 24%, with the 9900X leading by 27%. The 7900X is currently the same price as the 265K, making it a better value in this comparison.", "Adobe Premiere is up next, tested with the Puget suite.", "In this one, the 265K scored 10718 points in aggregate. Puget Systems takes the intraframe score, RAW score, GPU effective, and other filter and editing testing into consideration for this score.", "The score has it roughly tied with the eco mode 7950X and 9900X. Its advantage over the 7900X is at least a little more, at 8%. The 7900 (watch ", ") scored similarly. The 265K also leads the 13700K by 1%, so basically error. The 14700K leads the 265K by 2.4%.", "The 285K did well in this particular test and managed to outrank the 14900K, leading the 265K by 5.8%.", "The ", " is, in several cases, less efficient than our ", ". That’s not unheard of: The ", " is a higher performer, which benefits the efficiency, and the power budget is the same. Still, it’s improved over the ", ". Intel has retained that much, but as we said before, in all comparisons we run, AMD is more efficient still.", "So that wraps-up that side of things.", "It’s clear once again that the ", " is surrounded by good options on all sides. The 285K is exceptionally bad value for gaming users, with worse performance than you’d get on a $230 ", " or $480 ", " and also a far higher cost. In non-gaming uses, there are some limited scenarios where you could make an argument for the 285K, but they are relatively rare among our test suite.", "The ", " made even less sense: Production use cases effectively vanish as an argument, as the part is majority targeted at gaming users. In gaming, it gets absolutely crushed by not only AMD’s $100 cheaper ", " (which itself would give you $100 more budget to either keep or throw at a GPU), but also by Intel’s own predecessors that are now cheaper or the same price.", "The 265K suffers from a bit of both: The cost goes up by $70-$90, and yet the performance doesn’t scale anywhere close to linearly in gaming. The production performance is better, and in that situation almost solely, the 265K can make some stronger arguments for itself. It can outmatch its closest price competitors from AMD at times, so that’s at least good for the 265K. It’s just not a sweeping victory and Intel’s total platform cost is also questionable, especially with the potentially short lifespan of this one.", "That’ll wrap our reviews of these for now. We’ll have more Arrow Lake content, but as far as the core part reviews, they’re done until Intel launches more. We wanted to keep this one concise."]},
{"title": " AMD's Silent Launch: Ryzen 5 7600X3D CPU Review & Benchmarks vs. 7800X3D, 5700X3D, 9800X3D", "paragraph": ["AMD's Silent Launch: Ryzen 5 7600X3D CPU Review & Benchmarks vs. 7800X3D, 5700X3D, 9800X3D", "Last Updated: ", "The Highlights", "AMD somewhat secretly launched its ", ". It’s a 6-core, 12-thread X3D part that we bought for $300 from Micro Center in Charlotte. AMD didn’t email us about this CPU, didn’t do review sampling, and just sort of quietly launched it to the market through Micro Center. It’s similar to the 5600X3D launch (read our ", "). ", "This runs on Zen 4 and is advertised as having a maximum 4.7 GHz boost clock and 4.1 GHz base clock. TDP is listed at 65W. AMD’s ", " has a higher 105W TDP and runs an advertised maximum clock of 5.3 GHz, or 4.7 GHz base. That’ll make the ", " better in some specific frequency-constrained scenarios that can’t utilize the extra cache, like in our non-gaming tests, but it’ll also make it more power hungry and having that extra cache normally allows better performance in gaming, even if the frequency is lower, and it tends to be more efficient.", "Steve Burke", "Patrick Lathan", "Mike Gaglione", "Tim Phetdara", "Jimmy Thang", "That’d make the ", " more of a direct comparison for efficiency testing, as its TDP is also 65W.", "The 7600X3D was a surprise to us. A few weeks ago, we had a viewer ask why we hadn’t tested it yet -- the answer was that we didn’t know it existed, and we’re excited to work on it now. The CPU ends up being one of the most efficient we’ve yet tested thanks to its low TDP and high performance.", "Let’s get into the review.", "Technically, the CPU is currently a Micro Center-exclusive like the 5600X3D, so we’re not sure if that’ll change or how many they’ll have.", "Getting into pricing first:", "Currently, the 7600X non-3D (watch ", ") is $224 on Newegg and $208 on Amazon at the time of reporting. It’s $190 from Micro Center, which is the more like-for-like comparison to the $300 7600X3D.", "Other relevant parts include the ", " at 8 cores and 16 threads, priced at $480 or so on Amazon and $450 on ", ". Between the two, it’s $150 to $180 more expensive to get the R7 7800X3D (watch ", ") or the new ", ", which is $480.", "Intel’s most relevant, modern competition might include the $320 ", ", $350 ", ", $344 ", ", or, oddly, the ", " at $277.", "This review is going to be kept as simple as possible. We just launched a ", " and included a ton of charts, so coming off of all that hard work, we’re trying to go with a straight-forward review today. If you want more depth and more discussion with even more charts, make sure to check out the ", ". ", "For now, let’s get into a simple review of the 7600X3D.", "We’ll start with a frequency inspection to understand the performance we see later.", "Here’s an all-core workload. The 9800X3D we just reviewed ran at about 5225 MHz average, which is an impressive clock to hold for a 3D V-Cache part. It’s also a flat hold of the frequency thanks to the extra power budget. The ", " fluctuates more due to the power constraint, holding around 4850 MHz on average.", "The 7600X3D comes in below that, at 4700 to 4730 MHz, also moving up and down through the test.", "For perspective, the 7600X non-3D part ran at about the same clock as the 9800X3D, up around 5225 MHz. If you see the 7600X outperform the 7600X3D in some tests, that won’t be a surprise: Anything which relies less on the extra cache than on higher clocks will see a regression in performance. This is less prevalent on the Zen 5 9800X3D due to its higher power budget and because the ", " had a lower power budget.", "This chart is for the maximum single-core boost during a Cinebench single-threaded workload. This allows us to see how fast the cores go when unlikely to breach power limits.", "The 9800X3D we just reviewed held the same 5225 MHz clock we saw in all-core testing and did so throughout the benchmark.", "The 7800X3D ran faster than its all-core workload, which is more typical. That had it at 5050 MHz during this test on the fastest core per interval.", "The 7600X3D is far slower than that, with a comparatively huge drop to 4750 MHz for the fastest single core per interval. That’s a large drop that will likely contribute to losses in certain titles, maybe like Final Fantasy, more than the core count difference between the two would.", "The 7600X ran at 5450 MHz for the fastest single core, which will also benefit it in lightly threaded scenarios where the extra cache doesn’t contribute much.", "For gaming efficiency first, we were impressed with the 7600X3D’s efficient performance in Baldur’s Gate 3. It’s the new most-efficient CPU in our testing.", "Our efficiency benchmarks are a combination of both power drawn during the test and the performance output in the test, which is FPS in this situation. Tweaking either dial can improve efficiency since it’s a calculation of the two.", "The 7600X3D ended up at 42.8W in this test, which has it reduced from the ", ", 5800X3D (watch ", "), and 7800X3D. It’s among the lowest power draw parts in this test, alongside the older R7 2700. With the 12W reduction from the 7800X3D and with performance similar to the ", ", the 7600X3D ends up at 2.7 FPS/W, which is an awesome result that we didn’t expect to see. The 9800X3D is alongside it at the top, roughly tied with the 7800X3D at 2.3 to 2.4 FPS/W. This is a strong start. And for the 7600, that landed at 1.6 FPS per watt, which puts it above the ", ", below the 5800X3D, and predictably above the 7600X, but it’s still below the 7600X3D.", "Final Fantasy 14: Dawntrail also has insanely efficient performance. The CPU is, once again, not the best performer on the charts, but it encroaches on the top and manages to do so while at 34W during this benchmark. Because the power is so much lower overall, the efficiency climbs despite a reduction in max FPS versus better AMD parts.", "The end result is a 10.3 FPS/W rating, the highest we’ve seen, against 8.3 FPS/W on the 7800X3D. The 7800X3D is reaching the upper bound of what it can achieve for performance: It’s possible that this number increases with the launch of the RTX 5090, but for now, it’s stuck at 8.3 FPS/W. The 7600X original part pulls a little more power and performs far worse, landing it down at 5.6 FPS/W. That’s still ahead of anything Intel has to offer, including the ", " at 4.3 FPS/W, but nowhere close to the 7600X3D.", "In Stellaris, the 7600X3D required 33.1 seconds to complete the simulation. This reduces the time required from the 7600X’s 36-second entry by 8%. The 9600X, from Zen 5, outperforms the 7600X3D, benefiting from the overall Zen 5 uplift we’ve seen in this specific game. Aside from that, everything else above the 7600X3D is significantly more expensive, including the 285K at $630 but providing only a 1.8% reduction in time required to simulate.", "Against the 5700X3D (read ", "), the 7600X3D sees a 14% reduction in time required. The same is true compared to the 5600X3D.", "The new 9800X3D is aided hugely by its architecture and frequency, requiring 22% less time than the 7600X3D. The 7800X3D benefits from a 5.4% reduction in time required. Overall, the 7600X3D encroaches on the 7800X3D while being significantly lower cost, but can’t come close to the 9800X3D.", "Dragon’s Dogma 2 is up now. This is another title where the 9800X3D saw strong performance.", "For this game, the 9800X3D holds a 21% lead over the 7600X3D in average FPS, at about 129 FPS to 106. The lows are proportional to the increase in average FPS. There is no particularly abnormal advantage to those found on the 9800X3D, although they are good.", "Compared to the 5700X3D’s 103 FPS AVG, the 7600X3D holds a small 3.1% lead. It’s 3.5% ahead of the prior generation 5600X3D, which was also Microcenter-exclusive.", "As for Intel, key comparisons include the 245K (read ", ") at 95 FPS AVG and priced similarly to the 7600X3D. This gives the 7600X3D a 12% advantage in average FPS over the new 245K, with lows again proportionally higher. The i7 and i9 CPUs from the 13th and 14th series are all roughly tied with the 7600X3D, but slightly ahead. The 5800X3D maintains its position at the top of this grouping, beaten only by its newer alternatives.", "Starfield is up now. This was another strong one for the 9800X3D when we reviewed it.", "In this one, the 7600X3D ran at 122 FPS AVG. That means the 9800X3D’s 169 FPS result has it about 38% ahead of the 7600X3D, a significant jaunt. The 7800X3D ran at 145 FPS AVG, offering its own improvement of 19% over the 7600X3D. The 7600X3D is definitely a lower-end part than the two flagships. Compared to the 5700X3D though, the 7600X3D is technically improved -- though basically within error at 3.2% uplift. The 5600X3D gives the 7600X3D a lead of 8.2%, widening the gap in favor of the newer Micro Center-exclusive part.", "Intel’s showing includes the 245K at about the same framerate and a similar price, the ", " at a higher framerate, and the ", " also ahead. The 7600X3D is stunted by a combination of its lower core count and its frequency, not able to leverage the cache to the same extent as the higher-end AMD X3D parts. The 7600X3D at least holds about a 20% uplift over the 7600X, which was down at 102 FPS AVG.", "In Baldur’s Gate 3, the 9800X3D experienced a large performance boost that we spent several minutes digging into in its review. It’s an outlier.", "The 7600X3D is more typical: It ran the game at 116 FPS AVG, which allows the 9800X3D another 38% lead. The lows remain impressive on the 9800X3D, followed by the prior 13 series and 14 series CPUs as the next most impressive for lows. The 7600X3D is overall “fine” for lows, but its position is predictable within this stack.", "The 7800X3D posted a 126 FPS AVG in Baldur’s Gate, giving it a boost of 9% for the extra $180 or so -- that doesn’t seem worth it if you have a Micro Center near you. The 5700X3D remains pretty close by as well, with a 111 FPS AVG that would be indistinguishable from the results of the 7600X3D. The 5700X3D also benefits from a fiercely competitive price.", "The 245K slips down this chart, especially with Windows 24H2. It’s at 93 FPS AVG, giving the 7600X3D a 25% lead in average FPS. Lows are about the same.", "Final Fantasy 14: Dawntrail is next. This one has the 7600X3D at 349 FPS AVG with lows at 164 and 79 FPS. That positions it roughly tied with the 7800X3D, both of which appear to be encountering similar limits. The 9800X3D managed to break free of this bind and post a 373 FPS result. That’s good, but it’s not as impressive as we saw in other tests.", "But this isn’t meant to be another review of the 9800X3D. The 7600X3D boosts over the 7600X’s 259 FPS AVG by 35%, leading the 259 FPS entry by a significant margin. X3D in general completely divides this chart, forming a rift below the 5600X3D and everything else.", "Intel’s closest competitor is the ", ", although it’s more expensive, up at 310 FPS AVG. The 7600X3D leads even the former flagship i9 by 13%. Its lead over the 5700X3D is noteworthy, at 16%. This is because of the 5700X3D’s drop in clocks, which we know to impact its Final Fantasy performance. That’s also why the 5600X3D runs higher performance: Its clocks are typically at least 300 MHz higher.", "Rainbow Six Siege is up now. In this one, the 7600X3D ran at 613 FPS AVG -- sorry, 613.3… That 0.3 is important, because elite FPS gamers can see even the difference between 0.000798 ms.", "The 613.3 FPS result has it up alongside the ", " and below the 9700X (read ", "). The 7800X3D ran at 622 FPS AVG -- again, sorry, 622.1 -- which means it holds a 1.4% lead. That’s basically error. These CPUs are functionally the same, with lows differentiated only by how wildly variable this particular game is.", "As for the 5700X3D, the lead from the 7600X3D is a more noteworthy 17%. There’s also a big jump over the 245K, way down at 476 FPS AVG.", "Generally though, the top CPUs are mostly the same. The 9800X3D is boosted, but not in a huge way like in some other games. We’re up against limits.", "In F1 24, the 7600X3D ran at about 409 FPS AVG and was flanked by the 5800X3D and 7800X3D. The 7800X3D holds a 7.2% lead in average FPS, with a big jump in the 1% and 0.1% lows. Both are ultimately acceptable. The 5800X3D’s 391 FPS average gave up a 4.4% lead to the 7600X3D. The gap against the 7600X is massive, at 409 FPS to 312 FPS, or a 31% uplift for the 7600X3D. That’s a big climb when considering the frequency and cache changes discussed earlier.", "Intel’s 245K is far down the chart, more similar to the 7600X than the newer X3D variant. The ", " is closer, but still behind at 385 FPS AVG.", "In Total War: Warhammer 3, the 7600X3D ran at 484 FPS AVG. That has it in the top grouping again, but technically behind the 14700K. Realistically, in average FPS, they’re the same; however, the X3D CPUs all have large advantages in frametime consistency and pacing, as illustrated by the 1% and 0.1% lows.", "The 9800X3D and 7800X3D are both encountering external limits. ", "The real takeaway though is that Intel continues to get bodied by X3D: the 265K and 285K both suffer from the same impact we saw to the 14900K (read ", ") and 13900K, where frametime consistency plummets and large frametime spikes pop-up more frequently. This affects the averaging as well, since it drags everything down, which leads to the 285K and 265K seeming to perform worse than a lower thread-count 245K. This is a repeatable result. Even the DDR5-8600 285K entry has worse lows than the 245K, and that’s all because of scheduling. There are community mods to try and help with this, but we test games as the developer ships and maintains them.", "Production workloads aren’t a big focus for R5 CPUs, so we’ll fly through these to hit the basics.", "In Blender 3D rendering on the CPU, the 7600X3D required 21.3 minutes to complete a frame of the GN intro animation. This is one of the slower results, putting it in-line with the 5700X3D, 3700X (read ", "), and 5800X. The 7600X is faster than the 7600X3D, which isn’t new behavior: While the 9800X3D actually outperformed the 9700X, generally speaking, X3D CPUs are worse in production-heavy, all-core tasks than the CPUs they stack the cache on top of. That’s because the frequency comes down on prior generations, mostly for thermal budget reasons, and this is also why Zen 5 X3D is so interesting.", "So for the 7600X3D, we’re back to a situation where it’d typically make more sense to buy any other CPU above it on the chart for heavy workstation use cases that we test. If you’re building a machine that’s gaming-focused first and foremost, then the 7600X3D should still be in consideration. It’s capable of handling production-style work on the side, but there are better options for a build more purely focused on that kind of work.", "The 7600X3D is beaten by the ", ", 5800X, and many other CPUs. Blender scales cleanly with thread count, and that shows here. The 285K is also relatively competitive in this particular test, as are the 265K and 245K.", "In Chromium code compile, the 7600X3D required 208 minutes to complete the compile. That has it way down the chart and near the ", " and 5800X3D. The 7600X3D is struggling with its thread deficit and just wasn’t built to excel at the production applications we test with. Even the 3700X isn’t distant.", "The 7600X benefits from a time reduction to 198 minutes in this test, with the ", " and ", " ahead of that.", "In 7-Zip file compression, the 7600X3D ended up completing about 87K MIPS, putting it ahead of the 3700X and behind the 5700X3D. The 7600X is again better, at 91K MIPS, or improved by 5.2%.", "As with other pre-Zen 5 X3D parts, if doing this kind of work heavily, it’d make more sense to buy something else. The part is acceptable for its price if gaming is the primary focus.", "Decompression is similar: The 3700X outmatches the 7600X3D marginally, the 7600X3D is just ahead of the 12600K (watch ", ") now, and the 7600X non-3D runs 8.8% faster.", "The 9800X3D stood out here as improving on the ", ", benefitted by its higher power budget that enables higher boosting. We covered this in the ", ". The 16-core parts, like the ", " and ", ", have a major advantage in this workload that the 7600X3D can’t unlock with its 6-core configuration.", "Adobe Premiere is tested with the Puget Suite, using a mix of RAW performance, intraframe, effects, and processing. The result is in aggregate points.", "The 7600X3D scored 7832 points, which has the 7600X ahead of it by 4.2% at 8159. Next above that is the 12600K. The 245K posts a significant gain over the 7600X3D here as well. Against prior parts, the 7600X3D at least improves upon the 5700X3D and 5600X3D components in a more noticeable way. It’s just not impressive on its own.", "In Adobe Photoshop and tested with Puget Suite again, the 7600X3D fell down the charts to 14600K levels of performance and functionally tied with the 245K. That’s an OK spot to be, but AMD dominates the top half of this chart with other components -- including the 7600X. The reason for this drop comes down to the loss in frequency, which is important to Photoshop right now.", "The efficiency on the ", " is crazy. That’s great, but most people -- especially in this part of the market -- don’t buy on efficiency. From a pure performance standpoint, we get the expected Zen 4 behaviors: The 7600X3D is a little worse in production than its non-X3D counterpart in most of our non-gaming tests, but is far superior in gaming tests. Because an R5, like an “Ultra” 5, is targeted at gaming, that’s the most important aspect.", "Performance achieves most of what the ", " would have to offer, but at $300. For gaming, it’s a better option than Intel’s $300 options, especially over the new ", " at $320, but worse in non-gaming tasks. If you’re mostly playing games and have a budget limited to about $300 on the CPU, we think the 7600X3D makes good sense. The ", " offers a meaningful uplift at $480, but is also a huge jump in price and that extra money would possibly be better spent on a better GPU to unlock more performance. ", "The 7600X3D’s biggest strength is its impressive efficiency. Its biggest weakness is its core count, where non-gaming tasks will be restrained. For users who tend to mix heavier “work” applications than gaming, we’d encourage considering other options to better suit those needs. Our ", " goes into some of that. But for gaming-first users near a Micro Center, the 7600X3D performs overall well."]},
{"title": " Best CPUs of 2024 (Intel vs. AMD): Gaming, Production, Budget, & Efficiency", "paragraph": ["Best CPUs of 2024 (Intel vs. AMD): Gaming, Production, Budget, & Efficiency", "Last Updated: ", "The Highlights", "We’re looking at the best CPUs of 2024, following what are probably the last CPU launches for the year. ", "We’ve benchmarked most of the major CPUs out right now and have a huge lineup for you today, but there’s a remaining, weird factor from last year: And that’s the fact that prior generation parts are sometimes the best options. It wasn’t always the case that 3 generations of parts existed new-in-box from both vendors. They’d typically cleared some of those out by now, but with AMD and Intel alike, there are actually good, older parts available in some categories. They’re everywhere.", "Steve Burke", "Vitalii Makhnovets", "Jimmy Thang", "We’re going over the Best Overall, Best Gaming -- which is one of the easiest categories to judge, Most Balanced for a mix of workstation and gaming performance with price in consideration, best upgrade, most efficient, and more.", "Welcome back to the annual Best Of round-up series. We run these at the end of every year to get people back up to speed efficiently. A lot of you only check-in on PC part performance every few years for a new build, so this article will serve as a quick-start point for you to figure out which CPUs to pay the most attention to in your research. It also helps us get back up to speed on our own test data. As you find CPUs you’re interested in from this article, you can check out the in-depth reviews linked below for each of those components. That’ll get you everything you need to make a decision.", "As usual, these round-ups don’t go as charts-heavy as our usual reviews. We’ll scatter them to support the points, but the goal is to provide a quick-and-easy recap. ", "Let’s get into it.", " | ", "The first award category is for the Best Overall CPU for 2024. This one goes to the ", " CPU, which also takes our Best Gaming CPU category later. We’ll save the gaming discussion for this CPU for that category in a little bit.", "The 9800X3D (read ", ") gets Best Overall for a few other key reasons: First, its $480 price makes it a better buy than several of the other high-end CPUs that have come out recently, such as the ", " at $630 launch pricing. ", "Secondly, the 9800X3D manages chart-topping gaming performance -- which we’ll save for discussion in our Best Gaming category -- while also managing overall acceptable production and workstation application performance. It’s not the best in these workloads, but it’s still capable. ", "In Blender, the 9800X3D doesn’t benefit from its extra cache, but still manages to at least outperform the lower power budget Zen 5 components that are 8 cores and fewer, like the ", ". ", "In Photoshop, the 9800X3D ended up as our best performer. Photoshop likes Zen 5 in general and benefits from its architectural changes, and that really shows on the 9800X3D.", "The 9800X3D is also an excellent overclocker and is fully unlocked, something that wasn’t true for the prior X3D parts. It’s such a good OC part that we even took it to ", " to use liquid nitrogen to overclock it at -140 degrees Celsius, yielding some ridiculous performance scaling in real games that we might not have expected.", "AMD moved the cache die closer to the substrate, with the core complex getting the cores right against the inside of the integrated heat spreader for this generation. This has helped improve the thermal situation, which is what gives AMD more clock headroom. AMD designed Zen 5 ground-up for X3D this time. It’s also a single CCD part, which keeps things as simple as possible to set up. ", "We already know the 9800X3D is king in gaming, but it’s all these other reasons that make it the Best Overall CPU for 2024. We can highly recommend this one for new, high-end gaming builds especially, but it’s still an overall competent performer in workstation.", " | ", " | ", "The next award is for the Most Balanced CPU, which is a category we’ve used for years to ensure credit is given to CPUs that perform well both in workstation or production applications and in gaming. This weighs all aspects of GN reviews, so it considers price, gaming performance, and production performance. ", "We’re giving this to the ", " and secondarily to the ", " as a runner-up, now that its price has dropped. There are two reasons that it shares the category with the ", ": First, Intel’s poor handling of its instability issues that has caused us to question the company’s successful resolution of all its problems; second: Intel’s efficiency is through the floor and power is through the roof.", "Currently, the 7950X (watch ", ") has fallen to $480 and under, with the ", " now at $440. These CPUs both land on this list for their impressive workstation and production application performance, balancing good-enough gaming with high throughput performance in use cases like file compression and decompression, rendering or code compile, and Adobe applications like Premiere for video editing.", "The ", " had some impressive results in production, but it just has so many other faults and its price is so high that it doesn’t get a place here. ", "The 9800X3D is a great CPU, but its limited core count is a significant disadvantage in these non-gaming tests we run. ", "The 7950X, particularly with ECO Mode enabled, has some of the best efficiency we’ve seen in our CPU efficiency charts.", "The Threadripper parts can outperform it due to their incredible performance, but for a balance of price and performance, the 7950X remains strong. The ", " (read ", ") also does well in these same categories, but is significantly more expensive right now.", "The 14900K (watch ", ") doesn’t do well in efficiency (actually, it’s one of the least efficient), but its gaming performance is a little higher in most places compared to the 7950X and it trades places with the 7950X in some of our production tests. With the new lower price, it’s worth a second look. It’s just that the used market for these CPUs has been turned into a minefield with the stability issue parts potentially getting dumped secondhand. ", "But ultimately, the 7950X has the advantage of being on a platform that will live for many more years. You may one day be looking at your own Best Upgrade CPU in our 2027 or 2028 round-up for AM5, and that’s the advantage AMD holds here.", " | ", "Next up is the award for Best Gaming CPU. This one is extremely simple: We’re strictly looking for the best possible gaming performance and ignoring all other factors, including cost. This is a simple numbers-based category for framerate.", "Fortunately, the best gaming CPUs these days are often cheaper than their non-gaming flagship counterparts. The AMD Ryzen 7 9800X3D at $480 gets this one with a clean sweep of the gaming charts. It isn’t even close in some situations, surpassing even last year’s winner, the ", ", by sometimes large margins.", "Let’s go by the numbers for this numbers-based award:", "From our ", ", you can see how AMD has completely taken over the gaming charts.", "The 9800X3D has an incredible lead in Baldur’s Gate 3, up at 160 FPS AVG to the ", "’s 126 FPS AVG. We spent some time in our 9800X3D review explaining and exploring this one, as a 26.9% uplift was uncharacteristic. Ultimately, it replicated and we had data to support the finding. ", "Dragon’s Dogma 2 is a 2024 title that’s extremely heavy on the CPU. This one had another break-out success, where the 9800X3D doesn’t even take a second to identify with how it breaks away from the rest of the stack. The CPU holds a 16% lead over the 7800X3D, which was already the best gaming part before that. Intel isn’t even close here.", "F1 24 also has the 9800X3D advantaged. Even though it’s becoming limited by other components, it still holds a lead. ", "Dawntrail is another like this: Gains are lower, but ever-present.", "Starfield posted an impressive uplift for the 9800X3D as well, jumping to 169 FPS AVG from 145 FPS AVG on the 7800X3D, which was already a good result.", "Frametime pacing is overall strong with the 9800X3D. There are some categories where its 1% and 0.1% lows improve disproportionately from the average, which is another great result.", "Overall, the 9800X3D easily takes our Best Gaming CPU of the Year award for 2024, following up the 7800X3D before it.", " | ", " | ", "The next award is for the Best Upgrade CPU, a category we added 2 years ago. This is the best CPU that can drop into a prior generation of motherboards. In-socket upgrades are great for consumers, reduce wasteful spending on more boards and RAM but also reduce e-waste, and keep builds more affordable. ", "This year, the ", " easily secures the award. The preceding 5800X3D (watch ", ") got Best Upgrade last year, but has since largely disappeared as a new-in-box purchase and its price has gone up. The ", " has taken its place, commonly available between a shockingly low $180 or a more typical $230.", "The 5700X3D (read ", ") is able to achieve most of the performance of the 5800X3D CPU when looking at our gaming charts. Typically, it’s within 10 percentage points, often fewer. The 5800X3D benefits from a higher frequency though, so there are some situations where you’ll see the 5700X3D dip down the charts. ", "One example is the Final Fantasy XIV: Dawntrail benchmark, where our 5700X3D ran at a framerate that gave the 5800X3D an advantage of 11%. This is one of the highest deltas we saw in gaming between the 2 parts. The 5600X3D (read ", ") even outperforms the 5700X3D in Final Fantasy, which sometimes confuses people. The 5600X3D may have fewer cores, but its frequency is 300MHz higher. Both are 105W TDP parts, but reducing core count means more power budget available for the clock. Generally speaking, the 5700X3D is the better performer between the 2.", "In Baldur’s Gate 3, we saw the 5700X3D just behind the 7600X3D and about 10 FPS behind the 5800X3D. That’s an incredible rank for a part around $230, especially considering it’s outperforming a $630 285K (read ", ") or $440 14900K (depending on when you read this, as that price keeps changing).", "Broadly speaking, the 5700X3D’s price is wild, and the fact that AM4 boards exist in high quantities on the used market also makes it a good consideration for a used build.", "The CPU can socket into AM4 motherboards, keeping cost down. If you already have an AM4 board from an old Ryzen build, it’s likely that a BIOS update will allow it to support the 5700X3D. Some older boards, especially from the first gen of Ryzen, are spotty on their support, so check the motherboard CPU support list to be sure.", "We’re going to give a runner-up mention to the ", " (read ", "), which is about $350 these days. If you’re on an Intel Alder Lake ", " (watch ", ") or something, this would possibly make sense to upgrade to.", "This is a short one: This award is for the Most Efficient CPU we’ve tested this year, and it goes to AMD’s somewhat obscure Ryzen 5 7600X3D (read ", "). This part is sold in ", " and, from what our European viewers have told us, sparingly in some European retailers. It’s not widely available, but when it is, it seems to be around $300.", "In gaming workloads, the 7600X3D had impressively efficient results. Its power consumption was just 43W in our Baldur’s Gate 3 test, which allowed it to run at 2.7 FPS/W and outrank even the 9800X3D and 7800X3D in efficiency (both of which were impressive already).", "In Dawntrail, we saw chart-breaking results that required us to adjust our chart axis. The 7600X3D outdid everyone for efficiency.", "This CPU is somewhat rare, but its combination of lower TDP and X3D on Zen 4 is what enables this performance. Definitely an impressively efficient part and we want to encourage more CPUs like this. It’s too bad about the limited supply: If it were more widely available, we might have selected it for our best mid-range CPU as well. Speaking of, that category is next.", " | ", " | ", "The next award is for the Best Mid-Range CPU. This lineup is lacking in $150 to $200 parts so far.", "Considerations for this category would include: AMD’s ", " non-X (watch ", ") at $198 and benefitting from a modern AM5 platform; Intel’s ", " or ", " (neither of which make sense at their prices); and Intel’s ", " at $190. We’re giving this award to the Intel ", ". It feels weird since it’s from 2021 -- but the modern market means prior generation parts are persisting longer than typical.", "Above $200 and with a gaming-only build, the 5700X3D might make more sense. But the 12700KF (watch ", ") gives a great balance of workstation performance and gaming performance -- and it has a big benefit of not being on Intel’s plagued architectures.", "In gaming, the 12700KF typically lands alongside the Intel ", " (currently $320) or AMD 5700X3D, 5600X, or 7700X and 9700X (read ", "). The 5700X3D is more gaming-focused and tends to be a little more expensive, the 7700X (watch ", ") is frequently more expensive, and the 9700X is $320 to $350.", "In production, the 12700KF is similar to an R7 7700X or ", " in many cases, outperforms most of the X3D parts thanks to its core count, and equates Intel’s ", " (watch ", ") or ", ". The 245K (read ", ") does well in our production tests when compared to the 12700KF, despite its shortcomings overall.", "It’s weird to put a CPU this old on the list, but AMD and Intel really haven’t had a lot of activity below $200 for a few years.", " | ", "We’ll keep this one short. This is for Best High-End Desktop CPU. For the second year in a row, mostly because there aren’t any replacements, this is going to AMD’s Threadripper ", ".", "We like the ", ", but its super high core count is more limited in use case. If you need 64 cores, you probably know you need 64 cores.", "We’ve found the 7970X, which is the 32-core part, to be an excellent balance in production workloads that we use in our office. The 7970X does great with Adobe Premiere, has a ton of I/O capabilities with extra PCIe lanes that open up more storage options for true workstation-class computers, and along with other Threadripper parts, has some of the best efficiency results we’ve presented. ", "It also performed exceptionally well in some of our SpecWorkstation benchmarks previously, to the point that a ", " wasn’t even close in some comparisons. ", "But for now, we’d advise waiting on Threadripper. It sounds like the beginning of next year will be busy for everyone, and current rumors about the 9950X3D may be reason to pay attention there as well.", " | ", " | ", "Next up is the best gaming CPU Under $100. This one is self-explanatory.", "This goes to a split because the price is variable: The ", ", and the ", " or ", " all get attention.", "Once again, multiple years running, the ", " ends up on this list - but unlike last year, the ", " has also fallen below $100. The R5 5600 non-X also ends up on this list, with all 3 CPUs taking this category. Out of these three CPUs, the AMD R5 5600 (watch ", ") is the best overall balance and performer in most categories. The only reason to exclude it in favor of the i3s is if it’s over $100 when you check this -- but right now, there are OEM CPU-only listings for $99.99, which technically qualifies for the list. Value goes down at its other common mark of $120 and it falls off the list at that point.", "The 12100F (watch ", ") is $77, which would be crazy if it weren’t 2 years old. The i3-13100F (watch ", ") is $80. Neither of these F-SKUs have IGPs, which is why they’re cheap.", "When we looked at the i3-13100F last year, we found that the 13100F frequently outperformed the ", " by a significant percentage. The ", ", in our opinions, is not good enough to consider. It’s slightly more expensive than the 13100F but worse, and both are on dead platforms.", "For gaming, looking at our data from last year when we had all 3 of these CPUs on the charts, the ", " regularly outperformed the 13100F and 12100F. In fact, it was even over the 12400 in some tests. If you can find it under $100, the 5600 makes a lot of sense for this category. Even a few bucks over that is not bad.", "But where the i3-12100F and 13100F are $20+ cheaper and where the strictest possible budgets exist, they are still capable performers. We recently reran the 12100F and found that it was capable in every game we tested, with one exception of extremely spotty frametimes in our Baldur’s Gate 3 test.", "It’s impressive how much these 3 CPUs are capable of. They’re still playing games, and mostly without major frame pacing issues. It’s just unfortunate that Intel and AMD haven’t really launched anything new into this market for such a long time.", "The last category is the Biggest Disappointment. Intel gets this one for the second year running -- 2022 saw it going to AMD for the ", ". But this year’s disappointment puts all other ones into perspective.", "The ", " get this year’s award, reminding us that where other disappointments simply suck, there’s always room to suck more. The 13th and 14th Gen CPUs experienced a mix of problems, including fab-level oxidation defects confirmed by Intel all the way up to wider-scale stability issues relating to voltage and microcode. Intel fumbled the handling of this and lost consumer confidence, dragging its feet on a response and then trying to craft a careful narrative when it finally did respond.", "This was followed-up by the Ultra 200 series, which went back to simply being a disappointing set of products rather than a truly catastrophic failure. But this industry needs Intel and AMD to compete in a healthy environment: Intel of the past showed us what happens when the market has only one dominating vendor, and NVIDIA in GPUs shows us similar. It’s just not the job of consumers to prop-up a company that sells sub-par products -- or in the case of the disappointment this year, ones which have potential time-bomb failures baked-in. In the very least, Intel at least eventually responded with microcode patches that the company says has fixed the issue.", "Pricing today is a giant variable. It moves all the time, and especially as we approach Black Friday. All of this was based on pricing at the time we wrote this story, which is leading into Black Friday. Remember that we almost always consider price in our choices, so some of those may move around as prices fluctuate.", "It’s always weird when some of the best parts are prior generation components, but that’s becoming more common in both the CPU and GPU space lately.", "The biggest area that’s lacking in CPUs right now is the sub-$100 market, which is aging with the 12100F and ", ". The R5 ", " is only rarely sub-$100 right now, but would probably become the go-to choice if it ever solidifies in that range. Sub-$200 is better, but still mostly older components.", "That’s it for this round-up though. We love working on these and they’re a ton of fun to work back through all the components and refresh ourselves. It’s also nice to have some more positive lookbacks at components to remind us all that there have been some pretty good launches.", "We have a lot more of this coming up, including a Best Cases of 2024 story that we’re excited to finish and post."]},
{"title": " Intel Unbends Its CPUs: 285K RL-ILM vs. Standard ILM Laser, Pressure, & Thermal Benchmarks", "paragraph": ["Intel Unbends Its CPUs: 285K RL-ILM vs. Standard ILM Laser, Pressure, & Thermal Benchmarks", "Last Updated: ", "The Highlights", "Intel is finally trying to unbend its CPUs, despite having to be on a bender to buy a $630 ", " right now. Today, we’re using our laser scanner to look at the deflection in the CPU heat spreader from the different loading mechanisms, including these scans of the 285K (read ", ") and ", " with different coolers installed. Today’s testing also includes specialized pressure scanning to produce pseudocolor images of pressure distribution across the IHS surface, very brief thermal testing to look at the differences with Noctua’s LBC (Low Base Convexity) flat coldplate, and we’ll look at the mechanical aspects.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Andrew Coleman", "Jimmy Thang", "Unfortunately, Intel’s new and better ILM is optional. It didn’t force motherboard manufacturers to use it, so they can still cut corners if they want to save a few pennies. The new ILM is called the RL-ILM, or Reduced Load ILM, with the old one being referred to as the “Standard” ILM (indicating an assumption of it being the default). Our ", " ships with the RL-ILM, as do most high-end boards, so we used it as a test platform to swap to other official LGA-1851 ILMs for comparison.", "Let’s get into it.", "We’ll get some basic education in and go over the differences:", "CPU sockets are one part mechanical and one part electrical. Intel uses what is called an Independent Loading Mechanism for its socket. Some people include the ILM when referring to the socket. On a technicality, the literal socket is the Land Grid Array with the carrier that actually holds the CPU. The loading mechanism is the mechanical part of the socket.", "Intel is shipping 2 types of ILM, RL-ILM and Standard, and it is using at least 3 different suppliers that we’re aware of to manufacture these. Our ", " came with an RL-ILM by Lotes, which is a long-time supplier of ILMs. We also have the same-brand ILM of the Standard variant, plus the two other suppliers you’ll find on boards.", "Here’s a CAD render of the socket. The standard ILM has an angle that increases the force application along the edges of the CPU. That’s the real difference here. This is what causes the depression we’ve seen in previous 3D laser scans we performed. These scans are from our past content: You can see how the ILM causes significant bending and forms a central concavity with the heat spreader, leading flatter cooler coldplates to be worse on Intel despite being better on AMD. You can learn more about that in our previous coverage ", " and ", ". ", "Back to the CAD model, the RL-ILM is basically just flat. This is the biggest change, as the force should be reduced. This is also why Intel requires a higher force heatsink to be installed in order to ensure contact.", "The RL-ILM also has one other difference: There’s an additional adhesive spacer on the underside, which can be thought of as similar to the washer mod that Noctua now ships with its ", " coolers as an option. The additional spacer goes underneath the existing black spacer, meaning that the ILM leg component probably was taken from existing Standard ILM stock, then retrofitted with effectively a sticker.", "In our original ", ", we showed how the ILM clamp appeared to apply very slightly higher pressure to one side of the socket. This was exaggerated by the fact that the ILM has some play in it, where it can shift side-to-side and be repositioned and we saw that still happens on the RL-ILM. ", "Here’s our 3D render of the standard ILM: With the CPU dropped into the socket, the standard ILM uses a hook that’s attached to the lever to centrally press down on the ILM lid that clamps directly to the CPU IHS. With the lever fully down and secured, the ILM is now secured at 3 points: 2 on the bottom of the ILM and 1 at the top. All of this is the same on the new RL-ILM. ", "As for the CPU, the ILM has two wings that press down on the IHS at the borders, and with that curvature we showed in the CAD model, the force application at these points is high enough that a highly precise gauge can show how light is able to shine through despite the CPU being relatively flat when unclamped and looking flat to the eye.", "We’ll refer you to our ", " from 2022 to learn more about this older style of ILM.", "For the new version, clamping the CPU in the socket functions mechanically identically for the end user, with the lever pulling down to hook under a securing latch and clamp the ILM at 3 points, with 2 main contact points at the wings of the IHS. However, the lack of a bend in the ILM reduces the load. Intel still has to keep the force high enough that the CPU’s pads make contact with the socket pins, but has to be careful that it’s the right amount.", "Too much or too little force can cause boot issues and high clock memory stability.", "And that’s really it for these ILMs.", "Noctua just got done spending literal years developing its new ", " and shipped it with 3 different coldplates, which makes it a unique candidate for pressure testing. ", "For pressure testing, we take the different ILMs and apply a special pressure paper between the CPU and the coldplate. We then take that and scan it in with a specialized pressure scanner to create pseudocolor images of the pressure distribution.", "Here are the results for the two ILM types with the HBC cooler.", "The new Reduced Load ILM with the high base convexity Noctua coldplate yielded low pressure at the outer edges, but especially toward the top of the board near the VRM and EPS12V cables. The pressure centrally remained high; however, because the CPU should be flatter with this ILM, the Noctua cooler ends up with less evenly distributed pressure because it’s designed for a different scenario.", "The standard ILM with HBC cooler scans reinforce this: The HBC cooler ends up with more evenly distributed pressure at the top and bottom edges of the CPU IHS.", "And here’s only the RL-ILM with the 3 Noctua cooler cold plates.", "The RL-ILM pressure distribution was the most evenly distributed with the standard and LBC solutions. The two are mostly indistinguishable for distribution, although the precise pressure centrally will influence the results in thermal testing.", "The LBC cooler had slight gaps at the left and right edges, but consistently square distribution at the top and bottom corners, with good pressure across the entire center. The standard cooler had less consistent pressure at the top and bottom edges and similar gaps to LBC at the edges. Ultimately though, these two basically look the same for contact.", "Our ", " went into depth with laser scans of the cooler’s coldplates, and that hasn’t changed. We’re showing the LBC, Standard, and HBC scans again briefly here just to help recap the impact because when we’re looking at pressure and how it is affected by the ILM, the cold plate is a part of that equation. ", "And now we’ll scan the new Intel CPUs to see how their shape matches the pressure scans we saw earlier. ", "Here’s a look at the plain Intel 285K when it’s just flat in the laser scanner. The CPU isn’t in a socket at all here, so this is as simple as it gets. Even in our 2D screenshots of the 3D scan, we can see the letters -- the CPU IHS is so flat that the very slight indentation for the text is visible.", "The IHS itself has a few higher points, one just off-center, one along the right edge when oriented in a legible orientation, and one just off the left edge of the CPU.", "Magnifying it 100x, that coloration grows to form just a few high points. Overall, it’s flat, but at high magnification, some small deviations appear. One thing that is clear though is that there is no substrate curvature, which makes sense since it hasn’t been socketed.", "Let’s create a grid with the 285K and add the ", " to it. The 245K (read ", ") follows a similar pattern: Centrally, it’s a little higher, then just off-center right it’s also slightly higher at 1x. Adding 100x to the grid, there’s a similar pattern as with the 285K.", "Finally, we added our unsocketed 12900KS from the ", ". It’s still flat when unsocketed, but the difference in IHS design is also slightly showing through.", "And now, we’re going to throw this Z890 Hero with the new ILM into the scanner and socket the CPUs in it. We obtained this package of ILMs to test. The ASUS board uses the Lotes RL-ILM, so we’ll start with that one.", "Here’s a one-to-one 3D visualization in Blender taking STL files from our laser scanner, showing the 285K with the standard ILM first. As usual, 1x magnification doesn’t show much, but bringing that to 100x quickly shows a deep concavity centrally, just like we saw with LGA 1700 CPUs.", "Switching over to the new reduced load socket, we can see that the 1x to 100x magnification shows less of a pronounced curvature of the IHS itself. It’s still curved, but much less, with the CPU maintaining a more consistent height instead.", "Here’s a grid comparison of the different ILMs on the same motherboard, tested with the same CPU -- starting with the 285K.", "You can see that the Standard ILM at 100x magnification shows a huge deflection centrally, as we’ve seen before, with higher pressure on the far ends of the mechanism. While we can sort of see the slight ridgeline down the middle of the CPU, the bigger issue is how deeply it indents.", "The reduced load socket is significantly flatter, with less of a central deflection. The ridgeline in the CPU IHS becomes more pronounced in the graphic because it is more consistently the highest thing in the image. Remember that this is at 100x magnification, so the differences are exaggerated intentionally.", "Unveiling the 245K results in the grid, we see the same patterns: The standard ILM deeply indents the CPU centrally, deflecting and deforming it in a way that coldplates with matching convexity will cool it the best. The reduced load socket is flatter and more consistent, though is still slightly deflected centrally.", "We need a laser scan of the cooler coldplate before moving to the pressure maps, as the cooler and IHS alike contribute to the pressure distribution. ", "This laser scan shows the coldplate of the ", ", which is what Intel sent with its CPUs to reviewers. Other coolers would fit, but we wanted to test what Intel officially endorsed.", "At a 1x scale, the ASUS Ryujin coldplate looks relatively flat, but still shows a protrusion dead-center, gradually reducing height towards the outer edges. When we did our ", ", we found that this pattern often did well for Intel.", "Scaling it 100x, we get this almost comical tower protruding from the coldplate. This helps us see the steep slope as ASUS applies massive pressure dead-center with its coldplate design. This is sort of a hamfisted approach and version of what Noctua did more precisely with the D15 G2 for LGA 1700, except Noctua had more nuance in the exact shape of the convexity, which will better align with the concavity in LGA 1700 CPU heat spreaders previously. It’s similar to what we saw in the $60 Thermalright liquid cooler, which managed to brute force its way in performance thanks to similar protrusions.", "Time to look at some pressure scans of the ASUS cooler with the new Intel ILMs.", "These images show a new pressure scan of our ", " with the ", " and the old (or “standard”) ILM. In this scan, you can see the ", " has narrowing pressure on the left and right sides, with most of its pressure centered. That’s where it should be, and most of that is thanks to the comically protruding ASUS coldplate, but fuller coverage is ideal. The older IHS also is a little bit different shape than the new one. The second column represents the pre-installed reduced load ILM using the 285K. Looking at the third column, adding the standard ILM with the 285K, doesn’t look too different. The pressure profile appears to be distributed taller and narrower. There’s still some of that slimming effect going on when we get to the left and right sides but not nearly as pronounced as with the last gen IHS design and ILM. ", "Ultimately, what we see is that ASUS’ older brute force approach gets a better pressure distribution on the prior LGA 1700 socket than on the new ARL 285K socket, which is thanks to the massive central protrusion. This is the approach Thermalright took with its $50-$60 liquid coolers previously as well. It’s relatively hamfisted, but works, whereas the more carefully shaped approach of air coolers like the D15 G2 and the ", " are technically a better pressure match; now, that said, a 360mm liquid cooler is still “better” (with regard to capability) overall, and it will cool better, but the Ryujin could improve with more purposeful coldplate shaping.", "Thermal testing is up now. Full transparency that we’re keeping this really simple this time, mostly because it doesn’t take much testing to verify if there’s a difference at all.", "We’re only running the comparison thermals with one cooler this time. The ASUS cooler is so heavily deflected that we’re not sure the comparison would be that useful, so instead, we approached it with what should be a worst case scenario: The Noctua NH-D15 G2 LBC, or low base convexity, which is the flattest of Noctua’s options. In theory, this should be the worst on the more deflected standard ILM+IHS combination and the best on the flatter IHS from the RL-ILM.", "Other coolers could have more or less impact. Coolers with higher force application centrally and with more convexity would continue to compensate for design problems of the standard ILM, but we want to just run a quick evaluation on one of the uncompensated scenarios.", "We are also not testing anything below the minimum spec Intel declares for the socket, which is a 35 lb. force from the cooler. Anything high-end that’d be paired with the current CPUs will meet or exceed this requirement anyway.", "Here are the results from a simple A/B test. For this testing, we did two full mounts and at least 3 passes to average the numbers. This allowed us to check for variance mount-to-mount. All our other CPU cooler standards and methodologies apply, like manually spreading paste, controlling the fan speeds, and fixing the voltages and frequency. We disabled all power and thermal limits and set a fixed voltage with fixed frequencies. We have a known power draw down the EPS12V and 24-pin ATX12V through the 4 phases that it has (without PCIe slot power). That allows us to get these numbers.", "The result was 61.8 degrees delta T over ambient for average P-core temperature with the standard ILM and 59.6 dT with the RL-ILM, or the improved one, meaning about a 2.2-degree reduction when accounting for  ambient. Without the deltas, we were running the 285K in the 80s to low 90s because we disabled all TVB 70-degree throttle controls. Running the CPU hotter allows us to see more of a gap between the results. A CPU consuming less power with a stronger cooler would likely not show as big a gap.", "Checking briefly with Der8auer as a peer review, we learned our results are roughly in-line with his own. The differences are aligned with cooler and heat load differences.", "We observed a slightly lower core-to-core delta with the new ILM, but it was within error. The AVG all-core temperatures were not significantly different from the P-core temperatures in this one due to the proximity of the P-cores to E-cores in this architecture (combined with our adjustments in BIOS). ", "So, as short as possible, the RL-ILM is about 2.2 degrees better at this heat load with this cooler.", "Before we move to the conclusion, in case you buy a motherboard with a standard ILM and want to move from the high pressure standard one to the low-pressure RL-ILM, we’ll walk you through how to do that. ", "If you are going to swap the socket, we recommend sticking with the same brand for the replacement if possible. In our case, we used Lotes. ", "To begin, we recommend starting with the CPU installed to protect the pins underneath to mitigate the risk of dropping, say, a loose screw down into the socket. ", "From there, unscrew the 4 screws. We used a regular T20 Torx screwdriver. ", "Removing the screws frees the top and bottom pieces of the socket. It also frees the backplate. When you’re installing the backplate, it’s important to get the orientation right and to ensure that the plastic sticker side is touching the bottom of the motherboard and not the exposed metal side. The backplate also features a notch that aligns with the triangle that’s on the corner of the CPU.   ", "We found that it’s easier to install the lever arm piece first with its 2 screws. Once that’s in place, it’s time to secure the other side with its 2 screws. You don’t need a lot of torque for the screws. We recommend that you tighten them in a star pattern to evenly distribute pressure.  ", "We regularly see people online saying that some cooler is 3 degrees lower than some other cooler, so just a reminder here on how all of this works: That 2.2 degrees is specifically at the power load we tested and with the cooler we used, under the conditions we employed. It will be higher or lower based on how these parameters change.", "As an example, we did one round of tests with all the Intel throttle controls still enabled and saw less than 1-degree of difference -- but that’s because it was just throttling itself to regulate the temperature.", "The new RL-ILM is definitely an objective improvement in both the curvature of the IHS and substrate and of the temperature in our brief testing. The pressure distribution depends on the cooler more than anything and it isn’t always clearly better, but the thermal result tells us that the net result is positive.", "Frustratingly, this is optional. Intel is not at a stage where it should be making clear, simple, easy improvements “optional” for motherboard vendors. ", "Although we don’t want Intel or AMD to force certain lock-downs, like taking away overclocking features, we do think both companies should enforce a default or baseline configuration that is in the best interests of the consumer, with the option for the consumer to tweak as their motherboard allows once exiting default settings.", "In this situation, we do think Intel should just bite the bullet and force the better solution. It may be a situation where board partners had already purchased millions of these older mechanisms. Regardless, Intel has at least improved its mechanism. It is technically slightly more expensive than the original ILM, but since we’re talking pennies, we’d like to see this forced in the next generation as the standard ILM since it is just better. Intel needs to stop taking a soft-handed approach to its partners and taking the small victories when it can get them.", "This doesn’t kill the contact frame market, though: That’ll still provide uplift, as the RL-ILM remains a mid-step improvement without going full flat like the prior contact frames we’ve tested.", "That’s it for this one. We probably won’t do a ton of Arrow Lake follow-up testing since it doesn’t make any sense to buy right now, but we may explore a few other features."]},
{"title": " Intel At Its Best: Revisiting the i9-12900K, i7-12700K, i5-12600K, 12400, & i3-12100F in 2024", "paragraph": ["Intel At Its Best: Revisiting the i9-12900K, i7-12700K, i5-12600K, 12400, & i3-12100F in 2024", "Last Updated: ", "The Highlights", "We’re revisiting Intel’s best recent CPUs right now. Intel Alder Lake managed to escape the 13th & 14th “Gen” issues without a scratch while also being the start to this era of CPUs. They can socket into the same motherboard as a ", " in many instances and are somehow even still available for (sometimes) reasonable prices. Recently, the ", " was as low as $120 from Best Buy as it got purged from inventory.", "In this article, we’re revisiting the 12900K (watch ", "), ", " via our ", ", the ", ", ", ", and ", ".", "Steve Burke", "Mike Gaglione", "Tim Phetdara", "Jimmy Thang", "As a quick reminder of the history of these parts, this is what we thought of them back when they launched: “This is an excellent first volley from Intel with Alder Lake. It is on the expensive side. Price has crept up, performance, fortunately, has also crept up but so too has power. You get some new and exciting technologies with Alder Lake; DDR5 being one of them. Ultimately, it's about how this competes and this has surprisingly decent value when compared to the 5900X (watch ", ") and the 5950X (watch ", "), especially in production workloads. There are places where AMD still holds an advantage but they have gotten slimmer.”", "That was for the 12900K. For the 12100F (watch ", "), we were also relatively positive: “At $130, it's actually a pretty exciting CPU for us to review because, for gaming, it did very well. And even with a high-end GPU, it's doing pretty well, so we were impressed with its gaming performance.”", "It feels weird to revisit our old reviews because we were really excited about what Intel was doing at the time. It was fiercely competitive. ", "It’s easy to forget how positive we were on some of Intel’s launches back from the 8000 series into the 12th Gen with Alder Lake when looking at the last few rounds. The 13 and 14 series CPUs were largely refreshes, but Alder Lake brought a new platform forward with new I/O, including options for both DDR4 and DDR5 and PCIe Gen5.", "AMD had also forsaken its budget market at this time: Going back through our old reviews, we were reminded of how AMD had gotten so comfortable in its position that it had stopped the 5000 series briefly at the 5600X (watch ", ") levels. They introduced the 5600 (watch ", ") to help with this, but overall, AMD’s pricing was much higher than it had been in the preceding generations. That left Intel with a huge gap to fill with its 12100F, which later went on to land on our ", " list for at least 2 years for its viability as a true budget gaming part.", "So that’s the history. These CPUs were exciting. ", "For this revisit, to make space on the charts so they are somewhat legible, we’re removing the ", " non-X, ", " non-X (watch ", "), and ", " (watch ", ") ECO Mode results from gaming benchmarks. You can find all these numbers in our ", " or ", " if you’d like them. They are directly comparable.", "That’s enough of a history lesson. Let’s get into it -- and we’ll start with a new set of experimental charts.", "We have a table we’re experimenting with for this. This table will list the closest equivalent component for each application tested. Sometimes the ranges don’t line-up well, so we chose the closest within reason, but deferred to older parts where necessary. We defined “modern” as anything from Ryzen 5000 or newer and anything from Intel 13 and newer, even though 5000 can be pretty old -- it opened up more comparisons.", "Broadly speaking, we noticed that the ", " is similar to a newer i5 in several games. This included Stellaris, F1 24, Starfield, Final Fantasy XIV, and the Ultra 5 in Rainbow Six (but with worse lows). The Ultra 7 265K (read ", ") was also close in Final Fantasy and Baldur’s Gate 3. AMD’s CPUs are more varied, and include the ", " (watch ", "), ", " (watch ", "), ", ", and some X3D parts, generally those are higher performers.", "The ", " was broadly similar to an ", " from Intel or a ", " to ", " from AMD, with some X3D presence. Most X3D parts perform much higher than these Alder Lake CPUs.", "The ", " was regularly near the ", " and ", " CPUs.", "The ", " regularly neighbored the ", " and sometimes the ", " or ", ". The ", " had few modern neighbors, mostly aligning with a 3700X (watch ", ") or 3600 (watch ", ") for gaming performance.", "Here’s the same concept, but applied to production workloads.", "Intel Alder Lake does better here for modern equivalents. The 12900K is regularly similar to a 13700K (watch ", ") or 7900-class CPU. It isn’t distant from the ", " in Decompression, although dips in Premiere closer to a 245K (read ", ").", "The 12700K (watch ", ") is similar to the ", " in many of its tests, so after 3 years, it has dropped to subsequent series i5 performance levels. The 245K is regularly right alongside the 12700K. From AMD, the ", " (read ", ") and ", " are regularly its modern equivalent. The 12600K (watch ", ") is most similar to the ", " or ", " in many tests, with no nearby modern Intel equivalents. They are all much better than this. We might have to test a ", " (read ", ") or something to see this level.", "The 12400 (watch ", ") is regularly near the 5600X. In some tests, it is down at 3600 or 2600 (watch ", ") levels. The 12100F has no modern neighbors and, in some instances, no suitable comparisons close by. The R5 2600 (watch ", ") is regularly the closest comparison for the 12100F.", "We’ll start with Stellaris, the space game which we use to test for simulation time rather than framerate. This is still a great benchmark because the results don’t care about resolution or graphics: It is a highly CPU-bound game with real-world implications for time.", "First up, our new entry with the best result is the ", " with liquid nitrogen and at 6.2 GHz. Although you could have a friend or family member pour LN2 while you game, it’s not likely -- but we wanted to put it here to show just how insane the CPU is when pushed to the limits.", "Snap back to reality, we have Alder Lake: The 12th Gen CPUs land at 36.7 seconds for the 12900K, 37.7 seconds for the ", ", 41.2 seconds for the 12600K, and 43.1 seconds for the 12400. Top-to-bottom, this creates a range of 6.4 seconds, or a reduction in simulation time from the 12400 to the 12900K of 15% -- meaning 15% less time to simulate. If you had bought the 12900K for $630 in 2021, then it’s given you about 3 years of performance and has aged into a modern i5 in this test, which really isn’t that bad. The ", " is adjacent at 36.6 seconds. An in-socket upgrade to a 14900K (read ", ") would get you about a 9.5% reduction in simulation time and is probably not worth it for most people. The ", " (without liquid nitrogen) would yield a 30% reduction in simulation time.", "The 12700K is slightly better than a ", ", with the 12600K around 5800X (watch ", ") and 5600X levels. The 12400 is significantly better than the 12100F at 47 seconds and just behind the 5600X.", "Dragon’s Dogma 2 is up now. In this one, the chart leader is the 9800X3D at 129 FPS AVG, which is an incredible lead over the ", "’s 111 FPS AVG.", "The 12900K falls down to a cluster of Intel parts that cap-out around 100 FPS. The ", " is roughly equivalent to the 12900K in averages and lows. The 245K isn’t far behind. ", "The 14900K boosts the ceiling to 110 FPS AVG, alongside the ", ", ", ", and ", " that find a 10% higher ceiling. The ", " has functionally identical performance to the 12900K. Anything on this list is a sidegrade for it other than a 9800X3D.", "We feel the same about the 12700K: It wouldn’t be worth upgrading by this test alone.", "The 12600K and 12400 show more age: Both are still great for framerate and completely playable, but at least a gap to the top is established. Moving to a 9800X3D would boost performance by 46% from the 12600K. An in-socket upgrade might be about 22% by moving to a ", ". ", "The 12100F is at 71 FPS AVG, which is also remarkably good for such a modern game. The lows are hurting a little more and sometimes get spiky, but overall, we’re impressed by how it has held on. Upgrading to a 13700K in-socket would be a huge upgrade from the 12100F. It would be economical, and might be worth considering.", "Final Fantasy 14: Dawntrail is a 2024 entry for us.", "The Alder Lake series does OK here from an absolute standpoint, but is far down the charts in a relative sense.", "The 12900K and 12700K are between the Ultra 7 265K -- which did horribly in this benchmark -- and the 13600K. The Ultra 200 Series is known to be regressive in this game, with Intel also showing the same behavior. The sad thing is that you’d be going backwards if you didn’t pay attention to benchmarks and bought a 265K. It wouldn’t be a crazy thing to do, either: It’s 3 so-called “generations” newer, yet worse than a 12700K and 12900K, at least in this test. The 12600K wouldn’t even see a huge uplift to it either.", "The 13700K and ", " offer large improvements around 15-18% from Alder Lake, though you’d need a good price to be worth the purchase. The 14900K boosts to 310 FPS AVG, an uplift of 26% over the 12900K.", "AMD’s 9800X3D sets the ceiling at 373 FPS AVG, with all the other X3D parts right alongside it. ", "Starfield is up next. The 12900K hits 124 FPS AVG in our test here, which aligns it with the 13600K and ", " CPUs, slightly bested by the 5800X3D (watch ", "). This goes to show how good the 5800X3D was at launch, especially given the price gap when both the 12900K and 5800X3D were still regularly available new.", "The 9800X3D shows room for a 36% improvement in performance from the 12900K. The ", " with ultra-fast, expensive memory in Gear 2 improves by 23% on the 12900K, but the like-for-like comparison has it at 15% ahead.", "The 12700K is similar to a 245K -- you’d be downgrading overall by moving to it, aside from efficiency. The 5700X3D (read ", ") is also nearby. Upgrading the 12700K to a ", " would get you about 13% more performance and probably isn’t worth it overall.", "The 12600K stands to gain more notably if upgraded in-socket to a 13700K, where it’d gain 26%. The 12400 could be worth considering an in-socket jump to a 14600K (watch ", ") or 13700K as well, if cheap enough.", "The 12100F is somehow still chugging along, sandwiched between AMD’s 3000-series parts and outperforming the R5 3600 and R7 2700 (watch ", ").", "Baldur’s Gate 3 used to have the X3D series all in the 120s, but the 9800X3D broke that in a massive way and hit 160 FPS AVG in our particular test case. We validated this in our ", " and explained why it’s happening.", "X3D dominates the entire top quarter of this chart, followed next by the memory-boosted ", ". The prior generation 14900K, ", ", and 13700K are all within error of each other. Don’t be confused by their ordering: Their performance is identical and within run-to-run variance, which is due to encountering a memory limitation. We can see this from the 285K (read ", ") stock results versus the DDR5-8600 results.", "The 12900K ran at 96 FPS AVG, or equal to the 265K. The 265K would be an expensive downgrade when looking at the total picture. The 12900K is still doing well enough here that it probably doesn’t make sense to replace except maybe with a 9800X3D.", "The 12700K is about tied with a 245K. Like the 12900K, there aren’t many worthy upgrades here. A 13700K, 13900K (watch ", "), or 14900K would give about a 15% uplift in our testing.", "The 12600K and 12400 are at about 13600K levels of performance. An in-socket upgrade to a 13700K in this chart would yield about 28% improvement from these CPUs. The 12100F had trouble running this test. We might be able to force it to work, but natively, the low performance was bad enough that we consider it disqualifying in our test.", "F1 24 is up next.", "The game scales from 163 FPS AVG up to 464 FPS AVG in our testing. The 12900K starts Alder Lake off down in the range of the i5 CPUs, including the 13600K and 14600K. Inspecting the data, we found that the 12900K had a more variable average FPS than some other CPUs, which we think is due to its core arrangement and Windows 2H24: The range was 310.5 FPS to 316 FPS AVG run-to-run, and upon inspection, it is due to the frametime pacing where we sometimes get a higher throughput with worse pacing and sometimes the opposite.", "Overall, it ends up around 13600K levels. We saw this last round as well, just with an older Windows version. The 14900K has a 23% advantage on the 12900K. The 9800X3D runs 49% ahead of the 12900K.", "The 12700KF is between the 5800X and 5600X, with the 245K just ahead. Intel’s 12600K lands at 270 FPS AVG, meaning a 13700K upgrade would boost the average by about 34%.", "The 12100F still does great here, all things considered, and is just ahead of the 3700X.", "On to production benchmarks. For these tests, we’re looking at applications like Blender, Chromium code compile, and more. Users of the i7 and i9 CPUs are more likely to care about the performance here. It’s also one of Intel’s strong points of the past generations.", "Blender 3D rendering is up first for production.", "The 12900K did well here. It’s at 11.7 minutes required to complete a single-frame render of the GN intro animation, which has it about tied with the 12C/24T ", " non-X CPU. The 13700K does well with its higher frequency and equal core count to the 12900K. The 14900K has large gains here from moving to a 32-thread configuration, reducing the time required by 27% to 8.5 minutes. That’s about the same we see from the newer 265K, with the 285K doing well in one of its few strong tests and reducing time to 7.1 minutes. That has it at about the ", " levels of performance.", "If you were upgrading for gaming, the 9800X3D is the only option that might universally make sense against the 12900K. But for production, unfortunately, the options wouldn’t necessarily move the needle on gaming performance in a meaningful way despite offering large gains in workstation applications. You’d have to choose.", "The 12700KF has the same core count as the 13600K, so the two perform about the same. An upgrade to the 14900K in-socket would be a huge 39% reduction in render time required.", "The 12600K is at about levels of the 9600X. The ", " (watch ", ") outperforms it, but is better in gaming than production as compared to the non-3D parts like the ", ". The 9800X3D would at least improve on the 12600K somewhat while giving a big boost to gaming.", "As for the 12400 and 12100F, they’re near the bottom. The 12100F struggles with core count, so the 2600 is a little faster. The 12400 is roughly tied with the 3600.", "In Chromium code compile, the 12900K required 119 minutes to complete the compile. This has it closer to the R9 7900 non-X (watch ", ") than anything else. The 13700K improves with its higher frequency and equal core count, with the 14900K giving a compile time reduction of 26% less time. The 285K is also a big step up, though not significantly different from the 14900K.", "Intel’s 12600K might see enough benefit from an in-socket upgrade to a 14900K or 14700K (read ", ") that it’d be worth considering, especially for the gaming uplift, but only if you’re trying to save on cost by reusing a board and DDR5 RAM. ", "The 12100F required 382 minutes, which is still about an hour more time than the R7 2700 and about tied with the R5 2600.", "7-Zip compression testing makes the 12900K feel a little older, outperforming the 14600K by just 4.3% (and similar for the 9800X3D). In the very least, upgrading to a 9800X3D for gaming would at least net equal performance in this type of task.", "The 14900K offers a 38% increase in MIPS over the 12900K, maybe making it worth considering.", "A new build with a ", " yields about a 46% uplift in this benchmark.", "The 12700K is down near the 7700X (watch ", ") and ", ", with the 14700K 48% higher in MIPS.", "If you have a 12600K and wanted to stay on Alder Lake, moving to the 12900K improves performance by 48% here, which is pretty massive. ", "The 12400 is more similar to a 5600X or 3600, so anything would be an upgrade. The 12100F is at the bottom, falling behind the R5 2600 in a predictable way with its thread deficiency in this test.", "7-Zip decompression shows a lot of scaling with cores, as indicated by the 9950X (read ", ") and ", ". The 12900K still does OK here and bests the 9800X3D on a technicality. The 265K offers an uplift that wouldn’t be worth buying into, with the 285K pushing 30% higher in MIPS to 193K. The ", " (watch ", ") and 13900K offer more meaningful uplifts though, with the 13900K and 14900K benefiting from higher thread count and opening opportunities for upgrades.", "The 12700KF is at 245K levels of performance and about tied with a 5800X. The 12600K would see multiples of uplift with some of the newer options at the top of this chart, again including the 14900K and 13900K. The 12100F isn’t comparable to anything here, with the 12400 similar to an R5 2600.", "Adobe testing is next with the Puget Suite.", "Back with the Alder Lake launch, we stuck with Intel for our Premiere editing systems since it was the best opportunity at that time.", "Today, the part still does pretty well in Premiere. Actually, we still use its direct descendants in our main editing machines, including 13700Ks and various i9s. The 12900K scored 9948 points in aggregate, which has it between the 9800X3D and ", ". The 14900K wouldn’t boost it much, only 11% here. The 285K scores a rare victory in this one, but again wouldn’t be a huge move if you’re already on a 12900K. It might make more sense for a new build.", "The 12700KF could be kept relevant a little longer with a bump to a 14700K and still be a top scorer on the chart with modern memory. The same goes for the 12600K and 12400.", "The 12100F at least outdoes the 2600, but that’s it.", "Adobe Photoshop is last.", "This one is a bloodbath compared to many years ago, with Adobe updates and AMD architecture changes benefiting AMD.", "The 12900K is in the lower half of the chart and surrounded by i5 CPUs, with the 12600K near AMD’s 5800X. The 12100F at least does comparatively better here and outranks the R5 3600.", "Overall, almost anything is an upgrade over Alder Lake in this test.", "Wrapping things up, the 12th Gen CPUs are still pretty good. ", "People commonly ask us when they should buy or wait. If you’re on a 12th Gen CPU, we’ll break it down like this: Ask yourself if you’re happy with your PC right now. If you’re not actively annoyed by your computer’s performance, then you can just keep using it. If, however, the performance is bad or you just want to build a PC because it’s fun, then there are options here. ", "One of the options is for an in-socket upgrade, to which there are caveats, which we’ll discuss below. Another option is to build a new system.  ", "For the in-socket option, the 13th and 14th series would be potential drop-in upgrades. The lower down the stack 12th Gen CPU you have, like the ", " (read ", ") or ", ", the more meaningful it would be to do this. ", "For this to work, you need to make sure your motherboard with a 12th Gen CPU has the newer CPUs on its compatibility list. You should be able to find this on the manufacturer’s website. You would also need to update the BIOS. If you’re upgrading from something like a ", " to a ", ", you’d want to make sure that your board has a good enough VRM to handle the additional heat and power. Likewise, it’s ideally an unlocked board for more feature support.", "We tested on DDR5 here with like-for-like memory between the platforms. You could have used DDR4 with 12th Gen also. DDR4 could be a limiting factor, so if you have to upgrade your RAM and motherboard, you may as well go with a fully new build from AMD instead (if building a gaming PC), like a ", " or similar.", "And finally, used CPUs might be a bit of a landmine situation, unfortunately. Intel’s 13th and 14th Gen woes are detailed in other stories we’ve published, but one potential problem is that used CPUs could have instability issues. You’ll want to be careful when buying used. This is unfortunate, because CPUs have historically been pretty bullet-proof -- especially Intel’s -- and have been a great used option to save a quick $100 on an in-socket upgrade.", "The price of new 13th and 14th series have dropped in price, which makes something like a ", " not a bad option, especially if you’re on a lower tier 12th series part. ", "Overall, objectively speaking, Intel’s 12th CPUs (for the most part) are still great gaming parts. They’re not at the top of the charts anymore, but that’s OK."]},
{"title": " Investigating Reddit's Exploded 9800X3D CPU | AMD Ryzen Post-Mortem", "paragraph": ["Investigating Reddit's Exploded 9800X3D CPU | AMD Ryzen Post-Mortem", "Last Updated: ", "The Highlights", "We bought a used motherboard that has multiple burn sites, charred plastics, solder that has bubbled through the socket, scorched pins that were discolored by the heat and turned blue, and it’s accompanied by a CPU with a matching damage pattern.", "Also, it smells like…magic smoke.", "We’re taking a look at a failed ", " CPU that exploded in the socket and motherboard. We’ll dive into what went wrong for a ", ", hopefully providing an educational opportunity and some cool traces of catastrophic damage.", "Steve Burke", "Mike Gaglione", "Jeremy Clayton", "Tim Phetdara", "Jimmy Thang", "The used ", " and ", " we purchased are heavily damaged and likely totally dead. We bought them from the Reddit user, who posted it to r/pcmasterrace after the incident.", "The user said ", ":", "“I built a new PC last night, and I couldn't figure out why it wouldn't POST. When checking for bent pins, I found that it killed itself. :(“", "The situation immediately reminded us of the ", " ", " following its launch. Since that came down to a fix in the motherboard BIOS, other users naturally started asking questions. When asked about BIOS, the user said:", "“I don't know what the BIOS rev. was because it never worked, unfortunately. It has whatever BIOS it shipped with.", "It burned up before I ever entered the BIOS. The socket was brand new when I put the chip in, no bent pins or anything.", "Edit: Since people have many theories about pins being bent, here are some more photos: ", "The plastic is melted and I think this deformed them. It's a chicken or egg thing.", "This was not watercooled and there was no water around this PC.", "I don't see any stickers with the BIOS rev on it.”", "The above images are some photos the user provided. As you can see, it’s bad. But we have our own evidence and microscope shots to get into because the Reddit user was willing to sell us the components.", "The root cause last time, back with the ", ", mainly came down to excessive voltage over an extended period of time, possibly in conjunction with poor internal thermal protections, and motherboard overcurrent protection (OCP) being set way too high. This led to dielectric layer breakdown at the transistor level in a runaway failure state, causing shorts and internal temperatures hitting the point of melting silicon.", "In simple terms, too big zap force make CPU go boom.", "Ultimately, the issue was fixed via BIOS updates leveraging stricter controls around VSOC, as handed down from AMD to the board manufacturers.", "But this new failure likely isn’t the same. ", "A lot of the internet pointed toward some potential user-caused damage from improper installation. We had some tell us not to buy the part as they were worried we’d be paying for someone’s mistake. While we really appreciate the concern, it’s the audience that puts us in a position to be able to afford to buy out catastrophic failures like this when they happen. We view it as part of the business: If there’s a chance of something educational coming out of it, we want to be there to learn it. Worst case, some guy installed his CPU wrong and he gets helped out, never makes the mistake again, and we all get some cool shots of a crazy failure. ", "Best case: You never know when someone has discovered the next massive failure that could affect thousands of users in an anti-consumer cascade, like ", ", and it’s important for us to treat all of these events seriously and get the parts before they disappear into the hands of manufacturers with motive and opportunity to hide the results. Third-party investigation is important to transparency.", "So, that’s why we’re OK with spending money on something that unveils nothing every now and then, because every time it unveils something important, we can help keep a company honest. And when it doesn’t, someone at least got a bailout.", "Let’s get into the damage report.", "The bottom of the 9800X3D (read ", ") has two major burn sites with discoloration, charring, a hardened, enamel-like substance, and individual points of concentrated scorching where the tips of the LGA socket pins were located. Also, it smells bad.", "The motherboard’s socket has damaged areas directly matching the pattern from the bottom of the CPU. The pins themselves are slightly bent out of alignment and discolored, with a few showing an intense bluing as seen on heat-treated metal. Solder from under the socket flowed up onto some of the pins, and the bed of plastic is scorched, appearing molten. There’s also one pin near the bottom that’s badly bent over, without visible burn marks. It, too, smells bad.", "The plastic edge of the socket is damaged in two major locations. The bottom left corner shows marring along a slight angle on both the left and bottom borders of the socket area. Along the bottom edge, the plastic alignment pin is clearly misshapen, appearing crushed.", "Moving to the bottom of the socket actuation mechanism (SAM, as AMD calls it, also known as ILM in Intel-speak), the hole in the base shows two points of physical wear accompanied by discoloration on the PCB itself. This area differs in design between the AM5 socket manufactured by Foxconn, which this is, and the other AM5 socket, made by Lotes. We’ll get into that later.", "A final sign of damage is a missing chunk of plastic between pins 3 and 4 on the ATX 24-pin header, which we wouldn’t have expected.", "In technical terms, this board is f***ed up.", "We haven’t observed any damage to the back side of the board underneath the socket or anywhere else. That includes the top part of the SAM, which some people thought looked bent in the user’s photos. It is not bent. That may have been lighting and those users are incorrect.", "The CPU and motherboard are irreversibly and catastrophically damaged.", "Knowing all of the aftermath, we need some testimony.", "Other key pieces of first-hand testimony from the Reddit user include the following:", "In reference to the pins, the user said, “They were definitely not bent prior to installing the CPU. The CPU is bulging where it's burnt and the mobo socket is slightly melted.”", "When asked if all power cables were plugged in, the user replied, “Yes everything was in place. I checked all connections when it wouldn't post and everything was fine. Nothing was in the socket when I put the chip in. That was the first time it was ever opened.", "I did not update BIOS prior to trying to boot.”", "This is about the time we stepped in, offering to purchase the parts from the user for their full retail price.", "Moving on to our hypothesis, we thought that the cause of this failure was a dead short to ground, and not an inherent flaw in the CPU or the motherboard BIOS.", "We thought this could have happened two ways and kept an open mind.", "Option one would be a defect in the socket or the motherboard as a whole – manufacturers can always screw up. If the factory misaligned the socket in relation to the underlying PCB, or damaged the plastic surround of the socket, then it could have led to misalignment and a short.", "Option two is improper installation. If the user installed the CPU into the motherboard in such a way that caused the outer socket damage and misalignment of the CPU in relation to the socket pins, then that would be sufficient to cause a short as well.", "It’s possible that the issue was caused by something else we can’t account for, but given the evidence we have, we believe that improper installation is the most likely cause.", "Now for the details and evidence to support our hypothesis.", "The CPU appears to have been installed with an offset within the socket by ~1.01mm diagonally to the left and down at the bottom edge where the socket’s lower guide pin is. This is enough to cause the pins to mate with the wrong pads.", "To determine this, Jeremy on our team took a measurement based on converting the known width of the guide pin (1.3mm) and then pixel measuring the microscope shots by pixel counting.", "It took a while. There’s a lot of pixels.", "This got us the distance between where the CPU’s guide cutout is supposed to sit versus where the plastic is crushed on the guide pin, then we converted it to millimeters. It’s not exact, but it’s very close, and establishes the basis of our hypothesis.", "This is generally supported by the marred edge of the socket at the bottom left, and possibly faint rounding off along almost the entire bottom interior edge. This would also result in the bottom edge of the CPU being raised away from the socket in the Z-axis, adding light or poor pin-to-pad contact into the mix, i.e., higher resistance.", "Taking a closer look at the bottom of the CPU shows that it was rotated by 1.0-1.4° clockwise, relative to the socket, when the burn occurred. This is based on the pattern of pinpoint scorch marks left by the pins. We carefully inspected the burn marks on the pads where you can see the point of contact, which is evident not only from the natural scratches caused by contact, but by the residue surrounding the burn sites. They should contact the pins in parallel rows, but the marks clearly show an angle. As you go along the pins, you see it diverging. Measuring in software, we came to the 1-1.4 degree offset.", "Analysis of the burned pins in the socket shows that all of them are VDDCR (core voltage) pins that are down and/or left of VSS (ground) pins. If the CPU was shifted down and left in relation to the socket, then the burned VDDCR pins would have been in contact with VSS pads on the CPU, causing a catastrophic short circuit.", "The fact that the top row of pins in the bottom half of the socket has no burns at all supports this, as those pins would have been in contact with the CPU substrate, not any pads. There’s nothing else conductive to touch in that direction until you get across the gap to the upper field of pads.", "That said, not all VDDCR pins that were nearby to ground got burned. We can speculate on a few reasons for this. ", "The skewed angle of the CPU in the Z-axis and the unknown pivot point would make the offset inconsistent across the 2D plane of pins. Also, it’s possible that some pads on the single-CCD 9800X3D are not connected internally.", "The marring and discoloration where the tip of the SAM (or ILM) touches the motherboard PCB is less conclusive evidence as compared to the rest. ", "Best case scenario, it’s just physical wear unrelated to the burning incident. Worst case, it’s a location where core voltage was able to find another path to ground and scorched the PCB.", "Finally, the SAM doesn’t show any signs of damage or bending that we can detect. It’s made of springy steel that readily returns to its original state after flexing – assuming it isn’t pushed past elastic deformation into plastic deformation, or in other words, made to permanently bend. ", "We think the area suspected of damage in the user’s photo is an optical illusion – a reflection or light shining through the top of the case.", "Through all of this, we want to make it clear –  the user shouldn’t be bashed for this. This sort of thing can happen to anyone, and that’s especially true with newer platforms. We’re grateful that the user was willing to sell us the parts to inspect, because we had fun working through the diagnostic.", "We’ll use it as a learning opportunity.", "All of this led to one observation that we hadn’t realized before that we’d like to briefly cover.", "We have a new concern about the two different styles of AM5 socket by Foxconn and Lotes. Research on this piece led us to realize that there are actually a lot of differences between them, in ways that should mostly be immaterial to functionality. ", "For example, the Foxconn socket has solid pins and solid plastic, while the Lotes socket has split pins and a more skeletonized plastic molding.", "The discoloration on the burned motherboard where the tip of the SAM touches down raises our concern in general, even outside the scope of this piece, because the metal comes in direct contact with the PCB, directly on top of surface-level traces. ", "We don’t think this is what happened here, however: Repeated socket actuations could theoretically cause the SAM to abrade through the mask and create a short.", "The Lotes version of the socket has the insulation sheet run across this entire hole, adding a barrier of mechanical protection. ", "We aren’t saying that the Foxconn socket will have problems, just that we would like to see more conformity to a single style between vendors.", "We took a brand-new sample of the same model ", " and repeatedly opened and shut the SAM 16 times with a CPU in the socket to see if this area of the board would show similar wear or any change at all.", "At the beginning of the test, we saw some disturbance of the protective sheet on the left, and a small spot of what looked like adhesive on the right, surrounded by an extremely faint discoloration. At the end of the process, it looked virtually unchanged, and nothing like the burned motherboard.", "This pushes us to think these spots were subjected to heat, or maybe a direct short as we mentioned before.", "The short version of this is that, after looking through everything, we think that the result of all this is improper installation, which is something a lot of Reddit users were pointing out when looking at the photos online. ", "Regardless, we definitely think this story was worth doing. First of all, it was a lot of fun to piece together a mystery. It also allowed us to possibly learn something major as you never know when some random PC builder might encounter something like the next ", ", where it might initially be perceived as user error but then proves to be a big, valid issue. ", "In this case, this issue doesn’t seem to be something for people to worry about, though users should pay attention to how they're installing their CPUs. It’s possible that a situation like this could have happened if you tried to install the CPU with the motherboard oriented vertically. It’s important to lay the system flat to install it properly and to be careful with where the guides are aligned. You can also slightly wiggle the CPU a bit once it’s installed, but shouldn’t do it hard, to see if there’s something wrong."]},
{"title": " AMD Ryzen 9 9950X3D CPU Review & Benchmarks vs. 9800X3D, 285K, 9950X, & More", "paragraph": ["AMD Ryzen 9 9950X3D CPU Review & Benchmarks vs. 9800X3D, 285K, 9950X, & More", "Last Updated: ", "The Highlights", "The quick version up front: The ", " is comparable to the ", " in most gaming scenarios, sometimes trading places; in production, it’s similar to the 9950X. The biggest change has been to the setup, which AMD says should now be simplified from prior dual-CCD parts with one faster CCD and one extra V-cache CCD. Historically, setting this up properly has made it necessary to isolate drives. If you were to install a ", " and upgrade to a ", " later, the easiest thing to do would be a clean Windows install (although there were ways to avoid this). That should be fixed now, but we’re still keeping all our drives isolated.", "AMD is launching its R9 9950X3D CPU. This is a 16-core, 32-thread part with a listed MSRP of $700. The $600 MSRP 9900X3D will be launching alongside it, but wasn’t sampled, which is normally not a good sign.", "Steve Burke", "Patrick Lathan", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "But as we all know, MSRP often doesn’t hold at launch as new silicon gets sold at higher prices. We just uploaded ", ". In either case, for these CPUs, we definitely wouldn’t pay over MSRP since the ", " (read ", ") is available regularly for $545, with the 9800X3D (read ", ") for gaming at $480 (which is MSRP) as we write this. That may change, of course.", "Today, we’re reviewing the ", ". It’s been a long review cycle the past 3 months, so we’re going to keep this one simple and focus on the numbers.", "Let’s get straight into it today. We’ll start with the specs.", "The AMD 9950X3D is part of the Zen 5 architecture that launched with the ", " (read ", ") and other CPUs last year. The ", " swooped-in a little later and cleaned-up what was a confusing and messy launch, largely making major moves for gaming CPUs and giving us something to be excited about as it’s a really good CPU.", "The ", " a 16-core, 32-thread CPU with a 5.7 GHz max advertised boost, 4.3 GHz base clock, and L3 cache at 128 MB. TDP target is 170W.", ", the normal ", " also has a max advertised boost of 5.7 GHz, base of 4.3 GHz, and TDP of 170W. These are shared. The cache changes, at 64 MB of L3.", "The 9950X3D has two CCDs, with one of the two CCDs bearing extra cache. This is stacked vertically. As we described in the ", ", the cache this time is flipped so that it’s closer to the substrate than the lid, pushing the cores closer to the IHS. In the 9800X3D review, we demonstrated how this helped significantly with cooling.", "We’re keeping it incredibly simple this time. As always, you can find our test bench information published ", ". ", "For gaming tests, we have all new data including the latest Windows updates and microcode for everything. That means we’ve refreshed the data set and wiped out what we had, so every CPU you that has been run was done in the last 3 days or so. We got the important ones in there. For production, we were able to salvage a lot of data since it’s the same.", "We’ve been completely buried by one GPU after another in an onslaught of benchmarks and follow-ups the last few weeks, so for this one, we’re sticking to the basics.", "Let’s just get into it.", "Frequency analysis is up first. We do this testing to ensure the CPUs are functioning as expected and to help explain the performance later.", "First up is the Blender all-core workload. In this test, the 9950X3D had a frequency plot that started at about 5250 MHz, but settled closer to 5020 MHz to 5080 MHz during testing. This chart is intentionally zoomed-in to make it easier to see, so the scale purposefully does not start at 0.", "For comparison, the 9950X non-3D (read ", ") had higher peaks, but similar valleys. It ranged from 5010 MHz to 5080 MHz. In terms of average frequency over the course of the test, the 9950X3D averaged 5038 MHz all core to the 9950X’s 5036 MHz, but the X3D CPU did so with fewer peaks and more level frequencies in the middle of its range. We think this will be beneficial to it in gaming. ", "The 9800X3D 5220 MHz all-core, putting it well above both. This will help it in some specific workloads, but obviously the lower core count will set it back elsewhere.", "The next chart is for frequency in a Cinebench single thread workload. This has the 9950X3D up in the range of 5650 to 5725 MHz, which hits AMD’s advertised frequency of 5.7 GHz. The 9950X holds its frequency steadier and with fewer dips between tile cycles, but is overall comparable.", "The 9800X3D holds 5225 MHz throughout the test so it’s lower than both when in a single-threaded workload in this situation.", "Baldur’s Gate 3 is up now. This one had the AMD R9 9950X3D at 155 FPS AVG, technically becoming a new chart topper. The 9800X3D was our chart topper last time and is now functionally tied with the 9950X3D as the best CPU on the chart.", "The good news is that the 9950X3D doesn’t appear to be suffering from its dual-CCD approach, so parking is functioning properly and the CPU is not hamstrung by its extra threads. ", "The 9950X3D outranks the ", " by similar margins as the 9800X3D did: It’s 23% higher average framerate, with lows comparable for the average. The 7950X3D (watch ", ") outdid the 7950X, which we’re using old data for but should be no greater than 2-3% different based on our study of this test, by 29%. That’s with proper setup for the 7950X3D this time.", "As compared to the 9950X at 101 FPS AVG, the 9950X3D outdid it by 54%. The 9950X is closer to the ", " (watch ", ") for performance, which makes sense. This game really benefits from the extra cache.", "In fact, an easy example of this is the ", " (read ", ") vs. the 5600X3D (read ", "): In some games, the 5600X3D outperforms the ", " because of its higher clock rate. In this instance, the cache and core count was more beneficial than the frequency.", "The 5800X3D (watch ", ") remains an excellent CPU, up at 119 FPS AVG. The 9950X3D and 9800X3D outrank it by about 30%. As for Intel, it remains uncompetitive here. The ", " is getting crushed by two prior Intel generations for reasons discussed in that ", ", and that’s with new Windows updates.", "Stellaris is one of our favorite CPU benchmarks because it looks at time rather than framerate, which is the most tangible to a user and the most directly influenced by the CPU. Players of 4X or other grand strategy games like Total War with the campaign map, Galactic Civilizations IV with turn pacing (and that’s a great game, if you haven’t played it), and Civilization would also see value here.", "For Stellaris, the 9800X3D and 9950X3D both perform at the top of the chart. The 9800X3D outperformed the 9950X3D with a reduction in simulation time of 5%. That’s near error, but not quite. This seems to be a combination of a higher base clock and utilization.", "The 9950X3D is definitely working as expected, though, because it’s outperforming the 9950X significantly. The simulation time requirement drops by almost 15%, from 32.3 seconds to 27.6 seconds.", "This is the one game where Zen 5 in particular had stronger gains over Zen 4, with the ", " doing well here and proving that. That’s from IPC uplift overall, where Zen 5 is benefitted.", "Intel’s ", " is competitive with the ", " and 9700X, at least. The ", " (read ", ") and ", " (read ", ") are within error of each other.", "In Dragon’s Dogma 2, the 9950X3D leads the chart. It landed at 132 FPS AVG here, passing the 9800X3D by a measurable but irrelevant 3.2%. Both CPUs lead all of Intel’s, although Intel at least lands its prior two generations ahead of the 7950X3D and ", " with the game’s updates. This game really seems to benefit from extra cache, with the 9950X3D leading the 9950X by 46% and the 9800X3D leading the 9700X (although they have other differences) by 41%. Dragon’s Dogma 2 remains heavy on CPUs in NPC-intensive areas.", "The 285K continues to impress with how much of a downgrade it is from not only AMD’s current generation, but Intel’s past generations.", "We added the older results for the 3700X and 2600 to this chart. We noticed that performance on older generations hasn’t changed much. At most, there might be a 5% change here, but we don’t think so. Even with that though, anything is an upgrade.", "Intel has seen the most upgrade since our last round of tests. This game has gotten updates, so it’s possible some of those were targeted at Intel. Windows updates could also affect it. We consistently saw uplift across Intel’s CPUs. That’s shifted the relative ranking of the 14th and 13th gen against the 7800X3D (watch ", ").", "Final Fantasy 14: Dawntrail is up now. In this one, the 9800X3D ran at 380 FPS AVG, with the 9950X3D at 373 FPS AVG. We observed relatively wide run-to-run variance in some of these results, so the error bars are wider than typical. The 9800X3D leads the 9950X3D by just 2%, so they are functionally equal.", "The 9950X3D bests its 9950X non-3D variant by 50 FPS or so, or 16% here in average framerate. The 1% lows are also significantly improved, indicating that frametime pacing is keeping up with improvements in the average framerate.", "The improvement over the 7950X3D is 5.8%.", "Intel’s closest CPUs don’t appear until the ", " at 310 FPS AVG. This is mostly interesting because there was a time when Final Fantasy’s prior benchmark versions were entirely dominated by Intel, with the clean division halfway down the chart. This is actually what we’re seeing now favoring AMD, relegating Intel to the bottom. That’s flipped in recent years and generations.", "Intel’s 285K underperforms against its prior two generations. There was no change in performance against last time for the 285K. Intel’s one advantage in this test is frametime pacing, where the 0.1% lows indicate that Intel’s CPUs generally have more consistent frame-to-frame intervals than AMD’s CPUs, although not by an amount that’d change your experience in a noticeable way.", "The 5600X3D outperforms the 5700X3D in this game. This has been known and is because of the higher clock speed on the 5600X3D, which proves more valuable than the extra cores.", "At 1440p, the top of the chart truncates as a result of GPU limitations on the ", " (watch ", "). We’ll move to a ", " (read ", ") for our full revamp of CPU testing for the next major architecture, but for now, this is where we cap-out. We’re sure this is deeply disappointing to all 12 of you who have an ", ".", "The 9800X3D and 9950X3D are about the same once again. The 7950X3D is also now about the same, as is the 9700X, thanks to the external limitations. This is a good reminder that the gains once scaling graphics are most seen in time-based situations or in seriously heavy CPU games like Dragon’s Dogma 2, but otherwise, most of the time you’ll get the most uplift from a GPU.", "In Starfield, we had the 9950X3D at 171 FPS AVG, leading the 9800X3D’s 165 FPS by 3%. The 9800X3D was notably ahead of the 7800X3D and the 9950X3D continued that, though neither had as revolutionary of a gain as we’ve seen in other benchmarks.", "The 14900K trails the 7800X3D, improving upon its prior round result in a meaningful way; however, because of the improvements we’re seeing in the prior generations, the 285K now falls back behind Intel’s 14900K in this test. The 285K still regresses and generally embarrasses Intel, trailing even the ", " (watch ", "). Intel has continually tweaked its microcode on these prior generations, so it’s possible that they rolled-out a microcode that had lost some performance at some point and they’ve regained some now with the 13th and 14th series. We update BIOS to the newest version for each round.", "Against the 9950X at 124 FPS AVG, the 9950X3D improves by 37%. That’s one of the larger gains. Of course, if you’re not going to use the extra cores, the 9800X3D makes more sense for value.", "Cyberpunk 2077 is back in our CPU test suite again with the Phantom Liberty expansion. Tested at 1080p/medium here, the 9800X3D and 9950X3D both ran at about 219 FPS AVG and were well within run-to-run variance at only fractions of a frame per second apart. The 7800X3D trails, but not by much. It’d be roughly the same experience as these two.", "The lead of the 9950X3D over the 9950X is 37% again, matching some of the other games. The Intel 200 series outdoes the prior generations here, finally, with the 285K at 170 FPS AVG. Unfortunately, that’s still below the AM4 5700X3D and 5600X3D.", "F1 24 at 1080p is up now. This one has the 9950X3D and 9800X3D again roughly tied, with the 7800X3D not far behind. The advantage is only 7%. The 9950X3D leads the 9950X non-3D variant by 29%, slightly reduced from the advantage seen in other games. We might be hitting a GPU limit here.", "Intel’s 14900K is its closest competition, released in 2023, with the 285K down at 9950X levels. The 5600X3D and 5700X3D results show again that this game likes frequency and IPC to some extent.", "1440p is almost exactly the same in the bottom half, with the top switching around due to GPU overhead and limitations on GPU scaling. The 5800X3D falls down the ranks as the 14th and 13th gen handle the overhead a little better and with more stable frametime pacing, which helps the average. Otherwise, things are about the same sans limitations of scaling for the 9950X3D.", "We’re moving on to production tests now. This is where the 16-core CPUs do well. Historically, we’ve seen the X3D variants of all of these CPUs underperform against the non-X3D parts due to power allocation to allow higher boosting. Extra cache doesn’t help in our testing here normally. We’ll see if the 9950X3D breaks that general trend.", "Blender testing hasn’t changed since our October round. We ran validation on several CPUs and the results came out basically identically, so we can keep a lot of data for more comparisons. This should help those of you on older hardware because we’ve got more present here.", "The 9950X3D required 6.6 minutes to complete the render, which is about tied with the 9950X. It was technically faster, but in reality, these are tied. That’s good news for the X3D part, though: Past X3D CPUs, like the 7950X3D, have been technically slightly slower than their non-3D equivalents. That’s not because of scheduling or parking, but because the frequency is slower in an all-core workload.", "Another good example is the 7800X3D, which was slower than the 7700X by time required, or 5800X3D as slower than the 5800X. The 9950X3D is the first to break this trend in a big way. Technically, the 9800X3D looked like it was doing that against the 9700X, but the power target was what brought most of that change.", "The 9950X3D outperforms the 285K here, with about a 7% reduction in total time required to complete the render.", "Chromium code compile in Windows is another where the data set hasn’t changed, so we were able to salvage it after validation. The 9950X3D required 81 minutes to complete the compile, which is comparable to the time required for the 9950X, but technically improved. This puts it marginally ahead of the freshly retested 285K, with a reduction in time required to compile from 285K to 9950X3D of 4.7% less time required. The 14900K required 88 minutes here, with the 265K at 98 minutes. ", "The 9950X3D is the new leader in our compile test. This is not going to be representative of every type of code compile, just like none of these tests is representative of every angle of a use case; however, the way we test it, the 9950X3D is the new leader short of going to Threadripper.", "Data for decompression and compression can’t be salvaged, so it’s all new.", "In 7-Zip file compression testing, the 9950X3D led the chart at 206,643 MIPs, or millions of instructions per second. That has it just ahead of the 9950X by 3.3%. This is one of the tests where cache can help, depending on its implementation. The 5600X3D and 5600X are good examples of this: The X3D part has a lower advertised frequency, but manages to still roughly tie the 5600X.", "The 9950X3D outperforms the 7950X3D by 8.5%, which completed 191K MIPS. The 14900K is next at roughly 189K MIPS, then the ", " (watch ", "). The 285K follows all of these, down at 179K MIPS. ", "Core count clearly matters in this test: The 3950X 16-core CPU is outperforming the 5900X 12-core CPU and 9700X 8-core CPU.", "In 7-Zip Decompression, we measured the 9950X3D at 277K MIPS, with the 9950X non-3D at 272K MIPS. You wouldn’t really benefit from the 9950X3D in a meaningful way in either compression or decompression in this workload. The 9950X achieves all of the performance already, so you’d need use cases that more directly leverage the cache to get value out of the 9950X3D.", "Intel’s 14900K is its closest competitor, followed by the ", " and then the 285K.", "We saved some of the data for Adobe Premiere as well. The biggest swing was to Intel’s 12th to 14th Gen CPUs here, where we saw some movement from the Windows updates recently. Most of the other parts stayed relatively stationary. Any 12th to 14th Gen CPUs with data prior to this round would move around a bit, so be aware of that; however, just to try and offer some extra data that’s still mostly comparable, we’ve left those parts here. Most of this data is brand new.", "The 9950X3D scored 11600 points in the Puget suite aggregate extended scoring for Premiere, which puts it at the top of the chart. It bests the 9950X by 5.8%, with the 14900K closest to it, then the 285K. The improvement over the ", " non-3D is 7%.", "We’ll keep power and efficiency testing short this time and just show a couple situations.", "In Starfield, the 9950X3D ended up at 1.7 FPS/W, putting it behind the 7950X3D and 7800X3D, but tied with the 5700X3D and 9800X3D. The 9950X3D pulled 98.8W when playing this game, and Starfield is one of our games that most heavily loads the CPU (but is still nothing like an all-core Blender workload).", "The 9950X non-3D part pulled 168W in this same test, putting it down at 0.7 FPS/W. That means the 9950X pulled nearly 70W more than the 9950X3D, or about a 70% increase in power consumption despite running at a lower framerate. In terms of FPS/W, the 9950X3D is both higher framerate and lower power, and so it is far more efficient. It’s still not as efficient as the low-power 7800X3D, though.", "7-Zip compression shows that the 9950X3D can still be power-hungry. In our compression efficiency testing, the 9950X3D pulled 203.8W. That put it at 1014 MIPS/W, which makes it less efficient than about half the chart. The CPU is the best performer, but not for efficiency and that’s because it’s pulling 204W, its efficiency has decreased compared to some others.", "The 9950X scored 979 MIPS/W and pulled the same power at 204W, making it less efficient than the 9950X3D. The 7800X3D is a lower performer overall, and in big ways, but has such impressively low power consumption that it ends up being the most efficient.", "Of course, if you were serious about running this kind of workload all the time, you’d still want something more powerful than the 7800X3D.", "Decompression testing looks better for the 16-core parts, with the 7950X3D proving incredibly efficient here, followed by an impressive result from the 7950X non-3D with ECO Mode enabled. The 9950X3D ran at 1358 MIPS/W, putting it slightly ahead of the 9950X. They’re still in the middle of this chart though.", "That’s it. You have the numbers.", "For the quickest recap: For gaming, you can think of the ", " like a ", ". We didn’t run into any major issues with the 9950X3D here. That in and of itself is kind of an accomplishment for AMD. The company has really struggled over the years with the dual CCDs, where one has the extra X3D cache on it. Over the years, it’s taken them some time to get to a place where it’s not regressive and where it’s a little easier to set up. The 9950X3D does appear to do that in our experience so far and that is a major improvement for AMD. It’s taken them some generations to get there.  ", "If you have the funds and are looking to build a purely gaming computer, we think you should scale it down and go for a ", ". It’s just not that big of a difference as the 9800X3D often trades places with the 9950X3D and you save some money. ", "Intel, on the other hand, is out of this conversation right now. They are not part of the high-end expensive CPU for gaming build scenario at the moment. ", "Meanwhile, the ", " makes sense for production-heavy builds that don’t have an explicit use for that extra cache. There’s definitely use-cases for this out there. We see a little bit of that in our 7-Zip testing, but for the most part in the things we test, it doesn’t tend to benefit from the extra cache in non-gaming scenarios. ", "Where the 9950X3D, and the other X3D 16-core parts, shine is a more limited use case where you have some mix of really heavy production and really heavy gaming. If you do a lot of compression, decompression, maybe render things on the CPU, are heavy into Premiere, or do a lot of code compiles and play a lot of games, then that’s kind of the use case for the CPU. ", "If you’re in one camp or the other exclusively, then you can save some money by going for either a 9800X3D or a ", ".", "We wouldn’t pay more than MSRP for the 9950X3D. CPUs tend to stick closer to MSRP, but can still have stupid prices from some retailers or third-party sellers."]},
{"title": " AMD Delays Ryzen 9000: “Did Not Meet Quality Expectations”", "paragraph": [" AMD Delays Ryzen 9000: “Did Not Meet Quality Expectations”", "Last Updated: ", "The Highlights", "AMD was supposed to launch its Ryzen 9000 Zen 5 CPUs in a few days. The launch was set for July 31st. We still haven’t received review samples, which is normally a bad sign: That’d leave just a day or two for evaluation. As of today, AMD has decided to push back the launch. This is following ", " about its 13th & 14th Gen CPUs all week.", "When we called to ask where samples were, we received this statement:", "“We appreciate the excitement around Ryzen 9000 Series processors. During final checks, we found the initial production units that were shipped to our channel partners did not meet our full quality expectations. Out of an abundance of caution and to maintain the highest quality experiences for every Ryzen user, we are working with channel partners to replace the initial production units with fresh units.", "As a result, there will be a short delay in retail availability. The Ryzen 9000 series will now be available on August 15.” (AMD to GamersNexus)", "We’ll frontload the news and then get into the commentary. ", "This is a big change. It’s very uncommon for a major delay this close to launch. Some timelines for you all:", "Steve Burke", "Vitalii Makhnovets", "We’ve been asking about review samples since the AMD event that is ", ". That occurred in early July. AMD never set firm dates for shipment, but had numerous soft shipment targets for review units. It missed all of those targets. We started pressuring AMD for timelines today, as an arrival late in the week would require coordination for our team.", "AMD provided us with the statement in the introduction. This is the first time AMD has delayed a major product launch in a while. We asked AMD what exactly the “not meeting full quality expectations” comment means and were told this:", " Doing final checks, [the validation team] found something they didn't like. As we completed our final checks, we found the initial production units shipped to channel partners didn't meet full quality expectations.", "Speaking with AMD’s channel partners, including large OEMs and system integrators, we learned that CPUs have already been available for validation in new pre-built PC SKUs for at least a couple weeks now, if not longer in some cases. ", "Speaking with one large US-based retailer and confirming with AMD, we learned that AMD is pulling back all units from the channel and re-validating them. We’re not sure which lab AMD is using for that, but likely the validation lab we saw in our AMD lab tour is a part of this effort. AMD intends to run all the CPUs against its “mission” spec, or in other words, ensure they can hit out-of-box targets. We heard a rumor that AMD was having difficulty with memory overclocking performance, but have since learned that, if this is true, it is not related to the delay. The delay is strictly to hit out-of-box performance.", "We asked AMD if this was to try and sift for “gold” samples for reviewers. AMD said no, this affects all units currently in the channel. The “channel” here would mean retailers, distributors, suppliers, and OEMs like Dell, HP, and Lenovo, among other smaller partners. This does not just affect review units. Our understanding is that AMD is pulling all CPUs back prior to release. From what we were told by AMD, this is a simple pass/fail: The CPU either hits the targets or doesn’t. AMD emphasized that it is possible that most of the CPUs hit the target, but that it is exercising caution to ensure that it doesn’t have any escapes that underperform.", "Currently, the official date is August 15th for release, pushed back from July 31st. Our understanding is that it is possible AMD pulls this forward for some CPU SKUs, assuming it is able to clear them for launch in time.", "Now we’re getting into some of the commentary.", "This complicates things from a consumer standpoint as well: Currently, we are in a holding pattern on Intel until it releases its microcode and BIOS updates to resolve the ", ". Intel has publicly committed to a “mid-August” release for that. This means that Intel’s microcode may ship alongside or around the time of AMD’s CPUs. As we don’t know if Intel’s microcode changes will affect performance yet, it is possible that all of Intel’s CPUs need to be rerun with that change.", "The new CPUs include the AMD Ryzen 9 9950X, Ryzen 9 9900X, Ryzen 7 9700X, and Ryzen 5 9600X. These are commonly shortened to R9, R7, and R5 for the prefix. The CPUs will ship on the Zen 5 architecture and AM5 platform, including support for X670E, et al. New X870E, et al. chipsets will accompany the launch. The price is not yet known.", "AMD had the best possible launch timing with Intel’s fumbles recently. If it had hit the release in a few days, Intel would be at an all-time low, confidence and comfort with Intel recommendations would be near-0 for most the consumer-minded media, and AMD would be a de facto choice. ", ", we see this in two ways:", "First, if AMD had flubbed this launch, it would be peak embarrassment and the worst possible time to accidentally ship units with an uncertain or undefined performance issue. It’d hurt consumer confidence in effectively all available CPUs. Not delaying could be worse if any single reviewer, or any vocal consumers on reddit, ended up with CPUs below spec. As soon as two of those claims hit reddit, it’d drown-out the Intel story as the new hot controversy, speaking frankly.", "Second, AMD’s delay means it may lose some of its advantage against Intel if Intel is able to ship its microcode and regain some confidence in that time; however, we don’t believe Intel’s microcode updates will improve performance. It will either stay the same or get worse, so it’s possible that it works out for AMD either way.", ", this is how we’d look at it: We’d rather see a delayed product than a bad product. The somewhat famous quote attributed to various people in the games industry, from Miyamoto to Kojima to Newell, is that a late game is late once and that “suck is forever.” (That particular manifestation of the quote might be GabeN).", "We’d rather see a delay than have confusion and anxiety for consumers who’ve already built their PCs. It’s terrible to have to pull a new system apart that you’re excited about and sit in RMA hell, so this seems the better route. For partners, this will be a big time cost: They’ll have to pull CPUs out of prebuilts ready to ship and send them back, but that’s better than dealing with an RMA nightmare.", "There are some concerns: First, it’s not clear how long AMD has known about this. Based on the timelines, we would assume it has been a concern for at least a few weeks. AMD did not comment officially. If AMD thought it’d get away with it but saw what happened to Intel, that’d be concerning. ", "It’s also not clear why AMD’s processes would fail to catch below-spec units this late in the game. ", "The entire thing has seemed rushed from the beginning: AMD originally announced a “July” release date, but didn’t specify when. During the press event in July, it specified the literal last day in July. That always seems like the month was chosen with expectations that everything would be perfect.", "Even still, delaying is the best move if, in fact, this is a simple pass/fail and units that fail can be removed from retail. That’s what we’d want to see. It’s certainly better than shipping them and having a year-later revisit like we’ve seen with Intel lately.", "As a personal note, the industry is in the most chaos it’s been in for years. We’re wondering if this is related to COVID-era ramp mixed with recent cut-backs colliding."]},
{"title": " AMD R7 3700X & R5 3600 in 2024 Revisit: Benchmarks vs. 7800X3D, 5700X3D, & More", "paragraph": ["AMD R7 3700X & R5 3600 in 2024 Revisit: Benchmarks vs. 7800X3D, 5700X3D, & More", "Last Updated: ", "The Highlights", "We’re revisiting the AMD R7 3700X (watch our ", ") and R5 3600 (watch our ", ") today. We first reviewed these CPUs in July of 2019, so somehow, it’s been 5 years now. ", " CPUs are coming out in just a couple weeks, so we thought now would be a good time to refresh everyone on the performance of the 3700X and 3600. We’d recommend waiting to buy anything until we see how the new CPUs perform, but this gets things started.", "This testing features an entirely new test suite and new data for every chart. We have a big overhaul to our games testing, including a ton of new games. We’ve added Final Fantasy 14: Dawntrail, Dragon’s Dogma 2, Starfield, Baldur’s Gate 3, and we’ve brought back some others. This video will help lay the groundwork for upcoming reviews over the rest of the year.", "Steve Burke", "Mike Gaglione", "Tim Phetdara", "Jimmy Thang", "The AMD R7 3700X and 3600 launched in 2019. The original 3700X price was $330, with the 3600 non-X’s original price at $200. This was a massive difference. For gaming at the time, in a lot of cases, it made sense to buy the 3600 rather than the 3700X or 3600X. You could save money and, as with the older AMD X vs. Non-X CPUs, you were often paying $30-$50 for a letter. To overclock the non-X CPUs to hit X variant performance in early Ryzen iterations was trivial, often amounting to a few minutes of work. For that reason, we often advocated the non-X 6-core parts for cost-saving reasons with a few key exceptions.", "The biggest exception was for users who were going to perform non-gaming, heavily multithreaded workloads, which is where the R7 CPUs stepped in. This was the generation where AMD didn’t launch initially with a 3700 non-X, departing from the 2700 and 1700 series and their X variants.", "The 3700X went kind of crazy later in its life though: The CPU was regularly dropping into the $260 range, which made it instantly a top choice at that price.", "AMD’s closest competition at this time was fierce: In the first Zen launch, there were still early teething issues that’d get worked out over the next generation or two. Intel was relevant not just for performance, but for an expectation of stability -- and that tide has really turned on Intel in recent years in amusing ways.", "The 2700 (watch our ", ") and 2700X (watch our ", ") fought the 8000 series, including the 8700K (watch our ", "). ", "For today’s revisit, we’re mostly just re-establishing our dataset for the upcoming reviews and trying to produce something helpful for you all at the same time. For this, we’ll be focusing on two things:", "Our production workloads will also look at non-X3D comparisons, like with the ", ".", "Right now, a lot of your in-socket options would either be used chips of AM4 or a new ", ". New platform options might include the ", ", ", ", or similar.", "Intel currently has some massive problems with platform stability and reliability, so currently, we are not recommending Intel until it is transparent with what precisely is going wrong with their CPUs.", "And again, our goal today is to just start establishing charts. We ran 35 CPUs through thousands of test passes in just 1 week, which is a major accomplishment for our team. We’ve really refined both the manual processes and automation over the last decade and are excited we can run so much through so fast. All of that said, there are effectively infinitely more CPUs we can test. Our next additions will be the 8700K (watch ", ") and 9900K (watch ", "), then the Zen 5 CPUs.", "Let’s get into the testing. We’ll start with game benchmarks.", "Final Fantasy 14: Dawntrail is one of our newest updates and is from 2024. This benchmark just came out recently and brought with it major optimizations and new graphics.", "The 3700X ran at 177 FPS AVG with strongly positioned 1% lows relative to the average and overall consistent frame-to-frame delivery. The 3700X ranks just below the ", " in this particular test, with the 3600 just below the 3700X. This is consistent with reviews of the time, including ours, which were that the 3600 and the R5 series had supplanted the i5 series for the mantra “an R5 is enough for gaming.”", "Compared to the R5 2600 (watch ", "), the 3600 is 14% ahead. The 2700 trails from its reduced frequency and under-utilized cores.", "Anyone upgrading in-socket would be best equipped with the $183 R7 5700X3D, which we ", ". The ", " is technically superior, but in the places we were able to find it in stock, it was often double the price of the 5700X3D. The 5600X3D (watch ", ") has a 300 MHz higher boost clock than the 5700X3D, so in this situation, it does better by 7.5%. It isn’t widely available, though.", "If you were to move to the ", " at 363 FPS and an entirely new platform, ignoring the pending 9000 series CPUs, the uplift would be about 106% from the 3700X and 109% from the 3600.", "At 1440p, despite increasing the GPU load, we still ended up with scaling lower down the stack. The 3600 and 3700X would still benefit from upgrades, although realistically, both of these CPUs are perfectly fine in this test. The 3700X and 3600 are about the same as at 1080p since the CPU is still fully loaded.", "The 5700X3D would give an uplift of 50% from the 3700X and 54% from the 3600. The 5800X3D (watch ", ") does a little better, but the top of this chart is getting squashed for scaling by the additional load of 1440p. The 7800X3D’s 273 FPS AVG posts a similar 54% to 58% lead from these CPUs, limited by GPU scaling.", "Baldur’s Gate 3 launched to critical acclaim in 2023. At 1080p/Medium, scaling is fairly clean all the way up the stack. Memory posts an uplift in this game, with the DDR5-6400 7800X3D result climbing 3.8% from the standard test and the ", " climbing 5% with DDR5-7200.", "The 3700X ran at 68.5 FPS AVG with lows paced proportionally well, leading the 3600 by about 8%. Upgrading the 3700X to a 5700X3D would yield a 59% uplift, or 73% to the 5800X3D. The 3600 would gain 71% or 86% to these same options. Moving to a new platform and 7800X3D with like-for-like memory would improve by 93% from the 3700X and 108% from the 3600.", "Dragon’s Dogma 2 was a mess at launch, has received patches, and is still somewhat of a mess -- but it’s a great CPU benchmark. This is a 2024 title. We have a whole ", " on Dragon’s Dogma 2 if you want to learn more about our testing methodology on the game.", "At 1080p/High and tested in the same city we used for our standalone piece, the R7 3700X ran at 61 FPS AVG, about the same as the 3600’s 59.6 FPS AVG. Lows are overall OK, although we still see some animation stutter in this title for all tests.", "The 5800X3D posts a 98 FPS AVG, leading the 3700X and 3600 by 60-65%. The cheaper 5700X3D is 55-59% ahead of these CPUs. A 7800X3D boosts that to 78-83%. The ", " is more competitive here than it was in some other tests, but still doesn’t match the 7800X3D and carries with it too much uncertainty with Intel’s recent problems.", "Starfield is up next. This one was a 2023 release.", "At 1080p/Low, the 3700X ran at 84 FPS AVG, leading the 3600 by a more noteworthy 17% in this title. The extra cores seem to help between these two CPUs this time.", "The 5700X3D leads these CPUs at 121 FPS AVG, establishing a 44% uplift over the 3700X and about 68% over the 3600. The 5800X3D pushes that further, but isn’t worth the added cost based on prices we’re seeing right now. The 7800X3D at 152.7 FPS AVG leads the 3700X by 83% and 3600 by 114%.", "Intel’s best option would predictably be the 14900K, but until we know what is causing the failures of these CPUs, we can’t recommend them in any capacity. Intel’s lack of transparency means a lack of certainty and confidence for the public.", "F1 24 is up next. This one came out in... 2024.", "Framerate is high in this game. There’s a ton of room for CPU scaling with minimal GPU overhead using 1080p/high, so this allows us to see the impact of CPUs to total performance.", "The 3700X ran at 212 FPS AVG. Realistically, this is completely playable -- but we use these tests to look at the relative scaling performance. The 3700X led the 3600 by just 3% here and is ahead of the R7 2700 (watch ", ") by 24%. The 5700X3D is about 68% ahead of the 3700X, with the 5600X3D outperforming the 5700X3D in this test as a result of its higher boost frequency. If you live near a Microcenter, the 5600X3D could still make sense. It’ll come down to pricing.", "The 5800X3D is meaningfully ahead here, up at 400 FPS AVG and leading the 5700X3D by 12%.", "As for the 7800X3D, that pathway would more than double the framerate of the 3700X and 3600. We did not measure an uplift from the memory change in this title, however.", "Intel’s 14900K (read ", ") is the closest Intel competition, but underperforms against the 5800X3D. Notably, Intel’s 0.1% lows are generally advantaged over AMD’s in this specific game; however, variance is also high for lows in this title.", "1440p trims the top-end as a result of the increased GPU load, but the lower half of the chart remains mostly unchanged. Other than reducing the percent gain from the 3700X and 3600 to higher-end parts as a result of the nearer GPU bind, this is mostly the same. Let’s move on.", "The next test is for simulation time rather than frames per second. We’re using Stellaris, a 2016 4X game that has received continual updates. Despite its age, this is one of the more useful CPU metrics as it shows a real-world time-based performance, similar to what we see in production benchmarks. You can see a tangible impact to how long you’d wait for simulation to complete.", "In this one, the 3700X outperformed the 3600 with its 49-second result on average, a reduction from the 53-second result of about 7%. ", "The 7800X3D posts a 42% reduction in simulation time, at 28.5 seconds to 49.4 on the 3700X.", "Intel does OK here, with the 14900K about tied with the ", " and ", " -- there’s no meaningful difference between these CPUs. Upgrading the memory on Intel slightly improved its result, though.", "Rainbow Six Siege remains in our test cycle for its CPU-heavy programming. This is a 2015 game and is the oldest in our suite currently, but has received continual updates. It’s also interesting because Intel maintains the top rank for our testing in this game.", "The 14900K with faster memory ran at 684 FPS AVG, with the 14900K and ", " on the standardized memory next. The 7800X3D is a few ranks down and between the ", " and 14700K. As for the subjects of our revisit today, the 3700X ran at 364 FPS AVG, ahead of the 3600 by about 3%. The lead over the 2700 and 2600 is significant. If you’re on a 1000- or 2000-series Ryzen chip and are OK with used options, it may make sense to spend under $70 on one of these parts for a cheap upgrade. The 5800X3D and 5600X3D both benefit from their clock boost over the 5700X3D.", "That’s enough games for now. Let’s move on to production workloads.", "Blender 4.1.1 is up first, tested using the GN logo render. This is an unrelenting all-core workload.", "The 3700X is able to leverage its extra cores over the 3600 here, landing at 20 minutes to complete the render versus 26 on the 3600. That’s a noteworthy reduction in time requirement of 22.5%. The AM4 X3D CPUs don’t benefit from their extra cache here. More cores makes the most impact, followed by higher frequency. The cache doesn’t come into play much. The ", " is the current chart leader, followed by the 14900K from Intel. ", "The best in-socket upgrades for someone primarily doing work like this with the 3700X or 3600 would be the ", " (or even ", "). If leaving the socket, almost anything modern would be an upgrade.", "In 7-Zip compression, the 3700X completed 78K MIPS, or millions of instructions per second, which had it similar to the 5600X3D and 5600X. The 5800X leads the 3700X by 20%. Compared to the 3600, 3700X owners benefit from a 28% uplift. Upgrading in-socket for this specific type of work would be best done with a 5950X (watch ", ") or 3950X. At the top of the chart, the ", " and 14900K are similar in performance.", "In decompression, the 3700X has a larger 35% lead over the R5 3600. An in-socket upgrade to the 5950X would yield a 117% improvement from the 3700X, getting most of the performance afforded by modern CPUs. The 7950X extends beyond the 5950X with an improvement of 24%, of course at the cost of a new platform.", "We’re moving to the Puget suite for Adobe software.", "In Photoshop, the overall score doesn’t heavily skew towards high core-count CPUs. It still favors a mix of core count and frequency, as evidenced by the positioning of the 5600X3D and 5800X3D.", "The 3700X posts a score of 7000 points, where higher is better and is a representation of time taken for various filters, transforms, and other tasks. That has it 6% ahead of the 3600. The in-socket 5800X3D gives an uplift of 25% over the 3700X. The 7950X is a huge jump of 54% over the 3700X, though the gaming gains we saw earlier were generally larger for the 7000 series.", "Adobe Premiere allows Intel to take the lead. The 14900K and ", " solutions lead the 7950X, followed by the 14700K and then ", ". Intel is definitely stronger here than it was in most other tests. The 3700X had an extended score of 6613 points, boosted over the 3600’s 5895 by 12%. The 7800X3D produces a similar result to the 5950X. In this workload, the 7800X3D doesn’t carry the same advantages as it does in gaming.", "Now for Chromium code compile, also measured in time. Lower is better.", "The best result on our new chart is the ", " at 73 minutes, followed within variance by the 14900K at 75 minutes. The worst on the chart is the ", " -- we won’t expand the scale to accommodate it since it’s a one-off, but that bar that breaks the chart is 619 minutes. A more reasonable “worst” would be the 2600, down at 311 minutes.", "For the 3700X, the result is still OK at 180 minutes. The 3600 required 229 minutes to complete the compile, meaning the 3700X time requirement is 21% lower than the 3600’s. Like in Premiere, Intel does better in this one than in some other tests, but AMD still has the technical chart lead. The in-socket 5950X would bring a huge 80-minute reduction in time required from the 3700X.", "The 3700X has held on pretty well in production workloads, though both it and the R5 3600 have aged a lot since they came out 5 years ago, which is expected. There are many better options out there. The AM4 socket remains surprisingly relevant with CPUs like the ", ", which we like. It does seem like it’s getting more difficult to find at a reasonable price in the $300+ territory, which would make one consider a platform change instead.  ", "If you’re a gaming-centric user and you really want to save money, the ", " at $160 to $180 might make sense as an upgrade. ", "In the used market, if you have something like the 3600, you might consider a 5000-series part as a potential upgrade pathway. If you can get one used for around $70, that might be the best route short of going to a ", ".", "For new CPU options, the ", " is worth considering, but we’re going to see how the 9000 series does shortly and how that might impact pricing across the board. ", "On the Intel side, we don’t feel comfortable recommending any modern Intel CPU at the moment until there is more transparency from the company on what’s going on with their platform stability and longevity issues because it seems to be getting worse. Ignoring those issues, anything from Intel’s 14 series or AMD’s 7000 series would be an upgrade.   ", "In revisiting these CPUs, the R7 3700X and R5 3600 are still pretty damn good. It’s kind of impressive how good they still are. A lot of people get caught up in new launches and the desire to upgrade. If you want to upgrade because it’s fun, go for it. If, however, you’re pretty happy with the performance right now on the applications you run then perhaps just keep using the parts that you have. If you’re not happy, then that’s a great reason to consider an upgrade."]},
{"title": " AMD Strikes Back: Zen 5 CPU Architecture Changes & Chipset Differences (X870E vs. X870, B850, B840)", "paragraph": ["AMD Strikes Back: Zen 5 CPU Architecture Changes & Chipset Differences (X870E vs. X870, B850, B840)", "Last Updated: ", "The Highlights", "AMD’s Zen 5 CPUs will be launching on August 15. We previously covered the inbound CPUs in the 9000 series, but have more technical details now that AMD has hosted a conference dedicated to the Ryzen 9 9950X, R9 9900X, R7 9700X, and R5 9600X. We already posted a ", " featuring the extreme overclocking team with Bill & Amit hitting several new world records on a 16-core CPU.", "AMD’s new features include an on-the-fly memory tuning solution, including memory changes from within Windows and without reboot, a new “Curve Shaper” that builds on top of “Curve Optimizer,” new chipsets, and the Zen 5 architecture itself.", "We’ll cover the rest of the news about AMD’s Zen 5 CPUs as we prepare our test benches for the upcoming reviews.", "Steve Burke", "Jeremy Clayton", "Vitalii Makhnovets", "Jimmy Thang", "We’ll get right into the quick facts first – some of this we already covered from AMD’s Computex announcement, but some is new information. Unfortunately we don’t have price information to share at the time of writing.", "AMD’s Ryzen 9000 desktop CPUs are codenamed Granite Ridge, feature the Zen 5 architecture, and are still on the AM5 socket. This first image will be a recap of things we already knew, followed by new architectural information.", "The recap shows that the lineup is fundamentally identical to the initial Ryzen 7000 CPUs. The flagship Ryzen 9 9950X has 16 cores, a 5.7GHz max boost, 80MB of cache, and a 170W TDP. Down from that is the Ryzen 9 9900X with 12 cores, slightly lower boost and cache, and a 120W TDP. Then the Ryzen 7 9700X with 8 cores, 5.5GHz max boost, a smaller 40MB cache due to being single-CCD, and 65W TDP. Finally, the 6-core Ryzen 5 9600X holds up the bottom of the stack.", "Notably, the TDPs for the bottom 3 are down significantly versus their Ryzen 7000 counterparts. As a reminder, TDP doesn’t equate to power consumption and isn’t consistent across vendors or even across sockets. AMD’s Package Power Tracking (PPT) is a more useful power consumption guidepost, but we don’t officially have those for Ryzen 9000 yet.", "We asked AMD if the TDP formula and HSF thermal resistance values are the same for this series as 7000. AMD confirmed that the comparisons are like-for-like; however, actual power consumption will still vary somewhat. One way that will vary is from reduction in the actual heat, which should reduce power leakage.", "AMD claims it has improved the thermal resistance by 15% for a 7-degree reduction at equivalent TDP. We asked AMD where this improvement came from: The company told us that the improvement is largely from sensor placement optimization, or moving the actual temperature sensors to better locations on the die. This means that the Tdie value will be lower, which AMD says gives it more headroom for boosting.", "AMD gave press a deeper dive into its architectural changes for Zen 5, and it’s positioning it as a place to grow from.", "At the event, AMD CTO Mark Papermaster stated, “It really represents a huge leap forward, and in fact, it’s going to be a pedestal that we’re going to build upon the next several generations of Zen.”", "AMD redesigned key elements of the front end, including fetch, decode, and dispatch. This gives more instructions to the back end every clock tick. Zen 5 has wider execution pipelines to execute the instructions. AMD says that efficiency increases from improved cache with more bandwidth and an expanded execution window, which the company states is intended to avoid execution stalls.", "Moving into more detail and starting on the front end with pipe fetch, branch prediction is lower latency, more accurate, and with more predictions per cycle in Zen 5, according to AMD. This all adds up to more throughput in the front end. Downstream, Zen 5 has dual ported instruction cache and op cache, while decreasing latency. AMD also added a dual decode path.", "Next is dispatch and the execution engine. Zen 5 features 8-wide dispatch and retire, 6 ALUs with 3 multiplies, and a more unified ALU scheduler (there used to be a unique scheduler for each of the ALUs).", "Papermaster went on to say, “We then went from the fact that we had these wider execution pipelines, knowing that when you have more instructions that you're handling, you have to think about handling misses effectively and keeping the performance of those execution pipelines. Again, hardcore micro-architecture engineering.”", "AMD also expanded Zen 5’s execution window by 40% with up to 448 supported OPs, which AMD says is a significant driver of more performance. Zen 5 also has a larger 48KB data cache, up from 32KB on Zen4, and double the maximum bandwidth to the L1 cache and Floating-Point Unit, and improved data prefetching.", "Papermaster stated, “When you grow caches like that, what typically happens is you run a high risk of increasing the latency. You grew the cache, that's normally going to happen. But what we did in this case, the team just did a phenomenal job. And so they maintained actually that four-cycle access that we had had despite the growth, the 50 percent growth in the data cache. With Zen 5, we can now execute four loads per cycle.”", "The final key improvement AMD made regarding data bandwidth is to data prefetching, where AMD says that tuned algorithms give much more stride pattern recognition.", "Next are the floating point and vector math unit enhancements. These include a full 512-bit data path, 6 pipelines with two-cycle latency FADD (floating add), and a larger number of floating-point instructions in flight at one time.", "Papermaster stated, “So I talked about that 512-bit data path. This is more important than ever. Because when you think about it, there's been no reduction in the kind of math-hungry workloads of gaming, of HPC, of content creation. So when you think about those users of the math unit, none of them are going away. But AI with its need is now becoming a workload everywhere.”", "AMD has so far done AVX-512 by double-pumping a 256-bit pipeline, which made sure that the CPU wouldn’t have to drop clocks while doing AVX-512 workloads. With Zen 5, AMD engineered a way to support full frequency while running the physical data path at true 512-bit. Our understanding is that this is modular to the extent that the older double-pump approach is still possible in some situations if the company wants to build it that way. ", "Zen 5 also lowers the latency of floating-point operations from 3 cycles to 2.", "Papermaster stated, “So we doubled the physical pipeline, we lowered the latency, we’ve increased the throughput. And that, combined with the load/store improvements that I described, really create a super optimized engine across those workloads I described – AI, HPC, gaming, content creation.”", "All of these improvements bundled together result in the claimed 16% average geomean uplift in IPC versus Zen 4, with up to 35% single core uplift in AES-XTS encryption. ", "The breakdown of Zen 5’s uplift consists of data bandwidth, fetch/branch prediction, execution/retire, and decode/opcache improvements.", "In a more physical sense, Zen 5 moves to 4nm and 3nm process technology with an enhanced metal stack for higher performance and lower resistance.", "AMD shared first-party performance claims that focused on IPC improvements – something AMD wanted to make very clear since the listed max boost frequencies aren’t moving much, if at all. We won’t spend too much time here, since we’ll have our own full testing for each CPU, and it’s never good to blindly trust the manufacturer’s own benchmarks. This will at least set expectations. Our review will run near launch.", "According to AMD, the first set of tests were performed with matched clocks between a 9950X and ", ". Claimed IPC uplift ranged from up to 10% in Far Cry 6, to 23% in Blender. Geekbench 5.4 was even higher, but seems like a potential outlier.", "We would have preferred if these were done with matched core counts, as AMD is basically asking us to extend the benefit of the doubt that the tests weren’t set up to give an advantage to the CPU with a physical hardware advantage.", "Moving on to AMD’s competitive testing, it matched up the 12-core 9900X versus ", ", claiming a 41% improvement in Handbrake, 22% in Horizon Zero Dawn, and 4% in Borderlands 3.", "AMD also compared its 9700X to the ", ", citing a 19% advantage in Puget’s Photoshop benchmark, which we’ll run in our review, and game benchmarks that ranged between 4% and 31% in the 9700X’s favor.", "Then finally moving on to the 9600X, AMD matched it against the ", ". There’s a massive 94% win in Handbrake, along with a smattering of other productivity and gaming wins.", "Comparing its former AM4 king, AMD ran the 9700X versus the ", " where it claims an average 12% faster geomean. That could be a huge efficiency win as well, but we’ll need to test it.", "At the end of AMD’s event, it held an SOC architecture panel with four of its Fellows that had some really interesting insights into various aspects of AMD’s design and process and approach. These are four engineers at the company. Mike Clark is the Chief Architect of Zen and its originator, Will Harris is a platform engineer and knows the chipset and socket, Mahesh Subramony is a silicon design engineer, and Joe Macri is the computing & graphics CTO.", "One of the early questions had to do with the fact that AMD is rolling out heterogeneous core architectures in some of its products. There was a funny slip -- or maybe not -- from computing & graphics CTO Joe Macri, “Mahesh, you know, when we look at our competition, Intel, you know, they have a performance core, an economy core.” There were some stifled laughs in the crowd from that one -- it comes across as a dig at what Intel calls the “efficient” core.", "Macri also stated, “You know, we have heterogeneous cores also. Our philosophy is different in how we approach desktop or mobile.” Turning to Mahesh Subramony, Macri asked, “Maybe you could, you know, dive in a little bit there and explain, you know, why two companies that are aiming at the same markets approach things just so differently.”", "AMD Senior Fellow and Silicon Design Engineer Mahesh Subramony replied, “It really is microarchitecture exact, ISA exact, and IPC exact modular, the cache size it attaches to. So the heterogeneity, if you will, is really around the voltage frequency response. So giving up some of that peak, frequency peak performance and get some of that back in area and efficiency. So that's what the compact core does for us. The desktop user demands performance, low latency and throughput for every task they want to do. So they are better served with a homogenous classic core with a better performance, if you will, and a voltage frequency response, if you will, dynamic. And on the mobile side, even though they are not that far behind in their compute requirements, they care a lot about power efficiency. And that's where the compact core kind of fits right in. A right mix of the classic and the compact cores delivers that scalability in performance without compromising on the power efficiency.”", "Macri added that since AMD’s compact cores are in essence the same as regular cores, it makes things easier from an OS software perspective, “The corner cases that you experience when you got cores that are very separate in their attributes just confound the user, make that user experience more difficult, make the OS partners have a more difficult life.”", "Those are interesting words from the company that shipped the ", " and ", " – CPUs with different performance characteristics resulting from having one CCD with stacked V-Cache and lower core frequency, and the other without the extra cache but higher core frequency. Those CPUs open up a can of worms that, in order to get the best performance in all circumstances, require special drivers and even user knowledge and intervention that we would classify as confounding.", "Macri then addressed AMD Fellow and Platform & Systems Architecture Will Harris, bringing up the AM5 platform, its socket, and longevity – stating that AMD intends for AM5 to last up to 7 years. Will Harris, AMD Fellow of Platform and System Architecture responded by saying, “And so one of the first things that we do as we're designing a new infrastructure, such as AM4, AM5, is we kind of tie it to a major interface that's transitioning. So, in general, it's usually memory, for example. So AM4 was tied with DDR4, and AM5 was tied with DDR5.” Harris added, “...And like you said, we want that longevity, so then we do things like making sure that we have sufficient interfaces to go for several generations. We make sure that we've got the signal integrity, isolation on the pins on the package, so that we can get a few speed bumps and improvement over time on things like memory speeds or PCI Express speeds, for example.”", "Harris also said AMD evaluates industry trends, standards committees, and third party vendors to see where the market is heading more long-term.", "Subramony then jumped in, saying that with generational gains in the same die area slowing down, AMD has to add die size in order to get more substantial gains in IPC and total performance. If the dies get larger, they still need to fit on the same physical package – a difficult challenge across multiple generations. Macri responded, “And, you know, the team has to dive in at the device physics level, right, the process technology as we shrink it, you know, voltages want to come down, but the platform has to stay consistent.”", "Macri took the opportunity to get in another shot at Intel, “You don't have to go change your motherboard every other generation like some other folks do.”", "Fair enough, as long as AMD doesn’t start doing that at some point. We’re good to at least 2027, according to AMD.", "The conversation then turned to Simultaneous Multi-Threading, or SMT, addressing Intel leaving behind Hyper-Threading on the upcoming P-cores in Lunar Lake.", "At the event, AMD Corporate Fellow and Silicon Design Engineer Mike Clark stated, “Yeah, so I think as we talked about heterogeneity earlier, you know, with Intel having two core types, one with SMT and one without, I can definitely see how that would be really hard to manage for software. So I can't really comment more on their design choices, but that seems like an obvious one that sticks out.”", "Again, AMD’s ", " is right there staring us in the face with the same scheduling problems, but Clark continued, addressing the actual topic at hand, “For us, I mean, SMT is the best perf per watt per area feature that we have. …Implementation does matter, too, so you have to do it in a very smart way, just like all the microarchitectural features, you know, Mark rolled out yesterday. And so for us, you know, SMT is about a 5 to 10 percent area hit versus, you know, workload improvements that go from 20 to 50 percent.”", "Clark then stated that SMT doesn’t work in every scenario, and that if a workload is bandwidth intensive, having more cores won’t help more than having SMT. AMD makes some processors with SMT off, and it allows the end user to turn it off. ", "They also briefly discussed future Zen 6 and Zen 7 CPUs, but it was limited to the fact that AMD views Zen 5 as the new starting point for the architectures to come, in the same way that Zen 1 was for its subsequent generations.", "AMD is launching 4 new chipsets in the immediate future: X870E (a 2-die solution), X870, B850, and B840.", "This table simplifies it. AMD’s X870E and X870 chipsets will both run PCIe Gen5 to graphics and NVME. This is a hard requirement, as we understand it, that the motherboard vendors have to follow. Both will also support USB4 as a requirement, CPU and memory overclocking, and run 1x PCIe Gen5 x16 graphics slots or can run 2x 8-lane configurations. ", "AMD’s X870E chipset will use 2x Promontory 21 dies and keeps the dual-chipset silicon layout of X670E. Everything else uses a single chipset. This allows one of the chipset dies to be closer to the PCIe slots, which can be useful in trace routing. It also expands the general purpose PCIe lane count. B850 drops to Gen4 on the hard requirement for graphics, but can use Gen5 for graphics. USB3.2 at 20Gbps is also required. B840 is effectively an A-series chipset, similar to the prior A320, except rebranded presumably to either trick confusers intentionally or to just cause unnecessary confusion and havoc in the market. This is a low-end chipset that cuts-off at PCIe Gen3, runs USB 3.2 10Gbps, and removes CPU OC support. It also only has 1x16 graphics slots.", "The primary difference between X870E, X870, and the prior X670E and X670 boards is USB4 support. There may be other meaningful changes like availability of curve shaper, but some of these details aren’t finalized yet.", "Here’s a ", ".", "General Purpose PCIe lanes can be assigned anywhere on the board and are allocated by the motherboard manufacturer, but made available by the chipset. Ryzen CPU combinations with X870E will support up to 44 PCIe lanes, against 36 total on X870. Both support up to 24 PCIe 5.0 lanes. X670E also runs 44 PCIe lanes and 24 up to PCIe 5.0 total. X670 drops to 44 and 8. B850 and B840 aren’t on this table yet.", "B840 is effectively an A-series chipset. If you’re going to buy it, just be aware that B840 is not similar to B850 -- it’s a big step down."]},
{"title": " Wasted Opportunity: AMD Ryzen 7 9700X CPU Review & Benchmarks vs. 7800X3D, 7700X, & More", "paragraph": ["Wasted Opportunity: AMD Ryzen 7 9700X CPU Review & Benchmarks vs. 7800X3D, 7700X, & More", "Last Updated: ", "The Highlights", "The most positive thing about AMD’s ", " is its efficiency. The next most positive thing about it is that, even though we have looked everywhere, we cannot find a single word “Intel” anywhere on the product or in the packaging.", "We’re reviewing the AMD R7 9700X 8C/16T CPU with Zen 5 architecture. We would be posting a ", " review today as well, except ours has massive memory compatibility issues. Actually, we had trouble with memory on the 9700X as well, though we were able to work around it. Considering AMD recalled these CPUs prior to launching them, it’s not a surprise that this launch is a complete mess. Although there are stories about the recall being due to a typo on the IHS, that’s not the only reason (and we don’t know if that one is confirmed). AMD definitely had problems with clocks on some of these CPUs, mostly the 16-core options.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "But those launch next week. AMD is launching the 9700X and 9600X today, with the ", " and ", " launching next week. The 9700X will cost $360 and the 9600X will cost $280. ", "This sockets into the AM5 platform and uses existing chipsets, but will also be followed shortly by new chipsets in the 800-series, like X870E. We covered that and ", ". ", "Today’s focus is on performance. ", "It’d help to get some quick market prices so that everyone watching is up to speed on the current options.", "Checking Newegg and Amazon, and keeping in mind that the 9700X is $360, we found these to be relevant:", "We had problems working on these CPUs. We haven’t had any major problems with AMD’s launches for a couple of years now, but this one felt like a regression.", "AMD sent out the newest BIOS versions for common test boards. The ASUS X670E board we use was among those updated, which is good. ", "Except we noticed a number of problems:", "First, we noticed that FCLK was defaulting to 2100MHz, which is an error. It is supposed to default to 2000MHz still, which we confirmed with AMD. Fortunately, we control our FCLK manually for tests, so this didn’t affect us; however, anyone not paying attention may either have artificially high performance in these tests vs. the prior generation as a result of a non-like-for-like comparison and some may have instability.", "We typically use a 2-stick kit of Corsair DDR5-6000 memory for AM5. This has been used on all AM5 CPUs we’ve tested to-date, including on our exact board; however, we cannot get the 9600X or 9700X to stay stable with the same board we’ve been using, although there was a BIOS update so that is a possible and maybe likely candidate for why. We manually control most relevant timings and the voltage, plus we control the FCLK and UCLK:MCLK ratios, and it still wasn’t stable.", "We eventually got the 9700X working with a very similarly spec’d Lexar DDR5-6000 kit; however, the Lexar kit has some looser timings. This will minimally affect performance comparisons, but was more frustrating because it felt like AMD’s old teething issues with memory.", "The 9600X was not able to hold stability, which we’ll get into in our upcoming 9600X review.", "Regardless, we got the 9700X working on very similar memory, so it is mostly comparable. That said, differences within 1-2% of no-change can be thought of as within slightly wider margins due to the change.", "We recently debuted our new suite of testing for CPUs in our ", ". To quickly go over the major changes, here’s the list of games we’re currently testing:", "Not every one of these will be in every review. We sometimes rotate them out temporarily if game updates render existing data incomparable, like what just happened with Rainbow Six’s newest patch.", "All games are from 2024 or 2023, with the exception of Total War: Warhammer III from 2022, Stellaris (originally from 2016), and Rainbow Six Siege (from 2015). These have continued to receive updates, though, and Stellaris remains important for evaluating sim time rather than just framerate.", "Here’s a list of our current production or workstation tests.", "The main addition here is Spec Workstation. Otherwise, everything is mostly the same as it has been, just updated to newer versions of the software. Spec Workstation has become a standardized test for us as part of our CPU reviews, however, it is still in experimental phases, which means we’re still determining how exactly we want to use it and test it and it follows our use in our Threadripper reviews previously.", "And here’s our list of miscellaneous tests we do, such as thermal, power, and frequency logging.", "Finally, we removed this list of CPUs from our data for this review. We have these tested, but removed them because the charts became too crowded and difficult to read or because we were still validating some results. These will go live in a separate ", " piece soon.", "All of this is on our website free of third-party ads in the ", " for our general test benches and methodologies. It doesn’t contain full details as we’re still building it all out, but has most of the basics for you. You can check that page for updates on what we’re using lab-wide. That’ll give component information like the memory kits, motherboards, and so on. We’ll run some methodology videos as soon as we can find the time to put them together.", "Let’s get into the data.", "We’ll start with power consumption and efficiency, seeing as that’s the most promising aspect of Zen 5.", "This is tested in an all-core Blender workload that’s intended to max-out the power and measured after at least 5 minutes elapse, ensuring that any Tau-based boosting behavior on older Intel CPUs is in effect.", "The 9700X pulled 88W at the EPS12V cables, which has it equal to the non-X ", " and ", " CPUs and similar to the older 3700X. The ", " pulls significantly more power at about 150W. This will be important throughout this review: There are times that the 9700X slightly regresses or equals the 7700X (watch ", "), and that’ll be from the company’s choices on power limiting and boosting. In the very least, it is a significantly lower power part. Whether that’s an improvement depends on performance.", "For reference, the ", " was pulling about 287W with our original review microcode, ranked right alongside the ", ". The Threadripper ", " was at about 352W for significantly more all-core performance.", "Now for efficiency. This informs us how much work is completed per unit of power. We’re looking at total energy consumed as a formula of power and time for this, ultimately resulting in watt-hours. This test is interesting because the part that completes the work fastest isn’t necessarily the most efficient (and often isn’t).", "In this test, the 9700X is now our new chart leader for all-core efficiency. It gets the work done using the least amount of energy, making it the most efficient on this chart. The previous leader isn’t present, which was the ", " in Eco Mode. In terms of things running out-of-box though, the 9700X leads. The ", " is next for its low power consumption and the older ", " remains impressive as well. Intel remains one of the least efficient in general on this chart when you look at something like the 14900K (read ", ") or the 14700K (read ", "), which are down towards the bottom for the out-of-box settings and Intel’s “recommended defaults,” whatever that means.", "All-core frequency is next. These tests are important for understanding application performance later.", "Prepare to be disappointed.", "Testing with all threads engaged, the 9700X ran at an average all-core frequency of about 4440-4480MHz, with frequent spikes above that in a deviation from typical Ryzen boosting behavior. This is a remarkably low all-core frequency and is a result of the default power limits imposed on the CPU by AMD. Plotting the 7700X, we see the predecessor at 5200MHz initially, with a slow decay to around 5190MHz. There are no spikes that appear. That’s a huge gap between these 2 CPUs, one of which is supposed to be a predecessor.  ", "Frequency alone doesn’t mean anything for performance, but it is an indicator of it. Architectural differences mean that the frequency between the two is not purely like-for-like comparable, but this will explain some performance in all-core loads later.", "This is why manufacturers have “up to” numbers for boosting. It is typical that the boost listed on a box is higher than the all-core boost, as the listed spec normally refers to a low thread count load. We can look at that next. ", "Single core frequency has the 9700X at 5525MHz flat in Cinebench single-threaded. The advertised spec is “up to 5.5GHz,” so they hit the advertisement. Our 7700X ran the same test at 5550MHz, slightly higher, but 25MHz isn’t a big enough swing to counterbalance the architectural improvements in the 9700X. We should see improvements in applications where they run a lower thread count.", "The next big one will be thermals. This is an important section: AMD has moved the sensors to reduce hot spots, if we believe the reasoning, and the result of this is that the 7700X and 9700X cannot be directly compared with the internal sensors with out-of-box settings. What we can do though is compare the sensor behavior. Because the chiplet layout is the same and the IHS is the same, we can mostly isolate for architecture and sensor behavior. ", "For this test, we’re going to limit the 7700X down to the exact same power consumption as the 9700X in Blender, so we’ll run both at 86-87W in Blender at the EPS12V cables. That’s about a 90W PPT on the 7700X, or similar to the Eco Mode levels.", "Here’s the result.", "The 9700X plotted at about 50-52 degrees Celsius in a 21C ambient under a 360mm Liquid Freezer II at 100% fan speeds. This was with an all-core load. The original 7700X result at 150W ran at about 92 degrees Celsius. Remember that this was by design for the 7000 series: These CPUs boosted until they hit a thermal limit and would keep boosting until hitting a power limit. The limit is 95C. So we have two things going on: It looks higher because it’s boosting until that point, but also because AMD moved the sensors.", "Unveiling the 7700X at the same power, we see it’s now at about 59 degrees Celsius. As compared to the 9700X, this helps us understand two things. One is whatever the actual improvements there may be and the other is the change to the sensor behavior itself. This is much more directly comparable to the 9700X. It is as close as we can get without external sensors and the end result is closer to an 8 or maybe 9 degree change depending on where you look on the chart. So this makes sense and AMD’s previous claims were approximately 7 degrees Celsius at the same TDP. We're actually remarkably close for this approach so this would be the closest we can get to a real comparison. Although it'd be one hell of a story to say that AMD reduced it by 40 degrees, it's really just not that simple.", "Starfield is just embarrassing for AMD. The 9700X technically is below the 7700X here, but in reality, they’re about equal. This may explain why AMD stalled this launch. We’ve seen this with AMD in the past -- notably, the ", " and 3950X (watch ", ") in some production tests -- but this is just sad for the 9700X. It would have to be a good deal cheaper to matter.", "The higher spec memory helped it here, but remember that applying the same memory to the 7700X would likely yield another result nearing equivalence. Still, this is one of the few games where we saw uplift on the 9700X with the faster spec memory. The 7800X3D (watch ", ") didn’t seem to benefit much from it, but this is consistent with less reliance on memory in general due to the larger cache.", "As for Intel, there’s a large block that leads the 9700X, including the ", ", ", ", 14700K, and 14900K -- for now, at least -- with the 7800X3D above those.", "Final Fantasy 14: Dawntrail is up now. This is a brand new, 2024 update to FFXIV and includes a complete overhaul of graphics and other systems. It also totally changes how Intel and AMD behave on these charts in relation to each other.", "The 9700X landed at 330 FPS AVG at 1080p/Max, which has it 6% ahead of the ", "’s 311 average FPS result. The lows are proportional to the average and otherwise uninteresting.", "This makes the 9700X as worse than the 5600X3D (read ", "). As a reminder, the 5600X3D has a 300 MHz higher boost than the 5700X3D (read ", "), so in games where the clock helps more than the extra cores, it’ll outperform the 5700X3D. That’s what we’re seeing here. In either case, the 9700X ends up in a boring position: It’s below the 2-generation-old ", ", which leads by 4%, and behind the 7800X3D, which leads by 10%.", "Intel runs worse than cheaper AMD CPUs here. Even ignoring the uncertainty of the inbound microcode update, it isn’t competitive.", "At 1440p, we’re bringing in a GPU bind to the top of the chart that limits performance scaling of the CPUs. This also makes the data less useful at the top, as it will clip the upper bound of framerate and bring down the average.", "The 9700X ran at 273 FPS AVG, which had it about tied with the 7800X3D and 14900K... and ", ", 5600X3D, 14700K, 5700X3D, and so on. The lead over the 7700X is real, but not meaningful at 3.9%.", "Baldur’s Gate 3 is up now, the 2023 launch that saw worldwide success.", "Tested at 1080p/Medium in a carefully selected area of the city that creates a heavy CPU bind, the 9700X landed at 107-108 FPS AVG with both kits of memory. The 5700X3D has a technical but indistinguishable lead. The Intel lineup mostly clusters around 114 FPS AVG, also slightly ahead. The 7800X3D with our default memory leads the 9700X by 23% here, with the 5800X3D (watch ", ") ahead by 10%. As for things the 9700X is better than, it leads the 7700X by 8%.", "Older CPUs like the R5 1600 and R7 1700 (watch our ", ") ran poorly in this game, and so were removed from the data set. You can see the 2700 (watch our ", ") and 2600 (watch our ", ") for prior generation comparisons.", "Generationally, the 9700X leads the 2700 non-X by 101%, the 3700X (read ", ") by 58%, the ", " hasn’t been retested but would be similar enough to the ", ", which allows the 9700X a lead of 30%.", "Dragon’s Dogma 2 is up next, this one from 2024 and a remarkable CPU benchmark for its NPC load. Our testing includes the game’s recent patches that claimed to improve performance.", "The 5700X3D is back to leading the 9700X in this one -- and actually, so is half of the rest of the chart. The 9700X is only ahead of the 7700X by 1.8% here. The 5800X3D leads the 9700X by about 9%, with the 7800X3D leading it by 21% at 109 FPS to the 90 FPS of the newer CPU.", "Compared to older CPUs, the 9700X leads the 1700X by 86%, the 2700 non-X by 72%, the 3700X by 47%, and the ", " by 21%. Intel’s 14700K is ahead of the 9700X by 14%, though we don’t know what Intel’s microcode will do.", "The 6400 kit had no meaningful change from the 6000 kit for the 9700X in this particular game, but that’s not always the case.", "F1 24 is up next. The “24” stands for... 2024. We’re not sure what that stands for, though.", "At 1080p/High, the 9700X ended up at 380 FPS AVG, with lows mostly proportional as far as AMD devices go. Intel’s 14900K has a slight advantage in 1% and 0.1% lows here, but not in a way observable to a human.", "The 9700X with DDR5-6400 improves to 400 FPS AVG, a jump of 5%. The 7800X3D didn’t benefit from the same memory bump, but still leads the 9700X by 20.5%. Compared against the 7700X, the 9700X on the same memory spec was 4% ahead. Not very exciting. The 14700K trails the 9700X and leads the 7700X, landing right in the middle at the time of testing. ", "As for the 5700X3D, that one falls below the 9700X and 7700X in this game. The 5800X3D is still better than the 9700X with equivalent memory, though, and ties the DDR5-6400 result.", "At 1440p, the GPU restriction limits framerate to 370 FPS AVG on the fastest device here, which ends up being the 9700X by a technicality. Its rank is shared by the 7800X3D. Both are bottlenecked by other components, so these can be thought of as the same.", "Otherwise, the chart mostly scales as before, except with the top-performing devices having the max framerate trimmed, thus reducing the average.", "Stellaris at least shows some uplift. Although extra cache via X3D helps in some situations, like the large 5800X3D improvement over the 5800X (a reduction in time of 11%), it has never helped as much at the very top of the performance range in our test. We become bound elsewhere. For this reason, the 7800X3D isn’t as impressive a jump, leaving the 9700X the leader with a sim time reduction of 3.9% over it. ", "Against the 7700X, it’s a reduction of almost 3 seconds, or a somewhat large 9% drop. This game seems to benefit from the IPC uplift, and because it’s based on time and not framerate, it is immediately and clearly observable to most users. Games like Stellaris, Galactic Civilizations, or other simulation titles have clear time reductions from uplift like this. This is one of the 9700X’s stronger titles.", "Intel’s first showing is at 30 seconds with fast memory, or 30.5 with the same memory that almost everything else uses. But we already knew Intel’s simulation time is slow since it wasn’t able to run PR simulations fast enough to bury the recent controversy.", "This allows AMD a lead overall on this chart.", "We have to skip Rainbow Six this time since they just updated the game and we measured a performance impact from the patch, so we only have 9700X tests for the new version. We’ll move on to production benchmarks.", "Our production and workstation tests are up now. These tend to be more heavily multithreaded and are generally more reliant on core count.", "Our Blender render is a real-world one and performs a tile-based render of our intro animation to this video. The render requires 13.2 minutes on the 9700X for one frame, which roughly ties it with the 7700X. That’s unfortunate. Stellaris already showed us the opposite of this, where the performance of fewer threads matters more for the 9700X; here, however, the impact is lessened because of the workload distribution across all the CPU cores minimizes the difference.", "X3D doesn’t matter in these tests, so the non-X3D parts generally perform better since they tend to have higher clocks.", "Sadly for the 9700X, it’s outperformed by the ", " of a few generations ago (which is benefitted more by the core count than the 9700X is by frequency and architectural improvements). The same is true for the 3950X 16-core part. Intel’s 14700K also outperforms the 9700X here.", "The 5000-series X3D parts at least don’t lead this time, but the result is complete and total stagnation for the 9700X versus the 7700X. It’s just not good.", "Moving on to file compression with 7-Zip, the 7700X is technically 1.7% ahead. Functionally, they’re tied and we’re looking at stagnation. Remember that the 9700X was run technically on different memory, despite us matching the timings as much as we could stabilize. This could account for some very small differences, but not much. Ultimately, at best, the parts are the same and at worst the 9700X is slightly worse.", "The ", ", 3950X, and even ", " all run ahead of the 9700X. AMD’s performance here is embarrassing and fails to move the needle. There is absolutely no reason to buy this CPU for workloads like this unless you were going to buy a 7700X anyway and if this is cheaper. Both of those conditions would have to be true.", "In decompression testing, the 9700X completed 136K MIPS, which roughly tied it with the 14600K (watch ", "). Performance is below the 7700X for the reasons we discussed earlier. At best, you could maybe call them equal, but overall this is pretty disappointing. ", "The 9700X leads in Photoshop -- so for AMD, that’s a relief. This is less thread-bound and more individually intensive on fewer cores. As a result, AMD’s IPC improvements show through. The 9700X ends up leading the ", " and 7700X alike, with the lead over the 7700X at 10%. That’s the largest gap we’ve seen in our testing so far and is similar to Stellaris.", "The closest Intel CPU is the 14900K at 10049 points, giving the 9700X a lead of 19%.", "Against the original 1700X, the 9700X leads by 130%. That was the era when AMD was disadvantaged on clocks, manifesting in disproportionately bad Photoshop results.", "Adobe Premiere is up now. The Puget aggregate score is a combination of editing tasks such as filters, time warps, scales, RAW performance, intraframe performance, and more.", "This one favors the 14900K, which has an overall score of 10715 points in aggregate, or 14% higher than the 9700X. The 9700X is at least ahead of the 7700X in this one, boasting an unbelievable, breathtaking 3.2% lead. It’s truly mind-blowing what AMD is able to achieve in just 2 short years. It’s almost as much as what Intel achieved with each year of its 14nm era.", "Code compile testing is up next, compiling Chromium for a heavy and extended workload. The longer runtime of this test allows us to better see the impact of boosting behavior.", "The 9700X ends up slightly ahead of the 7700X again, this time with a 3.3% compile time reduction. The ", " is faster here, but what’s even faster than that is if it blue screens while compiling. Intel’s 14900K and 14700K also do well in this test, with the 7950X (watch ", ") and X3D leading.", "Rodinia CFD is next. Our observation of this one is that it likes core count and frequency, with less emphasis on cache and reduced on purely cores. It’s a balance.", "The 9700X has one of its larger leads over the 7700X in this one, at 10.7%. ", "Intel is overall dominating here.", "Next up are the Spec Life Sciences & Biomedical tests. The Spec Life Sciences & Biomedical LAMMPS test is described by Spec.org as “a molecular dynamics simulator that consists of five tests simulating a variety of molecular properties.”", "In LAMMPS, we’re seeing regressive performance again. It doesn’t happen often, but the 7700X’s 4.45 result leads the 9700X by 2.5%. Some of this may be due to the slightly different memory timings as a result of the compatibility trouble, but that shouldn’t account for the whole difference. The 9700X is just disappointing as compared to the 7700X in this one.", "This is a big review. We’ll keep the conclusion as simple as possible.", "Intel has been working hard this past year. Its concerted effort has ensured that it can nuke the confidence of its consumer base, and it’s going to take some time for Intel to earn that back. That’s the biggest thing going for AMD right now.", "But marketing on the back off “the other one is worse” isn’t good marketing. This leads to stagnation, boredom, and an overall slow-down in the market. AMD has efficiency going for it in a big way, and that’s the singular pillar preventing this launch from becoming AMD’s 14nm+++++ moment.", "Overall, the ", " is relatively boring. It’s slightly better than the ", " sometimes, sometimes it’s slightly worse. The biggest swings we see are 10%, but they’re not common enough to really stand out. The efficiency is exciting in a way, but we think AMD could have found a better balance between efficiency and performance to at least more consistently ensure there wasn’t regression in charts.", "The memory compatibility has also been rough for our testing, which is odd considering the stability for the literal same motherboard and RAM on the 7000 series CPUs. It could be BIOS or could be the CPU or AGESA, but ultimately, it’s AMD’s fault. They know whose boards are in the hands of reviewers to the extent that they personally vet and distribute the BIOS to reviewers. ", "The CPU is “fine.” If it didn’t have the efficiency improvements, it’d be getting the Intel 11th Gen treatment of being the dead generation -- the ", ". But because it has efficiency, it instead gets a “meh.” If you’re on AM4, you can either upgrade to a ", " for cheap or just wait. If you’re on AM5, there’s no reason to upgrade unless it’s from the lowest spec part or something, and even then, a ", " may make more sense for gaming in many scenarios.", "As for Intel, we’ll re-evaluate the company’s processors as soon as the new microcode ships."]},
{"title": " AMD Ryzen 9 9950X CPU Review & Benchmarks vs. 7950X, 9700X, 14900K, & More", "paragraph": ["AMD Ryzen 9 9950X CPU Review & Benchmarks vs. 7950X, 9700X, 14900K, & More", "Last Updated: ", "The Highlights", "We’re back with the ", ", following a hell of a long day working on a ", ". You should check that out if you haven’t -- it has a lot of unique data in it.", "But the ", " is up for review now. Here’s a quick pricing update:", "The 9950X is a $650 CPU. Direct alternatives might include the ", " at $520, the Threadripper 7960X as a “cheap” HEDT part at $1400, or possibly the upcoming ", " at $500. The existing ", " is $360 though, making it possibly a better contender. Finally, Intel’s ", " is $546 -- but again, we have currently paused Intel recommendations until we can evaluate the new microcode fully. ", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "Following the missed timelines for review units and later recall of the parts, AMD’s newest round of communication mishaps include not telling the media that the 9950X and 9900X (watch ", ") require a specialized Windows setup for core parking similar to the ", " and ", ". Those CPUs have always needed it, but the non-3D ", " and ", " did not. This is a change for the 9950X and 9900X, which meant that most reviewers had the CPUs for about 5 days before AMD communicated this requirement, causing everyone doing it right to throw out their data and re-test.", "For this review, we’ll be focused on production applications and power, since gaming is really only needed to make sure it’s functioning properly. Let’s get started.", "The 9950X is a 16C/32T part on the Zen 5 architecture, which means it sockets into AM5 motherboards with chipsets in the 600-series, such as X670E, and the upcoming 800-series. For reviews, we’re using an X670E motherboard as the X870E boards are not available yet.", "This is a list of CPUs that require the setup we are about to describe. The ONLY processors that require special care are the ", ", ", ", 9900X, and 9950X. The non-3D 7950X (watch ", ") and 7900X (watch ", ")do not get this treatment.", "Core parking is the behavior wherein half of the CPU’s cores are “parked,” or are specifically unused and avoided, when running applications that would benefit from instead running on a single CCD.", "The affected AMD CPUs have two CCDs, or two chiplets in addition to the I/O die chiplet. CPUs like the ", " only have a single chiplet which also has the extra cache.", "With the 7950X3D (watch ", ") and 7900X3D (watch ", "), the reason you’d park cores is because the extra cache is on one CCD. BIOS can be set to favor the CCD with higher frequency or with more cache, but you should be using the chipset drivers for all of this. If a game is bouncing load indiscriminately between cores spread across two very different chiplets, it is possible that performance is worse. Core parking is supposed to fix this, and typically, it does a pretty good job.", "If you were to force core parking on a CPU that doesn’t require it, it is very likely that you hurt the performance significantly. This could cut it by double-digit percentages. Likewise, not enabling it on CPUs that require it could hurt performance by double-digit percentages.", "We’ll talk about how to configure it first, then get into some downsides now that it’s required on the 9950X and 9900X.", "There are a few steps required in order to set this up. ", "Game Bar is the app that's responsible for deciding whether applications are games or not, which then activates Game Mode, which then parks cores. To test it, you can open Resource Monitor, open Game Bar (Win+G), and check the Remember this is a game box. Relaunch Resource Monitor, then go to the CPU tab, and half the cores should say Parked. ", "Keep in mind that Microsoft's Game Bar is still a huge piece of crap, and we've seen the Remember this is a game box randomly checked and unable to be deactivated, so play with this option at your own risk.", "These steps apply only when moving TO one of these four CPUs. If you boot with one of these four CPUs and then later move to a CPU that doesn't require core parking, AMD's official advice is to reinstall Windows, or you can try uninstalling then re-installing the AMD Chipset Driver as a workaround.", "That’s the setup basics. Some BIOS and CPU combinations may also have an option for core parking behavior. You should set that to let the Driver do what it does: Drive.", "As for other information that you may want for this review, you can check out our testing methodology notes (found in the ", "), ", ", ", ", and the efficiency ", ". For now, let’s get into the data for the 9950X.", "We’ll look at frequency first to make sure things are performing as expected.", "Here’s the all-core frequency when the CPU is fully engaged on every thread in Blender. The ", " was around 4500MHz here, +/- 20MHz. The 7950X plotted around 5100MHz all-core previously.", "As for the new 9950X, its higher power budget allows it to boost substantially higher than the ", ". The 9950X ends up around the range of 5000MHz. It’s spiky, but generally speaking, doesn’t have any major dips. It is a little bit lower than the 7950X, though. ", "We’d expect that our 9950X should generally outperform our 9700X in gaming scenarios based on this, as it’s theoretically able to boost higher. The only reason this wouldn’t be the case is if something is going wrong with the core parking behavior.", "In single-core testing with Cinebench 1T, the 9700X maxed-out at 5525MHz in most scenarios. The 7950X ran at 5750MHz in the same testing, pushing relatively high.", "The new 9950X is also in this area, with ours plotting at around 5710-5725MHz for a single-threaded load. As long as there’s architectural uplift, this should enable the 9950X to also outperform the 7950X in lightly threaded scenarios.", "Power consumption at the EPS12V rails in just Blender is up now. This isn’t an efficiency chart, just the peak power consumption in a worst-case scenario. You’d use this to help buffer PSU requirements.", "The 9950X pulled 223W in this benchmark, which is down from the 7950X’s 251W that we measured. The 9950X is about 70W below the ", " here. Against the R7 family, the 9950X is pulling about 136W more than the 9700X and its 87.6W entry.", "So far, the 9950X is down from what we measured on the 7950X. Compared to older generations, power remains up overall: The 3950X (watch ", ") pulled 137W in this test with all cores loaded, with the ", " at an impressive 120W. That’s why you’ll see the ", " perform the same as the 3950X in some benchmarks, but with huge power reductions due to the quality of the voltage bin.", "We’re starting with our efficiency benchmarks now. If you haven’t seen our ", ", definitely go check that out -- it’s extremely interesting and reveals a lot of CPU behaviors, but it also plotted the course for what we’re getting into in this review. We’ll run a limited set of additional efficiency benchmarks in this review.", "All-core workloads are where the 9950X belongs, so we’ll start with production applications.", "In Blender, the 9950X ends up neighbors with the ", " and is less efficient than the old 5950X (watch ", "), which was a remarkable chip for its era. The 7950X ranks at 29.5Wh here, so in the very least, the 9950X improves massively on that: Its improvement is a 26% reduction in Wh measurement for this specific test.", "The 7950X with ECO Mode does phenomenally here, as it always has. With 105W ECO, which we found to be the ideal configuration rather than dropping down to 65W, the 19.1 result has it as the chart leader and just ahead of the 9700X and behind the PPT-limited entries.", "AMD continues to improve in efficiency in this specific test, but as we saw in yesterday’s content, we need more than this.", "7-Zip is up now, then games.", "In 7-Zip compression, the 9950X ranked at 1003 MIPS/W, or millions of instructions per Joule. That has it as one of the least efficient on this chart. We haven’t run the 7950X through for these tests yet, so we don’t have comparative data. This is a brand new data set.", "For things we can compare against: The 9950X ends up in about the same place as the 9700X with PBO blasted and behind the ", ". Part of this may be explainable by hitting other non-core bottlenecks and limiting its total performance.", "Now for games.", "Final Fantasy is one of the ones that had more interesting behavior, especially on some of the 7000-series CPUs. That’s explained in yesterday’s video.", "For the 9950X, the CPU ended up pulling about 85W, or 10W more than the 9700X, but obviously far less than what we’d see in all-core work. That extra TDP gives it extra power budget, even though half the CPU is parked. The end result is overall good performance in an absolute sense, but less efficient operation. The 9950X outdoes the ", " and ", ", but underperforms against everything else. ", "In Phantom Liberty, the ", " pulled about 119W while producing a framerate similar to the ", ". As a result, its efficiency is through the floor. This CPU is just off the far end of the bathtub curve in these kinds of games: The baseline power consumption to keep this CPU operational is higher and it has a ton of cores sitting there doing next to nothing. This CPU needs to be fully leveraged to have a better result, and games just don’t really do that when you need core parking.", "In Stellaris, the 9950X completes 1.4 simulations per watt-hour, which has it below almost everything except the ", " and 14900K (watch ", ")CPUs. The 9700X leads by significant margin, up at 1.8 simulations per watt-hour, with the ", " roughly doubling the performance. The only positive is that it’s ahead of Intel here.", "We’re starting with production benchmarks for the 9950X since its intended use case would be for workstation-type tasks, followed by gaming benchmarks just to make sure it’s working as expected.", "Blender starts us off. The 9950X is the new chart-topper for tile-based rendering, posting a total render time reduction of 12% from the 7950X. That’s going to be one of the top gains we see in this review, as this is a fully-engaged, all-core workload.", "Intel’s 14900K required 7.9 minutes to complete the same work. Depending on launch day pricing and if the 7950X moves around, it’s possible that it remains the best option for a machine that combines workstation and gaming tasks when looking at it from a value standpoint, but it’ll depend on price positioning.", "Generationally, the 9950X reduces the total render time required by 43% from the 5950X and 3950X, which require about 10.4 minutes to complete. This is not a mistake -- they are just the same here. We talked about that in our original review from years ago. If you prefer to look at it from the direction of increase in time required, obviously the percent flips and nearly results in a doubling. We do these comparisons as percent reduction in total required time.", "AMD is at least moving the needle in this one. Let’s see if it sustains.", "Photoshop is next, tested using the Puget test suite. Scoring is done as a formula calculating filtering, scaling, and other types of tasks within the software.", "In this benchmark, the 9950X scored 11,694 points for Photoshop, which has it below the 9700X by a technicality. These two performed functionally the same. Photoshop can utilize extra cores, but isn’t making enough use of the extra 8 cores over the 9700X to matter. ", "Generationally, we saw similar behavior with the 7950X and ", ": They were within margin of error of each other. The 9950X improves on the 7950X by 7%, which still isn’t bad, but certainly isn’t a huge excitement. This is performance we’d expect out of a mid-generation refresh. It doesn’t really feel enough for how much this was marketed as a brand new platform to work off of. Versus the 5950X, the 9950X improves 33%. The 3950X gives the 9950X an uplift of 60%. If you’ve been on the 3950X for years now, it’s at least starting to look like you’ll get meaningful uplift in some of these tasks. ", "The newest version of this benchmark combined with the newest version of Photoshop shows AMD’s favorable positioning, whereas older versions showed Intel favor. Intel’s first showing is below the ", ".", "In Adobe Premiere, the 9950X scored almost 11,000 points for the extended benchmark. The 14900K flanks it with the standardized and faster memory, but ultimately, these are equivalent. Against the prior generation, the 9950X improves 31% over the 5950X (which is down near the ", ") and 42% over the 3950X.", "For comparison, the 5950X -- which itself wasn’t always an exciting uplift over the 3950X -- posts a 9% improvement over its predecessor. Anyone expecting a 7950X-era gain would be disappointed: That one is 26% better than the 5950X.", "Intel does much better in this test than some of the prior ones with our current data set. The 14700K (read ", ") and ", " are still in the top portion of the chart. We actually generally like the ", " and ", " CPUs for a cheaper option for this task, especially when the ", " is at its cheaper price, but we’re waiting for some of the smoke to clear before we resume recommendations of them. The microcode is still rolling out to boards.", "Code compile testing with Chromium is next. This requires a reminder that not all compile workloads behave the same, just like anything else.", "In our test at least, the 9950X leads everything. The new CPU required 66 minutes to complete the compile, leading the 7950X’s 73-minute entry and benefiting from a total compile time reduction of almost 10%. Obviously, Threadripper would be ahead of this, which we’ve tested in the past, but we don’t have it rerun for the new tests.", "The 7950X was able to reduce the compile time required from the 5950X’s 101-minute result by 27%, whereas the 5950X only reduced it from the 3950X’s 106-minute result by 5.3%. The new CPU is more similar to that era than the total platform change we saw with AM4 to AM5. That’s not too surprising.", "Intel’s closest entries are the 14900K, which roughly tie with the 7950X. AMD is gaining some distance where it only had equivalence before.", "File compression with 7-Zip is next. In this one, the 9950X completed 205K MIPS (millions of instructions per second) when stock, an improvement of 5.9% over the 7950X’s result. For that same generational perspective, here’s how it lines up:", "The 7950X gained 39% on the 5950X, which itself had gained 7.5% on the 3950X.", "The gains are up-and-down, but the 9950X is the lowest of these metrics so far.", "Intel’s 14900K encroaches on the top of the chart and was nearly tied with the 7950X previously; again, AMD benefits from creating some slight distance between itself and the 14900K, regardless of Intel’s current problems. If Arrow Lake can do better than this, Intel may be able to maneuver itself into a strong spot. It’ll depend if Intel can regain confidence before then.", "Against the 9700X, the 9950X completes 71% more MIPS. This aligns with the massive core count difference.", "Decompression moves some of these CPUs around, but the 9950X remains at the top of the chart. Its lead over the 7950X is only 1.6% here, though we may also be running into memory bandwidth limitations. That’d be a separate test.", "The next CPUs are pretty far away: AMD’s 9950X leads the 14900K and its 229K MIPS result by 22%. That’s a big advantage.", "The 5950X also did well in this one, shoving itself right between the 14900K and ", ". This test clearly favors having a bunch of homogeneous cores.", "Against the 9700X, the 9950X doubles performance. It also doubles core count, making this one of the most linear gains we see.", "Spec Workstation is up next. This testing is completed using the Spec pre-built benchmarks for various professional software.", "The first one is for LAMMPS, which is part of Spec’s biomedical suite.", "As tested by Spec, LAMMPS has the 9950X as the chart leader: It’s up at 6.93, leading the 7950X’s 6.61 result by 5%. That also puts AMD now ahead of the 14900K.", "The next one is for the Spec Workstation FSI test, which it says analyzes Black-Scholes pricing models, runs Monte Carlo simulations and probability simulations, and runs a binomial options pricing model. We are not familiar with these use cases in real-world environments, but our hope is that the tests are useful to the audience.", "Here, the 9950X ends up leading the 7950X-non-3D by 7.7%, at 9.47 to 8.79. The lead over the 14900K is 20%. Against prior generations, the 5950X gives the 9950X a lead of 61%.", "Gaming is up now. This is less important for the 9950X: You shouldn’t buy these CPUs for a gaming build only. Our main goal here is to just make sure it works properly and doesn’t chop the framerate in any major ways. We won’t spend much time on each of these charts as we think that time was better spent in the earlier production sections.", "Dragon’s Dogma 2 is up first, a CPU-heavy game that came out this year.", "The 9950X is about the same as the 7950X here. It’s technically slightly ahead, and as a positive, we are seeing benefit from the 16-core parts in this specific test. That’s at least good, as historically, some of the 16-core CPUs have had problems in gaming. That was especially true in older games.", "The 9950X is definitely not worth buying just for gaming, but neither was the 7950X. In this one, it is holding an AVG framerate similar to a 13600K (watch ", ") and 5600X3D (read ", "), both of which are much better value for just gaming. The lows on the 9950X are good though, which means it clears the bar of “working” in a gaming scenario.", "The 7800X3D (watch ", ") remains remarkably good value for this particular game. Intel’s i7 CPUs at the top also do well.", "You can see that the older 16-core CPUs also outdo their generational family by small margins: The 3950X leads the 3700X (read ", ") slightly and the 5950X leads the ", " and ", " non-3D parts slightly. This is pretty cool to see as this was rare in prior years of benchmarking. Dragon’s Dogma 2 testing seems to be good for this.", "In Baldur’s Gate 3, the 9950X landed at 111 FPS AVG. That has it about tied with the 13700K and slightly ahead of the 5700X3D. Against the 9700X, we’re seeing about a 2.9% uplift with the 9950X. Lows are similar, but with the 0.1% lows technically worse. The gain over the 7950X is about 5.2% The 3950X allows the 9950X to run 55% faster, with the 5950X giving it a 28% lead.", "As for the 7800X3D with our default memory, it outperforms the 9950X by 19.4%. The 14900K is also up here at 121 FPS AVG when paired with faster memory, or down at 116 FPS AVG without (where it and the ", " become limited).", "The 9950X is working better than we expected for Baldur’s Gate 3.", "Stellaris posts results that have the 9700X outperforming the 9950X slightly. The reduction in average simulation time is 1 full second, or about 3.5% time reduced. The 9950X is also tied with the 7800X3D, with this being one of the only tests where we saw the 9700X leverage its changes to pull ahead. The 9950X has the same architectural benefits, so it’s up here as well. ", "Despite not improving over the 9700X, the 9950X at least improves on the 7950X. The jump from 33.3 seconds to 28.4 seconds starts to become noticeable for longer play sessions.", "Back in the 5950X era, we can see that there was no real differentiation between it and the 5600X or ", ". The 3950X was actually a little bit worse than the 3700X. This makes sense for those CPUs, as they sacrificed more frequency along with their core count increases.", "Intel’s presence begins at the 30.5-second mark with the 14700K and 14900K, which are about the same.", "Final Fantasy 14: Dawntrail has the 9950X at 336 FPS AVG, which is a somewhat noteworthy lead over the 9700X of 2%. It’d be insane to spend this money on it for just gaming, but it’s at least tracking better and we seem to be past the old era of high core-count parts floundering, like what we saw with the original Threadripper 1950X (watch ", ").", "The 7800X3D remains the clear gaming chart leader.", "To better understand what’s going on in Dawntrail, we plotted the frequency of the 9950X and 9700X during this workload. We found that the 9950X’s all-core average was about 4975-5000MHz, which is lower than the 9700X’s all-core average of 5500MHz [but that’s because it’s averaging an inactive CCD. We’ll look at that soon. You can see that the 9700X’s all core is just below its maximum single core frequency.", "At the same time, the 9950X is able to boost its maximum core higher, up to 5670-5700MHz. At times, that’s around a 150MHz advantage over the 9700X, which explains the performance we’re seeing in Final Fantasy. ", "If we plot the average frequency for just the 8 cores that are active, we see it aligns with the max -- that helps even further explain the behavior. The 9950X is just boosting higher everywhere.", "Now for F1 2024. F1 had the 9950X at 393.7 FPS AVG, with the 9700X at 380 FPS. That’s about a 3.5% difference between them. One note: We have observed more variable behavior in this test on the 9000 CPUs as compared to the 7000 series, which we think has to do with the change in memory kit that we’re using. As we discussed last time, we can’t use our standard Corsair DDR5-6000 kit for the 9000 series as the platform has some issues running it at the manual timings we set, despite 7000 working since launch. The Lexar kit does pretty well to match, but is not a precise match and has some reduced controls on some timings.", "Even with all of that caveated, the difference remains within reasonable expectations.", "Once again, a quick look at frequency shows that the 9950X with its maximum single-core boost is pushing higher than the 9700X, with the single-CCD boost also running often right alongside the max single core at any given interval. The 9700X’s average is frequently significantly lower than that of the 9950X, helping explain this larger 3.5% gap in this particular title. ", "We’re going to keep the conclusion really short. We’ve been running at full steam ahead for a week and there’s a ton of content on this topic already.", "The ", " has a higher TDP than the ", ", so it can boost higher than the ", ". This does make it “less efficient” in some games. In terms of gaming, the CPU is just not as efficient as almost any other modern AMD CPU.", "AVX-512 is a strength for Zen 5, which becomes more relevant on these “mini-HEDT” CPUs. That’d be a big reason to buy a ", " instead of a ", ", as we saw in Blender where there’s a massive efficiency uplift but also a performance improvement.", "We think it boils down to this:", "For gaming, you’d buy a ", ". For production workloads without a particular focus on AVX-512, and you can research your applications for that, we think the ", " is far better value. These CPUs are more likely to be under a full, all-core workload than the R5 and R7 CPUs, so you’re more likely to benefit from the reduced power we saw in certain all-core workloads (but not all). That said, the ", " is $520 now. That makes the 9950X 25% more expensive for what is often similar performance or maybe 12% better results at the high-end.", "Generally speaking, we’d advise against the ", " and instead in favor of the ", ". You can learn about why in our prior reviews, but basically, most workstation applications we test can’t make use of the extra cache. They underperform versus the 7950X but do benefit from the higher frequency of the 7950X non-3D.", "On the positive side, the 9950X did better in gaming than we expected. You really shouldn’t buy it for gaming primarily, but the fact that it’s at least regularly matching or very slightly outperforming the 9700X is good. Overall, the 7950X is generally a better value. The 9950X is at least worth considering if you’re doing a brand new from scratch build for a workstation type of environment but the thing for you to really research and pay attention to is the type of application you use. If it is really heavily threaded, it is running all cores at 100% all of the time like in Blender and/or if it’s an AVX512 application, you are more likely to benefit from a 9950X in a way that at least might start to matter versus a 7950X. If those things aren’t the case then, we think, the better value is to buy the 7950X instead."]},
{"title": " AMD Ryzen 9 9900X CPU Review & Benchmarks vs. 14700K, 7900X, 9950X, & More", "paragraph": ["AMD Ryzen 9 9900X CPU Review & Benchmarks vs. 14700K, 7900X, 9950X, & More", "Last Updated: ", "The Highlights", "Today, we’re reviewing the ", ". This is a 12-core, 24-thread CPU that follows the other Zen 5 launches. We recently reviewed the flagship ", ", which is a 16-core part. Before that, we reviewed the ", ". The last one that remains will be the ", ".", "This CPU has a current price of $500, flanked by the ", " at $650 and the 9700X at $360. The 9600X is a $280 part. Competing CPUs include AMD’s own alternatives: The R7 ", " is $366 right now, so about the same as the 9700X, the ", " non-X is $289, the ", " 16-core CPU is $525, and the ", " is $359. The 9900X’s closest competition at $500 would be AMD’s own ", " or Intel’s ", " at $400, with the ", " at $546 or so. The ", " will be the most direct alternative, pending results of ongoing Intel microcode and customer support issues.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "As we’re now 3 stories deep in Zen 5 analysis, we’re going to make these progressively simpler and focus increasingly on the product-level and the value. Let’s get into it.", "The ", " and ", " both contain more production benchmarks than gaming. This is because gaming is well represented in our ", ", but also because for these CPUs, we firmly believe that the only real reason to test them in gaming is to ensure that they work. The gaming benchmarks are basically just to validate that there are no major unforeseen issues as a result of the core count; once they pass that barrier, we move on.", "We also have a list of unused tests. These are tests which we conducted, but haven’t put in the review for one reason or another.", "As a reminder, we have over 50 CPUs benchmarked right now, and frequently have 20-30 on the charts. Each of those CPUs undergoes multiple test passes per benchmark, so there are over 4,000 averaged data points that we have collected in the last month for all of these tests. These test suites currently require a few days of testing and analysis per CPU. While we are trying to continually add tests for the audience, we are also eliminating tests which either are redundant and show the same thing as another one.", "And as one other quick update, this is our current list of games and their release dates for our test suite. ", "As a note, we are aware that there is a new line of commentary along Windows and administrator permissions. Our testing is applied equally to all products and we’re evaluating these as users would use them. If AMD or Microsoft make any changes that affect CPU performance, we will re-evaluate at that time.", "All-core frequency starts us off to validate that the CPU is performing as expected. To first re-establish the other recent numbers: With all threads loaded rendering, the ", " was averaging around 4440-4480MHz all-core, mostly limited by its power budget. The ", " measured around 5000-5100MHz, commonly around 5000MHz. This was a big jump from the 9700X and is enabled by the higher power budget.", "The ", " plots above all of these so far, typically in the range of 5200-5300MHz. It seems to be striking a balance between the core count and a higher frequency. The CPU has a higher power budget than the 9700X, but less than the 9950X (but it also has fewer cores than the 9950X, which benefits its boosting).", "For reference, we’ve provided the results for the ", ". This one runs around 5150MHz all-core, so reduced from the 9900X. That’ll be good news for the 9900X, as it’s both lower power and higher frequency. The ", "’s TDP matches that of the 9950X. ", "Finally, the ", " non-X runs around the levels of the 9700X, just with more drops in frequency from bouncing off of the barrier more. This is a 65W TDP part, so the behavior is expected.", "Single-core frequency boosting is next, tested using the Cinebench 1T test. This plots the maximum frequency of any single core during the interval.", "The 9700X started this generation at 5525MHz single-core, followed by our 9950X review with a slightly more variable result of around 5700MHz, with some peaks to 5725MHz. This keeps up the tradition of holding a high frequency on modern Zen architectures and is what enabled the 9950X to pull ahead in some gaming tests.", "The 9900X holds at 5625MHz single-core, right between the other two that we’ve reviewed so far. The prior R9 7900X ran a higher single-core frequency of 5700MHz and is benefited here by its higher power budget, so expect to see some back-and-forth with the 9900X in scenarios where only a few threads are loaded. This may be the case in gaming, where sometimes the higher frequency can claw back ground. It’ll depend on architectural improvements, IPC, and what AMD gets done per clock on Zen 5.", "Finally, the ", " maxed-out at a flatlined 5450MHz, below everything.", "We’ll briefly look at thermal results with the same all-core workload. We’re using a Liquid Freezer II 360 at 100% fan speed for all of this testing. We try to emphasize this regularly because temperature is probably the one result with the absolute most confusion and misinformation around it, and always has been.", "Temperature is ultimately a manifestation of the power we push through a chip. Because of that, indirectly, one of the best indicators of the temperature is always going to be power. Temperature can be a tough metric to use when basing off of internal CPU sensors because they are not comparable: We see reviewers and users comparing Intel and AMD CPU thermals all the time, and you really can’t directly compare them. It’d make more sense to compare the power draw head-to-head, but not thermals. The thermal sensors are in different places; in fact, just this generation, AMD moved its Tdie sensor in a way that makes the 7000 series not directly comparable. We talked about that in the ", ".", "Anyway, here’s the result with the same Liquid Freezer II 360 at 100% fan speed in all tests. The 9700X and ", " are the lowest power of these. The 9700X ends up cooler on Tdie than the 9600X (that much is like-for-like) because it has more cores to spread the same power and heat across. ", "The 9700X ran at about 51 degrees Celsius in a 21-22C test environment. The 9600X ran at 58 degrees in the same controlled conditions and at steady state. The 9900X ran at 70 degrees Celsius, with the 9950X at 81 degrees Celsius. Under identical conditions, we’d generally advise a 360mm liquid cooler for a 9950X if you want some room to drop fan speeds for noise levels. The 9900X would do fine with a high-end air cooler or a 280mm liquid cooler. The 9700X and 9600X can use any number of affordable air coolers on the market.", "In a worst case, peak power consumption load where all cores are engaged with rendering, the 9900X pulled 176W at the EPS12V cables. The 7900X that it replaces required 13% more power at 199W, so AMD has definitely improved in all-core power consumption for workloads like this. ", "Here are some generational comparisons: The ", " pulled 133W in the same test and the 3900X (watch ", ") pulled 150W. The 5000 series is when AMD really dropped power consumption in big ways and seemed to have the 12- and 16-core CPUs correlate with better voltage bins.", "The ", " required 251W in this test, with the 9950X improving with its 223W result. Overall, this is an area that AMD has been improving in total power consumption, despite setbacks in gaming power efficiency and total power draw that we looked at in our video from a few days ago.", "Also, just for fun, we threw Intel’s own 9900 on here -- except it’s the 9900K from 2018 (watch ", ") and it pulled 94W. The company also had a 9900X, but it seemed extreme to buy a 6 year old CPU for one joke.", "Power efficiency is up now. We’ll start with the best-case scenario that relates to the prior power consumption chart, which is rendering.", "For this one, factoring in total render time in Blender of a frame from our GN logo animation, the 9900X ranked at 22.6 Wh. That puts it about equal with the 9950X, so it’s overall more efficient than the 7900X (which had a 29.9 Wh result). The improvement is huge, as we’ve seen consistently in this test: We’re seeing a reduction of 24% in Watt-hours used during the test, with comparable improvements from the 7950X (watch ", ") to the 9950X that we looked at yesterday. The 9700X kicked this all off by achieving the top score for an out-of-box CPU (at 19.2 Wh, behind only the 7950X in Eco Mode and the PPT-limited demo tests). This was a big improvement on both the same-TDP ", " and the higher TDP ", ". Zen 5 is looking good in this comparison. ", "The 9900X continues the trend of improving on efficiency in this all-core scenario.", "Testing efficiency with 7-Zip, we’re looking at the millions of instructions per second compressed per Watt. This could also be reduced to “Millions of Instructions Per Joule.” Like the others, this measures power during the test, but then calculates it against the MIPS compression score instead of FPS or minutes.", "The R9 9900X completed 1041 MIPS/W, which has it equal to the ", " for efficiency. The 9950X completed 1003 MIPS/W, where it pulled about 204W during the testing. The ", " is remarkably efficient here, with the 7700 (watch ", ") also doing well. ", "We don’t see the same gains as we saw in the Blender test and the Zen 5 CPUs are overall less efficient than their preceding counterparts when analyzing compression, which partly has to do with limited ability to continue pushing the performance higher (since efficiency is a metric including performance). We’re adding decompression efficiency now (a first for this suite), which is about the same power consumption, to help demystify this.", "Decompression gives the 9950X incredible performance in MIPS, so it’ll be helped in MIPS/W as a result. The 9950X ends up at the top of the cluster behind the 5700X3D. The 9700X does relatively well here, up at 1662 MIPS/W. It’s still behind the R7 7700 with the same TDP, and both are behind the impressively low-power 7800X3D (watch ", "). The 7800X3D’s ability to operate at only 70W here is what lets it lead charts so easily. ", "This is also a matter of the voltage bin for each CPU, which is a topic we recently talked about in our ", ". Check that out for more information.", "The new 9900X that we’re reviewing ends up in the middle, about the same efficiency as the R5 5600X and R5 9600X, not distant from the 9950X, and notably better than the ", " and below. Intel’s CPUs bomb this test thanks to their extremely high power consumption.", "We’ll look at gaming efficiency now, starting with Stellaris.", "In Stellaris for simulation time, the 9900X ranked at 1.5 simulations per Watt-hour. Predictably, it is less efficient in gaming workloads than the 9600X at 1.9 Sims/Wh and the 9700X at 1.8 Sims/Wh. The 9900X pulls a little more power but isn’t intended to outrun the R5 and R7 CPUs in gaming, and so it’s ranked instead alongside the 9950X. This is expected behavior; the 9900X and 9950X are really only meant to be capable of gaming, not outperform AMD’s other CPUs.", "The 7800X3D is once again a feat of engineering and productization, hitting its stride with a 3.0 simulations/Wh score.", "Intel’s CPUs mostly cluster around a 1.0 scoring, with the ", " finding a much better balance at 1.5.", "Phantom Liberty had the ", " at about 105W during the test, which landed it at around 1.6FPS/W. That ranking has it functionally tied with the ", ", which pulled 119W here, and the ", ", which pulled 90W. The ", " is a better balance for Zen 5, up at 2.2FPS/W. The ", " is tied with the ", " non-X and outperformed by the preceding R5 CPUs and the X3D CPUs.", "We don’t have Intel CPUs on this chart yet.", "Final Fantasy: Dawntrail had the 9900X at 4.3 FPS/W, which aligns it with the 9700X and ", ". AMD’s architecture is still more efficient than Intel’s for out-of-box settings, but it has defeated itself with some of its past CPU choices.", "As in our 9950X review, we focus our 12-core and 16-core reviews on production workloads because these CPUs are more likely to be used in those tests. We still test gaming just to make sure things work properly, but we focus on non-gaming scenarios for these “mini-HEDT” parts.", "First up is RodiniaCFD, which we added after working with Wendell of Level1 Techs, a neutral third-party, and AMD to validate our findings. We had to get some external help validating our findings before publishing this chart because the numbers were so distant from other charts, and we always want to make sure any outliers are confirmed valid test results. In seeking peer review, we were able to confirm our findings between the 7950X and 9950X shown here, where the 9950X posts an uncharacteristically large 28-29% uplift over the 7950X. This was confirmed by both Level1 and AMD, both of whom sent us their test results for our own verification.", "The 9900X sees a smaller uplift closer to 10% over the 7900X here, but consider that it’s at a 50W lower advertised TDP. This would be another situation where the Zen 5 CPUs may offer better efficiency and also better performance. We’ll talk about this chart in more detail in our ", ", but we wanted to shove it in here as well since the 9950X does phenomenally as compared to the other 21 or so tests we ran on it. The 9900X is also a good performer here when considering the power drop. Just as one note, this chart is not 100% confirmed yet. It is still what we consider an experimental test, which means we’re leaving some room here for changes in the event we find something related to the benchmark software or how it’s executing that drops below our standards in the future, but we did want to share this because we think it’s an important data point and we did some basic peer review with it and our numbers aligned with theirs.  ", "Rendering in Blender is up first. For this, the 9900X completed the work in 7.7 minutes. That has it just ahead of the ", "’s 7.9-minute result for our intro animation and benefiting from a 14% reduction in time required from the 7900X’s 9-minute result. The 7900 (watch ", ") is slower still, at 10.6 minutes, with the 9700X at 13.2 minutes. That allows the 9900X a render time requirement reduction of 43% against the 9700X, which makes sense with the core count increase. ", "Generationally, the ", " required 12.4 minutes, giving the 9900X a reduction of 38% in total render time for this one frame.", "The 9950X and 7950X both lead the 9900X, with the 9950X offering a render time reduction of 23% total time required. If you’re debating whether the extra cost is worth it, that should help form a decision.", "Up next is Chromium code compile. As with all tests, a single benchmark of a workload can only truly represent that workload. This is what we use for compile testing right now. Other compile workloads can and do differ.", "The 9900X required 80 minutes to complete this code compile, which has it tied with the 14700K (watch ", "). The 9950X completed the compile with a total time reduction of 17.6% with its 66-minute result, with the 7950X leading the 9900X with a reduction in total time of 8.5%.", "The 7900X required 87 minutes for this work, giving the 9900X a 7.7% time reduction. That gap grows with the 7900 non-X and its lower power budget.", "Generationally, the most interesting improvement is a 33% time requirement reduction against the 5900X (watch ", "), dropping from 120 minutes to 80 minutes.", "The only Intel CPU ahead of the 9900X is the i9 lineup of 14900K (read ", ") and ", " options.", "In 7-Zip file compression, the 9900X completed 168.9K MIPS, landing it between the 7900X (3.5% improved) and the 14700K (itself 3.4% ahead of the 9900X). The 14700K looks to be the direct competition to the 9900X, assuming Intel resolves its issues without collateral damage.", "There aren’t many upgrade options without going to true HEDT: The 9950X would grant a further uplift of 21% in MIPS, just ahead of the 7950X. The 14900K at 188K MIPS would improve about 11%.", "Generationally, the jump over the 5900X is large: The 9900X moves to 168,992 from the 5900X’s 123,278 MIPS.", "In file decompression, the 9900X completed 217.5K MIPS and landed between the ", " and the 14900K CPUs. It’s actually below the ", " here, so we’re seeing more benefit from just raw core count in this particular benchmark than some others. Another example is the ", " outperforming the ", ", or the ", " outmatching the 5900X, which is just a prior generation representation of the same thing.", "The 9950X and 7950X set a high ceiling in this test, with the 9950X leading the 9900X by 29%.", "The 14700K remains a good competitor, but it allows the 9900X to gain a lead of 8% in this benchmark.", "In Adobe Photoshop with the Puget Suite, the 9900X’s completion of filters, scales, warps, blend modes, blend layers, and other functions gave it a score of 11,385 points. That ties it with the 9950X, where both see a slight loss in performance compared to the 9700X. This test is more thread-limited and will not benefit as much from huge core counts, unlike what we just saw in decompression. That’s OK, but that’s why we run so many tests: It allows us to show all kinds of different software scenarios.", "The 9900X still does well if this is a side task you might do on your machine, ultimately remaining among the best. In this test right now, the Intel CPUs fall below about a quarter of the total entries we have, which are AMD. This appears to have shifted from an Intel favor in years past to an AMD favor today.", "Adobe Premiere is up next, also with the Puget suite. In this one, the 9900X scored 10380 points, again roughly tying it with the 14700K. In Premiere testing with the extended workload, the 9950X pulls ahead by 5.5%. There’s not a big benefit to the cores here, but the lineup makes a little more sense than in Photoshop.", "The 9900X outdoes the 7900X only marginally, at 2.8% total uplift. The lead over the prior 5900X is 26%.", "Spec Workstation is up now. This is testing financial simulations like probability calculations, options modeling, and similar tests. This is a workstation task scored in aggregate.", "The 9900X scored 7.27 in the Open Spec testing, which improves it upon the 7900X by 8.8%. The 9950X leads this chart currently, at least until we run Threadripper through again, at 9.47 (a 30% uplift over the 9900X). Intel’s 14700K trails the 9900X here, with the 14900K ahead of it.", "The next Spec test is for LAMMPS biomedical modeling. In this benchmark, the 9900X scored 6.06, which ranked it as tied with the 13700K. The 14700K leads by 8%. If you’re considering the 9900X vs. the 9950X, then the improvement of the 9950X would be about 14.4%.", "Uplift of the 9900X over the 7900X is 4.5% here. Not bad since the power also went down.", "We’ll keep the gaming tests short for this one, just like we did for the 9950X. The goal is to verify that it works properly. The 7800X3D will predictably remain the top choice for new gaming machines.", "Here’s the list of games we’ve been testing this time around. We made it a point to undergo a massive overhaul to our game benchmarks, so most of what we use now is from 2023 and 2024. This has been pretty awesome since some of the newer games are starting to really scale with core counts 8 and above.", "Dragon’s Dogma 2 is up first, a 2024 title.", "In Dragon’s Dogma 2, the 9900X ran at 90 FPS AVG with lows spaced proportionally, based on neighboring results. Cores are parked for the 9900X and 9950X, so they’re basically 9700X CPUs -- but with a higher power budget. This has the 9950X ahead of the 9700X as a result, for reasons we showed in our 9950X review. The 93 FPS AVG result is repeatable. The 9900X is tied with the 9700X and 7700X (watch ", "). Uplift over the 7900X is 2.7%.", "As before, the leader remains the 7800X3D. In a gaming scenario, you can expect an uplift in our custom testing in the big city here amounting to about 21% for the 7800X3D over the 9900X.", "The 14900K is also up top, but technically behind the 7800X3D. The 14700K that the 9900X was neck-and-neck with in many production tests is also shown favorable gaming performance.", "F1 24 is another 2024 title, clearly, and has the 9900X at 383 FPS AVG, just ahead of the 9700X and behind the 9950X. These 3 CPUs are functionally about the same. The 14900K lands alongside them.", "Chart leaders include not only the 7800X3D, but the two-generation-old ", " CPU at 400 FPS AVG.", "The 9900X is at least running properly and without a performance sacrifice.", "In Final Fantasy XIV: Dawntrail, the 9900X ran at about 333FPS AVG, which roughly ties it with the 9700X and 5600X3D (read ", "). The 5600X3D is enough alone to demonstrate that there are better value pure gaming parts, as we’ve been saying, but it doesn’t scale anywhere close to the 9900X in the production strengths we saw earlier. It all depends on your use case.", "The 7800X3D sets the ceiling at 363 FPS AVG in this one. The 9950X leads the 9900X on a technicality. The 7900 underperforms here: Its 65W TDP is limiting its power availability to boost, and so the 7700 non-X at the same TDP is better able to leverage that power budget across fewer cores to boost higher, which Dawntrail favors.", "Stellaris simulation time is next. Despite being among the oldest two games in our bench suite, and the only ones that pre-date 2022, Stellaris remains remarkable as we test simulation time rather than framerate.", "The 9900X required on average 30 seconds to complete the simulation. Leaders here remain the 9700X, 9950X, and then 7800X3D. Some of these are within error of each other. The 14900K entries are both near the 9900X, though it has a technical lead over both the 14900K with standardized RAM and the 14700K, the two of which are within run-to-run variance of each other. Improvement over the 7900X is about 10% less time to simulate.", "Baldur’s Gate 3 is last for games. Tested at 1080p, we found the 9900X to run at 104 FPS AVG, which is 2.9% ahead of the R9 7900 and exactly equal with the 7900X. There is no improvement in this situation.", "We have other games tested, but we’ll stop there since the focus was on production, power, and thermals. We’ve established that its gaming performance is predictable.", "For the ", " vs. ", ", performance across the board illustrates improvements in the range of 0% to 10%, depending on the use case. Production applications commonly see 3% to 7% uplift, with some at 10%. ", "Efficiency was explored in our ", " a few days ago and it’d be great if you check it out. That video got buried algorithmically when we posted our ", " so close to it, so we want to make sure people are aware it exists. You’ll get a deep-dive on this topic there.", "Broadly speaking, currently, it makes more sense to buy AMD’s previous generation CPUs. The ", " is also worth consideration; however, we are still on pause for our recommendations of Intel pending exploratory testing of its new microcode and support processes.", "There are a lot of angles to consider for a new product. Some consumers focus on value and performance for that value, and people who fit that camp will find our reviews the most productive. From a value standpoint, we think that Zen 4 currently offers better value at comparable efficiency in many use cases. While we are aware that some heavier number crunching workloads, like AVX-512 work in Linux, may present higher performance, it is not anything that shows up in our suite that we presented earlier with perhaps 1-2 exceptions.", "As a consumer-oriented review outlet with a focus on value, our recommendations would currently be Zen 4 alternatives. This includes the ", " for core-bound workloads, as its price is extremely competitive with Zen 5, and the ", " for gaming-focused builds. The ", " is competitive in many cases with the ", ", but again, we are currently undertaking a full test of Intel’s microcode before resuming recommendations."]},
{"title": " AMD's Zen 5 Challenges: Efficiency & Power Deep-Dive, Voltage, & Value", "paragraph": ["AMD's Zen 5 Challenges: Efficiency & Power Deep-Dive, Voltage, & Value", "Last Updated: ", "The Highlights", "Here are some Zen 5-related comments we received in response to some of our recent AMD CPU reviews:", "“First time I have completely disagreed with Steve's take. Same price, same performance, 30+% less power is huge.”", "“That power reduction is HUGE. I feel GN didn’t give enough emphasis to that.”", "“Don’t get me wrong, I really like what GN is doing. But am I alone in thinking that it’s a problem if reviewers complain about power consumption, then when a corporation decides to take a generation where they instead reduce consumption, 90% of the review is spent harping about how the part using less power has no meaningful performance upgrade?”", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "We dove into ", " efficiency because of dozens of comments like this and we found that, actually, Zen 5 isn’t universally more efficient than Zen 4; in fact, our new testing indicates it’s sometimes worse. ", "This chart shows the max VID of our ", " vs. our ", " when both are locked to 60 FPS, with the ", " running higher voltage. ", "This one shows the power over time, and while we see our Zen 5 CPU drew far less power in the loading screen for the game, it also draws significantly more power at times in gaming scenarios (which comprise more of the total experience). ", "This chart shows the FPS/W in Phantom Liberty, where the ", " in particular gets crushed by not only the ", " but also by the ", " and only barely equates the ", ". ", "This one shows simulations per watt-hour in Stellaris, establishing again that the 9000 series surprises everyone with its lack of efficiency.", "CPU efficiency isn’t a simple thing to measure because it’s so massively variable. We talked about this last year in a dedicated ", ", but gaming workloads can consist of times when a CPU is both efficient and inefficient, depending on what it’s doing. Loading is different from playing, and likewise, 100% isn’t 100%. “100% load” can mean different things at different times: A CPU might be 100% bound on a single thread in a game, or could be 100% bound on all cores during a production load. It could be 100% cache limited in some compile tasks. All of this means that efficiency is complicated to evaluate.", "But now, having spent a week evaluating only the efficiency of the AM5 CPUs, we have come to the new and updated conclusion that they are not universally more efficient. They are sometimes, but those scenarios are restricted largely to something like rendering in Blender.", "Today’s goal was scientific: We wanted to know how the lineup shifted with efficiency testing across gaming, not just production workloads. ", "A quick recap first:", "Our stance on the Zen 5 CPUs so far was that you generally shouldn’t buy them. Our reasons for this were these: The value is worse than Zen 4, we experienced memory compatibility and BIOS issues, we had a completely broken chip off the line following ", " (creating uncertainty if they can’t even get a reviewer a working chip after a recall), and the performance was sometimes ", " from Zen 4. Worse performance and higher price is already enough to generally advise a ", " (watch ", ") instead, but we said there was one upside: Efficiency, which we saw specifically in our all-core rendering production test. ", "That’s true, but the bad news for Zen 5 is that in gaming scenarios and even some other production workloads, it’s not more efficient. In fact, in a lot of gaming scenarios, it’s worse.", "The short version of today’s testing is that we are now hardening that stance: We still think the 9700X (read ", ") qualifies as “meh,” but in gaming scenarios, it also loses that efficiency advantage in most situations. Not all, like sometimes in loading, but in most.", "Here’s how this works.", "For this benchmarking, we’re testing by analyzing the power drawn at the EPS12V cables that go into the motherboard. We use an interposer between the power supply and motherboard and combined it with custom software we wrote that automates the test procedure to collect the same data at the same points in each test. This allows us to create these nice charts where the start and stop times, as well as the game loading times, perfectly align to allow us to analyze every aspect of the game.", "We’re testing 7 games and 2 applications using an Elmor PMD, or Power Measurement Device, of which we bought about 8 from Elmor’s Lab’s websites. ", "We use a current clamp and HWINFO to evaluate each PMD.", "The metric is FPS/W for gaming. FPS is frames per second, whereas a Watt is 1 joule per second. Because that’s frames per second per joules per second, we can simplify that to just say “frames per joule,” or FPJ. This is the same as FPS/W, but with unit cancellation.", "We ran a poll on our Community page asking you all if you’d prefer us to use Frames Per Joule or FPS/W, and the overwhelming majority voted for FPS/W. Reading the comments, the primary reason was that it’s easier for most people to understand and instantly relate back to power consumption. Our preference was for frames per joule, but after reading the reasoning from our viewers, I agreed with their reasoning and we’ll primarily use FPS/W language. We will put both on the chart labels, though.", "Stellaris’ base metric is simulation time in seconds, where lower is better. In order to stick with “higher is more efficient” and to make it algebraically easy, we are converting the Stellaris data into simulations per hour. We take the average simulation time in seconds and see how many of those will fit in 60 minutes, then use that to calculate the simulations per watt-hour.", "We are defining “efficiency” as completing the same unit of work with less total energy or achieving more work with the same or less total energy. We use 3 variations for this: Stock / out-of-box testing, 60 FPS locked, and 50W PPT.  The 60 FPS lock gives us a fixed unit of work that allows us to evaluate the ", " non-X and 9700X on even ground. The 50W PPT normalizes for power, but allows FPS to be unlocked.", "There are limitations to this methodology:", "The biggest one is that we can’t analyze transients of the CPU with this method. It’s much faster than using an oscilloscope, but it also means we aren’t polling the data on the microsecond scale. ", "The second limitation is that we are not using complicated combinations of tests to evaluate a total aggregate platform-wide efficiency. For example, assuming equal characteristics, a CPU hitting a GPU bottleneck can’t be fully leveraged and will pull less power than one which is otherwise the same but runs at a lower framerate and is CPU bottlenecked. That means that there are scenarios where a high-end, high-power CPU could feasibly underdraw power because it can’t keep up with the GPU. We tried to eliminate this possibility by picking games that are heavily CPU-bound.", "One other limitation of methodology is that we don’t have any insight into GPU power behavior. If there is a key driver or other characteristic of the platform that fundamentally changes how the GPU behaves, we are not capturing that power data. In general, this shouldn’t happen; however, it is a possibility, and we wanted to be transparent about the limitations of our tests here. ", "We believe in the scientific method and disclosures.", "OK, with all of that understood, let’s get started.", "As a reminder, this is where we started. This is the Blender workload, which is 100% loaded on all threads constantly. Because of the way PPT or power limits behave, this can manifest in different efficiency results than in games where we’re more likely to have power headroom to boost higher (and potentially run higher voltages on some cores).", "We added the 7700 (watch ", ") here. The 9700X at 19.2 Wh remains more efficient than even the 7700 non-X at 21.2 Wh, which remains a great and very positive result for AMD’s 9700X. It’s clear that the CPU absolutely can be efficient, and even with the addition of the non-X 7700, that remains the case. Limiting the 7700 to 50W PPT and 9700X to 50W PPT has them functionally tied and within error, although the 9700X burns more of its PPT budget on voltage.", "As for the ", ", its efficiency here is also better than that of the ", " (by a lot, actually) and the ", " by even more. This chart remains the most positive for AMD’s Zen 5 and is what makes it not as simple to just call it “inefficient,” because that’s not accurate. But in other tests, it’s not as positive and can be less efficient.", "Here’s Phantom Liberty for a heavy gaming workload. We’ve removed the Intel results from this chart as we are still collecting data for this game.", "The 7800X3D is a clear leader for stock CPU performance at 3.3 FPS/W, followed by the ", " at 2.7. Both are at about 65W, making them again directly comparable and functionally power-normalized. The 7600 (watch ", ") is also nearly power normalized, at 2.5FPS/W. The 9700X pulled 80W in this test, resulting in 2.2 FPS/W. It ties the ", " for framerate, but is less efficient. The 9700X was technically more efficient than the 7700 non-X here (by a fraction), but they’re functionally tied. The ", " trails the 9700X at 1.8 to 2.2 FPS/W.", "Locking the 9700X and 7700 both to 60 FPS but allowing power to do whatever it wants, the 7700 ends up achieving the same framerate for less power. We think this might have to do with voltage -- we’ll look at that in a moment.", "Although the 9700X is more efficient than the ", " and, on a pure and irrelevant technicality, more efficient than the 7700 stock here, the 9600X ends up less efficient than the 7600 and about tied with the ", ".", "As for PBO Max, it didn’t do much for framerate, so the power went up to about 100W (from 80W), but efficiency fell.", "When locked to 50W PPT, the 9700X became instantaneously more efficient. It pulled about 2W more than the 7700 at 50W PPT, but even if we called that “margin of error” and brought its power down by 2W, it’d be at 3.9 FPS/W against 4.1 on the 7700. As is, it’s 3.6.", "Before the research charts explaining the interesting behavior here, we need to see some of the 10-pt and 30-pt highs. For this, we are doing a very simple average of the 10 highest spikes and the 30 highest spikes during the entire test. This means that we’re including not just the gaming itself, but the loading period. Loading screens can sometimes run higher power consumption than gaming itself.", "This is not an efficiency chart, it’s just pure power consumption. ", "Here’s what’s interesting: In favor of Zen 5, the 9700X at 80W average had 10-pt and 30-pt highs that averaged much closer to baseline, at just 81.7 and 80.8W. The 7700X (watch ", "), meanwhile, had highs up at 121.4W and 115.2W. The 7700 non-X has slightly lower total power peaks than the 9700X. Looking at the 60FPS-locked 9700X, interestingly, we still see the same spikes (but fewer of them) as the 9700X under stock conditions. That’s because these spikes happen in loading, so an FPS limit has no bearing on them.", "PBO MAX absolutely blasts the power here. As for the 9600X, it’s functionally tied with the 7600 for 10- and 30-pt highs. These are within variance. ", "The 7800X3D deserves recognition for its relatively low spikes.", "This chart shows the CPU power over time for each of the CPUs in this load. Before each averaged power period, we can see large spikes in power consumption that correspond with the loading screen. These will show up in our 10-pt and 30-pt highs later. You can see the 9700X and 7700 both spiking to around 80W in these periods.", "During gaming, the 9700X is consistently higher in power consumption than the 7700, despite being locked to 60 FPS on both and having the same TDP.", "If we plot the Max VID, the 9700X is running higher point-to-point when looking at maximum per interval. It’s in the 1.32-1.38 range, whereas the 7700 is in the range of 1.27 to 1.32.", "Looking now to VDDCR_VDD SVI3 TFN voltage, the 9700X ends up in the 1.33-1.34 area, whereas the 7700 was typically around 1.29 to 1.30V.", "Looking now at Vcore from the motherboard sensor in software, we see another 1.30 to 1.34 difference favoring the 7700 with the lower Vcore.", "Finally, for frequency, the 9700X was frequently spiking toward 5400-5500MHz in this game, with expected fluctuations based on the game load. The 7700 ran a lower frequency on average. It appears that the 9700X is pulling a higher voltage across the board, even when locked to 60 FPS, as it tries to sustain these frequencies. Also, in situations where the older CPUs become architecturally bound, such as in Final Fantasy, which we’ll take a look at in a bit, the 9000 series is able to run a higher framerate and bypass some external binds. This also leads to higher power. In this instance, though, the voltage is largely to blame.", "That gives us an explanation for what we’re seeing. Let’s move on.", "Here’s Final Fantasy 14: Dawntrail.", "In this one, the 7800X3D returns as the most efficient CPU -- and by a longshot. The next closest stock CPU is the 5700X3D (read ", ") at 7.3 FPS/W to the 7800X3D’s 8.5. Behind that, the ", " is next at 6.8 FPS/W. The next stock CPU is the 7600, then the 7600X. These two are about tied. The 7600X (watch ", ") is slightly more power-hungry, but also slightly higher framerate. ", "Skipping down to the new CPUs, the 9600X ends up less efficient than the 7600 and 7600X alike. Despite an increase in framerate that was actually meaningful when compared to the 7600X, power consumption went up more. Even though the 9600X has a TDP of 65W and the 7600X has one of 105W, you can see that the 9600X is pulling more power during gaming but isn’t always the case. You’ll see that the 7600X  can pull more when loading the game. It makes this comparison very messy and difficult to really nail down which one is more efficient because they change. This is something we spent a day investigating. We’ll get to our best explanation of that in a moment. The data is repeatable and, referencing our data from last year, appears consistent with games like this one.", "Locking PPT to 50W gets the 9700X and 7700 closer to each other, with the 9700X pulling ahead even in spite of a slightly higher EPS12V power consumption. This is a game where its FPS lead is meaningful, at 9% over the 7700, just like the 9600X saw around 14% over the 7600X and 21% over the 7600. In the rare scenarios where the newer CPUs are actually able to get more than a 3-6% improvement, it seems that the efficiency scales more favorably than we’ve seen elsewhere when normalized for power.", "Intel’s performance here is unfortunate: It’s at the bottom of the charts once again.", "Here’s the research into that behavior of the 9600X and 7600X, which we’re plotting because it has a higher TDP and PPT than the 9600X, but pulled less power in the same test when gaming.", "First, for power over time, you can see the 7600X does actually burst significantly higher than the 9600X in some loads. That load is at the start: When we’re loading the game, in that first 40 seconds or so, the 7600X pulls around 115W at the peak when it’s first launching and loading the benchmark. The 9600X is pulling around 80W in the same scenario, so in fact, it is far lower power in this workload. This doesn’t show up in the gaming averages, because it’s not during gaming, and is also a shorter time window.", "In subsequent loads, the intensity is reduced, but you can still see the 7600X spiking to around 100W in the second pass, whereas the 9600X is around 78W. ", "Once we get in game, it’s a different scenario: The 9600X pulls around 20W more power in many of these sections of the game test.", "Here’s the Max VID chart for Final Fantasy XIV: Dawntrail. In this test, the 9600X plots 1.36-1.37 maximum VID point-to-point. Keep in mind that this is done with software logging, not an oscilloscope, so we aren’t catching any spikes that are on the scale of microseconds. We can’t see transients here.", "Even still, the 9600X maintains a higher max VID than the 7600X for the entire test sequence. The one exception is during our initial load of the game and its assets in that area before 40 seconds: The 9600X has far lower max VID, way down to 1.14 to 1.18V, whereas the 7600X is in the 1.34 range.", "Looking at VDDCR_VDD SVI3 TFN, the behavior is replicated: The 9600X is lower in the loading screens, but higher in the game. We think this is to do with CPU core utilization, where Final Fantasy has a known favor to CPU frequency on fewer cores. In other words, a 6-core CPU can outperform an 8-core CPU from AMD in this game if the frequency is a little bit higher and here we're seeing that higher frequency come into play.", "Here’s the motherboard Vcore sensor in HWINFO. In this one, we see a repeat of the behavior: The 7600X generally is lower for Vcore as measured here. ", "Here’s the frequency chart. In this one, The average all-core frequency has the 9600X basically pegged to 5450MHz, which explains the behavior we were seeing entirely. The 9600X is holding a higher clock, whereas the 7600X is fluctuating constantly with an average of around 4900 to 5000 MHz.", "The 9600X is getting most of its 9-14% performance bump, depending on which R5 you compare against, as a result of this behavior. It’s also running higher power consumption because of it.", "Let’s move to Stellaris. This one is interesting because it’s one of the games that plots a larger difference favoring the newer CPUs. The 9700X had an actually meaningful gain over the 7700X and 7700 here for the simulation time.", "This chart shows the simulations per watt-hour. The base metric in this is time, not framerate, with the original test data being simulation time in seconds. ", "In this test, the 7800X3D is again supreme at 3 simulations per watt-hour. The next stock CPU is the 7600 at 2.5, then the ", ". In this test, the extra cache on high-performance CPUs does not affect performance as much. The ", " is tied with the 5700X3D for simulations per watt-hour, as is the 7600X. The new CPUs are further down: The 9700X is less efficient in this game than the 7700X and 7700 alike, and the 9600X is likewise less efficient than the 7600 and 7600X. In the case of the 7600, the 9600X falls far behind. The 7600 is 32% higher in rank here.", "Intel lands at the bottom again, as predictable for its power consumption. ", "As for AMD, locking to 50W PPT caused the 7700 and 9700X to be equal in this test, contrary to the stock performance where the 9700X trailed the 7700.", "Now for F1 24. This one is good because the high framerate makes it easier to work with some of the numbers.", "The stock 7800X3D crushes everything else on this chart -- and that includes the 9700X. Despite its all-core efficiency in some workstation tasks, the 9700X pulled on average 79.6W in this test against the 7800X3D’s 55W, and since it was also lower framerate at 380.2 FPS to the 7800X3D’s 458.1, the 7800X3D is a clear winner. It really is the best gaming CPU right now. Not only is it higher framerate, but lower power.", "Even the two-generation-old 5700X3D is leading most of this chart. What’s super cool is that they run at the same average power, which means we accidentally end up with an additional controlled variable. That means that we’ve isolated for only FPS, so at the same power (or power-normalized), the newer 7800X3D is 28% more efficient. Actually, the 7600 non-X also ends up power normalized by pure coincidence. At 54.9W, it runs a 5.8 FPS/W average and is the most efficient out-of-box CPU without X3D that we’ve tested in this game so far. The 7600X is basically tied with it since the power draw went up slightly. The older R5 5600 (watch ", ") is also in this area.", "The 9600X CPU is a 65W TDP part, and yet compared to multiple generations of both the X and non-X R5 CPUs, it is less efficient in the actual gaming workload.", "Intel sits at the floor here, but notably, you can see that the ", " doesn’t draw the insane amounts of power it does in an all-core production workload. This goes back to what we were saying about games being generally lower intensity or at least more volatile.", "Now we’re adding a few entries to the chart. We’ll highlight the additions of the 50W PPT R7 7700, 50W PPT 9700X, and FPS-locked 9700X and 7700 non-X.", "The 50W PPT entries run at almost 311 FPS for the 7700 and about 316 FPS for the 9700X. With the 50W PPT setting in BIOS, the CPUs end up at about 35-37W for EPS12V. This boosts their FPS/W above the 7800X3D, but obviously you could play this same game with the 7800X3D to leapfrog them. The point though is that the CPUs can be more efficient than stock, but you start losing a lot of performance. Here, we dropped 17% FPS from the stock 9700X.", "Locking the framerate to 60 FPS still has the 7700 as above the 9700X. These two shouldn’t be compared to anything else: The efficiency appears much lower because we’ve just cut hundreds of FPS off the framerate, but a baseline level of power is still necessary to even run the CPU. Once again, it appears that the 9700X only deserves efficiency credit in some specific workloads. ", "We’ll look at another heavy gaming load next with Starfield.", "In this one, the 7800X3D is again the leading stock CPU. The 7700 is distant behind it and tied with the 5700X3D, both at 1.6 FPS/W. The 7700 and 9700X were pulling similar power in this one, nearly power-normalizing them. If you were to fully power normalize them, they’d be equal. Here, they are functionally equal but with the 7700 technically more efficient.", "As for the R5 SKUs, the 9600X is about tied with the 7600 and 7600X, landing right between them. After this, the PBO MAX 9700X boosts its framerate, but pulls so much more power (33W more) that it predictably loses efficiency.", "Intel pulls nearly as much power in this game as it does in full production workloads, but the baseline numbers show that this can be reduced with more limited PL1 and PL2 numbers.", "As for the 60 FPS locked comparison, the 7700 ran more efficient again than the 9700X. The 9700X pulled more power to do the same work, making it less efficient. This is related to the same voltage and frequency behavior we described a moment ago.", "Baldur’s Gate 3 is up now.", "For this one, the 7800X3D again leads the chart, now at 2.4 FPS/W. The 5700X3D follows it at 2.0, with the 5600 next. A large group of devices scored the same, with everything from the R7 7700X at 1.3 FPS/W to the 7600X at 1.4 FPS/W functionally equivalent. The 9700X lands in here, tying with the 7700 and technically more efficient than the 7700X. This is one of the tests where the newer 9700X is about the same or slightly better in some cases against its direct predecessors. Locking the 7700 and 9700X to 50W PPT produced the same result, and if the 9700X were fully power-normalized and shed the last 2W, it’d have a technical 0.1 lead over the 7700 at 50W PPT, but basically they’re the same.", "This is one of the better scenarios for Zen 5 in gaming, and it’s still generally not more efficient than the 7000 series in this game.", "Rainbow Six is pretty interesting. This one runs such a high framerate that we finally get some double-digit numbers for FPS/W.", "The 7700 and 9700X are remarkably efficient when locked to 50W PPT here, which is thanks to the fact that the game is so easy to make spew hundreds of frames per second even when extremely power limited. The end result is that we’re still soaking the base power requirement for operation with those large FPS numbers, enabling the gap that forms between the 7800X3D and the 50W PPT-limited CPUs.", "The 7800X3D is next, functionally power-normalized with the 7600 and 5700X3D, but outperforming both. The newer CPUs improve in framerate over the prior generation, which helps the 9700X outrank the 7700X for efficiency -- but it’s still behind the 7700. Once again, the 7700 is running at a lower voltage and pushing lower clocks, which obviously contributes to a slightly lower performance, but also makes it more efficient.", "The 9600X is beaten by both the 7600X and 7600. The 60FPS-locked 7700 and 9700X had the 9700X pulling significantly more power, again for reasons described earlier.", "Despite Intel’s overall good framerate in this game, its high power consumption pulls it down in this chart.", "We’ll close this out with 7-Zip before we move to the 10-pt and 30-pt highs for each test. 7-Zip is represented in millions of instructions per second per watt. This could be simplified as millions of instructions per Joule, if you preferred. Same idea.", "This one is intensive, but not in the same way as Blender -- it’s also a lot shorter, which can skew numbers the other direction.", "The most efficient CPU in this test is the 7800X3D. It’s not the best performer, unlike the gaming tests where it is both the highest framerate and most efficient, but it is the most efficient on this chart. The 7700 and 9700X are next and are tied with each other. These two are within margin of error; so, at best here, the new CPU is the same efficiency as the prior 65W TDP part. It remains more efficient than the 7700X by a significant margin, with an uplift of 39%. But again, the difference is about 0% against the 7700. If the 9700X were fully power-normalized at the same 77.6W -- which is really hard to dial in that much -- they’d be even more equal.", "As for the 9600X, it’s equal to the 7600 and within error. It’s not worse or less efficient, but it’s not better. It is better than the 7600X.", "Intel remains the most power-hungry here, approaching 300W in some tests.", "Here are the last few charts of the 10-pt and 30-pt highs that we previewed with Cyberpunk earlier.", "In Stellaris, the data between the highs and average is much wider overall (with the exception of the PPT-limited tests at the top). The ", " had a 160W high against its 112W average during the game itself, which again accounts for loading during this benchmark. The 7800X3D also deviates from its average, but has results low enough overall that it doesn’t matter much.", "We saw higher spikes on the 7600X and 7700X than the 9700X and 9600X, which makes sense for their rated TDPs. The 7600 and 7700 had lower highs, though, which correlates with the lower voltage that we observed earlier (in further correlation with the frequency differences).", "The last one we’ll look at is Final Fantasy. This one gets time in the story for being so different. We already talked about how the game has some unique behaviors for average power consumption in-game, but what’s also unique is the loading power. The gap between the 10- and 30-pt bars here helps illustrate how infrequent some of these spikes are. ", "The 7700 ran at 53W on average in the testing, but spiked to about 80W in some of the loading in between. The 9700X ran at 73.1W in testing on average, but spiked to 83W in loading -- a smaller percentage increase than the 7700, but more in total. This is also why it’s so difficult sometimes to have a short answer for whether a CPU is efficient or not. To fully analyze this, we’d probably need to measure the total loading time or something as well.", "Finally, as for what this all means, we’ll put this into perspective with a simple chart. This looks at the heaviest gaming workload we tested (Cyberpunk), calculated as a measurement of kWh for energy cost. Because the cost for just a CPU is so low, we went with the extreme: This is total shut-in, 8 hours a day of gaming for a full year.", "Our electricity is nuclear where we’re at and is $0.10/kWh, but we know that in Europe or even California with variable rates, it can go even beyond $0.40/kWh. We’ve scaled up to $0.39 here, using some online tools to look at common prices.", "This highlights the difference in cost per year if you used each of these CPUs to play the heaviest possible game for 8 hours a day. ", "For our electricity cost, the difference is basically a rounding error -- especially if you aren’t using the system this much.", "If you were to use the 5700X3D for 8 hours of gaming a day for a year, it’d cost you about $19 at our electricity rate.", "For the 7800X3D, those numbers would be about the same. The 9700X would plot at $23 for the floor in these conditions, or $91 for the ceiling. Obviously, all of these numbers decrease with less use, or could increase with higher electricity cost. This isn’t a benchmark, it’s just math -- so you can apply this to your own situation by looking up a kWh cost calculator and estimating your usage.", "Likewise, if you were building a rendering machine and running it literally nonstop, the 9700X would be a lower cost per unit of work completed -- but it’d be easily beaten by Eco Mode parts like the 7950X or Threadripper, as we’ve shown in the past.", "We’re not going to recap the results here: If you want to see them, you can check through the charts. ", "It’s a complicated subject and we’ve already walked through it. The shortest version is that we are hardening our stance against the ", " (and now adding the ", ") that they make less sense to buy than Zen 4. Previously, this was primarily because the value of Zen 4 was better, the performance was sometimes better, and functionality (as in actually working). Patrick fought the platform for a few days and had this funny quip the other day: “I believe AMD that it was an ‘architectural overhaul’ because on Zen 4, the memory worked and now it doesn’t.” As a reminder, and this was overshadowed by people demanding we praise the efficiency more in the ", ", our ", " didn’t even work with EXPO on literally a single kit. It was broken. Our new one works fine.", "Those were the reasons we didn’t recommend Zen 5. But now, it’s also because the efficiency isn’t as good as just Blender shows. The Blender result is accurate, but what we’ve learned from this situation is that there is enough of a demand for efficiency testing now that we clearly need to overhaul our representation of it. As a result, we immediately have added gaming efficiency benchmarks for our next reviews coming up. That’s the lesson we’ve learned. The downside is that the reviews get longer or other tests get cut as a result for practical reasons.", "Behind the scenes, AMD gave reviewers almost no time with these CPUs, especially when factoring-in that we received two CPUs that required 2 days of troubleshooting to even get running. This meant limited time to expand testing, as our test suite already required every hour of that review window to complete. Now that we’ve had another week to work on these parts, it’s made us cynically wonder if AMD’s decisions were strategic to limit time reviewers would have. Less time means a reviewer is less able to explore all the branching problems with a product. We explored the memory compatibility issues and confirmed them on our parts, but that meant we lost two days that could have been used on this task. This comes after AMD had already strung us along for 3 weeks with missed promises of CPU delivery for reviews, leading to an unpredictable schedule."]},
{"title": " GN Mega Charts: CPU Benchmarks & Comparison", "paragraph": ["GN Mega Charts: CPU Benchmarks & Comparison", "Last Updated: ", "The Highlights", "This article is an entry in our GN Mega Charts series. All Mega Charts are listed on the Features page, including these:", "This section contains disclaimers, limitations of the process, and disclosures relating to data quality control. We think that this is all important for your understanding of how this page works and so that you can adjust your own expectations and potential reliance on the data to calibrate with the two groups (“Active” and “LTS”); however, if you’d like to just jump straight to the charts and ignore all of that, you may bypass the wall of text and auto-scroll down ", ".", "This article contains our ‘Mega Charts’ for CPU performance benchmarks, including our production tests (commonly referred to as “creation” benchmarks) and gaming tests. Our power testing can be found on the above-linked page and is isolated, as it tends to be more static.", "This page will be regularly updated with the latest of our CPU benchmark performance numbers. It will consist of two types of charts: Long-Term Support (“LTS”) and Active. The long-term support charts have several special caveats, but are intended to be available to help people better determine upgrade paths. The LTS charts are more likely to contain older CPU results.", "The page also includes links to CPU reviews and comparisons, such as historical AMD vs. Intel benchmarks. It will be updated on a slower cadence from our latest reviews (so you should always defer to those for the most recent numbers), but will be updated a few times a year with larger charts than are found in our reviews. This is for a few reasons, but one is that we shorten review charts due to video height limitations (16:9 aspect ratio). The other is that it’s just too crowded for the regular updates.", "This page is intended to be used long-term for our Mega Charts. You can bookmark this page, as our future updates for CPU Mega Charts will land at this same URL. The update log will be posted at the bottom of the page so that you always know the latest data set. It will be updated a couple times a year, with more frequency updates in the CPU reviews themselves.", "Steve Burke", "Patrick Lathan", "Mike Gaglione", "Even as data ages, it is often still relevant for comparison -- particularly for older CPUs which mostly stop receiving performance-affecting changes, such as microcode updates or Windows patches. We are constantly re-running our CPU tests to keep data fresh, but unfortunately, this refresh cycle means that it is difficult to stack more CPUs on the charts before some sort of major change comes in. For example, major Windows updates necessitate full re-tests for reviews, but may not be as important for someone who just wants to see their older CPU represented for a “good enough” gauge of where things fall.", "That’s why we split these into the LTS (Long-Term Support) and Active charts. It allows us to maintain one older dataset that has more CPUs represented, at the cost of reduced insights gained from our most modern test methods. Active gives you that for more of a modern head-to-head. It’s the difference between precision (Active) and quantity of CPUs (LTS). This is the best balance that a small team can produce, especially since we provide this website completely ad-free (you can support us ", " or by buying something useful for your PC builds on ", ").", "The below is a simple list of CPUs that, at the time of writing (dated in the columns below), we think make sense ", "would make sense with caveats noted.", "Pay careful attention to the second column. We may only recommend some parts under certain pricing conditions. ", "They come down pretty regularly, especially with launch cycles. For instance, when we first posted this, the 7800X3D was about $250 overpriced. It's still on the list so that people are aware of it, but we advise waiting for it to approach that MSRP marker or to be replaced with the pending 9000X3D parts.", "For a ", ", please check our ", ". We will update for 2024 also.", "We frequently receive questions from people asking where their particular CPU would land on a chart. There are thousands of CPUs that could be tested, so we obviously don’t have all of those listed. The best bet is to approximate the positioning by just thinking through the data that is present and using deductive reasoning. Newer builders may not realize that it is often this simple, so we’ll outline some concepts so that you can at least get a rough idea of where your part might fall. You can apply this to any reviewer’s charts. And of course, if we’re missing a part, there are plenty of qualified reviewers out there who may have something we’re missing (and we likewise try to cover what they miss) -- that’s the value of multiple qualified reviewers.", "Example 1: The Ryzen 5 1600AF is not present on the charts.", "Solution: The Ryzen 5 1600AF is functionally an R5 2600, just at slightly different clocks. Looking up original reviews would get you this information, which you can then apply to modern charts. Looking at the R5 2600 in a chart is close enough to the R5 1600AF that you could base your decisions off of that part.", "Example 2: The Ryzen 5 2600 is also missing from the charts.", "Solution: Pull up a few old/original reviews of the R5 2600 and identify parts that are nearby or adjacent in performance. Look at a few charts, as some games can differ. Once you have found the most commonly comparable part, you can use that as a rough gauge on charts.", "Example 3: The i7-10700K is missing from the charts.", "Solution: If the i5-10600K and i9-10900K are present, it’s reasonable to assume that the 10700K is between them. Although this can have a relatively wide range, the reality is that, especially upgrading from something older, it won’t matter enough to hurt decision making on new processor purchases (since anything will be a huge upgrade).", "Example 4: The Sandy Bridge i7-2600K is present, but not the i7-2700K", "Solution: In situations such as these, where the part is basically just a slight change (example: 2700X vs. 2700, 2600X vs. 2600, 7700X vs 7700), you can just look at the one that is present and assume close enough performance to compare. This is again where it’s important to keep perspective: If the goal is to upgrade, being 2-5% off on the estimate isn’t going to meaningfully impact decisions if the alternative is no good modern data as reviewers move on.", "As a last-ditch solution: You can look at games or benchmarks which are least likely suspected to have had major patches, such as GTA V, and calculate the percent difference between the target part and mutually present part on both an older chart and the new one. Then apply this to the modern chart to approximate or interpolate the rank. For example, if you pull up a chart from two years ago with the 8700K and 12700K on it and calculate the difference (typically, (new - old) / old), you can then apply that on the same game chart from modern times. ", "because newer games may have architecturally evolved and may not be linear and older games get patches. You’d frankly be better off finding it somewhere else on the internet, but if you really can’t, this is a method that helps get at least something to work with.", "For standalone reviews that receive full video treatment, we run through a quality control process that is intensive and often takes several days to complete. These are time-intensive, cost-intensive, and critical to the accuracy of our mainline reviews. We would never skip steps for the fully produced reviews.", "But we want to publish more of the data we collect outside of the reviews process because it’d help people with purchasing decisions. We have been resistant to publishing the extra data because the ‘extra’ data doesn’t go through the same validation processes. It’s still useful and rarely has issues; however, our QC standards are high and we are careful with what we release. Anything we’re uncertain of or haven’t vetted fully is withheld until it clears those bars. ", "But a lot of people would benefit from knowing where an AMD R7 1700 lands today, and ", ", we don’t have a good avenue to release data that is useful, likely up to our usual standards, but just not quadruple-checked. That’s what the Long-Term Support (LTS) charts are for. ", "We’ve decided to release the extra data to try and cast a wide net to help people upgrading from older or more obscure parts, but are doing so with the upfront disclosure that the difference between the Active charts and the LTS charts is the validation process. In other words, data which exists on LTS charts but not Active charts should be understood by the audience as more likely to have some sort of data confidence issue or possible deviation from expected results. It is still ", ", but ", "charts. With that transparency and understanding, here’s the difference in our processes:", "One of our biggest hangups for publishing a full list of our “Mega Charts” for CPUs has been that we simply cannot sustain the intensive QC process for a secondary dataset that contains CPUs that haven’t been published on the channel recently. We often still collect data for older CPUs, but may not publish it for time reasons (meaning that it was collected for internal review, but not fully vetted for publication). ", "Here’s the full process, with some specialty confidential steps removed:", "You’ll notice that a big part of the process is passing the results through multiple team members -- typically 4-5 people look at it before publishing. This is ", ", but important. ", "The Long-Term Support charts will contain data which is not in reviews, but was used as internal gauges for where parts should sensically land. As a result, this is the process it has followed since it has not previously been published:", "This allows the team to continue work on important next reviews without forcing us to skip more important upcoming projects, but still allows us to get helpful data out. You’ll notice that this approach cuts at least 2 potential internal reviewers from the process, including reducing the amount of times the SME looks over the data, and reduces the review of every single data point down to ad-hoc glances to see if anything “jumps out” as obviously bad.", "If you see anything that looks out of order, you are welcome to email us at team at gamersnexus dot net.", "We are hopeful that this will allow us to publish more data to help people make upgrade decisions, with a middle-ground understanding going into it as to the limitations of the process.", "With all the helpful information on how to use these charts and the disclosures out of the way, let’s continue to the data set.", "Zen 5 Review Cycle (pre-Arrow Lake)", "The below CPU charts are those found from our long-term support list. These will be updated only a few times a year, but contain the most data for some of the older CPUs.", "This section contains the “production” benchmarks for workstation, creation, and development applications.", "The above chart ranks CPU 3D rendering performance in Blender by best to worst (faster, or lower time, is better). This should help you identify the best CPUs for rendering in 2024; however, GPUs are heavily relied upon and would be a separate benchmark.", "The above charts contain our tests for 7-Zip file compression and decompression. If you frequently work with compressing and decompressing data, such as for large file transfers in compressed formats or for certain game loading tasks, these will give an idea for performance.", "This chart uses the Puget Suite to benchmark Adobe Premiere for video editing and rendering tasks, focusing on CPU performance. Adobe Premiere cares both about the CPU and the GPU, and relies upon a strong combination (rather than biasing toward one component, like 3D rendering might do) for reduced scrubbing or playback ‘lag’ and improved rendering and encode performance.", "This chart is for Adobe Photoshop and compares some of the best CPUs currently out for Photoshop. Testing is done with the Puget Suite and includes warps, transforms, scales, filters, and file manipulation.", "This chart looks at a Chromium code compile. It’s a CPU benchmark for programmers and developers, with the caveat that (like any of these tests), we can’t realistically represent all compile scenarios. Because we try to represent a wide range of possible use cases, we don’t cater too much to any one specialty. This should give you an idea for at least how this specific compile behaves. If your workloads resemble this, you may be able to assume some level of linearity.", "Even if your specific game isn’t represented here, the best way to use our charts for determining CPU differences is to look at the relative ranking across a number of games. Our intent with this approach is that you can determine the best-value upgrade (our reviews are very value-oriented) by comparing the typical or average gap between two parts.", "In most scenarios, the CPUs will scale similarly from game-to-game, barring any unique behaviors of a particular game. If CPU A is better value in Game A, B, and C, it is very likely also better value in Game D (though not always). ", "For individual per-game benchmarks, we’d recommend our ", " that deep-dives on new releases whenever we get a chance.", "This is for Dragon’s Dogma 2, which is one of the newest games in our CPU test suite. Dragon’s Dogma 2 is still getting regular updates, so the CPUs shown on this chart were all run on the same game version. The game remains CPU-heavy in the cities with dense NPC populations, which is where we test. We published a separate deep-dive benchmark of ", ".", "This chart evaluates simulation time in Stellaris using a late game save file. The number is represented in time, with lower being better. Faster simulation (shorter time required) is noticeable in 4X or Grand Campaign / Grand Strategy games where AI turn processing requires significant CPU effort. ", "Baldur’s Gate 3 is tested at 1080p/Medium in the above chart, which allows us to see CPU scaling all the way up to the top of the stack for the best gaming CPUs.", "We test in Act III in the city itself, near a market with a lot of NPCs.", "This chart gallery is for F1 24 and includes both 1080p and 1440p results. Typically, in scenarios which remain primarily CPU-bound, we see roughly the same hierarchical lineup across both resolutions. The top of the chart truncates maximum FPS, which means that CPUs which occasionally bounce off of the GPU bottleneck will be less reliable to differentiate from one another (as they are externally bound).", "This set of 1080p & 1440p charts is for Final Fantasy XIV: Dawntrail, tested at Maximum quality settings.", "Rainbow Six Siege is a problematic benchmark as it updates frequently, causing entire wipes of our dataset. This is a list of results that were all run on the same game version. Unfortunately, we don’t have as much data for it as a result of the regular wipeout.", "This chart is for Bethesda’s Starfield at 1080p/Low. Despite the game’s memeable launch, it remains a useful benchmark for CPU performance comparisons.", "This gives us a look at a Grand Strategy / Grand Campaign Total War game, which tend to be CPU heavy. We’re using a battle for the benchmark.", "The below list of charts is our most heavily-vetted, most recently-published data set. Due to maintenance overhead and our focus on new content, we won’t updated it after every single review, but we will update this upload after major review cycles are fully complete. For example, if both AMD and Intel are launching CPUs across a 2-3 month spread, we’ll update this list at the end when we can breathe again.", "These will lack some of the data found on the LTS charts; however, they may contain more recent data (such as newer CPUs).", "There may be discrepancies between the LTS and Active charts. They are not necessarily comparable, and often are not. This is for reasons such as Windows version differences, game updates, and test platform changes.", "Rather than individually break them out into headings like above, we’ll just dump all the production charts below:", "And the same for gaming. You can find each game at the top of the chart:", "This table includes a simplified list of all CPUs on these charts, including links to the original GN reviews where present. Be advised that CPUs often have several follow-up pieces of content in rapid succession as the landscape changes. To keep things simple, we’ll just link the original reviews. You can still find the follow-ups on ", ".", "The below is an update log of changes to this page. The format is MM/DD/YYYY:", "Update process / house cleaning (externally visible, but used internally):"]},
{"title": " Intel's 300W Core i9-14900K: CPU Review, Benchmarks, Gaming, & Power", "paragraph": ["Intel's 300W Core i9-14900K: CPU Review, Benchmarks, Gaming, & Power", "Last Updated: ", "The Highlights", "The brilliance of Intel’s 14th “Gen” is limited only by its ability to ", ". If Intel just believes that incrementing from 13 to 14 makes the CPU more than 1.8% better, then it can be true.", "We were disappointed by the ", " in our ", " -- which went a little off the rails, but that’s the trade for spending a week on a product like this -- and now we’re back to try our luck with the ", "--err, ", ". This thing pulls a ton of power (just like the ", "), but now runs at 6GHz. That’s exactly the number that marketing needed to shove on a box and call this new, so we’re looking forward to it.", "The Intel 14900K is shipping for around $600-$625, depending on where and when you buy it.", "The 14900K at $600 most directly competes with the 13900K at $550 from Intel. AMD’s strongest gaming competitor is the ", " (find the ", "), which has been around $350-$400 all week. The strongest production competitor from AMD is the ", " (find ", "), commonly priced under $600. The ", " is around $425-$450 right now, depending on ", ".", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Patrick Lathan", "While we occasionally call Intel’s 14th series CPUs 14th gen, this isn’t really a new generation as it’s the same architecture and isn’t deserving of a new generational number. Unfortunately, Intel has misbranded this in a way where it will lead people to expect more than what they're getting.", "Testing today will consist of the following types of benchmarks:", "Let’s start with thermals. A quick reminder here: The temperature that comes out of a datalog for a CPU is not like a synthetic benchmark score. It’s going to change -- a lot -- and that’s entirely based on the motherboard and the cooler, plus the workload used for testing.", "In our tests, we use Blender rendering for a realistic and heavy daily use case. We also test with a 360mm ", " (find ", ") at 100% fan and pump speeds (you can find our acoustic and other thermal data in our cooler reviews for that). Finally, other than controlling the board to not blast MCE or something, we basically let it do its thing with regard to voltages. That’s because we’re testing an out-of-the-box state (we'd control these voltages if doing a ", "). This means that boards which are less controlled and push higher voltages, sometimes out of laziness to guarantee stability, will perform far worse than boards which are more tuned. We don’t try to pick one or the other - we just use whatever platform makes sense for the test or is sent by the company. In this case, the ", " served as the test platform for the 14900K.", "Here’s the chart -- first with just the 14900K bars. Logging every core at steady state and tested in a 21C environment, we ended up with temperatures that were shockingly consistent core-to-core. This is a lot better than we’ve seen in the past -- that much is typically the assembly quality and how the IHS is attached to the silicon. Our peak-to-peak delta for P Cores is around 4 degrees. We’re in the 70s with a ", " in a 100% core workload. It’s at least mostly under control. In gaming scenarios, this would be lower. We’ve seen others have been in the 90s, and depending on the cooler they used and the motherboard, that’s completely possible. The Dark Hero is logging via software as having a 1.172VCore. If that is to be trusted, that’d be low enough to explain the thermals. But sometimes this number isn’t an accurate representation.", "Looking at some other temperatures, ", " ran higher overall in this workload despite being in the same board and under the same cooler. Some of this might just be the STIM quality and lid attachment by Intel. It’s not an unreasonable swing.", "These can definitely be way worse with a BIOS that blasts voltage. One thing’s clear though: You really should be running a high-end liquid cooler if not planning to undervolt and if you want to run it under Intel guidance with heavy workloads.", "This testing will look at the power consumption as measured at the EPS12V cables.", "Given our years of data we’ve collected on CPUs with the same methods, we can provide some interesting perspective with a look-back at all the i9 CPUs we’ve tested recently. Remember that the i7 existed as the top-end before this, but we have those numbers in our ", ".", "Here’s the i9 chart. ", "’s 287W is close to the highest we’ve tested, and aside from ", ", it is the highest stock draw we’ve tested. The 13900K isn’t far off, though -- they’re about the same. Dating back to the original Intel i9 desktop CPU, the i9-9900K, power consumption was as low as 94W all-core. The 11900K was 127W, about the same as the 10900K. The Intel HEDT CPUs -- like the 10900X and 10980XE -- pushed closer to 200W. That the 10980XE was lower power consumption than the 14900K is crazy considering how it was received at the time. We see a generational climb with the 12900K going to 244W, then 275W with the KS SKU. ", "There’s a clear trendline here.", "Here’s a look at more comparative power numbers: We measured the 14900K at 287W at the EPS12V cables -- meaning just the CPU and VRM efficiency losses -- when tested under an all-core Blender workload. That has it about the same as our 13900K, which was 295W previously. The 14700K’s 284W is about the same. ", " maxes-out at 86W all-core (although, to be fair, Intel won’t be at 100% CPU load in games like it is here -- but AMD is still advantaged). ", " CPU pulls 251W without Eco Mode, also below Intel’s 14900K.", "This is a power-hungry CPU, and they’re only going to get harder to cool if Intel keeps going this direction. Overclocking also becomes more challenging -- although maybe in a new way -- in that it’s the cooling that begins to hit diminishing abilities to tame this power draw. Undervolting makes way more sense, and Intel boards traditionally have ", ", so there’s room for improvement.", "Energy efficiency testing will help us understand what all of this really means. For this number, we’re calculating the energy consumption during a Blender workload. Our metric is watt-hours, which allows us to see how much energy consumption there is for a CPU to complete the same workload. That means we’re normalizing for the workload, not the time. Lower is better.", " is towards the bottom-end of the chart. It’s more efficient than the 13900K, 14700K, 12900K, and 13700K -- and AMD’s 5800X, barely -- but it’s far below top performers like the 5950X and 7950X. It’s not the least efficient we’ve tested, but Intel is pushing its thermal envelope and power draw higher and higher.", "Blender is up next. Because this spawns one render tile per thread on the CPU, it scales well with higher thread-count processors.", "The 14900K required 7.3 minutes to complete the render, which has it dead equal to the 13900K.", "This has the 7950X and its 6.4-minute result ahead of the 14900K with a 12% time reduction. Against the 7900X, Intel’s lead is 15%, and against its own 14700K, it leads by 8.8% time reduced.", "In 7-Zip file compression testing, ", " completed 191K MIPS, or millions of instructions per second. That has it about tied with ", " and ahead of the 13900K by -- get ready for it -- 0.6%. So again, we’re basically re-reviewing the 13900K. Against the 14700K, that’s an 11% improvement -- if you can call total and utter stagnation an improvement.", "In decompression, it’s a little bit better at least -- the 14900K improves over the 13900K by 4% here. That has it behind the 7950X, not too distant from the 5950X, and leading the 14700K by 23%. ", "Adobe Premiere benchmarking via the Puget Suite is up now. This one has the 14900K at 842 points, leading the 13900K by 1.7%. So nearly margin of error, basically. Marvels like this are what Intel will be remembered for.", "When the improvement is so large that we need a decimal place just to illustrate that it’s not within test variance, that’s when you know it’s a good generational uplift. In fact, it’s so exciting that we’re not even going to talk about any other production tests.", "Time to move on to games. We were just so blown away by the production tests that we needed to take a break from reading through those charts -- it nearly brought us to tears just how much better this CPU is. ", "In Rainbow Six Siege at 1080p, the 14900K ran at 656FPS AVG. That has it ahead of the 13900K by 1.65840049597024%, a world-record for length of a percentage number in a GamersNexus review. Remarkable.", "The positioning has it just ahead of ", " -- so Intel gets its wish. It is now ", "ahead of the last-gen AMD X3D CPU. The 7000 series still leads, but it’s the small steps that count. Like beating something based on an architecture from years ago.", "Against the 14700K, the 14900K is also under a 2% benefit.", "At 1440p, it’s even more riveting. The 14900K leads the 13900K by 0.2 FPS AVG. As you all know, Rainbow Six is a highly competitive game -- so that 0.2 FPS matters. We should give some perspective here. The extra 0.2 FPS AVG means your average frametime is shorter by 0.0008ms.  ", "In F1 2023, the 14900K measured at 422FPS AVG, ahead of the 13900K by 1.1%. The difference genuinely is impressively tiny. If you’re picking between this and the 14700K, you’d be looking at about a 3.7% improvement moving to the i9. ", "Intel is struggling to meet AMD’s 5800X3D’s performance, which sits 7% ahead of the new i9. ", " is 21% ahead.", "At 1440p, we get the usual reduction of scaling as a result of imposing a GPU limitation at the top-end of the stack so let’s move forward.", "Baldur’s Gate 3 is up now. In this one, we again see the X3D CPUs soaring to the top of the charts. The 14900K landed at 110FPS AVG, gracing us with a 2.2% uplift over the 13900K while allowing the 7800X3D a lead of 10.4%. The 5800X3D isn’t far behind Intel and ends up about tied with the 14700K.", "1440p, predictably, is the same. We’re CPU-bound even at this higher resolution in this title, so the 14900K’s positioning remains largely unchanged.", "In Phantom Liberty at 1080p, the 14900K’s 168FPS AVG result had it ahead of the 13900K by 3.2%. The 14700K and 13700K are within run-to-run variance of each other, as we mentioned last round. All the Intel CPUs are getting clustered around the same spot. The 7800X3D, 5800X3D, and 7700X remain stronger options in this one. You can learn more about the other data and the testing for this one in our ", ". We’ll skip 1440p since it’s more of the same.", "Final Fantasy gives Intel some hope -- it tends to do well in this game.", "The 14900K is now formally the chart leader in FFXIV. They’ve done it. Intel wins -- we’ll stop here. Review over. The headline is now clear: Intel i9-14900K is the new king.", "With a crushing 3.05% lead over the 13900K, and a likewise mind-bending 5.47% lead over the 14700K, this battle has been decided.", "But, to be fair, this is a title where you’d want to favor Intel if you expect to be CPU-bound. The lead is a meaningful 23% over the 7800X3D for the 14900K.", "The 1440p scaling for this game is about the same. The framerate has marginally changed, but we’re still CPU-bound and they still stack-up largely the same way.", "Stellaris is up now, measuring simulation time instead of FPS. We mentioned this in our 14700K review, but the game isn’t scaling much once we’re at around 30 seconds for simulation time. They’re all jumbling up to look the same due to other limitations. In our 14700K review, we asked those of you who are serious players to email your most complex, late game save file to our ", " inbox so we can see if we can find more scaling in the game for the next round.", "In this one, there’s no difference -- but for once, it’s not the fault of Intel’s so-called-14th-so-called-gen, it’s just that we’re bound elsewhere. It might be hard to tell 0% generational scaling from 0% test scaling but it’s just 0% test scaling. ", "Starfield is another one that shows scaling for Intel -- sort of. Or at least, Intel has managed to wedge itself at the top of the chart to supplant the pesky X3D CPUs.", "The 14900K’s 132FPS AVG has it 2.8% ahead of the 13900K, with the 14700K not meaningfully far behind. You’d never notice the difference between 126FPS and 132FPS, so selecting between them isn’t that important. The lead over the 7800X3D is at least more meaningful, at 15% improved.", "Scaling is similar at 1080p/High, with a lower FPS due to a heavier workload. But overall, the lineup is mostly unchanged.", "The ", " is disappointing. There’s very little change in stock performance and it isn’t deserving of a new generational number. This whole CPU series feels like grasping at straws. If you already had your eyes set on the ", ", between it and the 14900K, you should just buy whatever CPU is cheaper.", "On AMD’s side of the fence, the ", " deserves the most attention in gaming, though the ", " still warrants attention if you’re on AM4. On the production side, you should look at the ", " and maybe the ", ".", "Update: We've since published our ", " to help with your choices."]},
{"title": " AMD Ryzen 7 2700X in 2023: Benchmarks vs. 5800X3D, 7800X3D, & CPU Upgrades", "paragraph": ["AMD Ryzen 7 2700X in 2023: Benchmarks vs. 5800X3D, 7800X3D, & CPU Upgrades", "Last Updated: ", "The Highlights", "Today we’re revisiting the ", " CPUs. These came out in 2018 and are now over 5 years old. Original launch prices ranged from $300 to $330, with the 2700 often available for around $200-$250 towards the end of its lifecycle. It was one of the most popular CPUs of its time and struck a strong balance with multithreaded application performance, particularly CPU-side streaming (as we showed in our original game + streaming benchmarks from the review). They competed most directly with Intel’s ", " that launched later in 2018, or the ", " before that.", "This content will show how the older AMD Zen 2000-series parts aged, but also what the best CPU upgrade options are for a similar build today.", "Steve Burke", "Vitalii Makhnovets", "Mike Gaglione", "Jimmy Thang", "If you’re in the market for a new build, it’s hopefully at least partly because you just want the fun of building a computer. We’ll cover some of the modern replacements to show you the potential uplift as well. Let’s get started.", "As a reminder, the R7 2700 and 2700X CPUs were from the earlier days of Ryzen when AMD was still selling the letter “X” for an upcharge. At that time, you could basically buy a non-X CPU and do a 5-minute overclock with experience, or maybe 1-2 hours without any, and save the money while getting X-class performance. The 2700X in our charts today helps to represent the OC performance potential, so remember that this is another avenue to get another small bump out of your CPU without spending money (other than electricity cost). These are 8C/16T CPUs that had a maximum ", ", or advertised up to ", ". The common all-core overclock was around 4.0 to 4.1GHz at the time.", "In 2018, we never would have expected ", " (find the ", ") to come out and offer the performance uplift it did. Vertically stacked V-cache is a relatively new innovation stuck to a newer generation of architecture, but retaining AM4 socket compatibility. It’s also still sold. We’ll mostly focus on that today.", "Finally, there were recently rumors of other X3D parts coming out soon -- it’s too soon to know if those are true, but this discussion might come back up if they are. The relevant rumor is of an alleged 5700X3D SKU.", "Before really getting into it, we’re going to give some quick pricing updates based on Newegg and Amazon US pricing. These are just from quick searches for parts that will be relevant during this review. We’re splitting attention between new and in-socket upgrade parts. We also included a couple sub-$200 options that we commonly found on the used market. The table below is just designed to get those of you who haven’t paid close attention for a few years up to speed quickly. It doesn’t have every CPU that’s out, but focuses on some of the main ones today.", "This table isn’t that advanced and you could obviously add plenty more CPUs to it. Our goal is to isolate the ones we think might be most interesting. We’re assuming someone who bought an R7 2700 is looking to spend a similar amount today.", "The 2700 and 2700X were around $300-$330 at launch. At the same price today, you could get an ", " -- which we already know is a gaming champion -- so that’ll be high on our list today. You could also get an ", ". It’s a CPU that's focused on non-gaming loads, like heavily multithreaded tasks, and is mostly worth considering if you're desperate to keep an AM4 machine alive while maximizing heavier non-gaming processing. Its biggest downside is that it costs noticeably more than the 5800X3D, at around $463. Newer CPUs give this stiff competition since its pricing is in a higher bracket than the 2700X was originally.", "Another option might be the ", ". It doesn’t have the extra cache. It also saves you some money retailing for around $200-$205 now, but loses a lot in gaming advantage. But you’d still get an uplift. The ", " won’t be in our charts today. It is very similar to 5800X performance and a bit cheaper. From a charting standpoint, the 5800X and 5700X are interchangeable. If you’re OK with used, then the ", " is a smaller upgrade for $90-$100, with the 5800X used for around $150 on eBay.", "New builds would require a much larger investment as you’ll need a new motherboard and likely new RAM. The same-priced CPU options would be the ", " and ", ", with the ", " in a higher price class by pure launch MSRP-to-MSRP comparison, but also a significantly higher performance class.", "We listed some other options too just to get you up to speed on the market quickly.", "There are a ton of CPUs out there right now, but these are the ones you’ll find most important on our charts today.", "We’ll start with gaming benchmarks, then move to production and power -- and the power efficiency changes over the years have been wild, so that’ll be an interesting chart.", "Baldur’s Gate 3 is a new game that ends up being CPU loaded in most scenarios. With its 2023 launch date, it’s 5 years newer than the R7 2700 CPU. We’ll look at CPU numbers here, but you can check our full video on ", " if you need that angle.", "In this one, the R7 2700 ran at 51 FPS AVG and held lows proportional to the rest of the average-to-low spacing. For a lot of people, this framerate is probably fine in Baldur’s Gate -- but the venerable 2700 is finally showing its age in big ways. It’s getting into borderline territory. The 2700X would offer about a 10% uplift for an in-socket upgrade, or you could just spend an hour overclocking your 2700 to the same performance levels. We think that’d be worth it to pull another 10% out of the CPU.", "If you went and bought a 3700X for about $100 on eBay, you’d get a boost to 60FPS AVG, or a 17% increase over the 2700 and 6.6% over the 2700X. We haven’t ", ", but ", " is similar in performance as a reference point: That’d get you a massive 50% uplift from the R7 2700 at 77FPS AVG, with lows also pulling up strongly. For $185-$200 in the 5700X and 5800X class CPUs, that’d be a strong, single-item purchase for a drop-in upgrade. But ", " remains the strongest: This one ran at 106FPS AVG, or basically a doubling of the 2700 and 2700X. It’s still available for $322 at the time of this story. There’s the ", " also, but the 5800X3D would be the best you can get in a gaming CPU for AM4.", "If you wanted a brand new system for one reason or another, AMD’s same-price modern replacement for your MSRP $300-$330 2700 series CPUs would be the ", ". That one’s at 90FPS AVG. It’ll have benefits elsewhere, like production applications later, but it’s not better than the 5800X3D for a pure gaming user. You’d save a lot of money sticking with one more run of AM4. A worthwhile, next-gen upgrade would have to come in the form of an Intel ", ", ", ", or ", ", all of which will have more benefits in production than gaming. The ", " might make the most sense for its bigger jump, but at $100 higher than your original 2700 purchase price.", "This one will be short. At 1440p, we’re still seeing full scaling. Increasing the GPU load isn’t affecting the results. It would in other games and at high settings, but it’s likely your 2000-series CPU is limiting performance of new GPUs even in higher GPU load scenarios.", "Cyberpunk: 2077 - Phantom Liberty is up now. This is another game that’s effectively brand new and would be a possible driving reason for an upgrade for 2000-series owners. Features like Ray Reconstruction and RT overdrive might make this more of a GPU-focused upgrade, but the CPU still scales a lot in this one. You can learn about Ray Reconstruction in our ", " or in ", ".", "At 1080p/Medium, the R7 2700 ran at 88FPS AVG and held lows at 60 and 46 -- that’s respectable, and actually still perfectly playable. The R7 2700X keeps a 9.5% lead, so again, an overclock on the non-X would get you at least about 10%. ", "If you wanted an in-socket upgrade to the best option, ", " would give a massive 100FPS jump. It’s actually insane that these two CPUs were tested in the exact same motherboard with the same RAM. We hope AMD will keep doing this, because even though it’ll make board partners less money, it’s certainly a lot less wasteful and it’s better for consumers. That’s a 111% uplift.", "Cheaper in-socket upgrades might include a used 3700X. That’d get you 27%. The lows scale comparably there. Another could be the 5800X or 5700X. The 5800X would offer about a 63% improvement.", "For totally new platforms, ", " offers the most at 200FPS AVG, or 130% improvement. Everything else is below the 5800X3D, but will offer benefits in workstation workloads. The 14600K, 7700X, and 14700K deserve highlights as parts to consider if doing more than gaming.", "1440p provides similar results, but with a truncated ceiling at 190FPS AVG due to an encroaching GPU bind. Let’s move forward.", "Starfield is up next. This is another brand new game, so we have a lot of new titles in this bench suite for your upgrade considerations. We recently ran standalone ", " and ", " on Starfield (and we’ve published a ", ", too), so you can get the full research from those.", "Here’s the 1080p/low chart. The 2700 ran at 51.5 FPS AVG when CPU-bound in Starfield, so that’s another lower FPS number that can prove actually relevant if considering an upgrade. Strapping an “X” to the CPU gave it a 9% boost. In rapid order, the likely upgrade options might include: A 3700X at 70FPS AVG, or 35% ahead of the 2700. The 5800X at 79FPS AVG, or 54% ahead of the 2700. The 5800X3D at a significantly higher 93FPS AVG, or 81% ahead of the 2700 and 67% ahead of the 2700X. The 5800X and 5800X3D would offer a noticeable improvement in frametime consistency when looking at the lows.", "New CPU upgrades could include the 7700X, which, in this game, is actually doing technically better than the 5800X3D at 100FPS AVG. The 7800X3D runs at less than half the frametime on average, or more than double the framerate, as compared to the 2700 series. That’s a big jump as well. Intel’s 14700K or 13700K would be the alternatives, providing close to the most you can get out of a CPU in this game.", "F1 2023 is up next.", "The framerate ceiling is obscene here: At 511FPS AVG for the 7800X3D, this serves almost more as a synthetic benchmark of scaling at this point. The 2700’s 177FPS result is perfectly fine from a gameplay standpoint. From a relative scaling standpoint, the 2700X at 192FPS AVG would provide a lessened 8% uplift (again, the same as the average OC on the 2700). The 3700X would give 31% over the 2700, or 21% over the 2700X.", "The 5800X3D offers a staggering 154% uplift over the 2700, or 136% over the X-SKU. If you wanted the modern I/O capabilities of a new platform, the 7800X3D would boost that to a max of 188% against the 2700. The 7700X comes in lower than the 5800X3D again, but would get you to a new platform while still providing 130% improvement. The 14700K is about the same uplift at 407FPS AVG, with similar benefits of a modern platform for those who know they need them.", "At 1440p, the top-end shrinks to a maximum 400FPS average. Scaling shrinks with that, demonstrating that GPU bottlenecks will always lessen the impact of a CPU improvement. Even still, the 2700 and 2700X are old enough that you’d still see improvement in many scenarios.", "FFXIV is up now. The game has been around for a while now, but remains one of the most popular MMORPGs currently getting played. Also, as far as an MMO goes, it has a relatively high load on modern parts.", "Here’s the chart. FFXIV’s benchmark test is interesting mostly because it has favored Intel’s CPUs for a long time now. The 7800X3D and the 12900K mark the start and end of compartmentalized AMD and Intel sections, with Intel holding a generally strong advantage. We think some of this is due to GPU driver behavior as well.", "The 2700X leads the 2700 by 11%. The 3700X would boost over the X and non-X by 6.7% and 19%, respectively. The 5800X offers a big in-socket improvement at 46% over the 2700, or 31% against the 2700X. Back to the king -- the 5800X3D -- that’d give a lesser-than-prior but still noteworthy improvement of 71% against the 2700. AM5 as a new platform would limit your gains to about the same as the 5800X3D here, but Intel would give significant advantages: The 14900K establishes a ceiling of 113% improvement over the 2700, with the 14700K at 100% better. The 14600K is similarly boosted.", "At 1440p, the lineup is similar. There’s nothing new here: The CPU limitation is still the main one, even with max graphics at 1440p. Let’s move forward.", "Revisiting the Ryzen 7 2700 and 2700X in Rainbow Six Siege for 2023, we saw the 2700 at 295FPS AVG and 2700X 8.2% ahead at 320FPS AVG. Here’s a rapid fire list of improvement options in-socket:", "The 3700X would offer 26% over the 2700, or 17% over the 2700X. The 5800X would provide a large boost of 87% to 552FPS AVG from the R7 2700. The 5800X3D would give a 120% uplift over the 2700, or 103% over the X. The 5800X3D is so comically far ahead that its 0.1% lows are higher than the average of the 2700X -- that’s insane , and illustrates exactly why X3D is such a good upgrade.", "Out-of-socket upgrades include the 7700X at 640FPS AVG, or still a doubling and some over the 2700 series CPUs, and the 7800X3D at a ludicrous 717FPS AVG. Intel didn’t even punch this high with APO in our recent tests. The 14700K would be another likely new platform option, running at about the 5800X3D’s performance but with newer platforms and modernized I/O.", "Stellaris CPU simulation time is next. This one bottlenecks hard at the top-end of performance, where everything from about the 14600K and up can be considered the same. ", "The 2700 and 2700X show huge room for improvement, though: At 57 seconds and 65 seconds, you’d absolutely notice a halving of the simulation time by moving to a newer CPU. This isn’t just framerate, but a noticeable amount of physical, real time.", "The 5800X3D would provide a cut of 48% time required from the 2700. It holds an advantage over the 5800X non-3D as well, despite a lack of similar scaling at the top-end of the chart. The 7700X and 14600K would be new platform alternatives worth considering.", "Now we’re moving to the production benchmarks. This section will go fast, but it’ll give us some insight as to the performance in more core-heavy applications. The 5800X3D won’t be as promising here, as the extra cache rarely shows as much improvement in the workstation applications we currently test. Let’s take a look.", "Blender rendering is up first, using the tile-based renderer to fully load all threads available. ", "The R7 2700 required 27 minutes to render a single frame of the GN Logo. The best result here is the 7950X, which reduced the time required by 76%. In other words, in this test, you could render 4.2 frames on the 7950X for every 1 frame you render on the 2700. That’s a huge improvement.", "The 2700X was 12% time reduced, with the 3700X reducing the time requirement by 28% over the 2700 and less over the X. The 5800X3D doesn’t see benefit here from V-cache. If you went with a 5900X or 5950X as an in-socket upgrade for more production-focused builds, you could get maximally a 63% reduction in time per render. That’s great for users who do less gaming and more of this kind of work.", "New builds would offer a 70% time cut with the 14700K at 8 minutes as compared to the 2700.", "Next is compression testing using 7-Zip. This would be useful if you do a lot of file compression.", "The 2700 completed 56,000 MIPS, or millions of instructions per second. The 2700X was 11% faster, with the 5800X offering a 68% improvement over the 2700. Going up to a 5950X in the same socket would offer a 148% faster compression time over the 2700. A new platform would need movement to a 7900X or 14700K to get meaningfully above the 5950X, unless you just need other features of new boards. The 7950X leads this chart, at 193K MIPS.", "Decompression shuffles the stack a little bit. The 2700 and 2700X run at 77K and 89K MIPS, respectively. It’d be worth overclocking the 2700 for this kind of performance if you plan on staying with it. The 7700X would offer a significant improvement for a new platform, although the 5950X runs impressively far ahead for its age -- and again, it ran in the same motherboard as our 2700. The best new Intel option here would be the 14900K, but it’s priced in a different bracket. The 14700K and 14600K are hard to get excited about as compared to the 5950X or 5900X.", "Adobe Premiere CPU benchmarking with the Puget suite has the 2700 at 454 points in aggregate, tied with the 3600 and giving the 2700X its standard 9% advantage. The 5800X gives a 33.7% improvement in the same socket, with the 5950X a bit above that. For a new build, the 7700X would get you 62% better performance than the 2700, offering a meaningful improvement for Premiere users. It’s not shown in this chart, but the biggest point of improvement was in intraframe and RAW performance.", "On the Intel side, the 14600K would give a 65% uplift, with the 13700K and 14700K at 76% and 81% better.", "Finally, in Adobe Photoshop, the chart leaders in the 1500 to 1600 range show scaling room approaching 2x improvements. Extra cache isn’t helping in Photoshop, but the 7700X at 1569 points sees its biggest contribution in the filter score and GPU score, where the GPU can be better leveraged. Almost anything would be an upgrade here -- other than maybe the R5 3600.", "For power consumption, the R7 2700 pulled about 76W in an all-core workload. Our overclock was a bit over-the-top back in the day, pushing it to 180W but improving performance notably. You could fine-tune this a little lower. The biggest improvement in modern CPUs though is the efficiency: Despite higher outright stock power consumption in something like a 7700X, at 148W, or 5800X3D at 108W, the output per Watt is much higher. CPUs in the 14-series are huge power consumers, especially the 14900K at 287W and 14700K at 284W.", "Finally, we’re looking at efficiency. This is judged using Blender render time against power consumed, with the unit of measurement as Watt-hours. In terms of energy efficiency, the 2700’s 33.9 Watt-hour result had it more efficient than a 14900K, but it’s obviously far less effective in performance. In other words, the 14900K will complete more work in much less time, but given a fixed unit of work, the 2700 will require slightly less energy doing it. The 7700X offers a notable efficiency uplift, at 31.1 Watt-hours. The 5950X remains one of the most efficient CPUs we’ve ever tested, thanks to its fine-tuned and low Vcore.", "For most people, as long as you don’t need that “all-new-stuff” itch, you can get a huge amount of punch out of a last-chance upgrade with the ", ". You probably won’t need a new motherboard (but check the BIOS support) and you won’t need new RAM. You could even keep your operating system. This would be the lowest-hassle upgrade possible. It’s likely your cooler would be fine, and a repaste is probably good for it. A new GPU would give the most possible “efficiency” in terms of performance per dollar, and that’d also be an easy change. An overclock might also be fun for giving another small bump, especially if hanging on to the 2700(X) a little longer.", "For anyone who’s less on the gaming side but heavy on the production side, it might be worth considering a used ", ".", "One reminder too: A lot of people who see decaying performance over the years are actually suffering more from operating system bloat than they are from the CPU itself. If you’re trying to save as much money as you can, doing a clean install might be a good intermediary step to see if you can revive some performance. It doesn’t always work, but users with a cluttered OS (especially driver bloat) can see benefit. ", "Ultimately, the 2700 and 2700X still work well in a lot of scenarios. Anyone more sensitive to framerate or things like render times would benefit from an upgrade, but these CPUs are far from obsolete. They still run most of these games well overall. ", "For those who just want the fun of building a fully new computer, the similarly priced modern options would be the ", " or ", ". Both offer large uplift in overall performance, but nothing compared to the ", " for gaming uses. ", " in particular is a strong part, posting the highest overall gaming performance right now. If it helps you cope and mentally justify it, the $300 you spent on a 2700 would be worth about $370 today, after inflation, so that’s basically a 7800X3D. Then again, maybe thinking about the loss of value makes it worse."]},
{"title": " Best CPUs of 2023 (Intel vs. AMD): Gaming, Video Editing, Budget, & Biggest Disappointment", "paragraph": ["Best CPUs of 2023 (Intel vs. AMD): Gaming, Video Editing, Budget, & Biggest Disappointment", "Last Updated: ", "The Highlights", "There are a ton of CPUs available right now, and we're looking at the best CPUs for 2023, and this year is particularly confusing. In some ways, it's a good problem because that means there are a lot of options. The difference, the past couple of years versus the many years prior, is that last generation parts remain abundant right now alongside new components. This creates kind of an odd schism down the stack where there's clear good options, but from a last generation. So, you're either buying into an end-of-life platform (hopefully you already own it, and you're just doing a drop-in upgrade) or buying into a new platform.", "We're going to be walking you through the best CPUs in multiple categories. We're looking at best overall, best gaming, best balance, best budget options, HEDT options, and a category we particularly like, which is most power-efficient. For that one we had to choose two CPUs because one of them is unattainably expensive.", "We just published ", " as well!", "Steve Burke", "Vitalii Makhnovets", "Jeremy Clayton", "Welcome back to our “Best of” roundup series. We do these at the end of every year, and there's a lot to catch up on. To set the expectation for this particular piece, and all the other “Best ofs” you'll see coming up, this is intended to get people up to speed as quickly as possible.", "We have run thousands of tests over the past year. Actually, if you count the individual test passes, we're in the many tens of thousands at this point. We've looked at dozens of parts, and it's hard for us to keep track of – we have to constantly reference the data. The purpose of these pieces is to both refresh ourselves on the data, and to get everybody who's been out of the market for a couple of years back up to speed quickly – or even if you followed it closely, just a reminder. A lot of people will build their system, check out for a few years, come back in, and wonder what happened. So that's what this is intended to help with: to resituate you.", "If you want the individual in-depth reviews for any of the components we're talking about today, you can find some of those as articles here on the site, or definitely in video form on the GamersNexus YouTube channel. We will be including some charts to reinforce a couple of key points that we think are important, even if you're maybe not as much of an enthusiast user, but if you want all of the charts, you can go back and check through the individual reviews. We'll also have links to the processors on Amazon or Newegg. The point here is to give a flyover and help you come to some conclusions quickly.", " | ", " | ", "The first award category is for Best Overall CPU of 2023. This one goes handily to the ", " CPU, which has had price reductions down to around $360. This CPU is a double-winner, also taking our Best Gaming CPU category later -- so for Best Overall, we’ll focus mostly on the non-gaming aspects of the 7800X3D.", " is priced right around where high-end gaming CPUs long held pricing in the pre-i9 and R9 days, bringing chart-leading framerate back to a more normal price-point for a high-end machine. They’re also single CCD solutions with only one size of core. This makes scheduling easier and simplifies setup as opposed to something like a dual-CCD 7950X3D or, in Intel’s case, a P-core/E-core design. The 7800X3D isn’t a leader in production benchmarks like Blender, but it’s more than acceptable while still leading in gaming. There’s a balanced category for CPUs that sit in the middle better. It does do excellently in Photoshop though, so the X3D CPUs can punch up depending on workload.", "Another non-gaming contributing factor is the efficiency: The 7800X3D is an extremely efficient part and ranked behind the new Threadripper parts that blew the doors open in this category. Because of the efficiency, it’s relatively easy to tame thermally: You don’t need a 360mm CLC to cool the 7800X3D, reducing cost barrier to entry and opening up cooler options.", "The 7800X3D particularly stands-out for anyone trying to max-out the framerate in gaming with a 7900 XTX or RTX 4090, where you want to minimize bottlenecks as much as possible. We’ll come back to that in the gaming category.", " | ", " (13600K) | ", " (13600K)", "The next category is for the Most Balanced CPU -- we've had this category for several years now, though skipped last year due to having other options. This one goes to the i5 K-SKU CPUs: The ", " or ", ", depending on whichever is cheaper because they’re basically the same.", "The Most Balanced category is specifically a weighting of all tests we run for GN reviews, but also considering price. This means we’re factoring-in the $270 price of a ", ", for example, which makes it extremely competitive from a pricing standpoint. Even though the name is a generation old, the CPU isn’t -- it’s perfectly good as a new chip that is balanced between price, gaming performance, and production performance.", "As an example, we found the 14600K scored 747 points in our aggregate Adobe Premiere benchmarks, putting it ahead of the 7800X3D and about tied ", ". The CPU was likewise particularly competitive in our Blender rendering benchmark, where the pair completed in less time than the 7700X and 7800X3D. The 13700K and ", " do well here, with an overall strong balance across all tested applications despite not being the “best” in any of them, but the 13700K and 14700K didn’t win this category due to the high power consumption and price.", "The gaming performance is also strong for the price, with our pre-patch Starfield numbers -- which were run with all of these on the same version -- at 111-112FPS AVG for the i5 CPUs. That’s behind the 7800X3D, but with the higher production workload performance in many cases and the lower price, it’s balanced.", " is also good, putting the i5 CPUs alongside the powerful 5800X3D. The 5800X3D got a different award, but doesn’t get our balanced award primarily due to weaker production performance.", "While the i5 K-SKUs are not the best in any single category, they fulfill an overall well-rounded performance and value profile.", "Next up is the award for Best Gaming CPU. This one goes to the ", ". The category is as basic as it can be: This considers only the absolute, highest-performing CPU in games we’ve tested. That means we’re looking at CPUs for FPS snobs. While there are other options that’ll get you 80% of the performance, those aren’t considered here. That makes this one heavily numbers-based.", "First, the basics for anyone who’s been out of the market: The R7 7800X3D is a socket AM5 CPU that uses AMD’s stackable cache, or V-cache, which we’ve found to have a large impact on gaming performance. It’s an ", " that is currently around $360 at the time of filming, with occasional small discounts on Newegg and Amazon. This one has been hovering at this price for a while now, down from its $450 launch MSRP.", "Because this is a purely numbers-based category, let’s look at some recent gaming benchmark charts:", "In the new Cyberpunk: Phantom Liberty expansion that probably a lot of you will be playing during the holidays, the 7800X3D led the charts. It was about tied with the 7950X3D, although it carried better 0.1% lows. We have run the 7950X3D through this game several times and found that it always encounters a couple sluggish frametimes run-to-run despite an overall good average, which we think just has to do with scheduling. Either way though, the 7800X3D is meaningfully ahead of everything here and isn’t even the most expensive gaming CPU on the chart. ", " would get you most of the way there as an upgrade, but ", " leaves a large gap to the 7800X3D.", "In Stellaris turn time simulation, the 7800X3D was roughly tied with the rest of the chart leaders. It’s up there with the 14700K, 14900K, and 7950X3D, which are all roughly within error of each other.", "Baldur’s Gate 3 had the 7950X3D ahead on a technicality, but it was ultimately very close to margin of error. The 7800X3D and 7950X3D both establish a relatively wide gap between themselves and the next CPU, the 14900K. “Relatively” is the important word: It’s not meaningful, but if you glance at the rest of the chart, you’ll notice much more gradual scaling of the average bar down the chart. If you were to look at the 1440p chart, you’ll see that the 7800X3D is still at the top and retains all of its performance, despite an increase in GPU load.", "Finally, we’ll show Starfield as a counter-example. This was before the most recent patches, so new numbers will be a little higher, but all of these were run on the same game version and so are directly comparable to each other. Intel kept a lead here, with the 14900K ahead of the 7800X3D by 15%. It’s not always the best, but it’s the best often enough that it’s our go-to for a high-end gaming machine.", " is the overall best gaming CPU. There are places where the cache doesn’t get leveraged as heavily, but the places it’s beneficial outweigh the areas we saw diminishing returns. Although the extra cache doesn’t benefit this CPU in most of our production workloads, the core count allows it to remain a good overall option. If you’re editing videos or running file compression and decompression workloads, the CPU does perfectly fine. This will most likely bottleneck you on the GPU, so to fully leverage this CPU, consider a higher end GPU. We’d be looking in ", " or ", " and up categories especially, although you could obviously pair anything with it. We recently revisited the RX 7900 XT ", " if you want to see how that is today.", " | ", " | ", "Next up is for the best upgrade. We added this category last year. We’re defining this as the best CPU that can drop-in to a board of a past generation, either Intel or AMD. It’s probably no surprise that the winner is the ", ", and we hope that this encourages both AMD and Intel to keep offering good upgrade options in the future -- it’s great for consumers and often highly cost effective for a stricter budget.", " showed just how much room there still is to bring AM4 forward, especially in gaming. The best part is that a lot of boards from the prior Ryzen generations can support the X3D CPU already (just check the CPU support list and update BIOS before pulling your old CPU). Many of the boards that support the R7 2700, R5 3600, and obviously the 5000-series CPUs will run ", " without issues, and even some of the older R7 1700-era boards on X370-era chipsets can work (though it’s more spotty). ", "If we look at a couple of gaming charts from our 2700X revisit, you can see how you’ll get a performance bump from those older CPUs that feels like a totally new PC build (especially if coupling it with a drop-in GPU upgrade, so you can save on RAM, the motherboard, and the case).", "The 5800X3D is also relatively low power consumption for its performance. In an all-core workload, we had it at around 108W. That makes it easy to cool for a good $30-$50 dual-tower air cooler, something like ", " that ", ".", "It’s almost good enough for a modern build too, but the board cost starts affecting value for a new system, although options on eBay may open things up. Ultimately, the 5800X3D makes a ton of sense as a cost-saving, high-performance upgrade, where you can allocate what would be spent on all new components instead toward the CPU and GPU alone. That AMD has kept the platform alive this long is commendable and we hope to see this going forward. The environmental impact and e-waste impact is far lower and the value for existing owners of the platform is strong.", " | ", " (7980X) | ", " (7980X)", "The next award is for the most efficient CPU. On a technicality of actual power efficiency, based on our testing, that goes to the ", " 64-core CPU. At $5000, this CPU costs more than a full gaming PC for a lot of people likely referencing this list, so we’ll name its runner-up as well: The ", ", with an honorable mention to the R9 7950X in Eco Mode.", " leads by a lot, though: In workstation applications that scale cleanly on 64 cores, the amount of time required to complete a given unit of work by the 7980X is impressive.", "In our efficiency chart, the 7980X posted a 12.9 watt-hour result, with the 7800X3D previously being the most impressive modern CPU outside of utilizing Eco Mode (although the 5950X remains a leader for its era). That’s what earns the 7800X3D the runner-up status, but the 7980X is even more interesting.", "As we talked ", ", its power utilization per core is exceptionally low due to a 0.84-0.85v Vcore during all-core operation when capped with a 350W PPT. These results plus the multithreaded efficacy in all-core applications earn it the most efficient award, with the 7800X3D being one of the most effective in framerate per Watt efficiency in a lot of games.", "Intel is currently way behind in all-core efficiency for desktop-class parts, with its 300W flagships propping-up the high-end CPU cooler market well.", "The next award goes to the best budget CPU, where we normally target around the $150 to $200 price range. This one was hard: There aren’t many current generation options under $200. There’s ", " at right around $200, then the ", " makes a ton of sense for its current $170 price on Newegg, Intel ", " (or KF) for 'cheap' now too, and there’s also an R5 7500F that isn’t officially out in the West. The ", " was also in our consideration here for its reduced modern pricing. This makes choosing difficult: There are a lot of good last-gen options, but not many under $200 from newer lineups.", "We’ll do this two ways: If you’re one of the many people on AM4, the ", " might be one of your best budget-friendly options to get a final upgrade. It has nearly identical performance to the 5800X in gaming from the tests we ran in our original 5700X review, but tends to be cheaper. It’s not as big of a jump ", ", but where price is a hard limiter, it could be a worthwhile midstep. The 5600 makes less sense as an upgrade just because you’d have to be upgrading from pretty low and far back on the Ryzen stack while also being budget-constrained. We’ll give the best budget CPU to the 5700X if you’re keeping an old platform.", "As for something new, the ", " really is worth considering: The Ryzen 7000 series launched with high pricing that reduced some of the appeal against prior generations. The 7600 is now around $200 and is often within striking distance of the 7600X. If you’re able to find a 7600X at the same price, you might as well get that instead as it is a bit faster -- although TDP is lower on the 7600.", " | ", " | ", "The next category is for the best high-end desktop CPU. For this, we don’t mean the literal “best,” but instead what we think would provide a strong foundation for something like a video editing machine, CPU-based rendering machine, or something dealing with Chromium-like compiles.", "We’re naming the ", " here, and the only reason we added this CPU is because we’re very likely going to switch to the 7970X for our own editing stations.", "The 7980X isn’t viable for us, but ", " posted excellent  Adobe Premiere results in the Puget Bench while also posting particularly strong RAW video benchmark results and intraframe benchmark results. In that sense, this is a selfish pick: We’re planning to build a 7970X machine for the office because, based on our hands-on experience with it, we think it’d really help accelerate some of our video editing and rendering experience.", " (13100F recent tests) | ", " | ", "This one isn’t just for a budget CPU, but for the cheapest CPU that can still manage to play at least some games. We’re back with an award that’s getting increasingly difficult to assign each year: The best CPU under $100, which goes to the ", " right now.", "We checked, and right now, the brand new CPU options under $100 are slim: There’s i3-13100F at $110 to $120, which is problematic both because it’s not below $100, but also because there are better options not distant from $120. The R5 4600G is also around, but not competitive with the 12100F in its intended use case with a dGPU. There’s also the R5 5500, but last time we reran that through the suite at the request of viewers, we found its value was worse than ", ". The 12100F was also just a better performer, with boosts anywhere from about 5% AVG FPS to 31% in games, or 2% to 35% in 1% lows.", "We had a lot of reservations about FPS/dollar charts for reasons we explained in our 13100 review, but it does help illustrate a point here: Using the pricing of the time, that had the 12100F as one of the best value CPUs available. Higher was better here.", "In an absolute sense, the i3-12100F is more than capable of playing a lot of games: The performance in F1 2022 from our test at the time had it at 270FPS AVG. It’ll struggle in some games -- like Cities: Skylines 2, assuming you’re not just completely bound-up on the GPU, or maybe Starfield with the same caveat -- but overall, for builds where you can’t spend more money, this is a good starter option when financials are the bottleneck. It really helps to give some perspective on how good a cheap CPU can be just for the basics. And this really is an important category for PC parts: Every year, we have people comment about “if you just spend another $40,” but for a lot of people, $40 more is not a “just,” it’s a make-or-break on the build. Everyone has a price limit on their hobbies, and keeping that range as tunable as possible is good. Have no illusions: The 12100F will struggle in some games and it won’t age as well, but it does fall in the “good enough” category for a lot of games, and it does come in under $100. That also helps keep board costs down.", "The last category is a classic of ours: It’s for the biggest disappointment.", "This year, that award goes to the entire 14th “Generation” -- and that’s the first clue. It’s not a generational iteration, but is instead a numerical one. Which is fine, except there wasn’t any meaningful uplift. The 14th series didn’t do anything to advance performance in a meaningful way, but at least briefly reset the prices. Now, the 13 and 14 series CPUs have shuffled around a little bit in price. We’re completely OK with product refreshes, but they need to be more clearly branded as such and should at least post some kind of uplift. The 14 series just didn’t do that, and the temporarily high pricing was likewise unfortunate -- although they did seem to reset.", "The pricing we mentioned is from just before Black Friday is actually happening. Depending on how much things change, you're going to see some numbers move around. If things drop in price, then that may affect how much we value a processor versus something else, of course.", "Based on the numbers we've given you, from our data, and the prices we have today, the decisions for the most part are pretty clear: The best gaming CPU ", " (that's an objective fact), the most efficient part ", ", ", " is the best upgrade path, and Intel makes the strongest showing in ", " or ", " (whichever is cheaper) for a balanced build, or ", " for an ultra-budget build.", "There are a couple of categories where it's less clear, like Best Budget. It's really not as straightforward as it used to be for us. It used to be as simple as saying “R5 2600, 200 bucks, yep, that's definitely the winner, no questions about it,” assuming it didn't win best overall or something for that year. Now though, it's difficult because some of the best CPUs are a prior generation, which feels a little weird to recommend now since they're EOL platforms. There's a lot of value in buying into a new platform if the companies (AMD specifically) do anything like AMD did with AM4. That's the one category where it was kind of difficult to nail down a single CPU, so we gave you the two options.", "That covers it for the best CPUs of 2023. Again, you can find the full reviews on the site or the channel, and those will give you complete depth. This piece hopefully got you up to speed quickly so you can use it as a launching point to go do your next bit of research on the CPUs we've hopefully pointed you in the direction of. We have other roundups coming up, so check back regularly for those.", "Just a quick note too, these are really fun to work on because we lose sight of just how many products ship in the computer hardware market over the course of a year. There's a lot that aren't that interesting, but compiling the most interesting ones (plus one, in this case, group of disappointing ones) into a single piece is a lot of fun. It gets us back up to speed – there's so much going on it's hard to stay on top of it all the time. Hopefully this helped you as well! Check back for more.", "HARDWARE NEWS", "PC BUILDS", "PC BUILDS"]},
{"title": " GN Mega Charts: CPU Power Consumption", "paragraph": ["GN Mega Charts: CPU Power Consumption", "Last Updated: ", "The Highlights", "This is part of our long-term reference series of component charts. We will roll these out over time.", "This page will be updated regularly with our latest power consumption figures for CPU testing. There will be a slight delay to incorporate the latest data following a CPU review, so the charts on this page may not be as up-to-date as our latest CPU review; however, it will contain more data than is presented in the reviews. If we were to make a software analogy, think of this page as the “LTS” (or long-term support) version of the charts: They won’t be updated as often, but will contain the most stable set of data. ", "Steve Burke", "Patrick Lathan", "Mike Gaglione", "however, we want this page to be as useful as possible, so we're putting the charts right at the top in a gallery format for quick reference. Please scroll down and read the methodological details for further information, and also note that the Legacy & Miscellaneous chart has an important bit of information about BIOS controls and test parameters accompanying its section at the bottom of the page. There is also an update log at the bottom. Here's the quick-reference gallery!", "The above is the current (as in 'today,' not as in P=VI) power efficiency chart. Unlike our above (and below) power consumption snapshot tests, this chart cannot be compared across multiple test generations. That's because it relies on a unit of work (a Blender render) to complete for the calculation, and that unit of work gets updated for our review cycle every 1-2 years. Everything on the chart is directly comparable, but it cannot be compared to older versions of itself. This gives us a measure for a known and fixed unit of work (the render) versus the power required to complete that unit of work. As an example: Something that's faster and draws more power could be less efficient than something that's slower, but ultra low power.", "This page contains a mix of test methodology information, limitations of testing data, and the data itself. We also present links and resources for the original reviews (or related content) and to the Amazon or Newegg pages, which contain affiliate links to help support this page.", "Of course, we'd recommend reading the limitations and methodology section first. Once done there, we'd recommend ", "to find the CPU you care about. that will jump you to a table naming the CPUs in each chart.", "We intend to update this page quarterly. The results are dependent on methodology. As long as the method doesn’t change for each chart, it can be appended going forward.", "We suspect these long-term reference pages will get higher traffic volume than typical. The intent of these pages is to serve as a quick reference, permanent URL for performance data. Because we currently are ad-free on this website, we ask that if you find this page regularly useful, you please support our maintenance of this information. You can support us a few ways:", "Unless stated otherwise, all power tests on this page were conducted using the same testing methods. The test benches have changed (naturally) for each CPU tested; however, because we isolate to only the EPS12V cables and test at a full and fixed load, the only meaningful impact to power consumption would come through motherboard changes.", "Methodologically, we control all motherboard power settings (unless otherwise stated for the DUT) to match the official guidance from AMD or Intel. That means boards which run MCE out-of-box will be tuned down to operate at the proper guidance and closer to the commonly understood “spec” (although that specific word is arguable) by the community. ", "We are advancing and changing our testing processes for power all the time, but for purposes of maintaining a directly comparable dataset, we maintain these tests long-term.", "The test uses a full, all-core Blender rendering workload using the Cycles renderer to load the CPU to 100%. We use an “impossible to render” GN logo frame with high sample count and resolution.", "This set of tests includes a 5-minute wait period (under load) before taking a steady state power figure. This does a few things: ", "First, it ensures we’ve had some time for leakage to set in and for power to stabilize. Power will bounce more at the beginning of a workload, especially on CPUs that may have features like Precision Boost or may boost to a particular thermal ‘value’ for Tdie. ", "Secondly, and most importantly, it ensures we are measuring after any Turbo time limits on processors that have them. We do this to make sure we are consistent in measurement. Different tests are performed for the Turbo power consumption (this occurs within the first 45-50 seconds of boost on older Intel CPUs). For all-core, steady state testing, we measure only after the CPU has stabilized. The Turbo/Tau tests are not on this page yet, but again, that primarily affects Intel CPUs dating back a couple generations.", "Although we have begun the process of changing our power measurements to use an interposer, this dataset uses a current clamp to measure the current at the EPS12V rails. We then multiply that current by the known voltage going into the EPS12V rails to land on the total power consumption in Watts. This does not include total system power, and as a result, allows us to compare even relatively ‘ancient’ data since we are eliminating the impact from GPU components. The motherboard will affect the data (via VRM efficiency losses), but we’re still getting pretty close to the ‘true’ power consumption of the CPU without moving to software measurement, which introduces new issues. The interposer method further improves this, but for purposes of this long-term reference table, we will be presenting and maintaining the clamp method data.", "Testing is conducted in a 21C environment with controls to keep it +/- 1 degree Celsius. Temperature has an impact on power and leakage. All tests since ~2020 are conducted with a 360mm Arctic Liquid Freezer II AIO, with all tests prior to that conducted on a 280mm Liquid Freezer II AIO. Prior to the existence of this Arctic solution, we used the Kraken X62 CPU coolers. In all scenarios, we ensure that the CPU does not thermal throttle. If a CPU is pushing too much power for its cooling, in years past, we’d move to a 360mm CLC from a 280mm solution. Now, all tests are done on a 360 (and that seems to prevent any throttling).", "For CPUs wherein a 95C target is part of the design, we let them boost within the limits of their cooling.", "This testing has limitations, and it’s important that you understand them. We want our audience to be aware of the value offered by the data we present and the limitations of the data.", "First, this page currently only presents all-core, 100% load data. That means we are not presenting, for example, the extreme power consumption that might be seen in a Prime95 workload (although Blender is still a heavy, realistic workload). ", "Additionally, we are not currently presenting gaming power consumption in these charts (although that is something we’ve recently added, it isn’t public yet). Gaming typically uses less power in total than production workloads due to the more variable nature of gaming impact on a CPU. This becomes more complicated if the bottleneck shifts: If a CPU is fully GPU-bound due to its ultra-high performance, it might appear to draw less power than alternatives that are fully CPU-bound. Again, that’s something we’ll soon be talking about in video format. It’ll make its way to articles later. There are realistic ability and time constraints with a small team, and as such, we focus on presenting the data we find to be the most reliable and which we can maintain with the highest quality. The current approach enables those goals.", "Although we collect it, we are also not currently presenting idle power consumption. This is because the idle measurements are often more complicated than stock due to Windows behaviors. We might add these in the future.", "The below charts are our latest vetted, full power consumption charts. Data dates back several years. Because it is measured at the EPS12V cables and not total system draw, we are able to provide like-for-like comparisons between these CPUs (sans VRM efficiency losses). Keep in mind that if retested with the newest BIOS, it is possible some of these numbers change.", "To keep things legible, we will be breaking these into charts based on generations and architectures that we think people will most commonly compare. The data between all charts should be almost completely cross-comparable, so you can pull two up side-by-side if both parts you're interested in aren't in a single chart.", "The axis has been kept at 400W for all charts to make it easier to spot-check comparisons between charts. The one exception is for the Legacy & Misc. chart, which goes to a higher wattage.", "These CPU power consumption comparison charts will help you understand the full load power requirements of AMD vs. Intel CPUs for each generation. These don't necessarily show power efficiency (that's a different test and requires a unit of work for comparison), but will at least give you a better idea for what kind of power supply you need for your gaming PC build or workstation build. As general guidance, our recommendation for how many watts your PSU needs is to spec for at least maximum power consumption (+ some overhead) to ensure you have enough capacity during peak loads. If you're wondering how big of a power supply to get, start first by looking at benchmarks for CPU and GPU power consumption, then go from there. Although it's unlikely you'd hit 100% load on both components simultaneously, that would allow prep for the worst case scenarios.", "For search reasons and Ctrl+F users, the above chart contains the following CPUs:", "This chart contains the following CPUs:", "The CPUs in the above chart include:", "We don't have as many power consumption numbers dating back to Ryzen 2000, 1000, or the Intel 7th Generation CPUs. We have some random/legacy results (below) that were from various revisits at points in time, but the Ryzen 1000 era and Intel 7th generation would have been when we just started collecting power numbers.", "CPUs in the list above include the below, plus various overclocking tests:", "The next chart is for miscellaneous and legacy results. These are 'orphaned' tests: We ran them at one point or another, but they don't necessarily belong anywhere else. ", ": With the oldest CPUs in this table, there is a higher likelihood than typical of a result which does not necessarily match the expectations of the time. The result would be 'accurate' in the sense that the current clamp would have been accurately used, but the BIOS settings may not match whatever the guidance was from manufacturers at the time, as we were not receiving guidance in the pre-2015 era for AMD or Intel. In other words, we would have exercised less control over BIOS as we did not have official guidance on the expectations (since we were not part of the reviewer circuit).", "The above chart contains these CPUs:", "The below contains an update log of changes to this page. The format is MM/DD/YYYY:"]},
{"title": " AMD's Cheap Threadripper HEDT CPU: 7960X 24-Core CPU Review & Benchmarks", "paragraph": ["AMD's Cheap Threadripper HEDT CPU: 7960X 24-Core CPU Review & Benchmarks", "Last Updated: ", "The Highlights", "AMD didn’t send its ", " out to reviewers. We’ve already reviewed the ", " and ", " and bought this “cheaper” CPU for $1,500 for today’s review, and it’s a 24-core, 48-thread part that sockets into the new HEDT motherboards in socket sTR5. The CPU claims a boost clock up to 5.3GHz single-core, which would make it fast for a Threadripper CPU.", "By HEDT standards today, where the 7970X is $2,500, the ", " is a “cheap” CPU. It’s still about $1,000 more expensive than a ", " though, which itself has 16 cores. That’s a big jump in price for an extra 8 full cores, and the boards are also a huge jump in price. Although they’re not all launched yet, it looks like several of the HEDT Threadripper motherboards will be in the $1,000+ price class.", "But more so than the core count increase, the more significant increase with the 7960X is in I/O capabilities. It’s an interesting balance of higher frequency, still high core count, and fuller I/O options as compared to desktop parts like the ", " or ", ".", "Steve Burke", "Mike Gaglione", "Patrick Lathan", "Vitalii Makhnovets", "This 24-core HEDT Threadripper part almost seems like the boring option and maybe that's why it wasn't sent out for review because in comparison to a 64-core or 32-core part, 24 just seems almost too close to normal but it's still a really potentially useful part because there are some cost reductions. Whether or not that amounts to savings for you depends on if you're actually going to leverage the CPU. But for people like us, we've taken advantage of 24-core parts. For example, we had one in one of our old editing machines instead of the 32-core processor because for Premiere, it just worked almost exactly as well and gave us all the I/O options we wanted, and it was still a little bit cheaper. We imagine a lot of people might fall into a similar situation.", "It is still more expensive than we’re used to. Compared to older HEDT parts, the prices have all climbed.", "The AMD Threadripper 7960X CPU is a 24C/48T part with 1.5MB of L1 Cache, 24MB of L2, and 128MB of L3 cache. The PPT max is still 350W, alongside TDP, and it’s fully unlocked. The CPU has four memory channels.", "For I/O options, the TRX50 HEDT platform offers a total of 92 PCIe lanes, or 88 usable. Maximally 48 of those can be PCIe Gen5. The platform also has options for ECC memory. If you haven't been following the Threadripper news, basically these are targeted at sort of professional users; maybe not quite in the area of pro. They've got the WRX90 platform for that, but for HEDT, you're still in that sort of enthusiast class entering workstation territory and that's what we're going to be looking at today.", "You can learn more about the platform and PCIe support in ", ". For now though, let's get into the benchmarking.", "Since efficiency was such a big part of the ", ", we’ll start with power consumption.", "In an all-core workload with Blender, the 7960X pulled 337W at the EPS12V rails, which had it lower than the 7980X’s 352W and 7970X’s 360W. As an aside, we measured the 7960X at 360W in Cinebench R23, so it can still stretch up to a 350W PPT, +/- a bit depending on load.", "For reference, the ", " (", ") mainstream CPU pulls 251W in the same work, with the ", " at 287W in this workload. Even though the power consumption is high in an absolute sense, what the CPU does with that power is another important aspect.", "Now we’ll look at efficiency in an all-core, fully-threaded workload that hits the CPU at 100%. The ", " really impressed us here: It did phenomenally, with the best result on the chart other than prior 7950X Eco Mode results. The 12.9 Watt-hour result was so impressive that we spent a few minutes explaining the per-core power consumption in our original review, which you can watch ", ".", "The ", " was still good, but not as impressive. It runs at a less efficient part of the volt-frequency curve, and that extends to the 7960X as well. The 7960X also did fine at 25.9 Watt-hours, ranking it ahead of most mainstream CPUs (but not all -- the ", " and ", " remain extremely efficient chips). Intel has a lot of ground to gain here.", "Now we’re going to move into ", ". These are excellent benchmarking tools that help represent biomedical, financial industries/services, and life sciences (things like heart and medical imaging). While we’re not doctors and medical researchers and aren’t super close to the data as a result, our viewers have commented that these benchmarks are very helpful, so we’re including them here.", "First up for Spec is the Product Development category of testing, which includes computational fluid dynamics benchmarks.", "In this one, the 7960X performed impressively in some tests even in spite of the heavily reduced core count. WPC_CFD is based on OpenFOAM’s combustion CFD solver. The 7960X scored 13.65 points here, putting it close in performance to the 7970X and 7980X, relatively speaking. The scaling isn’t that favorable for the higher core count Threadripper parts, but is favorable enough to establish a large gulf between the 7960X and the mainstream desktop parts.", "The Rodinia CFD solver tests scale more cleanly, with the 7980X leading the 7970X by 62%, which itself leads the 7960X by 33%, but the 7960X (and 7970X) were outperformed by the ", " in this test, with the 7960X also outperformed by AMD’s 7950X. The CalculiX testing had the 7960X at 5.12, leading the mainstream Intel part by 34%. ", "Next up are the Spec Life Sciences & Biomedical tests. These ", " look at LAMMPS, which Spec.org says “is a molecular dynamics simulator that consists of five tests simulating a variety of molecular properties,” NAMD, which also runs molecular interactivity tests, and RodiniaLifeScience, which does heart wall medical imaging, among other tests.", "In this suite, the 7980X leads the 7970X by 30%, which itself leads the 7960X by 16%. The 7960X holds a significant advantage over the mainstream desktop parts and prior Threadripper CPUs alike for LAMMPS, at 71% improved over the ", ".", "For NAMD, we observed limited scaling against the 7970X, but still a significant gain against the 14900K. The ", " did particularly well in this test previously. NAMD also posted significant scaling favoring the 7980X as compared to the LAMMPS and Rodinia tests here.", "Now for the financial services & probability tests, where Spec Workstation runs Monte Carlo simulations, Black-Scholes pricing, and binomial options pricing tests. While we don’t necessarily understand any of the real-world applications for these financial workloads beyond running the test, many people seemed to appreciate this particular test in our last review. The scaling is excitingly clean overall.", "The 7980X gaps everything, holding a 60% lead over the 7970X. The 7970X’s lead over the 7960X is 27%, which itself rests closer to the 3970X in some of the prior tests. The 14900K is at the bottom of this particular chart.", "In the Spec Energy test, the application tests for seismic data processing with SRMP algorithms, a convolution filter with a 100x100 random filter on a 20K x 20K pixel image, and more.", "Here, the 7960X ranked third by convolution again, although its convolution result is only barely ahead of the 3970X. It’s interesting to see them at about parity despite the core difference -- architecture and frequency definitely count for something. The FFTW results had the 7980X massively ahead, so core scaling is strong there. The 7960X was relatively close to the 7970X, but far ahead of the 3970X. The Poisson result had it behind the 3970X and ", ".", "This next section will use our standardized suite of production benchmarks. These benchmarks include Adobe Premiere, Adobe Photoshop, Blender Cycles rendering on the CPU, code compile, compression & decompression via 7-Zip, and more.", "Now we’re moving to our standard suite of production tests. Starting with Blender, we have some fun stats to add: The 7995WX came through our lab for an ", ", which you should absolutely check out on our YouTube channel because it was hugely educational. The 7995WX with liquid nitrogen and an extreme overclock set the mark for the best performance we’ve ever seen in this test, at 1.2 minutes. The stock result was about 2.1 to 2.2 minutes, but wasn’t 100% comparable due to some differences in test setup as it was AMD’s engineering team on-site helping run it.", "Back down on earth though, the 7960X required 4.6 minutes to run Blender, so it allows the 7970X an improvement in the way of 1 minute -- or 22% time reduced. We always do our chart calculations in the direction of improvement, so in this instance, improvement is a % time reduction. We don’t flip the axis and invert it to a rate (or renders per unit of time), but instead use the base metric of time.", "The 7980X required 2.2 minutes to complete the render, an improvement of 52% time reduced from the 7960X. That’s a big jump. Even for those using EVEE with CUDA, it’s impressive to see how much can be done with CPU cores.", "The relevant desktop parts would be the 7950X, marked at 6.4 minutes, and the 14900K at 7.3 minutes. Respectively, these allow the 7960X an advantage of 28% and 37% time reduced. The 7960X manages to offer benefits over the mainstream desktop parts beyond IO in several of these tests for those who can make use of its capabilities.", "Chromium code compile is next. This is like Blender: Smaller bars are better and we don’t invert the axis to a rate, but use the base metric of time without abstractions away.", "The 7980X’s 31.4-minute result has it running at 27% time reduced against the 7970X, which itself reduces the time requirement to complete the compile by 16% over the 7960X. ", "The 14900K required 71 minutes to complete this compile, with the 7950X basically the same. The result of the ", " against these parts, assuming a 71-minute average, is 28% time reduction.", "The 3970X is still hanging in there at about 60 minutes, sticking close to the 7960X and still establishing a gap against the 7950X and 14900K.", "7-Zip is up now. These tests are measured in millions of instructions per second, or MIPS. For decompression, the 7960X ran 388K MIPS, allowing the 7970X a lead of about 29%, with the 7980X in a similar spot. We’re limited in headroom this high up. The 7960X performed similarly to the 3970X, but had a more drastic lead of 41% over the desktop 7950X part, or 66% over the 14900K.", "In compression, the 7980X sets the ceiling at 393K MIPS, followed closely by the 7970X at 352K MIPS, and then the 7960X at 288K MIPS. The 7970X leads the 7960X by about 22%, with the 7960X leading the 7950X non-3D by 50% (which is near the 14900K). That’s a big gap between this lower-end HEDT part and the best desktop parts.", "In Adobe Premiere and looking first at aggregate score with the Puget bench, the 7960X scored 913 points -- just behind the 7970X and functionally tied. That has it ahead of the 7950X, 14900K, and everything else. IGPs can help Intel in some aspects of Premiere, but there’s still value in brute-force CPUs (just to a limit).", "Looking at the RAW sub-score for RAW footage processing, the 7960X retains its second-place rank. The lead over the 14900K, the next CPU, is about 9%. Threadripper does pretty well with RAW footage processing, but the cost efficiency still rests with the desktop parts.", "Looking at the Intraframe video score, the 7960X does exceptionally well here and ties the 7970X. Both CPUs establish a clear lead over the next CPUs, which themselves are led by the 7950X.", "Unfortunately, as we saw last time, Threadripper doesn’t do particularly well in the comparative for Photoshop. It’s not bad, but purely against alternatives, it’s an expensive and under-utilized CPU. Photoshop just isn’t threaded this way. The 7960X is ahead of the 7980X and behind the 7970X, with this chart being led by more mainstream CPUs like the ", " or ", ".", "Before we dive into the gaming benchmarks, it’s worth noting that these HEDT CPUs aren’t intended for gaming as their main use-case. What we will be looking for is whether or not there are any massive problems here that cause games to be unplayable. ", "In Cyberpunk: Phantom Liberty at 1080p, ", " ran at 135FPS AVG. That has it just between the ", " and ", ". The lows are timed almost exactly with the other new Threadripper CPUs. If you’re planning to use a 7960X CPU for work, at least so far, it wouldn’t be a buggy mess in gaming. ", "At 1440p in Phantom Liberty, the 7960X’s 135FPS AVG keeps it again about tied with the other new Threadripper CPUs, and more than capable of at least running the game well, despite not being a top performer. ", "In Stellaris for CPU simulation time, the 7960X required 44 seconds to complete the simulation. That had it about tied with a ", ". The 7980X and 7970X did better on a technicality, but ultimately, these CPUs aren’t able to leverage their cores in a meaningful way here. They’re still acceptable performers if gaming is a secondary use case.", "In Baldur’s Gate 3 at 1080p, the 7960X ran at 90FPS AVG and again had good frametime pacing. The CPU was just behind the 7970X and 7980X, but realistically, all 3 of these are roughly tied. And from a practical standpoint, you’d never notice a difference.", "Rainbow Six Siege was buggy and couldn’t launch with our 7980X previously. We’re not sure if that’s been fixed, but we ran the 7960X through it successfully. The framerate is overall impressive, still managing 547FPS AVG. The 1% lows are worse than a ", ", but not in a way that anyone would realistically care about. At least, not any of the target audience for the 7960X.", "Now we’ll briefly look at frequency. AMD advertises a maximum single-core frequency of 5.3GHz. With a single-threaded Cinebench run, we measured this frequency for the 7960X. The CPU held about 5340MHz for the entire test. It’s technically slightly above spec. We had no issues maintaining this single-core frequency in our testing. Our previous review had the 7980X at about 4800MHz single-core, so this is a lot higher for lower threaded applications.", "For all-core frequency, the 7960X ran in the 4600-4700 MHz range. We were between 0-5% away from PPT max, so this was a fully loaded test. Frequency dropping from the single-core high is expected. The 7980X was closer to 3.9-4GHz all-core in our previous review, again marking the 7960X much higher in trade for its position on the volt-frequency curve for efficiency.", "The 24-core ", " can make sense as a “cheap” or “economical” workstation that gets you access to more PCIe lanes/storage compared to a mainstream CPU. With it, you’ll get most of the performance of the ", ", the 32-core part, for a bit less money. Now, in applications that scale more linearly with cores, then obviously that jump widens. But for, say, an Adobe Premiere user, it can make sense. Piggybacking off our past, subjective experience configuring a Premiere workstation, we found our ", " to be one of the most reliable systems we’ve used for that purpose. It did have a limit.  At the time, we found it worked best with the 3960X in balancing out frequency and core count. Anyone who uses Adobe Premiere knows how much of a nightmare it can be; your experience can change almost on a day-to-day basis. There doesn’t seem to be a good way to measure how this feels as a user, unfortunately.", "If you can get more core scaling in the applications you use, like the SpecWS stuff we highlighted above, then the 32-core 7970X or the 64-core ", "might be worth considering carefully. Some instances in which we saw notable uplift were in SpecWS’ financial services benchmarks, where cores scale well.  ", "If you’re looking to primarily use the 7960X for gaming, then you should buy a different CPU. While we didn’t encounter any major problems running it through our suite of gaming benchmarks, we didn’t test every game and it would only make sense to get the 7960X here if you’re planning to run heavily multi-threaded applications on the side."]},
{"title": " AMD Ryzen 5 2600X & 1600 AF 2024 Revisit vs. 5800X3D, 7800X3D, & More CPU Benchmarks", "paragraph": ["AMD Ryzen 5 2600X & 1600 AF 2024 Revisit vs. 5800X3D, 7800X3D, & More CPU Benchmarks", "Last Updated: ", "The Highlights", "Today we’re revisiting some of 2018’s best CPUs: ", ", and ", " (original reviews linked), the latter of which is basically a 2600 that came out later in 2019 and quickly sold out at its $85 launch price. ", "In this story, we’ll be looking at how the 2600 series (and we’re including the 1600 AF here) performs against modern CPUs. So we’ll be looking at AM4 options for drop-in upgrades like the ", ", new Intel options, and also AM5 processors.", "If you’ve been running on a 2600-class system for a while and you’re thinking about upgrading, this should give an idea for what kind of relative percent uplift you could see or some absolute numbers in some cases.", "Today we’re revisiting some of 2018’s best CPUs: ", ", and ", " (original reviews linked), the latter of which is basically a 2600 that came out later in 2019 and quickly sold out at its $85 launch price. ", "In this story, we’ll be looking at how the 2600 series (and we’re including the 1600 AF here) performs against modern CPUs. So we’ll be looking at AM4 options for drop-in upgrades like the ", ", new Intel options, and also AM5 processors.", "If you’ve been running on a 2600-class system for a while and you’re thinking about upgrading, this should give an idea for what kind of relative percent uplift you could see or some absolute numbers in some cases.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "We initially gave the R5 2600 the ", " award back in 2018. The Ryzen 5 series CPUs were incredible performers at the price back then, punching above their weight class for value and in a market where Intel wasn't as present. The 2600 launched at $200 and the 2600X launched at $230, which were extremely competitive deals at the time, not to mention the $85 1600 AF (a somewhat sneaky launch using an updated node, despite the naming).  They offered a good amount of performance, particularly good multithreaded performance for the time, which made them awesome options for AM4 builds.", "A lot of people are running those CPUs and they’re still good today, especially in games (as long as the GPU can keep up); however, at the time of launch, they did struggle a bit compared to Intel’s best options in games that were more frequency-dependent at the time. Things may have changed in the time since, and that's what we're looking at today.", "Since it’s been a while, let’s check back in on those specs. ", "Here are the spec listings for the CPUs we’re revisiting today:", "The ", " is a 6C, 12T CPU that advertises a boost of up to 3.9GHz. Back in the day, overclocks could commonly hold 4.0-4.2GHz. ", " is also 6C and 12T, but advertises a maximum boost of 4.2GHz. Its base clock is also 3.6GHz, up from 3.4GHz. The ", " is a slower variant of Zen+ 2000-series CPUs, just with an older name. Back when we reviewed it, we noted that it may not be as good a bin as a 2600, but that there’d be no way to know. Its price was shockingly low. Our 1600 AF and our 2600 ran at almost identical clock speeds when stock, so it’s effectively an R5 2600. There are some slight differences, but we talked about those in the ", ".", "Now we’ll talk about pricing and options. This should help anyone who hasn’t followed the industry get reacquainted with what CPUs exist currently.", "First, here’s a quick reference table for some pricing right now on modern AM4 and AM5 CPUs. We’ll look at Intel next. The R5 2600, 2600X, and 1600 AF original prices are also listed. The 2600 was a $200 CPU, which most recently has been handled by the ", " non-X, or the ", " as shown here. The 1600 AF was briefly an $85 CPU, which was an insane price considering it’s a 2000-series CPU from a generational standpoint. That price didn’t last long and it quickly got scalped.", "Modern in-socket upgrades could include the ", " or ", ", the ", " (which is basically the same in performance as a ", ", and the ", ". The X3D is still available new. It costs around $322. If your budget dictates that you either get a ", " and a new board or a 5800X3D, then the X3D will get you the most gaming uplift if newer board features and I/O aren’t needed. The ", " (", ") isn’t too distant in price right now, although it’s been on and off sales.", "These prices were all spot-checked on Amazon and Newegg for this piece, but remember that prices are fluctuating nearly daily right now.", "Let’s look at Intel.", "For Intel, some of the relevant options include the ", " or KF at $250-$270 (find ", "), which are cheaper than the new ", " (watch ", ") and functionally the same -- or the same enough that it’s not worth extra money. The 13700K is around $345 now, with the higher-end i9 CPUs at $580 or so for the ", ".", "There are a lot more CPUs than this, of course. These are just some of the most relevant ones right now. We’ve taken out some of the ultra high-end CPUs just because it’s such a difference in performance class. If you want to see those, you can check out our ", " for the truly high-end stuff. Today, we’ll be focusing more on the gaming side of things with some production benchmarks at the end. ", "Baldur’s Gate 3 is up first, tested at 1080p/medium. This one has been a reliable CPU load and shows clean scaling for most parts tested, but especially for these older CPUs.", "The R5 2600X ran at about 51FPS AVG, with the 2600 just behind it and 1600 AF effectively tied with the 2600, which makes sense for reasons we discussed above.", "We’ll talk upgrades first: ", " would be the largest in-socket improvement, pushing a little past doubling the FPS for any of these 3 older Ryzen parts. Assuming your GPU can keep up, it’d feel like a new system.", "Other in-socket options might include a cheaper ", " or ", ", where we saw about a 54% increase in performance, depending on which CPU you look at. It wouldn’t make much sense to move to a 2700-series CPU from a 2600, but ", " or ", " might be an option if the cost were low enough.", "On the new platform side, ", " or ", " would be the most price-conscious improvement. You’d have some added benefit in multithreaded workloads and applications that the ", " won’t match, despite a deficit in some of these games. For most people watching, probably the gaming performance matters more.", "As for new AMD, ", " would push past the 5800X3D to 122FPS AVG, while something like ", " or ", " would offer uplift with a lot of new motherboard and I/O options, but a lower barrier to entry price.", "At 1440p, the lineup is mostly the same. That makes sense since we’re so CPU-bound. If you were running a better GPU than CPU, or just in games that are more CPU-constrained, you’d see an uplift even as resolution or graphics options increase. That’s shown in this example.", "Cyberpunk 2077’s new Phantom Liberty expansion is up now, serving as another relatively high CPU load for a modern and popular game.", "At 1080p, the 1600 AF and 2600 ran at about 87-88 FPS AVG, which is within run-to-run variance for two entirely different chips. The 2600X ran at 91FPS AVG, boosted from its higher clocks (and also benefited against the 2700 non-X, as the 2600X has a higher maximum boost clock).", "These CPUs are still handling Cyberpunk well, despite the age. The lows are also completely acceptable here, with no major game-ruining spikes in our test passes. The 5800X3D in-socket upgrade would add about 100FPS to the framerate, up at 186FPS AVG. In a relative sense, that’s about 104% over the 2600X. A new CPU and board, like with the 7800X3D, move the needle to 122% uplift, at which point we’re likely grappling with some non-CPU limitations.", "Going from the R5 2600 series to the ", " or ", " would still provide meaningful uplift if you can get one for cheap enough, with the ", " (and likewise, the unshown but nearly identical ", ") posting some scaling beyond that. Intel’s 13600K would provide a major improvement of about 71% on the lower end. Non-3D new CPUs, like the 7700X, get most of the benefit of the 5800X3D.", "At 1440p, we saw about the same lineup. The very top-end is now slightly limited, cut from 203FPS AVG at the peak to about 190, but otherwise, you’d still get a big improvement with a sufficiently high-end GPU if moving off of the R5 2600 or 1600 AF CPUs.", "Starfield is up now. As another of the 3 brand new games we’ve recently added, it’s gone through the most dramatic changes. All of the testing for this was conducted on the same game version, which is one version prior to the recent mega patch. That means the data on this chart is directly comparable to itself, but that you’d get some uplift moving to a new game version. For purposes of comparing old CPUs though, we still have plenty of room to see scaling.", "The R5 2600, X, and 1600 AF all ran at about 53-54FPS AVG. The 2700X was around 56FPS AVG, so not much difference there. The 2700 data on this chart is within error of the 2600 and 1600 AF. Another round of reruns might get us another 1-2 FPS depending on variance. That’s within error. But the 5800X3D definitely isn’t: ", " would give you around 71% uplift against the 2600X. That’s not as crazy as in some other games, but still a huge improvement. The 14900K sets the ceiling at 132FPS AVG in this one, so the 13600K or ", " would be viable alternatives providing around double the framerate.", "F1 2023 is up now. In this one, the 2600 ran at 175FPS AVG, with the 2600X holding a 4% lead. The 1600 AF was near the 2600, at 172FPS AVG. That’s basically run-to-run variance at this scale.", "That these CPUs can still run modern games in the hundreds of frames per second shows how viable they still can be. It all depends on the game, of course, but at least here, we’re seeing good performance.", "The 5800X3D leads the 2600X by about 149%, which is an insane jump considering the in-socket nature of the change. As we’ve said before, it’s crazy that such a wide gap can exist while being tested in the exact same board, with the exact same RAM and other components. But remember, that’s only made possible if the GPU provides enough scaling headroom.", "The 7800X3D boosts further, at 181% over the 2600X. Intel’s options might land you on a 13600K at about 350FPS AVG or the 14700K at 407FPS AVG, which itself is about tied with the 7700X (although it produced higher 1% lows, at least on a technicality).", "At 1440p, the R5 2000 series (and the AF) ran in the 170-180FPS AVG range. The top of the chart has changed, with the limit now closer to the 400FPS mark. ", "In Stellaris, we’re looking at time reduction for CPU simulation time. As always, that means we calculate in the direction of improvement -- which is reduction -- so faster simulation time here means % time reduced from the reference point.", "In this one, the R5 2600 required a long 65 seconds for the simulation time. That’s noticeable as a player -- you’re waiting over a minute for the full simulation to process. The 2600X is similar, with an improvement of 4.7% time reduced. The 1600 AF ran a little behind the 2600, where the 2600 was improved by 2.5%.", "The 2600X shows us that frequency does have an impact here, and the 2700X vs. 2700 comparison teaches the same lesson. 3D Cache benefited the 5800X3D over the 5800X, where we saw an uplift of 12% time reduced, but didn’t meaningfully help the 7800X3D over the 7700X as a result of encountering other limitations -- possibly engine limits.", "The Intel upgrade pathway for a new build might yield a 13600K or 14600K as the best affordable options. Here, we see simulation times of 32 seconds on the 13600K, or 51% improved over the 2600, where improved again means % time reduced.", "In Shadow of the Tomb Raider, the R5 2600 ran at 130FPS AVG, with the 2600X at about 135FPS AVG. That’s about a 4% lead over the 2600 and similar over the 1600 AF. Lows are similar on all of these. As for the upgrade avenues, the first meaningful one might be the R5 5600X at 209FPS AVG or 5800X (or 5700X). Intel’s 13600K reference point we’ve used improves by about 76% over the 2600X. The 5800X3D approaches the limit for this chart, but doesn’t quite hit it. It’s at 315FPS AVG, or about 133% over the 2600X.", "The 7800X3D and ", " show us the limitations of scaling in this test, even at 1080p. ", "Our last game test is for Rainbow Six Siege: In this benchmark, the 3D cache scaling is huge. You can see that when jumping between the 5800X and 5800X3D (at 552FPS AVG to 650FPS AVG, or from the 7700X’s 640FPS to 717FPS AVG with the 7800X3D). The older 2000 series had the 2600 at 295 FPS, the 2600X at 305, and the 1600 AF at 291. The improvement to a 5800X3D is massive here, at 120% from the 2600. The jump to the 5600X is also a meaningful change. New builds with a 7800X3D would multiply in performance to 717FPS AVG, with the Intel 13600K mid-range option offering a step between the 5800X3D and 5600X.", "The wild thing with this chart is just how clear the generational improvement is: If we draw a horizontal line between the 5600X and 3700X, there’s a clear gap that forms as a result of generational changes, particularly with clock speed.", "Now we’re moving on to production benchmarks, including Blender rendering -- which we should rename Blendering. For this, we’re adding the ", " and ", " to the charts, as they may be viable upgrade options for anyone who’s heavy in non-gaming workloads. In Blender, smaller bars are better, so we don’t invert the axis and turn it into a rate for this test but instead use the base metric of time. Some other tests conducted in suites, like Puget’s, invert the axis and use aggregate calculations for “bigger bar better” charts. But we keep it simple in Blender. Calculating improvement means % time reduced for CPUs that complete the single frame fixed unit of work in less time.", "In this, the R5 2600 required 33 minutes to complete the render, allowing the 2600X to complete the work in 5% time reduced. The 2700 and 2700X show clear core (and with the latter, frequency) scaling in this work. Upgrade paths might include ", " at 17 minutes, or an improvement of 48% from the 2600 when calculating time reduced on a smaller-is-better axis with the base metric unchanged. The ", " would offer an insane improvement if you went heavier on this kind of work, although the value against a brand new build would heavily depend on pricing. The jump to about 10 minutes render time is massive, or a 70% time reduction. The 13600K offers value as a balanced chip here, with its good overall gaming performance earlier and advantaged all-core performance against something like ", ". There’s a reason it ", " from us.", "7-Zip compression is up now, back to “bigger-bar-better” for when “bigger number better.”", "In this one, the 2600, the X, and the 1600 AF are all adjacent at the bottom of the updated chart. The 5600X would offer a meaningful uplift in file compression performance, with large gains coming from the 13600K or, if you can spend more, the 5950X. Newer CPUs like the 7900X or ", " begin offering crazy performance improvements, but these would really only be worth paying for if you regularly run compression processes.", "In file decompression, still measured in millions of instructions per second, the 2600X allowed the 5800X an improvement of 81% and the 5950X an improvement of 230%. The 13600K again provides a good balance, although the 5800X3D isn’t too distant if your focus is gaming first-and-foremost.", "The next one is Adobe Premiere, tested with Puget’s bench where it aggregates multiple scores based on performance. Premiere can be measured in a number of ways depending on what’s done: Examples could include simple FPS for playback and scrubbing and time for rendering. Here, Puget converts various results to a single weighted points-based system.", "The 2600 scored 423 points here, just ahead of the 1600 AF and predictably just behind the 2600X. The 5800X and X3D score around 607-616 points, or an uplift maximally of 46% over the 2600. The 7700X also posts large gains of 74% over the 2600 and would be a good, modern option. From Intel, the 13600K again illustrates a good balance of price, gaming performance, and non-gaming performance. The 14900K and 7950X are chart leaders here.", "Adobe Photoshop still hates optimization, but it seems to hate it less than it used to. ", "In this one, the 2600, 2600X, and 1600 AF again establish the chart base. The 5600X posts a massive improvement from generational changes, marking a 33% boost over the 2600X. The 5950X sadly doesn’t benefit from its core count much here, with the 5900X establishing more of a so-called “sweet spot.”", "The 7700X offers a great balance by leading the chart but remaining in a more affordable price class, with the 13600K doing the same but with more price focus at a sub-$300 price class these days.", "Here’s the power consumption chart. The R5 2600 originally was measured at about 84W when tested in the exact same conditions as our modern CPUs are tested. The X isn’t on this chart, but we did overclock the 2600 to 4.2GHz back in the day: For that test, we measured a 145W draw at the EPS12V cables, with the 1600 AF pulling 152W for its higher Vcore requirement to sustain 4.2GHz. The 1600 AF base model pulled 83W. ", "The non-overclocked numbers are easy to cool by today’s standards. The overclocked numbers, while super inefficient overall, still manage to be lower than a lot of today’s CPUs.", "Here’s the efficiency chart, where we’re completing a single frame of work and monitoring the energy consumption. In this one, the 2600 ranked the lowest on the chart, at 46Whr. Although the 84W draw (in the previous chart) was relatively low in an absolute sense, the efficiency isn’t nearly as strong as modern AMD parts. Anyone upgrading from this generation will see huge improvements in efficiency, or the amount of work completed against the power. The 2700 pulled about 8-9W less power in Blender testing which, alongside its core count increase and therefore performance boost, made it much more efficient than the 2600.", "This might be the real story: AMD’s efficiency has significantly improved generationally. Some of that is also in the BIOS improvements.", "The performance of the ", ", just like the ", ", which we also ", ", is clearly still good for a lot of the games we tested. It becomes a question of if it’s good for the applications you’re running. If you’ve transitioned into more multithreaded applications and workloads, you’re probably starting to feel its age. While the R5s from that era were competitive at the time for their pricing, things have definitely changed when you factor in newer CPUs, which may make it a compelling reason to upgrade. You may also want to build a new computer or feel like you could get more framerate performance out of your games.", "As a general reminder, these are still capable CPUs, so if the performance of your system isn’t bothering you then you don’t have to upgrade. If you did want to upgrade then the obvious choice would be the ", ", which will get you the most out of AM4. ", "If you wanted to move to a new platform, the next obvious option from a budget-conscious and balanced-build perspective would be the ", ", especially the ", " SKU with its occasional price drops (assuming you don’t need the IGP). ", "If you want to stick with AMD but are still a little budget-conscious, the ", " is a pretty good contender replacement for these R5s. If you want a truly high end CPU, then you might want to look at the ", " for gaming. On Intel’s side, there are also the ", " and ", " for mixed workloads. It’s worth noting that Intel’s 13-series is mostly the same thing. These options are noticeably more expensive, however, which make the ", " and ", " options that are worth looking more into for what you do. For more gaming heavy scenarios, we would start looking at the X3D, for more mixed workloads and less of a focus on just gaming, then an i5, maybe an i7, or 7700X are all worth your consideration."]},
{"title": " AMD's New Ryzen 7 5700X3D & More AM4 CPUs, APU 8700G, 8600G, 8500G, & 8300G Specs", "paragraph": ["AMD's New Ryzen 7 5700X3D & More AM4 CPUs, APU 8700G, 8600G, 8500G, & 8300G Specs", "Last Updated: ", "The Highlights", "AMD has a ton of CPU news coming out of CES. There are multiple new AM4 processors, including the R7 5700X3D, new 8000G desktop APUs for AM5, and 8040 mobile parts. Let’s get into it.", "We’ll start with the new AM4 CPUs. ", "AMD announced the Ryzen 7 5700X3D and noted the 5700 non-X, non-3D will launch to DIY (it’s already been out in OEM systems), and it also announced the 5600GT and 5500GT.", "Steve Burke", "Vitalii Makhnovets", "Jimmy Thang", "These were expected only because there were leaks a few months ago about them, but generally speaking, we all kind of assumed that ", " would be the final AM4 entry considering the age of the platform. ", " and received its first Ryzen CPUs in 2017, meaning that the platform is still getting new processors now 8 years later, or 7 if you just start at Ryzen. That is actually completely insane and is the longest-lived socket we have ever seen in GN's testing tenure.", "The 5700X3D is an 8C/16T part that runs at 4.1GHz boost and 3.0GHz base, with 100MB of cache and a 105W TDP.", "Jumping over to the ", " specs, they’re overall similar: The ", " is an 8C/16T part with a 105W TDP and likewise 100MB of combined L2 and L3 Cache, at 4MB and 96MB. The difference is clock speed, where the ", " ran at 3.4GHz base and 4.5GHz boost. That means it’s about 400MHz faster than the 5700X3D.", "It’s basically a 5800X3D but slower. MSRP is $250. How much that clock reduction will impact performance will depend on the application: Something that doesn’t utilize the extra cache at all and is also largely single-threaded will benefit disproportionately from the 400MHz boost. Something fully engaging all threads at the boost frequencies might also post a departure, like Blender, but it depends on the all-core boost frequency.", "We noticed recently that the 5800X3D was starting to jump in price in a few places as third-party sellers overtook listings that were running dry. Depending on if that’s permanent and if AMD will continue making 5800X3Ds, it might be the case that the 5700X3D will replenish that segment to hold prices down a little longer.", "At time of the pre-briefing, AMD did not provide any first-party gaming comparisons against the 5800X3D. The comparisons were against the ", ", but they looked to align roughly with a 5800X3D.", "The AMD Ryzen 7 5700 CPU isn’t new and has been available in OEM systems, but AMD is now selling it as a boxed processor with an included Wraith Spire cooler. As a refresher, the 5700 is an 8C/16T part with 20MB of cache (no 3D cache), a 65W TDP, and a base and boost of 3.7GHz and 4.6GHz, respectively.", "For reference, the ", " runs at ", ", but has 32MB of L3 and 4MB of L2. ", "It also has Gen4 PCIe support, whereas the R7 5700 stops at PCIe Gen3. It is more comparable to a ", ", just without the integrated graphics.", "AMD noted that the price will be $175 MSRP for the 5700. ", "Finally in the AM4 lineup, AMD announced the 5600GT and 5500GT. These are 6C/12T parts with 19MB of cache and a 65W TDP, per AMD’s definition of TDP. They also include IGPs. Boost is 4.6GHz for the 5600GT and 4.4GHz for the 5500GT.", "We’ll show AMD’s first-party charts for these:", "Compared to the existing 5600G, AMD presents the 5500GT as equal or marginally better, depending on application.", "Another slide shows the 5600GT vs. the ", ". It’s similar here, just with a higher ceiling for the relative comparison. The biggest gaming improvement was in PUBG.", "These CPUs will ship for $140 for the 5600GT and $125 for the 5500GT.", "We’re excited to see that this platform is being kept alive. Remember that the world outside of major markets like North America and Europe often ends up on slightly older platforms as a matter of cost. Keeping parts coming into the market will help other areas of the world with cost control and keep up with modern components which, from a market-share standpoint, will help AMD grow in regions where Intel has long been the primary option.", "Let’s move to AMD’s new 8000G APUs.", "AMD announced four new desktop APUs for AM5 today: These are the 8700G, 8600G, 8500G, and 8300G. ", "The 8700G is an 8C/16T part that boosts up to 5.1GHz and has 24MB of cache. Its TDP is 65W. The AMD 780M integrated graphics processor is included, which is an RDNA3 part with 12 CUs. The 8000G series supports up to PCIe Gen 4.", "The 8600G drops to 6C/12T and 5GHz boost, with a predictable cache reduction aligned with core reduction. The 760M replaces the 780M here, dropping to 8 CUs from 12. ", "That’ll be the more notable impact, as it’ll be uncommon for anyone using the IGP instead of a dGPU to be CPU-bound in games with this solution.", "The 8500G is a 6C/12T part also boosting to 5GHz, hosting 22MB of cache, and dropping to a 740M part. The 740M has only 4 CUs.", "Finally, the 8300G will be an OEM part for now and is a 4C/8T APU boosting to 4.9GHz and hosting 12MB of cache. It also uses a 740M.", "As an important note, the core configuration isn’t consistent across these. AMD’s names are confusing, but it was at least forthcoming with the difference.", "The 8700G and 8600G APUs use Zen 4 architecture, whereas the 8500G uses a mix of Zen 4 and Zen 4c, with 4 cores on Zen 4c. The 8300G has 3 cores on Zen 4c and 1 on Zen 4. Zen 4c cores have a smaller areal footprint than Zen 4 cores and sacrifice clock frequency and L3 cache per core.", "The APUs will support AMD’s Fluid Motion Frames, so frame generation will help boost framerate in borderline scenarios.", "We’ll briefly show some first-party claims. Remember that benchmarks will evaluate all of this soon enough.", "AMD’s 780M and 8700G benchmarks at 1080p/low ran at 63FPS in Cyberpunk 2077, 68 in Valhalla, and 165 in Dota 2. These APUs are generally best paired with games like Dota, League, Rocket League, or similar titles that are commonly called “eSports games.”", "AMD also showed its 8700G and 8600G solutions against the ", ", all running their IGPs. AMD is claiming significant advantages in most cases, with parity in the case of Far Cry. We’ll validate this in our review.", "The most interesting tests for APUs are normally the cheapest possible dGPU + CPU solution. We’ll probably look into a few combinations, like a 12100F at $100 plus the best GPU that fits in the same comparison budget at time of launch.", "Let’s move to AMD’s last CPU announcement of the show.", "AMD is also launching its 8040 mobile solutions. We won’t spend much time here as our coverage of mobile is currently limited to handheld systems, and some of these are nearly the same as the 7000 predecessors aside from the Neural Processing Unit (NPU).", "AMD’s big change here is its addition of more local AI processing power with a dedicated NPU for handling AI workloads. ", "We don’t cover these benchmarks right now and aren’t familiar enough with them to provide meaningful rebuttal or support of claims, so we’ll leave that topic to more AI-centric outlets.", "On the gaming side, the big one is the R7 8840U with a 780M graphics solution. The 7840U also had a 780M, and actually, these parts are basically the same other than the AI processing capabilities. If you’re choosing between the two, unless you have some sort of local AI workload that you want to run on a mobile part, you can basically consider them the same."]},
{"title": " The Intel Problem: CPU Efficiency & Power Consumption", "paragraph": ["The Intel Problem: CPU Efficiency & Power Consumption", "Last Updated: ", "The Highlights", "“Saying that the ", " is less efficient is LUDICROUS, unless you are specifically talking about gaming. Im betting a paycheck put both at the same wattage - the ", " is going to beat the crap out of the ", " in every single workload - it will be both faster and more efficient.” – Greg, a commenter of ours.", "That was the tweet we got after we gave the ", " for the year.", "Greg here brings up a great point, if a bit defensive, and we’re curious what the results are. ", "The goal is the scientific approach: We don’t care who wins or loses here. We just want to see what the results are. Today’s tests include gaming power consumption without constraints, efficiency calculations for gaming (not just Blender), power-normalized efficiency tests in some cases, and FPS-normalized efficiency tests with unconstrained power.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Tim Phetdara", "It’s a lot of small one-offs bulked into primarily stock configuration testing. We’ve long said that our biggest weakness in our power testing is a lack of non-all-core workloads, specifically gaming workloads, and so we’re finally resolving that today by using a special PMD interposer from Elmor Labs, which is really cool as a means to look closer at what's happening for power consumption when gaming or working.", "Here’s the plan:", "Currently, we produce power consumption charts that look like this: ", "and power efficiency charts that look like this: ", "Those give us a baseline, but we’ve long had a big weakness in our testing -- and that’s power consumption in gaming workloads, which tend to be lower (but aren’t always). There are a couple reasons for that gap: First, games are extremely variable, so to even pick a game to be our representative, we need to test a lot of them. Secondly, we needed to develop a repeatable methodology that was more reliable since games can fluctuate heavily even on the same CPU and in the same test, whereas something like Blender will be relatively flat once it starts.", "We’ve solved those things, so now we can look at power efficiency and consumption.", "Today’s tests will involve a few different metrics of efficiency:", "First, we’ll focus on frames per second per watt (or effectively, frames per joule). This will be done both unrestrained, or “out of box,” and with a few one-off tests that control for FPS or power. In instances where we control for FPS, we’re fixing it to 60 or 144. That produces a fixed unit of work.", "We’ll also provide a Wh chart for Blender, but now with an entry of the ", " power-controlled. This increases its render time, but increases its efficiency.", "Additionally, we’ll provide a MIPS/W chart for 7-Zip, or millions of instructions per second per Watt -- or again, millions of instructions per joule, basically.", "And finally, we’ll be looking at some numbers for the maximum 10-point and 30-point non-consecutive spikes during the entire measurement pass, which includes game and benchmark loading stages. We noticed that loading the game often resulted in higher temporary power consumption than playing it, so we want to provide that as well.", "There are a lot of ways this testing could be done, but our main interest is in the out-of-box performance since that’s how CPUs will actually be used in most cases. Almost no one is restricting their 14700K or ", " to 90W, and if you’re writing a comment right now saying “but I do!” just know that this is a limited use case. So our focus is on stock performance, but just as an academic exercise, we have a couple of those tests.", "Let’s get into it.", "Let’s start with something easy as a reference point. This is F1 2023, which runs in the hundreds of frames per second. The chart shows AVG FPS/watt, with higher meaning better efficiency. The average power consumption is next to the CPU name, rounded to the closest whole number.", "The ", " is unbelievably power efficient here, producing almost 10 frames per second on average per watt of power consumed at the interposer. The total EPS12V power was 52W for the 7800X3D while it spewed about 511FPS on average. The ", " is close by, with the ", " also posting incredibly strong results at almost 8FPS/W. In fact, AMD dominates almost the entire top half of the results, with only Intel’s ", " -- a CPU which we’ve awarded ", " twice now -- ranking alongside AMD’s 5000 and 7000 series choices. The ", " at 34W was able to run at about 246FPS AVG. ", "Intel’s best performer, the ", ", was the least efficient on this chart. Its framerate was 422FPS AVG while its power consumption was about 123W on average. That’s lower than in a 100% workload, but still less efficient than AMD’s competition. ", "Now, we figured some people might suggest that this isn’t fair because it’s a completely realistic and valid out-of-box scenario, so we also ran this iso FPS -- or with the FPS locked to 144. This is important for a few reasons: First, it makes sure we are neither fully CPU nor GPU bound, but instead are limited by the game engine. Secondly, it forces a like-for-like unit of work as a rate (144 FPS) for direct comparison. Our CPUs are now producing the same work for different power. ", "Here it is. It’s the same chart, but with two new entries: The ", " and ", " both have equalized FPS entries. Both CPUs become less efficient than they were natively. The 7800X3D is now pulling 30W and the Intel CPU is pulling 76W. In terms of FPS/W, that means AMD maintains a significant advantage over Intel’s position.", "There’s no more argument that we might be hitting a GPU bind on the better-performing part now. This is also now the same kind of metric as when we measure a single frame rendered in Blender for efficiency: It’s a fixed unit of work.", "Part of why AMD’s rating deranked a little bit is because the floor for its IO die is relatively fixed, so we’re approaching power consumption where the baseline required just to sustain operation of the chip is uncuttable, even though core power is reducing. The only thing left to look at would be a power limit on Intel -- we’ll do that soon.", "This next one is really interesting. ", "In Cyberpunk: Phantom Liberty, we observed power consumption was much closer to what we saw in Blender. That’s because the CPU load is so heavy in this one. The 14900K was around 200W, so it’s much higher than in F1.", "Because of our commenter who asserted that power-locking the 14700K would make it more efficient in all workloads than the AMD parts, we decided to do that in this one. The 14700K at 164W, unlimited, yielded about 1 FPS per Watt. It was nearly 1-to-1. The 86W-limited 14700K ran at 1.7FPS/W, a significant uplift. The raw FPS trade-off was about 22FPS reduced with that change. Intel is definitely way past the efficient part of the V-F curve, but we already knew that.", "Unfortunately for Greg and his bet paycheck, the 14700K remains in the lower half of this chart. It is neither faster nor more efficient. Even the ", ", which is functionally at power parity with the 14700K with its 91W draw and, helping the tweeter out, yielded a 1.9 FPS/W result -- and that’s worse than the 7800X3D. The ", " is directly comparable in power, and it’s not even AMD’s best gaming part.", "The 7800X3D and ", " both broke 3FPS/W in this game, producing phenomenally efficient performance. The ", " was up there as well, about tied with the ", " and ", ". The ", " also broke into this category.", "We wanted to be sure we had a heavier GPU load for some additional testing, so we ran Phantom Liberty at 1440p/Ultra. This dropped framerate of both CPUs tested significantly as the GPU began limiting us, which was intentional.", "Here, the 14900K still pulled 190W, with the 7800X3D at 72W. The 7800X3D remained the more efficient of the CPUs. Framerate overall has come down, not only because of the CPU, and so it is natural that the FPS/W figure dropped. That’s normal with a settings quality increase and you can’t directly compare these numbers to the prior chart unless you’re comparing graphics efficiency cost, but comparing the two CPUs to each other does show that the hierarchy remains the same.", "Starfield is an interesting one because Intel leads this chart in framerate, as opposed to AMD’s X3D CPUs. You can see that here: The ", " ran at about 132FPS AVG, with the ", " at around 115FPS AVG. That should bias the math in Intel’s favor, depending on its power consumption, as it tips the framerate higher to potentially yield a better calculation. Note that this test was conducted before the recent massive patch, but all the data was done on the same game version and so is directly comparable.", "And... nope. That didn’t help. AMD, despite running generally lower framerate in Starfield than Intel, is still miles ahead for efficiency. The 7800X3D crushes it comparatively, with a 1.9FPS/W result. The i3-12100F does excellently here though, so it’s the true benefactor of the favorable Intel performance in this game. The ", " also makes an appearance alongside AMD’s ", " and ", ", so it too is doing well overall and gives hope for Intel’s efficiency.", "But it’s the high-end K-SKU CPUs that suffer. The 14900K gets 0.6 frames per watt. We had it at about 212W against the 132FPS AVG. We’ll check on how much of that is a result of the GPU work in a moment, as it’s feasible that a CPU still has to work hard to keep up with a GPU.", "As for AMD’s worst performer here, it’s the ", ". It’s just at a less efficient part of the volt-frequency curve.", "Let’s look at how busy that 14900K was with GPU scheduling. For this chart, we’re looking at GPU Busy, the new metric we’ve been talking about a lot lately. We have a couple videos talking about this in more detail (see ", ", ", ", and ", "), but the basics are that we’re showing you the total frametime from one of the test passes as mapped against the GPU Busy, or GPU Active, time synchronized. The closer they are to parity, the more loaded the GPU is.", "In this one, we can see that Intel is GPU-bound. The GPU is busy almost the entire duration of the frame creation process. That doesn’t mean the CPU is sleeping though -- and clearly it wasn’t, with that power draw -- and so the CPU remains busy and in a power state where it blasts power regardless. That could be because it’s busy tasking the GPU, but AMD in the same GPU-bound state in F1 did not produce this behavior. It could also be that the Windows telemetry that Intel is relying on is encouraging it to continue blasting power. ", "Here’s a look at AMD’s GPU busy in the same chart. It wasn’t as bound-up for Starfield, although in F1, it was hitting a similar GPU bind despite the lack of this power characteristic.", "We can control for this, though. We’ll run the test again, but this time with the 7800X3D and 14900K both restricted to 60FPS.", "In this one, the 7800X3D falls from 1.9FPS/W to 1.4, with its new FPS of 60 and its new power of 42.5W. The Intel 14900K scored 0.5FPS/W here, a reduction even from its already bad 0.6 result. That has it at 127W against a 60FPS AVG. To produce the same work and same experience in-game, Intel is drawing about 85W MORE total EPS12V power. We’ve now tested iso FPS and iso power for two different sets of CPUs. ", "FPS matching produces the same unit of work, so what this tells us is that whether Intel is GPU-bound, CPU-bound, or artificially engine restricted, it is less efficient in these titles.", "Baldur’s Gate 3 is up next. This one is interesting because it’s much lower power consumption on everything overall. The ", " and ", " were the highest FPS in this game, followed by the ", ".", "Here again, the efficiency advantage goes toward the X3D CPUs -- and that includes the ", " which isn’t anywhere near a GPU limit. The 14900K also wasn’t at its GPU limit, with the GPU Busy time well below our total frametime, and yet it remains the least efficient on this chart at 146W. The ", " is alongside it and at 135W. Intel’s most efficient point on the curve is hit with the 12100F, at 41W and a 1.6FPS/W result. The ", " is next in line for Intel.", "Blender is up now. You all already know this chart, so we’ll keep it short. We ran the 14700K at 86W limiter, which had it at about 91W, and the 14700K finally outperforms the 7800X3D. All we had to do was run it in a configuration most users won’t use. It produced a 12.1-minute render, a massive worsening from the baseline 14700K’s 8-minute render. This definitely slowed the CPU down, but it became more efficient.", "For 7-Zip, we’re looking at the compression performance against power consumption, represented as MIPS per Watt, or millions of instructions per second per watt.", "The 7800X3D leads this chart, despite middling performance for the actual compression rate. The 7950X3D follows it. Both of these are generally good bins with low vcore requirements, making them overall efficient here. The 5800X3D is next in order, then the ", ", then the 12100F. Intel’s 14900K performs the worst, at 707 MIPS/W, with the ", " and 14700K close behind. All 3 of these CPUs are in excess of 200W, with the 14900K approaching the 290-300W figure we saw in Blender when stock.", "Now for Photoshop. In this one, we only reran the 7800X3D and 14700K for new numbers, but with the 14700K restricted to the same power budget as the 7800X3D. Here, the 7800X3D outperformed the 14700K in overall score, which allowed it to outperform the 14700K in efficiency. Points/W directly correlates to Watt-hours as this is largely a time-based test.", "Let’s look at some 10- and 30-point averages. This section pulls the highest 10 seconds and 30 seconds of each test suite to look for spikes. These measure non-consecutive seconds, so it’s primarily averaging out spikes. This doesn’t go deep enough to look at transients.", "This also includes the time between and loading the tests, which can spike higher than the time in the game itself (and often does).", "In Phantom Liberty, the 7800X3D’s highest points were 70-73W, running relatively tightly together. The average of 61 is also nearby. The 14900K establishes a much wider gulf with its results: Despite an average during the actual workload of 196W, the load before and after the test loading interval pushed to 272W and 237W for those average peaks.", "The 14700K was around 202-241W, also higher than the average. This goes to show that it’s not only an all-core Blender load that’ll push a CPU towards its upper bound, but also every day work like loading applications, changing levels, or pulling assets for a save game.", "The 12100F was the lowest overall power draw, which isn’t surprising -- it’s a good CPU for its price class and isn’t that power hungry.", "In Starfield, the average peaks were about 68W for the 7800X3D, 79W for the 5800X3D, 206W for the 14700K, and 244W for the 14900K. So again, it’s not as high as the average during actual gameplay (which is shown next to each CPU name), but it’s high during those intermediary periods when we’re loading or preparing the game and benchmarks.", "In Baldur’s Gate 3, which was overall a middling game for in-game power consumption despite generally high focus on the CPU, we still saw high spikes in the Intel i7 and i9 categories. The 7800X3D was also a significant percentage higher than the average at 72W. The 14900K was around 235W to its 146W average in-game load power draw.", "Out of curiosity, we also did this for 7-Zip. We already know Blender is mostly stuck at the max power draw.", "Here, the 12100F shows us just how it looks when you’re already close to the max: 41W average against 42W 10- and 30-point non-consecutive highs.", "The 14900K was only 7W over its average with this measurement. The 7800X3D was also a couple watts over its average.", "This final section is just to put it all into perspective. Ultimately, how much the efficiency matters is up to you. On a scale of a single person, especially at our electricity cost here of $0.10/kWh, the difference in total energy cost is basically a rounding error. But for people in more expensive areas, or if you ignore cost and just look at global energy consumption impact multiplied across millions of users, it starts to matter more.", "This chart looks at the total cost per year in US dollars, calculated using our total shut-in gaming assumption of 8 hours per day with the heaviest game in our test (Cyberpunk). We used 6 rates that we found across a few online services that aggregate average costs in populous areas. ", "In our recent YouTube community post, some of you told us that you pay $0.45/kWh or more, like in Germany, so obviously the numbers can keep going up. Likewise, anyone with a variable rate should just assume the most likely time to be gaming.", "Starting at the extreme of $0.39/kWh, at 8 hours of heavy gaming load per day for 365 days, you’d be at a total cost of $70 for the 7800X3D’s power consumption, or $223 for the 14900K. This is maybe an instance where it could start to matter. Likewise, the 14700K at stock vs. 86W locked is approaching a $100 difference at $0.39/kWh.", "Where we live, we’re spoiled by cheap electricity from local nuclear plants. At $0.10/kWh, the annual difference at 8 hours a day would be $30 between the 14700K and 7800X3D. If you assume a more normal utilization of 2 hours per day, that’d be closer to $7.50 per year energy cost difference. The more expensive your electricity and the more you game, the more this might be relevant to you.", "We can’t fit every cost on the chart, but you can pull up a kilowatt hour cost calculator and run the numbers on your own. Remember that this is the heaviest gaming load we tested.", "In a lot of these scenarios, without any controls, AMD is not only producing better gaming performance in raw framerate, but at a lower power consumption. Since these two are directly related in a formula, that gives AMD an efficiency advantage in games. Even when we lock the power or the FPS, generally speaking, AMD appears to hold an advantage in gaming.", "Now, critically, Blender shows the ", " as gaining an edge when power constrained as opposed to the ", " -- although it also has a performance edge here. But that’s not true in every production benchmark: In Photoshop, AMD pulled ahead.", "Unfortunately for Greg, that paycheck's going to have to go because “every single workload” was the qualifying statement there and it was not better in every single workload. Sorry, Greg. You can keep the money or give it to ", ".", "Ultimately, we can create as many abstractions and calculations as we want, but it’s tough to argue that Intel is operating overall at a less efficient point in its V-F curve. The CPUs are blasting power to maintain frequency, which is what helps Intel hold a competitive position in gaming right now. Yes, we can modify the Vcore or reduce the power target, but at some point, it’s not fair to do that unless we also start undervolting AMD. It just becomes an arms race. Out of the box, generally speaking, AMD holds an advantage in efficiency. Even only tuning Intel, AMD is still overall competitively positioned or often winning.", "This testing was extremely educational though and we think there are a lot more metrics we can derive from it. Likewise, we think this might be something we can begin including long-term in our reviews process. It won’t be this many games, but we’ll probably pick one or two long-term representative titles and use them for these charts in reviews.", "We’ll also soon be updating our ", " for power consumption to include some of these metrics, as gaming consumption was one of the main requests (and we think it’s a completely valid and good one) to add to that page. We can look at idle next -- Intel should hold an advantage there since AMD’s IOD has a high baseline, but we’ll need to test that."]},
{"title": " AMD Ryzen 5 5600X3D CPU Review & Benchmarks: Last Chance Upgrade", "paragraph": ["AMD Ryzen 5 5600X3D CPU Review & Benchmarks: Last Chance Upgrade", "Last Updated: ", "The Highlights", "The AMD Ryzen 5 5600X3D is likely the last call for AM4 CPUs and, as we ", ", it’s an odd one. AMD didn’t have enough supply to make a global launch, but did have enough leftover or defective ", " to convert them into something. So they made the 5600X3D and gave it to ", " to launch.", "This launch was a total surprise to us and we had far less time than usual to get hands-on with the CPU, but we still put together a full review. This is a $230 part and, based on the original 5000 series numbers, that’d be an amazing price -- but the market has changed. In the time since the 5000 series was in our reviews, the R5 5600 non-X is now around $140 -- which is probably among the best budget CPUs available -- and the R5 5600X is about $170. The R7 5700X is about $200, making the 8-core option $30 cheaper than the new 6-core X3D CPU. AMD’s closest 7000 series CPU is the R5 7600, which costs around $215-$220, and the 7600X, which retails between $230-$250. This has become a dense market.", "Steve Burke", "Patrick Lathan", "Vitalii Makhnogvets", "Jimmy Thang", "The main market for this thing will be drop-in upgrades. That makes price comparisons tough if they’re not within AM4, seeing as telling someone “but just upgrade to an entirely different motherboard and RAM” is a much bigger jump than “consider another AM4 alternative.” We’ll review with this in mind, but still provide comparisons to fully new platforms in case you’re not upgrading.", "First up, some musings on the market: Now that we’re fresh on the pricing of last-generation parts, we’ve been wondering if maybe this is the way of the future for this market.", "We’re seeing a new trend where older parts are either stocked enough or remain in production long enough for companies to slow releases of low-end parts in the current generation and instead continue selling last-generation parts as a new form of ‘low-end.’ We’ve seen this with the 30-series NVIDIA GPUs also, where the company has continued selling RTX 3060s and 3060 Tis even with the 4060 series launches.", "This could just be the greedy over-purchasing that everyone did when expecting the pandemic sales to last for eternity, alternatively though, it also seems like a possible paradigm shift. The question is whether that’s a good thing: If the mid-range becomes the low-end one generation later, the economics may be better for companies. We’re not sure how it’d play out for consumers. Being one generation back isn’t necessarily bad if it also means you get to keep other cheap, older technology, like DDR4 (in the case of AM4), that pairs well with the budget market, but as we get past the DDR4-to-DDR5 switchover, it may be a worse outcome.", "Anyway, that’s just something we thought of while writing this post. We haven’t put a ton of thought into it yet, but figured it’d be an interesting discussion point. ", "As for the 5600X3D, we covered the full specs and launch details in our ", ". The shortest possible version is this:", "The 5600X3D is made of leftover or defective 5800X3D CPUs and is limited in supply. Micro Center is the only official retailer for it, which means it’s limited to specific areas of the US (not even just the US on the whole). Micro Center expects 3-6 months of availability for this part and informed us that AMD is only making one batch of these CPUs.", "The CPU is a 6-core/12-thread 5600X with lower frequency and higher cache. Overall, you should expect this to encroach on the 5800X3D in gaming performance, but lose capability against the 5700X or 5800X in production applications due to the core deficit.", "Now, this dropped in our laps with very little notice and after most of our team had scheduled vacations. We got as much done as we could and ran a few more CPUs through the charts to get comparisons. We’d like to have added the 13400F again and some other Intel CPUs, like the 13500, but we also weren't going to ask team members to pull extra hours without any notice whatsoever and after many had plans to travel. We still have a full review for you, we just want you to be aware of why the dataset is more limited. We’d typically have about 1 more full work week to process a review like this.", "Anyway, let’s get started.", "First, we’ll quickly look at a frequency plot versus the ", " to help give context to the performance figures.", "In an all-core Blender workload, the R5 5600X3D plotted a perfectly flat line at 4350MHz. That’s with an all-core workload. Technically, that’s 50MHz below the advertised boost speed. What matters is whether it can hit that speed in a single-core scenario, which we’ll look at next.", "The frequency behavior is much different when compared to the R5 5600X non-3D variant. The 5600X is more variable, falling gradually from a 4450MHz starting frequency down to about 4400MHz. That’s also below the technically advertised number, but that’s a result of two things: The first is that this is a first-round sample, and the second (more important) reason is that it’s an all-core load.", "Here’s a frequency plot with a single-core workload.", "In this one, the 5600X3D was still below the advertised 4.4GHz speeds. AMD isn’t hitting what it’s marketing. Being off by 50MHz is a pretty big gap. Now, technically, there are a few blips to 4400MHz or just past, but 6 plotted seconds of 500 doesn’t really qualify for hitting that marketing, in our opinion.", "The 5600X held about 4650MHz for the entire test, which actually exceeds the marketing by 50MHz. Unfortunately for AMD, the two don’t average-out. They need to hit the marketing every single time.", "Let’s look at some games.", "This next section will get into gaming benchmarks for the AMD R5 5600X3D CPU.", "We’re going to start with the two games where we saw the most uplift in previous X3D tests. Tomb Raider is up first, another game where we’ve seen massive uplift from 3D V-Cache CPUs.", "The 5600X3D’s 301FPS AVG pushed it into the company of Intel’s much more ", " and AMD’s own -- and more expensive 7700X at $300. The 5800X3D is 10% ahead of the 5600X3D, with only the modern 7800X3D (a $440 part now) ahead of that.", "Compared to the cheaper options, the gain of the X3D CPU over the 5600X is a massive 39%. The benefit against the 5700X is similar, as our recent rerun of that CPU had it at 221FPS AVG.", "Titles like this and Far Cry 6 are going to be the strongest cases for the 5600X3D since they allow it to encroach on the 5800X3D, but still have a significant gap from the far cheaper 5600 and 5600X CPUs.", "1440p promotes some movement of the top few parts, but overall, the 5600X3D still carves-out enough of an advantage to be worth considering even with a slight or inconsistent GPU bind. ", "In Far Cry 6 at 1080p, the 5600X3D ran at 163FPS AVG, boosting it 30% over the 5600X-non-3D, with lows also higher. As we’ve seen before, the V-Cache works in the right scenarios. The 5700X’s 132FPS AVG allows it good value positioning -- basically where the original 5800X should have been -- but the 6-core X3D still outperforms it significantly here. The extra cores are less helpful in this game.", "As for the 5800X3D, it’s still ahead of the 5600X3D and holds about an 8% lead. Lows are proportional. This makes the 5600X3D a seriously strong drop-in, end-of-life option for AM4. For gaming, the nearest AM5 price option is the 7600X, which is outperformed by the 5600X3D. Owners of existing builds would get one last gaming uplift with this without going up to the 5800X3D. ", "As mentioned early, we don’t have all of Intel’s current CPUs on here since this was a total surprise launch. The closest we have in our dataset right now is the ", ", which ran at about 176FPS AVG. That’s ahead by 8% and is sold about $60-$70 higher than the 5600X3D.", "As for 1440p, the results were the same: We’re not GPU-bound, so it makes sense that there’s no change in the middle of the stack. Only the 7800X3D shows any change, and it’s not much of one.", "Final Fantasy 14 is up next, tested first at 1080p. This gives us a look at some of the best CPUs for FFXIV.", "The gain isn’t as large here, but there’s still an improvement: The X3D part’s 210FPS AVG, 116FPS 1% low, and 83FPS 0.1% low allow it a lead over the 5600X in all 3 metrics. Frametime pacing hasn’t improved disproportionately, but in-step with the average. The boost is 18%, with the lead over the 5700X similar at 16%. Keep in mind that the 5600X’s $170 price means the X3D is about 35% more expensive right now. It’s late in the cycle, so remaining inventory is cheap. It’s a real gain, but you are paying for that performance.", "Compared to the ", ", there’s not much performance difference -- but the entire rest of the platform is cheaper or maybe even already in your possession. The 5800X3D is similarly not much of an improvement.", "Intel’s 13600K holds about a 21% lead here, keeping its trend of generally higher performance in this game.", "Like with Far Cry 6, there’s no change to the middle of the stack at 1440p. Actually, there’s basically no change other than some small movement: Even the 13900K remains about equal in performance. We’re fully CPU-bound.", "In Cyberpunk at 1080p, the 5600X3D posted a 22% uplift over the 5600X, with a slightly higher lead over the 5700X as a result of the higher base clock on the 5600X. The 5600X3D managed to outperform the 5900X and even the former flagship 10900K and is within striking distance of the 5800X3D. 3D V-Cache clearly still works even on a 6-core part -- and maybe even better, seeing as there’s no multi-chiplet complexity that we saw ", " that we didn’t even bother to rerun for these charts.", "We’ll skip 1440p. It was GPU-bound, so the 5800X3D and 5600X3D looked identical, as did most of the other high-end parts.", "CS:GO is next. Tested at 1080p, CS:GO had the 5600X3D at 346FPS AVG. That’s tied with the 5800X3D; in fact, even the lows are tied. Between these, we had 8 test passes and the end result is about the same. That’s impressively consistent, but of course, means that the 5600X3D is taking from the 5800X3D’s viability in this kind of title. Overall though, that’s true of the 5600X and 5700X as well. The 5700X is $20-$30 cheaper than the 5600X3D and manages the same performance in our retests, albeit with marginally longer peak frametimes -- but not noticeably. That makes the 5700X a better deal here. The 5600X is significantly cheaper and only gives up a 5% lead to the X3D, so it's an even better value. We don’t have a 5600 non-X retest, but at $140, it’s also worth a serious consideration as a budget option.", "Rainbow Six Siege recently updated. The update improved performance, which is good overall, but is bad for us. It wiped out all of our comparable data because the numbers no longer match the game’s current patch. We reran just the 3 most relevant AM4 CPUs for this test. Normally, we wouldn’t bother with a chart that only has 3 parts on it, but it’s still interesting data.", "The 5600X3D held about 600FPS AVG. For reference, in the pre-patch tests, the 13900K was over 800FPS -- there’s plenty of room for scale left here. That means the 5600X3D gained about 14% over the 5600X in average framerate performance, with lows also boosted. The lead over the 5700X is only 11% in this one.", "Up next is Stellaris. This was added by popular demand among our audience. We won’t be fully detailing the methodology today -- that’ll be our next major refresh of the test setup -- but the basics are that we’re averaging the turn time over multiple test passes. That’s as opposed to FPS. This is also new, so we only have 5 parts on this one -- all are AMD. We’ll add Intel to the next bench refresh. ", " managed to pull ahead of everything else tested so far. The turn time reduction against the 7700X was 6%, or 10% reduced from the 7700. As for the 5600X3D, that one required 38.5 seconds per turn on average. It allows the 7800X3D a reduction of 26%, but manages a time reduction of 13% against the R5 5600X.", "Now for F1 2022. In this one, the 5600X3D ran at 393FPS AVG, leading the 5600X by 27%. That’s another large lead over the namesake predecessor. That’s near the 5700X too, so the gain over the budget 8-core counterpart is similar. ", "Once again, the new X3D is near the 7600X -- close enough that the price wouldn’t be worth it if only for gaming performance. The 13600K ends up behind the 5600X3D this time, with the 13700K and 13900K contending against AMD’s impressive 7800X3D performance in this game.", "Now we’re moving on to production benchmarking, which includes applications like Adobe Premiere, Adobe Photoshop, Blender, and code compile testing. These scenarios are more core-bound, which means the 5600X3D will show its primary disadvantage as compared to the 5800X3D in these tests -- although technically, most of these X3D CPUs are worse than their same-part non-X3D counterparts in our production suite as a result of the reduced frequency.", "Blender is up first. In this one, loading the CPU cores with tiles to render, the 5600X3D required 22 minutes to complete the GN Logo scene. For reference, the 5800X3D took a little over 17 minutes, which is 22.6% faster. Although it’s not on here anymore, our last runs of the 5800X non-3D showed that it outperformed the 3D CPU marginally in most of these tests for its faster frequency.", "The 7600X posts a large 29% time reduction in this one. Despite being the same core count, the architectural and frequency improvements benefit it in a big way. If you do more of a mix of core-intensive workstation use with your gaming, that’d be where the newer same core-count CPUs would do better. The Intel 13600K also posts a large advantage, landing at just 11 minutes to render.", "Code compile of Chromium is next. For this one, the 5600X3D required 117 minutes to complete the compile. That’s almost identical to the 5600X, with the two within error. There was no benefit from the extra cache in this particular type of compile -- although there are workloads that can benefit from the extra cache.", "The 5700X ended up a better value here, posting a 96-minute result from its core count increase. Intel’s 13600K halves the time required by pulling a 55-minute result. The X3D still does fine here, it’s just not the reason you’d buy it.", "In Adobe Premiere, testing live playback, renders, filters, and other features, the 5600X3D scored 869 points in aggregate. That has it ahead of the 5600X by 50 points, or 6%. That’s a real lead -- it’s just not much of one or particularly worth it for the money. The 5700X manages an 8% lead over the 5600X3D while being cheaper, making it better value between only AMD options. Intel’s 13600K remains a competent performer -- as do the 13500 and 13400, although we haven’t rerun them recently -- and lands in the top half of the chart.", "In Photoshop, the R5 5600X3D scored 1120 points in aggregate by using a similar approach to the Premiere test suite, both with Puget’s tools. That result has the 5600X3D technically ahead of the 5700X, but realistically, they’re the same. The lead over the 5600 is outside of error and is about 1.7%, but nothing meaningful. That’s consistent with the other workstation tests. Intel’s more expensive 13600K is significantly ahead at 1489 points, or a 33% lead. The 5800X3D is ahead of the 5600X3D as well, establishing the core advantage.", "Here’s a quick look at CPU power consumption. In this test, the R5 5600X3D pulled 74W in an all-core Blender workload. That has it the same as the Intel 13400F and insignificantly more than the 5600X. As a reminder, the 5600X was the most efficient CPU we’d tested back when it launched, and so that translates well to the X3D: Keeping roughly the same power consumption but increasing gaming performance is an uplift overall.", "The 5600X3D definitely does what it’s supposed to: As we’ve seen with past X3D CPUs, it maintains similar power characteristics to the non-3D variant, but with higher performance in gaming, which means better overall efficiency. This is likely an upgrade for people. The biggest competition for AMD right now is its own parts, especially for the upgrade market seeing as how jamming an Intel CPU into an AMD socket isn’t recommended.", "The R7 5700X at $200-$210 is mostly worth considering if you want to save more money or if you mix in a heavier dosage of workstation applications. You can find ", ". Overall though, the 5600X3D does outperform it in games.", "The lead over the 5600X is anywhere from 10% to 40%. The upper end of that is impressive and enough to consider. The 5600X at $170 is a good price though, and for ultra-budget buyers, ", " also makes sense as an upgrade from an older generation AMD CPU.", "Intel’s closest competition would be the 13400 at $230. We have charts for that in our ", " and you could extrapolate the comparison with good accuracy. ", "AMD’s Ryzen 7000 parts are mostly defeated by the 5600X3D in price-for-price comparisons except for in workstation applications.", "AMD also misses the advertised frequency by 50MHz, which is unfortunate, but not a deal-breaker. We just need to stay on them about that so they don’t slide backwards."]},
{"title": " Starfield CPU Benchmarks & Bottlenecks: Intel vs. AMD Comparison", "paragraph": ["Starfield CPU Benchmarks & Bottlenecks: Intel vs. AMD Comparison", "Last Updated: ", "The Highlights", "Today we’re benchmarking CPUs in Starfield. This content became a lot more interesting than just a CPU benchmark. As a matter of fact, the CPU benchmarks were done in one really long day, but we added a lot more time to start exploring GPU Busy, which is the new frame time metric that we were talking about with Intel engineer ", " recently.", "In terms of CPUs, we’re going to be looking at a bunch of SKUs, everything from the AMD Ryzen 2000 series up to modern CPUs like the ", ". On the Intel side, we’re looking at the company’s 12th and 13th generation processors. We also spent some overclocking time using the ", " just to try and see how much clock scaling there is in addition to CPU core count.", "There’s a lot of real cool stuff coming your way. GPU Busy, in particular, will be a lot of fun to go through because it’s a new type of metric that we can learn from.", "Steve Burke", "Patrick Lathan", "Jeremy Clayton", "Vitalii Makhnovets", "Our key focus will be on CPU benchmarking and that entails building a CPU bottleneck. In order to do so, we use a high-end GPU and high-end memory. Throughout this process, we also tested some memory bandwidth situations with the ultimate goal being to try and isolate as much load as possible onto the CPU.", "It’s worth noting that at the time of this write-up, the game is only a few days old and it’s not officially launched yet, we expect there’s going to be a major patch at some point in the near future.", "We've seen efforts to explain why the ", " performs nearly the same as a ", " in Starfield, including theories about poor NVIDIA driver optimization based on low GPU utilization and low power usage (percent TDP). We're not testing those theories in this video: this piece is about CPUs, and the ", " is still one of the best choices for benching CPUs. ", "Some of the community discussion has centered around GPU-Z showing “100%” utilization for the GPU despite having lowered “TDP” reported in GPU-Z. We’ve also seen some discussion around low Windows task manager GPU utilization despite being seemingly GPU-bound, e.g. at 4K/High but showing 30% task manager GPU load on NVIDIA (or something). We won’t get into this today, but task manager uses a simple method for reporting this utilization. There may be one part of the core, like graphics_1, at 100%, but task manager will represent the total GPU utilization in summary as a much lower number.", "Likewise, it’s possible for a GPU to be 100% loaded on one specific component and not pull full power. ", "Regardless, we did a lot of utilization testing and ultimately determined that, for purposes of a CPU benchmark, we were in fact largely CPU-bound except possibly at the very top-end (like 5.9GHz on a ", "). The game’s behavior is objective and testable even if it isn’t fully “optimized,” and the numbers are what the numbers are. ", "Now we get into some super exciting new data. We’ve never previously produced charts like what we’re showing today and we’re really excited to do it. We’re using the latest update to PresentMon, an open source tool, to illustrate the GPU/CPU load split in Starfield. ", "A massive disclaimer here: This is a brand new type of data presentation for the reviews industry. As such, because we’re trying something new with data we didn’t have before, it’s very likely that these charts and our understanding of them will change with time. ", "As we get into this: We verified that using the command line version of this tool has no impact on performance metrics, but there are some specific conditions that need to be configured to minimize impact. We did that configuration.", "We’ll start with the ratio chart first, then go to the roots. This is a little backwards but, from an educational standpoint, we think it’ll make it easier to absorb the objectives of this data. One very important thing: THERE IS NO “BEST” in this chart. It depends how you want to interpret it. If you want your GPU to be fully utilized, then a 1.0 result would be the “best,” but your CPU will be underutilized. You’re always going to have a bottleneck somewhere. But it’s just about balancing the component expense to try and maximize each part without leaving a lot on the table. There’s a lot more going on within the frames that we can’t see yet either.", "Now, there’s one large important thing here: GPU Busy can still show as high, or as GPU-bound, even if the GPU isn’t actually bound. Remember that while we walk through these charts. That’s going to be really important, because the GPU actually isn’t being fully utilized by Starfield. We’ll come back to that.", "This chart shows the ratio of total frametime against GPU busy time. The maximum value is 1.0. In this chart, the closer the blue bar is to 1.0, the more GPU utilization we’re seeing. The red bar indicates non-GPU work per frame rendered, whereas the blue bar represents GPU occupancy or busy time per frame rendered. A shorter blue bar means less GPU utilization as a result of the CPU being overloaded, which tells us that there’s an imbalance in the resources for the game.", "So, for the ", ", we can see a 0.57 ratio of average GPU Busy divided by average frametime. What this chart tells us is that our 1080p/low benchmarking will bind every component heavily on the CPU up until about the ", " and 13900K, where we’re beginning to occasionally bounce off of a GPU bind. That means these parts are close to their maximum scaling in the CPUs before we get limited methodologically in our ability to demonstrate a meaningful difference.", "Let’s look at the raw data. This will set the groundwork for future use of this, so you’re seeing the development of a new paradigm for us. We’re excited for it because we’re not sure where it’s going yet, but we can see the foundation for something useful.", "This first chart is for the ", " at 1080p/low. This is just a snapshot of 500 frames from the test -- we have a lot more, but limited the X axis to make it easier to read. The average FPS for the entire set of 4 passes came out to 81.8 out of a maximum on this GPU of about 145. The distance between the red and blue lines indicates that, in this chart at least, we’re CPU-bound. The GPU is not fully occupied during the creation of these frames and has time that it’s waiting on the CPU.", "Let’s go to the opposite viewpoint: Here’s the 13900K at 1080p/low. We’re using a much higher-end CPU. The lines are almost on top of each other, aligning with our 0.95 ratio earlier. This indicates that our GPU utilization is much higher than with the 13100F -- which makes sense, seeing as it’s a 4090. The overlap tells us that we may not be able to see a fully decoupled framerate out of the 13900K at 1080p/low because we are still at least occasionally hitting a GPU bind.", "The cool part about this is that it helps us frame our writing around the data: We can now more confidently indicate to you all whether we’re actually GPU-bound or whether we’re just capped on the CPU. In this case, we’re approaching and sometimes hitting a GPU bind, which means (of course) that the 13900K might be able to stretch a little further and distance itself from the rest of the pack slightly more if only it had a GPU that doesn’t exist or was on ridiculously low settings.", "And now for those settings: Here, the 13900K at 720p/low -- which we recognize is a completely stupid combination of things, but is useful as an academic exercise -- is now establishing a gap between the GPU Busy and Frametime lines. This reinforces our earlier newfound understanding: The lower the ratio, the lower the GPU utilization. The higher the ratio (or closer to 1:1), the higher the GPU utilization.", "Let’s look at one last one.", "This is the 13900K at 1080p/ultra, so we’re definitely GPU-bound. Here, the lines are effectively right on top of each other. The ratio for this result was 0.99. It is effectively fully GPU-bound.", "This stuff is crazy cool and we’re really excited about it. It’s a paradigm shift in the making for component benchmarking, and the industry is only just now at the front edge of figuring out how that shift manifests. We’re excited to see where the reviewer community goes with it, and on our side, we’re already planning to integrate it with most of our content going forward. Make sure you watch our ", " to learn more about the render pipeline.", "As for what all this tells us: This game becomes very GPU-heavy (and rapidly) as settings increase. There’s not much of a middleground transition. It tends to be either GPU-heavy or CPU-heavy at the extremes of the settings.", "Coming back to the utilization thing we talked about: We saw when the game was GPU-bound vs bound by other components. But the GPU utilization is suspect.", "Buildzoid shared a theory after seeing CPU tests from another outlet that there may be a utilization issue in regards to RAM, so we dove into that.", "For our tests today, we’re not memory-limited on our CPU benchmarks. We did see some other numbers online that used very low-end memory, and in that case, they are memory bound. We think it was PC Games Hardware that used DDR5-4400 in their charts, which would be a limitation. Buildzoid is absolutely right about that. That’s still valid information, but it does restrict the scaling on the CPUs alone to more complexly include memory as part of the limitations and become more of a memory benchmark. What that test taught us is that memory can impact Starfield in large ways, so we wanted to make sure ours wouldn’t for a CPU comparison.", "We didn’t spend much time on memory and only used a few different kits to rapidly see if there’s any meaningful change with our test setup. All we care about is eliminating as much of the memory and GPU bottlenecks as possible to focus on the CPU to see scaling. We also talked with Buildzoid about some of these theories -- we’ll come back to that after this chart.", "First, here’s the chart at 1080p/high with a 13900K. Here, you can see we are completely bound on non-memory components -- that’ll turn-out to be the GPU, as you’ll see later. Memory did not affect our results outside of run-to-run variance here.", "Here’s our 1080p/low chart. We didn’t do any tuning here. Our standard kit is the DDR5-6000 Corsair kit at 30-36-36-76, which we use in all our CPU reviews and tests. As you can see, it was within run-to-run variance of the DDR5-6400 kit at 32-38-38-76. We also have a custom V-Color kit that the company gave to us when we visited previously. As far as we’re aware, it doesn’t have an existing SKU on the market. At DDR5-7000 and 38-48-48-126, we were within error of our prior two kits. We had one more test at DDR5-5600 -- this is worse than our standard Corsair kit. After seeing no change in the prior tests, we decided to leave the looser timings and drop the frequency to see what happened. Here, we did get movement -- and a lot of it -- but what really matters is that, for our testing, we do not appear to be memory-bound.", "As for the SK Hynix kit, for that, Jeremy on the team manually configured it at DDR5-6400 and 34-40-40-84. This is a dual-rank kit, so we used it just in case. Ultimately, although technically higher in framerate, it fell within our usual run-to-run variance.", "If you were to run DDR5-4400 or some other slow speed, you’d probably get bound-up on a higher-end i9 CPU. This test isn’t definitive and it wasn’t our main goal to do a memory test with Starfield. All that mattered to us was determining if our standard memory kit was meaningfully limiting us from showing CPU scaling, and that answer is “no.”", "We spent a couple hours working with Buildzoid on the next ideas. Although memory can still be a factor in our testing, we began looking elsewhere. He suggested a few tests:", "We tried each of these independently and combined with help from Buildzoid to dial-in the overclock settings for rapid testing. Here’s what we came up with. This testing was done with our SK Hynix kit, which is different from what we’re using later in the charts. This testing is also done with 50% scaling against 1080p with FSR2, which is an abominably low resolution and some of the worst visuals we’ve seen in a video game -- BUT it’s intentional. We wanted to ensure we were not GPU-limited.", "Our baseline result with these settings was 147.9FPS AVG. Disabling hyper-threading hurt the 0.1% lows, but did not affect the average framerate. Overclocking to 5.9GHz with HT off boosted us to 155.4FPS AVG, an increase over stock of 5.1%. It appears we’re clock-bound. Adding a cache overclock to 49x boosted us to 156.1FPS AVG, mostly error of the prior result but possibly an improvement. Disabling E-cores hurt the performance to below stock, even in spite of the overclock -- although it’s possible that E-cores off with hyperthreading on produces a better result.", "We also ran these numbers with an ", ", yielding about the same maximum improvement over the 4090 as we saw in our tests earlier -- about 3.7%. But the improvement over baseline indicates that we were CPU clock-limited and overclocking helped here.", "One thing we learned is that we were definitely clock-bound at the upper-end of our results, not GPU-bound. Now it’s time to get into the CPU benchmarks we’ve been promising.", "Remember that these are accurate as tested regardless of the game or the driver’s issues right now. These still give you insight as to how it performs. We expect this will change as they patch things, so if you’re reading this in the future, you may want to check if we or others have newer data.", "For this testing, we’re using 1080p/low as the extreme to show full scaling, then 1080p/high to produce a more realistic use case. You could estimate that medium would be in between.", "Here’s the chart where we get the most scaling, but at the least realistic settings -- and that’s fine. We’re starting with the pure scaling. That helps people on older hardware have a better idea for limitations. And most of this hardware is going to be bound by the CPU, not other components -- especially the older stuff. Anything with DDR4 is on our prior CPU test methodology kit that we’ve previously shown to be a strong performer.", "At 1080p/low, we’re starting to become limited at the 13900K level, with the ", " occasionally hitting that limit. This would be boosted with an overclock, as we saw earlier. The ", " establishes the floor, at 54 FPS AVG with these settings. To bring attention to a few other older mainstays, users of the ", ", ", ", and more modern ", " and ", " have plenty to gain if running on lower settings or overpowered on the GPU.", "X3D CPUs don’t appear to offer as much of an advantage as we’ve seen in other games, with the 7800X3D capping out at 124FPS AVG, leading the ", " by 15%. The ", " struggles with its usual oddities, despite using the core parking behaviors and the specialized OS setup that we detailed in our ", ". It’s OK, but not scaling for the price.", "For some other comparisons, the ", " leads the ", " by 20%. The ", " leads the 7700X by about 10%, with the 13900K leading the ", " by about 18% until we start becoming bound on other parts.", "Let’s move to more realistic but GPU-limited settings.", "At 1080p/high, we’ve lost about 22FPS AVG off the 13900K’s ceiling and we’ve truncated the ", " in the process. There’s also a 13900K with a 7900 XTX on here, where we gained about 3.7%. But we used the 4090 for our tests because this is our standard CPU review GPU, and given the general proximity, we still get most of the scaling here while being able to remain consistent for our future CPU test suite.", "The 13600K and down have lost some framerate from the average, but overall, we were CPU-bound before and we remain CPU-bound now for those CPUs.", "Compared to other modern titles, we’re definitely running at a relatively low framerate for 1080p and no ray tracing. This game is heavy and there probably is a lot of room for optimization both at the driver level and the game or engine levels -- especially since the engine remains a Frankensteined Bethesda monster.", "When we did a quick validation test at the beginning of this work, we saw that the 7900 XTX and 4090 were within about 3-4% of each other even at a ridiculous 720p/low. This represents to us that, for purposes of selecting a GPU for a CPU-bound specific set of tests, either is fine. 720p/low is an incredibly low GPU load, obviously, and yet we were at the same framerate. By traditional understanding, this would tell us that the GPUs cannot differentiate themselves because the CPU is dictating the performance ceiling -- that’s useful here, since this is a CPU benchmark.", "We ultimately stuck with the 4090 because that’s what we use in our standardized CPU reviews.", "Wrapping things up, we learned that at the very top end, you can definitely be clock-bound, which indicates that there are benefits to overclocking.", "Starfield, in general, is very GPU heavy. At higher settings like 1440p and above or if you’re using high to ultra settings, you will more likely be GPU bound, but in situations where you are more CPU limited, say if you’re using an R7 2700, 3700X, 12400, ", ", or something like a ", ", you have some options. In cases where you have an unlocked CPU like the older Ryzen stuff especially, we think if you haven’t yet, it’s a good time to explore overclocking because you can actually get some clock scaling benefit here.", "For people considering new purchases, there are a couple of takeaways. We saw on modern architectures that there’s some core count scaling between six core and eight core CPUs. It’s not huge but it exists so there’s some benefit there, particularly on AMD. On Intel, using a ", " or ", ", you’re more likely to start bouncing off of a GPU limit because you’re realistically not going to be playing at 1080p low settings, since we imagine you’ll try to push the graphics a little bit more on your system; otherwise your rig would be wildly imbalanced in terms of components. If you intend to play at something like 1080p high or 1440p with reasonable settings, then the 13700K and 13900K will be very similar to each other. The ", " is also pretty close to them as well in those more graphics-intensive scenarios."]},
{"title": " Intel is Desperate: i7-14700K CPU Review, Benchmarks, Gaming, & Power", "paragraph": ["Intel is Desperate: i7-14700K CPU Review, Benchmarks, Gaming, & Power", "Last Updated: ", "The Highlights", "Making a new generation of product is hard. It requires years of development, engineering feats amounting in new CPU architectures, and sometimes it even needs new process nodes. Intel’s ", " does NOT represent that ethos.", "Out of the recently released ", ", ", ", and 14700K, the latter represents the only processor in the lineup of 3 that is remotely interesting. That’s because it has more cores than its predecessor, the ", ", moving to 8P/12E/28T from 8P/8E/24T. ", "This CPU launch is Intel’s attempt to buy time while it works on its next actual architectural generation. We think the company was caught off-guard by how well AMD’s X3D CPUs (like the ", ") did in the gaming market, and now they’re scrambling to shove anything out the door to try and retain some of those buyers.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Tim Phetdara", "Patrick Lathan", "Intel’s new processors are called “Raptor Lake Refresh.” Instead of using the same generational naming though, Intel wanted to make the 13 a 14 to sound better -- so they did that, immediately setting expectations of something better than a couple percentage points of uplift. The “new” CPUs have higher clocks, but the 14700K in particular is different. It climbs from an 8 P-core, 8 E-core, 24-thread configuration to an 8 P-core, 12 E-core, and 28-thread configuration. So it has an extra 4 cores -- they’re E-cores, but they’re still cores. Those extra E-cores will mostly be useful in fully threaded applications like Blender, but will be of limited usefulness in games.", "Frequency also climbs: Intel says its max turbo frequency is now 5.6 GHz, up from 5.4 GHz on the 13700K. Likewise, E-core turbo has climbed 100MHz. The base clock is the same, however.", "Cache has also increased (which makes sense, since the core count increased). The official ", " claims an increase of 4MB in L2 Cache. The TDP remains the same.", "The new CPUs land at the same MSRP as the original 13 series parts, but the 13 series has been reduced in price since launch.", "That’s $440 or so for the 14700K at launch, although it has been ", ", $415 at launch for the 14700KF, but now ", " is cheaper, and $625 for the ", ". Unfortunately for Intel, its own 13 series parts are not the prices they were at launch: The ", " can regularly be found for around $550 to $570, with the ", " ", "So instantly, Intel will struggle to fight its old value.", "But we need to look at the current landscape for pricing for any of this to matter.", "Believe it or not, the ", " (Amazon) is still ", " (Newegg). You can check out our review of that chip ", ". You can typically find AMD’s 8-core, 16-thread CPU for around $320, making it one of the best values on the market -- especially as a drop-in upgrade for AM4 users. That's fierce price competition against Intel, especially if you eliminate the need to purchase a motherboard by making new use of an older AM4 platform. The ", " is another relevant competitor and one that we reviewed ", ". That CPU typically goes on sale for under $400. ", "Our power consumption tests will start with a chart showing only the Intel i7 series, then we’ll look at the comparison. We’ve been fortunate to collect power data on over 150 CPU configurations over the years, so we can start splitting that into different charts.", "This test looks at all-core power consumption in a Blender workload.", "In an all-core workload with Blender, the Intel i7-14700K consumed 284W at the EPS12V rails during the test. That’s power to the CPU and VRM efficiency losses, not total system power -- so it’s a power-hungry chip. But not much different from the 13700K, which itself was around 280W. The Raptor Lake generation is the most power-hungry in all-core of the i7s.", "If we look back further, the ", " pulled around 158W in the same test, around the same as last gen’s ", " (shown in the next chart). Going back further, the ", " was around 126W, although using various BIOS options would push it closer to 200W, but 126W was the Intel guidance. The ", " overclocked pulled about the same, or 78W when stock. The ", " was about 84W. As a final reference, the ", " -- the oldest currently on this chart, although we have other prior data -- pulled 83W.", "The 13700K kicked it into a higher gear, and the 14700K followed. The extra few watts is close enough to call them the same.", "Here’s info on many more recent options, including competition.", "The Intel i7-14700K outdraws the 7950X and its 263W consumption by an impressive 20W -- and not the good kind of impressive. The 14700K also outdraws the 12900K. AMD’s most dangerous competitor in gaming would be the 7800X3D, which pulls just 86W for the same workload. ", " remains relevant as well, plotted at around 108W.", "At the uppermost-end, the 13900K ran at 295W when stock on the test platform we used. These numbers come down in gaming, of course, but they come down uniformly. Intel is pushing power hard for all-core boosting now. High-end coolers become more of a necessity than they were a few generations ago.", "Energy efficiency is next. This is calculated by taking our Blender time required in minutes and running a simple watt-hours calculation against the power consumption. The end result is the energy consumption required to complete a full render -- so faster is better in isolation, but depending on the power consumption, it may be less energy efficient.", "The 14700K ranked at 37.7Wh in this calculation. Lower is better, so that has it less efficient than almost everything else on the chart. It’s at least improved over the 13700K, dropping from 42.4Wh previously. Even if the 14700K is faster than many of these CPUs, it’s also pulling more power to complete the same work. Whether that matters to you is a personal choice: If you need the fastest thing possible, or the fastest in a budget, power is often one of the sacrifices. If you’re running these all the time though and are concerned about the power bill, this is a factor to strongly consider.", "We’ll talk about raw performance separately, but some high-end competitors would include the ", ", which is one of the most power-efficient CPUs we’ve ever tested. Its binning was phenomenal and the voltage requirement was low. The 7950X also scores significantly better than the 14700K in efficiency.", "Intel’s all-core power efficiency is currently behind AMD’s. AMD remains impressive here. And check out our prior ", " to see where it does even better.", "Rainbow Six Siege is the first title in our line of game benchmarks. This game has some insanely high FPS ceilings, so it makes for an excellent tool to compare CPUs.", " blows way past everything in these charts, setting a ceiling at 717FPS AVG -- that’s impressive for the AMD CPU, especially considering it’s been $350 on US retailers lately.", "The 5800X3D is next in the running, at 650FPS AVG. These numbers are crazy to even talk about. The lows are relatively consistent, especially considering how high the FPS is here. ", " is functionally tied in average with the 5800X3D -- you’ll never notice that difference. Lows are technically higher, but given the standard deviation of 1% can be as high as 10FPS in this particular game, depending on which set of runs it is, these end up roughly tied.", "Generationally, the 14700K is tied with the former flagship 13900K. It’s within 1% of ", " (which is currently $300 to $330), and it’s ahead of the prior 13700K by 1.8%. That’s a shockingly boring lead for the 14700K over the 13700K. Just from this game, you’d want to buy whichever is cheaper.", "Users of the R5 3600 would see an uplift in the range of 80% -- more if you’re on older Ryzen generations -- but then you might as well get a 5800X3D and keep the same motherboard. Your cost would be way lower.", "At 1440p, AM5 leads again: We’re bouncing off of a GPU bind at the very top-end, with the 7800X3D and 7950X both restricted by the 4090 (as evidenced by the reduced maximum framerate). The 14700K isn’t quite there, instead ending up in a cluster with the 7700X, 13900K, 5800X3D, and most of the other high-end CPUs. Its lead over the 13700K is once again irrelevant, unfortunately. But this goes to show that even at 1440p, there can still be scaling with modern high-end GPUs.", "Most of these are functionally the same though: The 7700X equals the 14700K, for instance.", "The F1 series has been in our bench for years at this point and F1 2023 is another game that generally scales well across CPUs and GPUs alike, plus ray tracing inclusion makes it a good test candidate for GPUs.", "Looking at the 1080p results for CPUs, the 7800X3D leads once again -- it’s at 511FPS AVG. The lows are slightly reduced versus other CPUs, but not meaningfully. The 5800X3D is also in the upper echelon of CPUs here, hanging on to a podium finish with a 452FPS AVG result.", "The 14700K’s result places it down at 407FPS AVG, ahead of the 13700K by a “whopping” 4.4%. ", "At 1440p, the 14700K’s “mind-blowing” technological prowess strikes even harder: This time, we’re seeing a 4.19786096256684% improvement in AVG FPS over the prior 13700K. That’s almost as many numbers as an AMD mobile CPU name.", "The results overall on this chart have come down, even those which were more distant from the GPU bottleneck. We see that with the 5800X, which dropped about 20FPS AVG off of its 1080p result. The 14700K is functionally at the top of the chart, though -- it’s hitting limits, as are the 7800X3D, 7950X, and other nearby neighbors. ", "Baldur’s Gate 3 is brand new to our test suite, but we already studied it extensively in our ", ". That video also goes into detail on GPU Busy metrics for Baldur’s Gate 3, plus some information on Vulkan versus DirectX 11. The standard deviation run-to-run for all our CPUs averaged out to 0.9 AVG FPS, 1.4 for 1% lows, and 4.1 for 0.1% lows, so Baldur’s Gate 3 is remarkably consistent and makes for an excellent CPU benchmark.", "At 1080p with Dx11, the 14700K ran at 106FPS AVG -- slightly behind the 13900K and about 1-2% better than the 13700K. Unfortunately, the 14700K multi-classing into more E-cores didn’t benefit it here. Like a mimic deep in Undermountain, the 14700K looks like the healing potion that Intel needs -- until you realize you only get to roll 1d4 on use. And subtract 1.", "It’s not a bad CPU at all, but it’s not a meaningful improvement in this game. If you were buying Intel no matter what, the choice between the top 3 Intel performers doesn’t matter in this game benchmark. The X3D CPUs, meanwhile, blow past everything.", "At 1440p, standard deviation is even lower for the 1% and 0.1% lows (and about the same for AVG FPS). The results are slightly impacted, but overall, we’re looking at even scaling. We’re still effectively completely CPU-bound. There’s nothing new to see here -- just another 1d4-1 health potion.", "Cyberpunk: Phantom Liberty tests are next. These are brand new to our test suite. As nice as it looks, we’re not using any ray tracing options here -- that’d create a GPU bind in most scenarios, and we want to see CPU scaling.", "Now, this game has a specific setting of importance: The SMT toggle has been updated in recent patches and now should automatically toggle off for some CPU configurations. According to CDPR, the SMT option will flip when core count is under 8 cores. We had the option of forcing SMT on for all CPUs, forcing it off, or following the behavior that will result in the best performance as according to the game’s native behaviors. We decided to use the SMT toggle on “auto,” which is a dumb toggle that flips at 8 cores. If running a 3600, SMT will be enabled. This allows each CPU to maximize its performance but in a predictable way -- it’s not a random auto.", "Here’s the chart. Unfortunately for Intel, in this one, we just didn’t see any scaling with the 14700K. The results are within error of each other. AMD is pulling far ahead with the 7800X3D again. The gap is 24%. The 7950X3D has some terrible 0.1% low behaviors in this title, but the 7800X3D is doing well, as is the 5800X3D. The R7 7700X also leads Intel.", "1440p has the same lineup -- we’re mostly bound by the CPU, which is good for scaling. The top of the results get truncated a little bit from the resolution increase.", "Final Fantasy remains one of Intel’s strongest games, so this should be a more beneficial test for the new CPUs.", "X3D doesn’t trend as high here: You’ll notice that the 5800X3D and 7800X3D are bound-up at effectively the same framerate. ", "The 13900K leads this chart until we run our 14900K review (which will be on the channel within the next 24 hours). It holds a 2.3% lead over the new 14700K, which itself rests near 256FPS AVG. Now for the exciting part: That’s a “staggering” 3.18% better than the 13700K. ", "If you’re choosing between a 13700K and 14700K and they cost exactly the same, then the 14700K is the better CPU. But otherwise, this isn’t convincing enough on its own.", "The 1440p results were the same. We’re CPU-bound, so we still see scaling even at the higher resolution.", "In Stellaris, we’re testing simulation time measured in seconds across 4 test passes. This isn’t an FPS benchmark, but a time benchmark. Lower is better.", "Unfortunately, we’re just not seeing scaling past about 30-31 seconds. Everything hits a wall, and the jumble at the top doesn’t actually mean any CPU is better than the other, just that they’re all the same. We’re using a late game state for this, so it should be fairly intensive. That said, we want to experiment with some other ones. This game has a lot of potential since it scales great above the 31-second mark -- just look at the gap from the 2700 to the 7700X. We want to experiment with some more save game files, so if you have a really late-game save with a lot of complexity and if you want to see us continue to use this test, please email it over to us at ", ". We’ll see if we can force some more scaling room.", "For now, the 14700K and 13700K are about the same -- a far, far cry from our “staggering” 3% differences we’ve seen so far.", "Speaking of space games, it’s time to go to one that needs some more work. Starfield is new to our CPU test suite. We’re testing using the latest version of the game as of October 11th.", "Our first test begins at 1080p/low. The 14700K ran at 126FPS AVG, posting what was, unironically, the most exciting result so far: A 7.6% improvement over the 13700K.", "This puts the 14700K near the 13900K and technically ahead of the 7800X3D. AMD’s CPUs generally run slower in this game, with Intel largely controlling the top half of this chart.", "At 1080p/high, we saw a similar lineup but with a truncated top-end for performance. Nothing that stands out here, so we’ll move on.", "Now we’re on to production benchmarks. These actually show some double-digit improvements -- not always, but at least we see them sometimes. These include tests of Adobe Premiere, Blender, file compression and decompression, and more. ", "We’ll start with Blender, the 3D modeling and animation software. ", "The i7-14700K finished in 8 minutes here, improving upon the 13700K with a 12% reduction in time required to complete the render. The 13900K still outdoes the 14700K by 9%. This is because Blender will use every thread given to it at 100%, so we see more scaling. ", "AMD’s closest competitors would be ", ". It leads and represents a 20% reduction against the 14700K. That CPU costs roughly costs $590 right now.", " is next and gives up a 7% lead to the 14700K.", "File compression and decompression are measured in millions of instructions per second.", "In compression, the 14700K completed 171K MIPS. It’s 9% ahead of the 13700K here. It’s still just an overclocked 13700K, but at least it does something in production. The 7900X is AMD’s closest price competitor, with the 14700K ahead by 4.6%. The 7950X leads by 12%.", "Decompression is interesting since the stack sometimes reshuffles. Here, the 14700K gets led by the AMD 5950X from a generation ago -- and by a lot at 17%. The 14700K improves over the 13700K by 12%, but losing to last-gen AMD isn’t a great position. ", "The next chart looks at the best CPUs for Adobe Premiere. This is scored in aggregate with the Puget bench. The 14700K scored 822 points, outperforming the 13700K by 3.1%. We’re back to those “groundbreaking” numbers we discovered earlier. The 7950X leads the 14700K by about 1% -- there’s not a ton of difference at the high-end in this one.", "Adobe Photoshop had the 14700K at 1548 points in aggregate, functionally tied with the 13900K and 7900X. The top of the scoring in this one isn’t spread out much. The lead over the 13700K was 3.5%.", "Intel’s latest 14000-series CPUs were less the savior than we thought they were going to be, specifically the ", " with its higher core count. It’s 12 percent time reduced versus the 13700K in our Blender test, and that’s not bad, but that’s only in a single productivity test.  ", "If you’re thinking about buying either the ", " or the 14700K, you should look at pricing. For gaming, the 14700K does not justify the price increase as it offers virtually the same performance and currently costs roughly $36 more. For example, the 1.8% lead the 14700K showed over the 13700K in Rainbow Six Siege is so small that you might see a similar delta if you ran it up against another 13700K.", "And even to this date, AMD largely holds a lead in gaming with its X3D CPUs. Anyone building a new system should strongly consider the ", " (if primarily for gaming), as it's a direct alternative in price to the i7-14700K, but often better in gaming. Owners of AM4 (or anyone trying to build a more budget-oriented gaming PC) should seriously consider ", ", which has managed to remain available and in a dominating position in the gaming market.", "In productivity tasks where you might get some uplift, then we suppose it’s worth considering the 14700K, but you should know it’s not a great value overall. Intel’s older ", " offers some stiff competition, not to mention AMD’s current crop of CPUs. ", "This wasn't a good launch for Intel. It comes across as desperate and weak and reminds us a bit of the company’s 11th series processors, which offered maybe one decent CPU -- and we almost forgot about that series. If, however, you look at the 14000 series chips as slightly pre-overclocked CPUs, then you won’t be disappointed because that’s what they are."]},
{"title": " New AMD Ryzen 7 5700X3D CPU Review & Benchmarks vs. 5800X3D & More", "paragraph": ["New AMD Ryzen 7 5700X3D CPU Review & Benchmarks vs. 5800X3D & More", "Last Updated: ", "The Highlights", "The year is 2024 and there’s a new AM4 CPU, continuing launches into what is probably AMD’s most successful consumer platform ever. AMD’s new $250 ", " follows-up the prior ", "’s huge success and the limited rollout of the 5600X3D (Read our ", "), but the 5700X3D is a more familiar 8C/16T part. In essence, it’s a ", " but a little slower in clocks.", "The current CPU pricing goes like this: The R7 5700X3D is $250. The 5800X3D is $308 to $315. The ", " is about $300 now as well, with the ", " at $290. A new AM5 platform would cost more, but the ", " alone would run $390 or so.", "We’ll benchmark the ", " and focus on the comparison against the 5800X3D (watch our ", "). We’ve been good with recommending the 5800X3D mostly since it launched, as it’s been one of the most competitive gaming chips. For brand new builds, it has lost some viability to new platforms, but particularly for existing owners of AM4 motherboards, these X3D CPUs offer the best option for a last-chance upgrade before moving to a new socket altogether.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "The specs will help us understand where to look for performance differences.", "They’re both 8C/16T parts. They both have 96MB of L3 cache. TDP is 105W on both. The clock is where it’s different: The 5700X3D has a maximum 4.1GHz advertised boost clock and 3.0gHz base clock, with the 5800X3D at 4.5GHz and 3.4GHz base. This is a huge swing in frequency and is where most of the differences will manifest; however, it’s possible the equalized cache will still give the 5700X3D an advantage in some gaming scenarios.", "Production results will be predictably worse on the 5700X3D as a result of the frequency reduction, but we’re mostly focusing on these parts from a gaming perspective today.", "As for why these exist, we think the most likely reason just comes back to binning. It’s the same as the story we broke with the 5600X3D, just a different part. AMD can sell 5800X3Ds all day long, so they probably don’t strictly “need” a 5700X3D. It will bring some renewed enthusiasm, but it’s also possible that some percentage of these CPUs exist because the chips couldn’t hit and sustain those elevated clocks, but can hit the lower 5700X3D clocks.", "Regardless, it exists, and we’re testing it.", "We’ll start with summary charts to get you a rapid recap of all the data as quickly as possible, with the primary comparison against the 5800X3D since many of you are likely familiar with its positioning. New buyers are likely choosing between these two as well.", "Here’s a simplified summary chart of the 5700X3D vs. the 5800X3D. This shows percent change in the direction of improvement. For time-based benchmarks, we are showing the time reduction as a percent improvement here. That’s because less time is an improvement. ", "Overall, in gaming especially, the change generally hovers around the 6-10% range. Call it about 6-8% on average. Some of the lower figures, like F1 at 1440p, are capped by other components. Starfield remains CPU-bound though and shows less scaling than other titles, likely due to less reliance on pure frequency. Larger gains appear in games where the frequency is more relevant, with Final Fantasy being a great example of that.", "This chart is the relative value comparison. Our recent ", " contained a huge discussion about this style of chart. The short version is that we have a lot of reservations about these and that there are limitations of their usefulness, plus they abstract away from the nuance, but for a head-to-head, they start to make sense. ", "The number towards the left is indicating a reduction in the amount of money you’re spending for the FPS you’re getting with the 5700X3D as compared to the 5800X3D. Larger reductions are better for value.", "Boiling it all down, the relatively huge cost reduction of the 5700X3D, despite slightly lower performance, allows for a significant benefit in value. We’re seeing a range of 10-17% reduction in USD per FPS against the 5800X3D.", "We’re still experimenting with these charts and will be changing the style constantly as we seek discovery of something we like and feel represents the full picture. We make no claims as to it being a perfect representation and in fact, don’t think it is -- but it gives you a quick snapshot. Our full performance charts will give the full picture, so let’s get into those.", "We’ll quickly look at frequency validation of the two parts. Our recent ", " proved why these are a necessary part of the reviews process to ensure companies’ components are running properly.", "Here’s an all-core frequency chart of the 5700X3D and 5800X3D, using Blender on all threads. The 5700X3D boosts to 4GHz and holds steady for the duration of the test. It is expected behavior that these CPUs won’t hit peak boost clock in all-core workloads.", "The 5800X3D ran 300MHz faster here, at 4300MHz for the test duration. That’ll be the main reason for performance differences.", "In a single-threaded workload, the maximum frequency we measured here of any given core for the 5700X3D was commonly 4150MHz. That’s about 50MHz over advertised, so that’s great to see. The 5800X3D was about 4450MHz.", "Stellaris is up now. This test looks at simulation time rather than framerate, so the difference is in real-world time and definitely feels noticeable when waiting for simulation processing. This is one of the tests that you might notice more than frame rate in a lot of situations.", "The R7 5700X3D completed simulation in 36.4 seconds on average against the 5800X3D’s 33.5 seconds. The result is an 8% time reduction favoring the 5800X3D here, which aligns with the frequency advantage. This game tends to favor higher frequencies more than some other games. Considering the 20-21% price reduction against Newegg’s current $315 pricing, that’s not a bad trade-off. This is actually good value in relation to the 5800X3D, which itself has historically been good value.", "If you went to AM5 instead, the ", " gives perspective on the ceiling: At 29 seconds, its time reduction against the 5800X3D is 13% in this test and 20% against the 5700X3D. The ", " completes the simulation in 16% less time than the 5700X3D. Intel’s 14600K (watch our ", ") can definitely compete in some of these titles but the pricing is different. ", "We also have some older parts present for reference.", "Our Starfield results are pretty barren because the game just got a massive update. Generally speaking, we saw about a 30% change in performance between the prior game version and current for our test area and approach. All data on this chart is new as a result and results are sparse, but still useful.", "The 5800X3D roughly equated the 5700X3D. As evident from the ", " and ", ", there is definitely CPU scaling headroom, so we are not limited by external components on the prior generation X3D CPUs. The similarity in performance relates back to a reduction in frequency dependency in this game with its updates, and given the equivalence of core specs for the CPUs, the difference is only a 3% lead for the 5800X3D.", "As for the 14600K, that CPU leads the 5700X3D by about 14%, or the 5800X3D by 11%.", "At 1080p/High, the ", " and 7800X3D (watch our ", ") become constrained by GPU requirements, despite the ", ". The 5800X3D is about 3% better than the 5700X3D and neither hits the GPU ceiling. The 14600K maintains its 13% lead over the new R7 5700X3D CPU.", "Final Fantasy 14 is up now. In Final Fantasy at 1080p, the 5800X3D ran at 218 FPS average, leading the 5700X3D by 11%. The 7800X3D gets bound-up at 219 FPS AVG due to GPU driver overhead in this particular game between Intel and AMD when handling NVIDIA GPUs. ", "In F1 2023 at 1080p, the R7 5700X3D ran at 410 FPS AVG, establishing about a 40 FPS gap between it and the R7 5800X3D. The 5800X3D therefore leads by 10% again. The 7800X3D on AM5 leads by 24%. The 5700X3D ends up surrounded by some of Intel’s newer parts, with the 14900K (read our ", ") and ", " flanking. It outperforms the 14600K meaningfully while being cheaper at time of writing, at $250 to $300.", "At 1440p, the top results get truncated due to the resolution increase. This is expected behavior. The 5800X3D now ties with the 7800X3D, with both being limited by other elements of the platform and by the increase in GPU workload. The 5700X3D doesn’t reach the same heights, but closes the gap to 3% as a result of external limitations. This is a good reminder that scenarios not exclusively bound on the CPU will show limited scaling between high-end CPUs.", "In Shadow of the Tomb Raider at 1080p, the 5700X3D landed at 301 FPS AVG, allowing the 5800X3D about a 9% lead. That’s in-line with some of the prior results. The 7800X3D leads at 350 FPS AVG, with the 14900K trailing the 5700X3D and 5800X3D CPUs. Their cache is benefiting them here.", "Baldur’s Gate 3 has also received multiple massive patches since our October data set. We found that CPU performance was typically around 5% different from previously at the upper-bound of the testing, or 2-3% at the lower. Because of the 5% swing in some scenarios, this chart contains only directly comparable data that has been run on the newest game version.", "This data set is very limited as it was only collected this week, but contains the most interesting comparison: The ", "’s 105 FPS AVG yields to the ", " at 115 FPS, about a 9% lead over the new R7. That has the ", " ahead of the ", " for performance and about tied with the ", ". ", "The ", " leads the 5700X3D by 23% in this test, with the ", " 11% ahead.", "At 1440p and Medium settings, we remain bound by components other than the GPU. This is good news for CPU scaling and means that you’d still see benefit even in this particular workload. Keep in mind that our Baldur’s Gate 3 testing is in Act III and in a densely populated market area of the city, which increases simulation load on the CPU.", "The ", "’s 130 FPS leads this chart, with the ", " at 111, which leads the 5700X3D by about 11%. The hierarchy remains the same as before.", "Rainbow Six Siege validated as similar on our AMD Ryzen passes, but had changed outside of our acceptable tolerances for some Intel CPUs following recent patches and updates since October. We’re removing old Intel data as a result, so Intel is in limited supply for this chart.", "In Rainbow Six Siege at 1080p, the  5700X3D held at 606 FPS AVG, with the 5800X3D 7% ahead at 649 FPS AVG. The 5700X3D ends up below the ", " in this one and just behind the freshly retested 14600K (but not noticeably for any human).", "We’ll quickly look at a few production benchmarks. This section will be kept short since it doesn’t change as much.", "In Blender, the 5700X3D completed our frame render in 19 minutes, meaning the 5800X3D reduces time to render by 4%. X3D CPUs in general don’t provide additional value in this test, and in fact, typically perform slightly worse than the non-X3D counterparts as the frequency is more useful in this benchmark. You can see that in the ", " result vs. the 5800X3D and in the ", " vs. the 7800X3D.", "7-Zip file compression is measured in millions of instructions per second. The 5700X3D completed 90K MIPS, with the 5800X3D about 5% ahead of this result. The gap here is smaller than what we saw in most of the gaming tests earlier and is within a range where, functionally speaking, most people can think of the 5800X3D and 5700X3D as the same performance in file compression work.", "In file decompression benchmarking, the 5700X3D completed 109K MIPS, giving the 5800X3D a lead of 5.7%. The 7800X3D pulls 20% ahead here, with the ", " further still and benefited from the frequency change. The ", " non-3D also leads its X3D counterpart. ", "Finally, in Chromium code compile, the 5700X3D required 181 minutes to complete the compile. The 5800X3D used about 5% less time, at 172 minutes. The 14600K leads both of these massively, with a 106-minute result and 41% time reduction from the 5700X3D’s result.", "It’s a ", ", but a little slower. In gaming, commonly we’re seeing about a 6-10% swing and the price difference is much larger. ", "Generally speaking, value is good. The ", "’s value has also been good, particularly if you already own AM4. Buyers of brand new machines really should be carefully weighing sticking with more modern hardware for better upgradeability, especially now that the ", " prices have stabilized. But definitely for owners of existing AM4 builds, the 5800X3D and ", " are both good value options to get one last push on the CPU-side. ", "But for these two parts, you’re looking at around a 20% increase in price -- from $250 to $300 or so -- and a 6-10% increase in performance by buying the 5800X3D instead.", "If this truly is going to be the last hurrah for an AM4 build and you want to stretch it as long as CPU-ly possible, then the 5800X3D does get the most traction to keep you going another couple years. The ", " is just there for anyone on a stricter budget.", "What is less clear is whether it’d make any sense to build a brand new AM4 machine with all new parts. With used, it makes more sense. But for all new, remember that you are going to inevitably be marooned on the platform. There’s some value in a new platform for new builds for that reason. This is clearly a good upgrade option, though.", "Intel’s ", " has also stabilized in price over the past couple months, but we don’t consider it a direct alternative to the 5800X3D. The 7000 series might be a closer alternative, just because you can’t install a ", " in an AM4 board, and we think that's probably the primary user of these new AM4 parts in 2024.", "Ultimately, we’re just happy to see a platform get supported for 8 years now, or about 7 of Ryzen CPUs. That’s great for reducing e-waste and helping keep PCs affordable in an era of expensive GPUs.", "Our conclusion is pretty straightforward. We still think the ", " makes sense. It is not invalidated entirely by the 5700X3D, which does take a good chunk out of the potential sales for people who are really sensitive to that extra $50 to $65 but we think the 5800XD mostly still makes sense as an option if you are really just trying to get one last drop in to squeeze everything out of that motherboard. With that price gap, however, the ", " is a better value strictly in the sense that it's a lot cheaper and the performance gap is really not that wide."]},
{"title": " Get It Together, Intel: Core Ultra 9 285K CPU Review & Benchmarks vs. 7800X3D, 9950X, More", "paragraph": ["Get It Together, Intel: Core Ultra 9 285K CPU Review & Benchmarks vs. 7800X3D, 9950X, More", "Last Updated: ", "The Highlights", "We’re reviewing the ", " CPU.", "Take a look at the giant spiky ATX12V line for the ", " on the chart below compared to the ", " ATX12V line. This is going to be a problem for testing power today and efficiency. It’s not as simple as just measuring the EPS12V cables anymore, at least not on ASUS.", "Steve Burke", "Patrick Lathan", "Mike Gaglione", "Jeremy Clayton", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "We had to build a monstrosity to isolate the power consumption to the CPU for Arrow Lake, because ASUS is pulling significant power down the ATX 24-pin connector and not just the EPS12V cables. ", "If we didn’t do all of this, we would have measured the 285K as the most efficient CPU possibly ever made, but that’s because the power has simply moved to split across 4 phases for the 24-pin and 18 for the rest. ", "If it’s been a while since you checked in, you can think of the 285K as the “i9-15900K,” except Intel stopped that naming. ", "Intel’s big claim is that power consumption is halved, so we’ll spend a lot of time validating that today. Let’s get started.", "We’ll start with a price round-up of the current landscape.", "We put this table together a few days before launch, so the exact prices may be different when this story goes live; however, as Chronomancers haven’t been a core D&D class since ", ", we haven’t had a way to time travel for a couple decades and regretfully can’t review future prices anymore.", "The 285K is $630 with the pre-order pricing, or $160 more than the 14900K (read ", "). We don’t care about the launch MSRP of prior parts, only what they’re available at today since that’s when people buy things.", "The ", " is $350-$375, the ", " is $290 in some places, the ", " is down to $280, and the much weaker ", " is now $160. Buying into these dead platforms isn’t a great feeling, though.", "AMD’s direct alternatives include the $480 ", " with a rumored 9800X3D in a week, so if that’s true, we’ll have more to say soon. The 285K is 31% more money than the ", ". The ", " is also cheaper than the 285K’s current pre-order price.", "The new 285K is flanked by the best gaming CPU with the 7800X3D (watch ", ") -- which is also the most efficient CPU we’ve tested recently -- and the ", " and ", " for production.", "For the absolute barebones basics, the main thing you need to know is that Arrow Lake and the Core Ultra 200 lineup (so far) move away from monolithic silicon and toward a tile-based approach, including manufacturing from Intel competitor TSMC.", "Intel has gotten rid of hyper-threading and is instead moving to just P-cores and E-cores with these CPUs, so the 285K has 8-P cores, 16 E-cores, and 24 threads against the ", "’s 32 total threads. Frequency is also down, now at 5.7GHz advertised but because the architectures are different, you can’t directly compare the frequency numbers. We’ll review the ", " next, but that one’s at 6 P-cores and 8 E-cores. ", "The new platform is LGA 1851 and requires new motherboards. These will not work in LGA 1700 motherboards, and LGA 1700 CPUs will not work in LGA 1851 motherboards. There are also multiple independent loading mechanism options chosen by motherboard manufacturers -- we’ll have a separate video shortly with laser scans and pressure maps of those. More specs can be found in our ", ".", "First off: Arrow Lake really doesn’t seem ready for launch. Intel told us this about Arrow Lake in a briefing:", "“The big change is that every ODM now, without fail, every ODM ships with this [APO] enabled. In the BIOS, the Camarillo device is turned on, there’ll be a yellow bang, the driver will install, and APO will be enabled by default. That’s the out-of-box-experience everybody is going to have. You’d want to mimic what folks are going to see.”", "“This is going to be something that is going to be probably just as important as the hardware improvements. [...] All your ODMs, the board vendors, it’s all enabled by default and should auto-install, 13th Gen onward.”", "This is important because we don’t test with APO so we had to consider it for this review. ", "Intel presented first-party benchmark slides with APO enabled and emphasized with us that not only would it be on by default with Z890, but that it would also be on by default with Z790. Neither was true. We discovered this issue and brought it to Intel only because we weren’t sure if it was our fault, and it wasn’t. The company seemed totally unaware of this failing and, after some back-and-forth, eventually realized it had simply screwed up. As a result of our findings, Intel is moving to publish a list of motherboards that support APO out of the box on by default in BIOS going forward. ", "While that’s great for consumers so that it clears up the misleading nature of the original claims, this product is clearly not ready if we’re the ones beta testing such strong statements as “without fail” for a feature that wasn’t present, as pointless as it often is. ", "Dynamic Tuning also no longer exists on our board, despite Intel telling us that it should be present and enabled. The option has been renamed to Innovation Platform Framework and was off by default, which meant APO was off.", "With the latest microcode and BIOS on Z790 for these reviews, we also found that APO was off by default for those platforms as well.", "We consider APO off the default user experience for the product as Intel shipped it to us; however, we tested with both. APO was ultimately irrelevant in our test suite.", "This was one of many unforced errors from Intel, with others including BSODs on Windows install due to a driver conflict with NVIDIA devices when the IGP is enabled. This issue did not exist on prior architectures and seems to be a combination of the new IGP claiming the PCIE resources and of NVIDIA’s driver code not having an error handler for 0 PCIE resource availability. You can bypass it by disabling the IGP, but for a lot of people, this will be frustrating.", "The platform also has some issues with Easy Anti-Cheat, which Intel will soon be publishing a statement about, but we’ll leave that to ", ", but basically, if you disable security features, you’re able to work around the issue. We just wouldn’t recommend it.", "Additionally, Intel sent a statement about power profiles where balanced power on 24H2 results in uncharacteristically bad performance. We test with high performance except where we’re specifically required to use balance in some X3D situations so this didn’t affect us but does represent one of Intel’s launch problems. ", "Intel even got its own specs wrong on the slide above where it said the chipset can support up to 32 USB 3.2 devices but actually it’s supposed to be 10. This is all to point out that Arrow Lake is really just not ready for launch.  ", "Let’s get into the efficiency testing.", "This is really important, but we’ll try to keep it short: On at least the ASUS Z890 motherboard we have, the 24-pin is doing disproportionate work. This is likely a board-to-board thing, not Arrow Lake as a whole.", "Proving our work: This plot shows the 14900K’s power draw in a known workload spread across multiple rails. You can see that EPS1 and EPS2 power is similar, both at around 70-80W in this lighter weight gaming workload. The 24-pin has several voltages, including 3.3V, 5V, 5VSB, and 12V shown here. ", "The ATX12V rail includes things like fans, the CPU, and if we hadn’t isolated it, slot power, among other miscellaneous controllers on motherboards. ", "Slot power is around 30-35W, which is why it’s important to isolate it if capturing 24-pin power. ", "Here’s why we isolate slot power: This benchmark was for 7-Zip on the 14900K. The GPU does literally nothing in this test except spit out the display. It does not engage in the test. However, occasionally in any test, we measure seemingly random spikes to slot power. This could be for a number of unpredictable reasons, including innocuous ones like Windows background tasks or NVIDIA’s drivers doing something in the background, such as telemetry.", "Here’s the comparison we’ve wanted:", "In 7-Zip, ignoring EPS12V, we noticed that the ATX12V power was exceptionally high on the 285K and Z890 Hero combination compared to the 14900K and Z790 Hero. It’s at about 50W here, whereas the 14900K had ATX12V down around 30W.", "ATX3V power is comparable on both and within 2W. ATX5V power isn’t easy to call a simple average since it fluctuates so much: The range is 14-30W on the 285K+ASUS combination and similar on the 14900K, with peaks about 3-5W lower than the 285K. We don’t know if any of that power is getting used for regulators that might feed the CPU, but if any of it is, it’s not much. A lot of it is driving other components, like I/O.", "The ATX12V line is clearly important though, as not factoring-in that 20-30W difference in this test would mean representing the 285K as artificially efficient because the power is sort of “hidden” in a cable where it’s not typically meaningfully high. ASUS’ reasoning for this is theoretically better power regulation. We don’t know if anyone else is doing this.", "Finally, as an example of AMD, here’s the 7800X3D and 285K.", "The 285K and 14900K ATX12V remains from last time. The 7800X3D was pulling about 12W ATX12V fixed during this test and didn’t seem to fluctuate based on load at all. It appears fairly isolated. Typically, this gap of 10W comes out in the wash when you’re talking a 280W 14900K versus an 80W 7800X3D, so it’s just part of the usual margins. In this scenario, however, the difference against the 285K really starts to show.", "Here’s ATX3V. The 7800X3D platform is marginally higher here -- we’re using an ASUS board for this also. This is part of why 5V normally comes out in the wash: Some rails are a few Watts higher, some a few Watts lower. There is always going to be error.", "ATX5V is about the same between them all. There is possibly spikier behavior on the 285K from the I/O, but that’s about it. ", "All this is done with hardware. We also can’t trust various software readings because they can be manipulated heavily by software or motherboards. Years ago, there was an issue where AMD motherboards were underreporting the power in a way that allowed boards to pull more or less power while hiding it in software, thus manipulating the report. We also spoke with ", " about his experiences, and he noticed that CPU Package Power is calculated based on VID, so if anything is wrong with voltage, it will manifest in erroneous software readings.", "And that leads us back to our monster we’ve built. We are fairly confident in the results, but we have to caveat that this is a very opaque platform currently and it’s not fully clear how all the power is routed. For the most part, it should be proportional to the VRM split of 18:4 of the 22 phases total, so we were able to use that as a guidepost.", "Finally: You might be asking “who measures the measurers,” and the answer is... us. Working with Elmor, we hooked up other current monitoring devices in series to monitor the current monitoring devices, and we also clamped the cables to monitor the monitoring of the monitoring devices while monitoring the software of the monitoring-monitoring devices and the CPU-monitoring software monitor.", "Once that was all done and we had tested against calibrated Fluke meters with known current loads, we proceeded with the most accurate combination of monitoring.", "Let’s get into the efficiency testing.", "7-Zip decompression efficiency is measured in MIPS/W, or millions of instructions per joule.", "In this test, the 285K ended up in the lower-third of the chart. Intel’s 14900K pulled 273W in this test, with the 285K now at 162W for ATX12V and EPS12V without slot power, or 175W with ATX12V, ATX5V, and EPS12V. We think the 162W number is more accurate, but want to transparently present both since the power split is still not fully clear.", "Because performance is lower and the formula relies on both, the efficiency increase isn’t as impressive as the power drop. The 285K runs with an efficiency of 1101 MIPS/W decompression with the reading that includes 5V, or an improvement of 29% over the 14900K. The reading without 5V is 40% improved over the 14900K, which we think is the more accurate one. Whether 30% or 40% is closer, the point is that it’s a big uplift. AMD still dominates here, holding the entire top-third of the chart, though. The ", " in ECO mode sets a seemingly untouchable score at 1936 MIPS/W. The 7800X3D, which is much slower than the 285K in 7-Zip decompression, is more efficient thanks to its 70W power draw.", "Here’s the 7-Zip compression result. Power consumption is measured across compression and decompression in the same test suite, so those figures are unchanged.", "The 285K scored 1051 MIPS/W with ATX12V and EPS12V, an improvement over the 14900K’s 672 MIPS/W of 56%. This uplift versus decompression comes from the higher performance in 7-Zip compression relative to its scaling in decompression.", "AMD’s 7800X3D is at the top here. Again, it’s not the best performer, but its 70W power is impressive and allows it to remain the true most-efficient CPU we’ve tested lately. ", "Baldur’s Gate 3 could get more complicated, but we’ve isolated out the PCIe slot power by using an interposer to power the video card instead.", "The entire X3D lineup continues its domination in this game, and most others. The high framerate and low power land the 7800X3D at 2.3 FPS/W, as it’s pulling only 55W during this gaming workload. The ", " is about the same, with the 5800X3D (watch ", ") slightly less efficient. Intel’s new 285K isn’t remotely close to these numbers.", "The 285K with ATX12V and EPS12V ran at 1.1 FPS/W, so the 7800X3D is creating over 2x as many frames per Watt of power. The 14900K ran at 0.7 FPS/W here. Looking at just Intel, the 1.1 result of the 285K has at least improved substantially over the 14900K, with an uplift of 57%; if we include the 5V power, since we’re not certain if any of it is being used for the CPU, that would be a 29% uplift. ", "Starfield is a heavier workload from gaming.", "In this one, the 7800X3D is again the most efficient. Its result was 2.1 FPS/W, holding a large lead over the next closest CPUs. The next closest CPU is the ", ", also at about 70W. The 5800X3D, ", ", and ", " non-X follow this. We eventually hit the 3700X (read ", "), then the 285K.", "With the ATX12V and EPS12V measurements and without PCIe slot, we end up at about 147W for a 1.0 FPS/W rating with the usual rounding.", "The 14900K ran at 0.7 FPS/W here, so Intel has improved by 43%. Its Ultra 9 is now about where the ", " was previously. Measuring 5V as well had it at 172W, or 0.8 FPS/W. That would instead be an improvement of 14%. As before, we believe the 1.0 figure is closer to reality, but it likely falls in between.", "The next game is Stellaris, where we measured simulation time in seconds and power. In order to make this as easy to follow as possible, we’ve done some simple arithmetic to convert this into “simulations per watt-hour,” meaning that a bigger number is better despite the base metric result being lower-is-better.", "The 7800X3D has an impressive score here, at 2.7 simulations per watt-hour. The next closest is down at 2.4 with the 5700X3D (read ", ").", "The 285K ran 1.5 simulations per Watt-hour. That means for each watt-hour, the 7800X3D is able to complete 1.2 more simulations, or about an 80% increase. ", "The 14900K completed 0.9 simulations per Watt-hour. That means the 285K’s best entry is an improvement of 67% in efficiency. Remember: Most of Intel’s presented numbers were only for power reductions, not necessarily for efficiency. The 285K’s simulation performance is better than the 14900K’s in this benchmark, so its combination of higher performance and lower power (which was reduced by 46.6W from the 14900K) yields this huge increase in efficiency. ", "Finally, Final Fantasy 14 for efficiency. In this one, the 7800X3D led with an impressive 42.5W power draw while spewing hundreds of frames per second, allowing it a result of 8.3 FPS/W. That’s great. The 5700X3D keeps its second-place spot at 7.7. The 14900K ran at 3.1 FPS/W, so the 285K is 32% improved by these numbers. This is one where the 285K was regressive in performance against the 14900K -- and by sort of a lot, but we’ll come back to that. The result is reduced efficiency gains.", "Next, we’ll validate the frequency behavior to establish how the CPUs behave out of the box.", "This chart plots the highest single core frequency per interval during a single-threaded Cinebench workload.", "With the 285K, the max single-core frequency is 5700MHz during testing, with frequent drops to 5400MHz. These drops are abnormal on Intel during this test.", "The 14900K with the latest microcode held 6000MHz. These are different architectures, so it’s not as simple as stating that higher is better; however, it helps at least illustrate where some of the performance losses are coming from.", "The original launch microcode had it at the same frequency.", "This chart looks at P-core frequency averages during a Blender workload. ", "The 285K maintains an average P-core frequency of 5400MHz in this testing. It’s relatively flat. That has it higher than the 2024 ASUS test entry, which is what we used for our review comparison today, at around 5100-5220MHz. The 2023 launch entry was higher, at 5280-5400MHz on average. The microcode changes may have affected this since launch. The MSI 0x11D microcode entry had the CPU at around 5000MHz from the same window as the ASUS 2023 entry. The most up-to-date frequency entry sits between the two flanks of early 14900K tests. ", "Finally, this chart shows the all-core averages in the same test. The 285K averaged 4867MHz when factoring-in the E-cores, with the modern 14900K just below 4500MHz and flanked by the two older entries.", "Now we’re going to get into gaming benchmarks. We have a lot of 2023 and 2024 games in our test suite along with mainstays from the past.", "Dragon’s Dogma 2 is up now. This is one of the 2024 titles we added to our suite last time. It’s had updates that affect performance since our last round of benchmarks. APO doesn’t do anything in this benchmark and isn’t supported. We tested with it on and off for both the 14900K and 285K and its performance was the same, so we removed the redundant entries here since they have no impact.", "The 285K landed at about 104 FPS AVG, with lows at 64 FPS and 51 FPS. ", "This allows the AMD 7800X3D at $480 to lead the $590 285K by 6.1%, with the 14900K at 5% ahead. The lows between these 3 CPUs are functionally identical. The ", " and ", " also lead the 285K here, with the 14700K (read ", ") far cheaper at $350. The 5700X3D and 5600X3D (read ", ") are effectively tied, with the 5700X3D at $230, or sometimes down closer to $200.", "In F1 24, which, for hopefully obvious reasons, is a 2024 title, we end up with this set of results when fully retested in 24H2 and with new microcode and AGESA.", "The 7800X3D sets a high ceiling and establishes a 28% lead over the more expensive and higher power-consuming 285K, at 438 FPS to 344 FPS AVG. The 14900K is also advantaged, this time by 12% with a 385 FPS result. The lows for the 285K were 186 FPS 1%, which is a worse entry than the 14900K’s 250 result. The frametime pacing appears better, in-step with the average, on both the 14900K and 7800X3D.", "Looking now at the APO results, toggling APO does appear to do something in this game: The 285K gained 1.3% with APO on. How very exciting -- we can hardly contain ourselves. You’ll surely notice the extra 3-4 frames per second on top of the other 343 before them. We’re so glad we spent half a day troubleshooting Intel’s fumbled pre-launch settings to gain those frames back... Whatever would we have done without the extra 0.0369 ms reduction in frame time?...", "The 14900K also gained about the same amount. It’s irrelevant on both.", "Using DDR5-8600 on the 285K with Gear 2 and blasted VDIMM boosted it to 359 FPS AVG, a 4.5% like-for-like lead over the 344 result. This is almost enough to get the 285K tied with the two-generation-old 13700K (watch ", ") from 2022, but not quite. It does, however, tie it with the AMD’s 2020 architecture found in the cache-bolstered 5700X3D with its lower power.", "1440p results are mostly uninteresting: The top is truncated heavily by the increase in resolution. Even still, the new Ultra 9 ends up in the middle. It’s fitting that the Core Ultra 9 is in the middle of a cluster.", "Final Fantasy 14: Dawntrail is up now. This is another 2024 addition to our testing.", "The 7800X3D again establishes the ceiling. It leads the 285K by 31% in this game, at 353 FPS to 270 FPS AVG. The 14900K’s 310 FPS AVG establishes a 15% lead over the 285K, marking one of the largest declines of Intel’s performance in our gaming suite.", "The 5800X3D and 5600X3D are also at the top here, showing that Dawntrail just generally really likes cache, at least on these CPUs. The 5700X3D is a little lower down since its frequency is 300MHz below that of the 5600X3D, so these results make sense.", "The 285K ends up below the 14700K and 13700K, with APO doing nothing on the 285K. It’s within error. Final Fantasy 14 is officially supported by APO though and is on the games list, and we do see a slight uplift on the 14900K of 1%, basically error. Switching to DDR5-8600 on the 285K provided an uplift of 4%, with it still below the 13700K after that. Of course, the same memory treatment would lift others up also.", "At 1440p, the limited ceiling is shuffling the stack as a result of the framerate bouncing off of other limits. We saw a 1.9% uplift from APO on the 14900K. The 285K, again, did not benefit from APO, with both entries at 255 FPS AVG +/- 1FPS.", "Baldur’s Gate 3 is up now, a 2023 title that we added to our permanent suite this year. We test in Act III in a densely populated city area for a heavy CPU load.", "The 7800X3D establishes a 26% lead over the 285K, at 126 FPS to 100 FPS AVG. The 14900K leads the 285K by 4.5%, at about 105 FPS AVG.", "The 5800X3D, 5700X3D, and 5600X3D also lead the 285K, as do the 13900K, 13700K and 14700K.", "Toggling APO did nothing here and was within variance for both the 14900K and 285K. Swapping to DDR5-8600 memory boosted the 285K by 7.6%, allowing it to pass everything except the X3D CPUs (this also perfectly aligns with why X3D does so well here). Of course, shoving better memory into the 14900K or 9000-series AMD CPUs would also boost them fairly proportionally.", "Stellaris is up next. ", "APO has no impact on this game. ", "The 285K required 32.5 seconds for the simulation, finally putting it ahead of the 14900K. The 285K requires about 1-2% less time than the 14700K and 14900K CPUs.", "The 7800X3D outranks the 285K again and requires about 3.7% less time for the work. The ", " remains the fastest here, which is consistent with our last round of data.", "Boosting memory helps in this game, so the 285K benefited from a 4.3% reduction in time to complete the simulation.", "Rainbow Six Siege is up. In this one, the 7800X3D leads by a much smaller amount, at only 6.6% for 622 vs. 584 FPS AVG when APO is in its default off position that this board shipped in. The 14900K was tied. Enabling APO did nothing on the 285K. The result was within error when considering we’re almost at 600 FPS. Enabling it boosted the 14900K by 1.7%, and this is with Intel’s sh*tty Microsoft Store App confirming that it’s enabled for both CPUs. This boost is reduced for the 14900K versus APO’s launch because Rainbow Six has updated the code that was causing problems.", "Going to DDR5-8600 increased performance over the 584 result by 2.6%.", "The 285K is at least better than the 14700K in this one, with an uplift of 2%. It’s also about 1.8% ahead of the 7700 non-X, which has been $280-$290 lately when you can still find it. ", "As a general note, this game has some serious 0.1% low consistency issues. We noticed that the 12-14 Series CPUs have significantly higher 0.1% lows than AMD’s options and than the 285K alike. It’s easier to look at a frametime plot.", "Here it is. Because Intel noted that Rainbow Six had specifically tuned to reduce reliance on APO, and because of the low advantage of Alder Lake onward, we’re assuming that Rainbow Six Siege has specific and manual tuning for the Alder Lake architecture and its more recent derivatives.", "This frametime plot shows the 14900K is overall highly consistent frame-to-frame, with most of the intervals deviating at most by 2ms. There are a few spikes, but only one notable spike to 6ms -- which is a 4ms deviation, and thus wouldn’t be noticed by the vast majority of users.", "Adding the 285K, we see several spikes to 10-11ms. By themselves, these frametimes aren’t bad. 60 FPS would be 16.667ms, so this isn’t a huge stall. But it is a big change from Raptor Lake and is objectively worse.", "In Starfield, another 2023 game, the 7800X3D maintains a 2% advantage over the 285K, at 145.4 to 142.5 FPS AVG. We’re bound elsewhere -- and that elsewhere is obvious: The DDR5-8600 result jumps to the top of the chart, illustrating that at least some of our limit is memory. As a reminder, applying the memory tuning treatment to everything would boost all numbers, so looking at baseline will give you an idea for their headroom.", "The 14900K actually falls behind for once, at a slight loss to the 285K. We think this corresponds with the cache changes, based on the memory performance we just saw.", "APO, once again, does nothing between the two main 285K entries.", "Total War: Warhammer 3 is up now. The 7800X3D led the 285K by 7.2%, with the 14900K leading by 2.8%. Total Warhammer 3 is on the APO list, so it’s supported. On the 14900K, we saw an uplift of about 1.2%. On the 285K, we measured an improvement of 0.6% -- basically error.", "Lows in this game have been historically awful on Intel’s i9 CPUs, which we previously proved is due to scheduling challenges with the thread count. The 285K at least seems to somewhat improve here, possibly by the reduction in threads.", "We’re getting into production benchmarks now. ", "Blender is up first. We’ve updated it, so it’s not comparable to prior results.", "The 285K is our second-highest performer on the charts for desktop-class CPUs. The 9950X (read ", ") benefits from a render time requirement reduction of 5.6%, while the 285K reduces render time from the 14900K by 16.5%. That’s finally some uplift.", "These types of tests are also where AMD’s 7800X3D and 5800X3D show their limits as 8-core CPUs, both falling far down the charts. That’s a known quantity. If you’re only gaming, they make the most sense. If you mix in a good amount of heavily threaded software for work, it may make sense to buy something else on this list.", "In file compression with 7-Zip, the 285K completed 170K MIPS and roughly tied the i7-14700K. The 14900K holds an advantage of 8%. The 9950X and 7950X (watch ", ") outperform the 285K significantly, with the ", " just behind. Memory seemed to really help in this test, pushing the 285K up by a gargantuan 18.7%. That’s a huge uplift. ", "Decompression doesn’t benefit as much, posting a 4% improvement. The stack also shuffles, with the ", " and ", " both surpassing the 285K here. The memory subsystem benefits don’t translate as much as they did in compression, both stock and with the better RAM.", "The 14900K leads the 285K by a staggering 21% in this benchmark, benefitting from its extra threads. The 9950X establishes an impressive ceiling, at 42% ahead of the 285K.", "Next is our Chromium code compile test. For this test, we double the RAM capacity on some CPUs when they page-out or otherwise fail to complete the compile. This only occurs with the highest-performing few CPUs. This test has been updated since last round, so load on CPUs has slightly changed.", "In the situation of the 9950X, there is one disclaimer here, we were not able to get it stable at DDR5-6000 with 64GB when running our usual tighter timings. We experimented briefly with reducing the timings, higher voltages, and altered infinity fabric, but ultimately had to call it for now and run it at DDR5-5600 to accommodate 64GB. That makes the 9950X an imperfect comparison. With that limitation disclosed due to stability issues, the 9950X and 285K are roughly equal. That may change if we can rerun the 9950X and find stability.", "For direct comparisons, the 285K leads the 14900K by only about a 3-minute time reduction or a total compile time requirement reduction of 3.8%. As usual, the 8-core X3D parts are lower down the stack, like the 7800X3D and 5800X3D. ", "Now for the Adobe software, tested with the Puget Suite. ", "Premiere has the 285K as the new chart-topper, at 11,336 points. That’s how this whole review should have been, especially with a power reduction. Unfortunately, it wasn’t this way.", "The lead over the 14900K is small, at 2.5% uplift in aggregate. The 9950X is AMD’s top CPU here, at 10,914 points. The 285K has a 3.9% lead.", "In Adobe Photoshop, AMD has a clean sweep of the entire top half of the charts. Those of you who’ve been watching us for at least 5 years will remember an era where it was the opposite. The first Intel entry doesn’t appear until below the ", ", and that’s the 14900K. ", "The 9950X leads the 285K by 22% here and the 14900K leads it by 3.5%.", "Simplifying all of this, our current conclusion is this:", "The ", " does not have a particularly strong place in any one market. ", "The ", " is far superior in both gaming and efficiency. The ", " can hardly make sense against even the ", ", and AMD’s 9800X3D is days away at this point. For non-gaming, the CPU is more interesting but we still don’t think it is broadly justifiable at the current CPU and platform costs. ", "Even Intel’s prior-gen parts are far cheaper right now, like the ", " and ", ", which theoretically have been fixed with microcode. If you were to argue that the inefficiency of the prior gen parts counters some of the savings in the form of lower power, it’s just not a strong argument. The ", " is $350 now, so it’s $280 cheaper than a 285K. ", "If your power costs $0.10/kWh like ours, then you’d need to play the highest CPU load games for 8 hours a day for an entire year in order to gain $19 of value in power bill reductions for the 285K against the 14700K. At $0.15, the shut-in gaming levels would give the 285K a savings of $30 over one year of literally playing Starfield or Cyberpunk as a full-time job. At the peak of degeneracy that we all strive to achieve, you’d have to play games at this pace for 10 years to have spent more on power than the cost savings of buying the cheaper CPU (it’s the delta, not total cost). Maybe throw in a cheaper cooler as well since power is down and call it 8 years.", "Even at $0.30/kWh, the $280 price savings from the 14700K would require 5 years to wipe-out with the power bill while playing Cyberpunk 8 hours per day for 5 years, or in other words, 14,560 hours of Cyberpunk.", "Let’s just say you pay $0.50/kWh. In one standard 3-year upgrade cycle, you can save the amount of money in power you’d save buying the 14700K -- which we still don’t recommend for gaming -- rather than the 285K. That’d be a savings of $92.60 per year (at $307.7 - $215.1).", "Or, you go with the ", " and get higher framerates and still a power cost reduction, even at these high electricity prices, of $114 per year at these crazy gaming hours.", "And ultimately, no matter what argument is made for power savings, like room temperature or something, you can still point to AMD as an answer.", "The reduction in power consumption is important and does mean cheaper cooling is possible, so that’s good. Intel is objectively getting more efficient, but regressive performance in games is hard to deal with. The production performance mostly improved at lower thread count, and that actually is great. The problem is that at $630, there are very few cases where the 285K makes sense right now.", "Our approach to reviews is very consumer-oriented and value-oriented. That means for us, we need to see a strong value argument to recommend a part. Even forgetting completely about power as a factor and looking only at performance for the price, it just doesn’t make sense to us despite being an important building block.", "The best news out of the 285K is that it might be a fresh start for Intel and that it is genuinely a lot easier to hit higher memory clocks than before, and that benefits it in tests like our 7-Zip benchmark.", "But we just think there are better CPUs out there at lower prices."]},
{"title": " Intel Core Ultra 5 245K CPU Review & Benchmarks vs. 5700X3D, 13700K, & More", "paragraph": ["Intel Core Ultra 5 245K CPU Review & Benchmarks vs. 5700X3D, 13700K, & More", "Last Updated: ", "The Highlights", "Now we’re reviewing the ", ", which you can think of as sort of a 15600K, just with a new name. This is a 6 P-core, 8 E-core part with 14 total threads. It’s priced at $310 MSRP and is meant to be a new mainstream gaming part.", "Intel’s big Arrow Lake claim is efficiency and power consumption reductions, so we’ll spend a lot of time looking at that in addition to gaming and production performance.", "Key comparisons against competing modern CPUs would be the ", ", such as if you’re on AM4 and can upgrade one more time, the ", ", and Intel’s prior generation parts. We’ll get into all of that.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "Again, this review is hyper condensed compared to our ", ". We really are leaving a lot of detail, but that’s because it’d be complete repeat information and is the same. We’ll focus mostly on charts today.", "Let’s start with the price comparison. These prices were taken in the week before reviews are going live, so they may change by the time it publishes.", "Here’s the list. Prices for both Intel’s 13th and 14th Series CPUs have recently dropped, as have some of AMD’s Zen 5 CPUs.", "The ", " is as cheap as $350 right now, which makes it a direct alternative to the ", ", despite buying into an older platform. It has at least gotten microcode updates that should resolve the major concerns. The ", " is $225-$250 now, which is about the same price as the AMD 9600X. The 13600K is dwindling in supply, but $225 lately. The 12900K is also cheaper than the 245K, despite being on a pretty old platform, and is $280-$300. AMD’s 5700X3D (read ", ") is around $210-$230 now, making it a key upgrade pathway for AM4 users. The ", " is priced out of this territory, up at $480 typically. Keep in mind that a 9800X3D -- or whatever they end up calling it -- is due out on November 7th.", "Here’s a slide showing the basic specs. The ", " is a 24-thread part and has 8 P-cores and 16 E-cores. Intel ditched hyper-threading, so it’s just the two core counts combined for thread-count. The 245K is a 14-thread part and has an advertised boost of up to 5.2GHz. Overall, Intel is focusing heavily on power consumption reductions and efficiency improvement.", "But in the ", ", we saw several areas where the CPU regressed in gaming performance. This complicates efficiency, because if the CPU is doing less work but also lower power, it’s not a clean improvement.", "Let’s start with all of that.", "This section gets into efficiency testing. There are some really important details in our ", " that you need to see to fully understand and appreciate this section. We’re not going to go through it all again here. The most important part is that ASUS is directing some power through the ATX12V cables on the 24-pin connectors now, so we can’t rely on purely EPS12V. We’re going to leave a lot of detail out here on the assumption you got it in the ", ".", "In 7-Zip compression efficiency testing, we measured the 245K with EPS12V and ATX12V at 108.1W on average, which produced a MIPS/W rating of 1130.6, or in other words, 1130.6 million instructions per Joule.", "The 245K outranked the 285K’s efficiency in the same test, meaning that the 285K is beyond the optimum point in the curve for efficiency. It’s still improved over the preceding ", ".", "The ", " scored 768.3 MIPS/W here at 166.5W, so the 245K is improved in efficiency. The 245K’s performance in Compression MIPS is actually lower than the 14600K’s (read ", "), but its power consumption dropped so drastically (even with ATX12V measured) that it has measuredly improved in efficiency, at 47% more efficient than the 14600K. Adding the 5V line includes I/O and so isn’t perfect, but even that is more efficient. We talk about why we add both in the 285K review.", "AMD remains the leader, with the ", " at 1152.8 MIPS/W, the ", " at 1281, and the ", " non-X at 1436.2.", "7-Zip decompression uses power from the same test since we combine them, but has different scores. In this one, the 245K held a score of 1090 MIP/W. Its actual MIPS throughput, which we’ll show later, is significantly behind the 14600K, so the efficiency percentage uplift is dragged down by regressive performance, despite the total power reduction. The improvement over the 14600K’s 821.9 result is 32.6%.", "The closest score in MIPS throughput to this is the 5800X3D (watch ", "), which is just outside of error. The 5800X3D and 245K are therefore completing about the same output and are normalized in this way, allowing the 5800X3D a staggering lead of 28% more efficiency than the 245K.", "In Baldur’s Gate 3 efficiency, the 245K ran at 71.5W and scored 1.3 FPS/W. That has it tied in efficiency with the ", " and it tied with the ", " which wasn’t distant. These three CPUs can be looked at as nearly work-normalized, or FPS-normalized, in addition to scoring the same efficiency. ", "The 5800X3D has a substantial framerate lead and runs at only 65.7W, giving it a 1.8 FPS/W result at 38.5% more efficient than the 245K. The 5700X3D has a larger lead with its 51.1W result and is also typically cheaper, though on an old platform now with old I/O support. Still, it’s impressive.", "Comparing the 245K to the 14600K, the lead is 44% uplift in efficiency compared to the 14600K’s 0.9 FPS/W result. The 14600K also had a slightly lower framerate in this one.", "In Final Fantasy 14: Dawntrail, the 245K ran at 4.3 FPS/W and 51.8W, putting it behind the 9600X (which has a significantly higher framerate but about 10-11W higher power consumption) and ahead of the 14600K. The improvement over the 14600K’s 3.6 FPS/W result is 19%. The 5700X3D crushes here, up at 7.7 FPS/W and leading the 245K by 80% thanks to its lower power and its higher framerate.", "Stellaris shows us simulations per Watt-hour, so higher is better despite the test being in seconds (with lower being better). ", "In this test, the 245K ran at 53.5W and completes 1.9 simulations per Watt-hour. That has it about tied with the 5800X3D, which likewise is roughly tied in power consumption. These are good direct comparisons.", "The 5700X3D’s power consumption drop benefits it greatly here, although it slows down in simulation time. Its score is 2.4 simulations per Watt-hour, or an improvement over the 245K of 26%.", "Against the 14600K, the 245K improves by 46%. The 14600K is slower in simulation time here.", "We’ll look at maximum single-core frequency under a Cinebench workload first, just to verify that the CPU does what Intel advertises.", "The 285K plotted at about 5700MHz during this workload, with the ", " at 6000MHz. The 14600K ran a maximum of about 5300MHz at any given period, with the new 245K at 5200MHz max. This is what Intel claims as the maximum, so that’s the bare minimum bar to clear and they have at least done that.", "This chart checks the P-core boosting behavior in an all-core workload. We measured the 285K at 5400MHz on average here. The 14900K’s (read ", ") most recent result fluctuated around 5100-5200MHz. The 14600K has a flat 5300MHz P-core average from the original review. The 245K plots at 5000MHz for P-core boosting.", "Dragon’s Dogma 2 is up. In this one, the 245K ran a baseline of 95 FPS AVG. This allowed it a slight lead over the similarly priced ", ", at 91 FPS. The 245K also technically outperforms the 14600K, although realistically, they’re about equal. ", "The cheaper and low-power 5700X3D outperforms the 245K by 8.4% with 103 FPS AVG, a considerable lead for the older platform with the X3D-refreshed part. Moving to the 285K yields a 9.8% uplift, but you should ", " for all the nuance on that. The price jump is so significant that, especially for gaming-first builds, the ", " likely makes more sense for most people.", "APO did nothing here.", "F1 24 is up next.", "The 245K ran at 307 FPS AVG here. That has the 9700X (read ", ") 23% ahead at 378 FPS, the 5700X3D 16% ahead at 355 FPS, and the 14600K 4% ahead with a 319 FPS AVG. Intra-architecture, the 285K offers a 12% uplift at 344 FPS AVG. Notables that the 245K outperforms include the ", " from 2021, at 13.7% ahead.", "APO actually does something in this game sometimes: We talked about the exciting 1.2% gain in the 14900K. The 245K gained 1.8 FPS AVG from APO. Some of that might even not be margin of error. Groundbreaking stuff. That’s almost 0.6%!...", "Because APO was so impressive, you can understand why we decided to not bother dedicating time to running it for the 1440p test of F1. We didn’t want it to embarrass everything else…", "At 1440p, the chart becomes truncated by the resolution increase. The end result is largely the same lower down the stack, though: The 245K remains outflanked by the ", " and 14600K above it and encroached upon by the ", " below it. These CPUs were already mostly CPU-bound and remain so here.", "Final Fantasy 14: Dawntrail is up now. At 1080p, the 245K ran at 220 FPS AVG. This allowed the 9700X a staggering lead of 41% for a similar price. The ", " is cheaper than the 245K, at $280 at the time of writing, and produces a 265 FPS AVG result. ", "Against other CPUs: The 5700X3D outperforms the 245K by 37%, up at 301 FPS, with the 14600K leading it by 12% with its 248 FPS, and the 285K leading by 22% at 270 FPS. In our ", ", we noted that Final Fantasy is one of Intel’s worst generational titles between the 14 Series and the Ultra 200 CPUs. As for APO, we were not able to pick up a difference outside of usual margins. The APO on result is 0.77% ahead of APO off, which is functionally noise.", "At 1440p, the 9700X’s lead is cut down to “only” -- and that “only” is doing some heavy lifting -- 22%. This is because of other limitations from the resolution change, but it shows that even at 1440p, the 245K is disadvantaged.", "Baldur’s Gate 3 is up now, tested in the densely populated city center in Act III.", "The 245K ran at 92-93 FPS AVG here. As a result, the 9700X improves upon its framerate by 7%, the 5700X3D’s 111 FPS result improves by 20%, and the 14600K is behind the 245K and alongside the 9600X. The 245K leads the 14600K by 6.2% here. This is at least better than what we saw with the 14900K and 285K. The 14900K was also encroaching on memory limitations, as evidenced by the ", " and ", " bouncing off of the same limit and the 285K with DDR5-8600 pushing ahead.", "As for the 285K’s like-for-like lead over the 245K, that’s 8% at 100 FPS AVG.", "Stellaris is up next for something different. This one gives us simulation time in seconds rather than framerate per second.", "The 245K required 34.9 seconds to complete the simulation, with APO doing nothing for simulation time. The result has the 245K just ahead of the 5800X3D, behind the ", " non-X, and behind the new 9600X. Zen 5 does well in this particular benchmark.", "Against the 14600K, the 245K benefits from a simulation time requirement reduction of 4.6%. The 245K also leads the 5700X3D with a simulation time reduction of 8.9%, with the 5700X3D falling back from its reduced frequency. The 285K reduces the time requirement from the 245K to 32.5 seconds, or reducing the time by about 7%.", "Rainbow Six Siege is next. In the ", ", we showed the above frametime plot -- which we’ll show again here -- to illustrate some behavior where it appears as if frametime pacing is a little more tuned on the 12-14 Series CPUs than most the others we test.", "Here’s the chart for the 245K. The 245K ran at about 476 FPS AVG, allowing the 9700X a staggering 31% lead at 621 FPS. The 5700X3D ran at 526 FPS, or a 10% lead. Next is the 14600K at 517 FPS for a 9% advantage over the 245K. Intra-architecture, the 285K leads the 245K by a noteworthy 22.6% -- though we still don’t recommend it against alternatives mentioned in the 285K review. That’s at least a real gap for the price gap.", "Toggling APO didn’t change the 285K or 245K, though that’s not shown on this chart.", "Lows remain reduced on some architectures, including Arrow Lake.", "In Starfield, the 245K ran at 121FPS AVG. The 9700X held a 117 FPS result, within about 3% of the 245K but technically behind. The 5700X3D is also slightly behind, at 118 FPS. Intel’s own 14600K breaks away at 127 FPS, a 5% uplift over the 245K. Finally, the new 285K is about 18% ahead of the 245K -- similar to the gains we saw in Rainbow Six.", "Toggling APO had no appreciable impact.", "Time to move into production tests. Like with the 285K, we’ll keep this short and focused but dense with charts.", "In Blender with CPU rendering, the 245K required 12.6 minutes to complete a render of a single frame from the GN video intro animation. That has it about a minute faster than the 14600K, reducing the time requirement by 7.4%. The 245K is beaten by the ", " at 9.5 minutes, or a 24% reduction in time required. The 14700K (read ", ") is $350 as we write this, which is a 13% increase in price over the 245K. The 285K was a relatively impressive performer in this test as well, with only the ", " ahead of it. This is one of the few where Arrow Lake does OK in competitive scenarios.", "File compression with 7-Zip has the 245K at 122K MIPS, landing it behind the 13600K (watch ", ") and 14600K. The 13600K improves upon the 245K by 4.1%. The 245K is just ahead of the ", " and 9700X. The 7800X3D (watch ", ") isn’t far back, but the extra cache doesn’t benefit it in our production suite.", "The 285K with DDR5-8600 illustrated that this particular test benefits from better memory, providing a large uplift over the baseline 170K MIPS result that tied the stock setup with the 14700K.", "Decompression doesn’t benefit nearly as much from the memory improvement, but does benefit from the extra threads found on some CPUs. The 14900K-to-285K comparison is an easy example of this, as is the presence of both of AMD’s 16-core SKUs at the top of the chart.", "The 245K lands far down the chart, just ahead of the 5800X3D and behind the ", " and 7800X3D. The ", " illustrates that the higher frequency is more beneficial to this test than the extra cache on the 5800X3D. The 245K ends up beaten by the 14600K at 137K MIPS, an increase of 16%. The 13600K is similarly advantaged.", "The 285K’s 193K MIPS result has it 64% ahead of the 245K, similar to the lead we see from the 14900K over the 14600K.", "Ultimately, the 245K is beaten by several CPUs that are direct competitors, including the 7700 non-X (watch ", "), the preceding ", " and 14600K, the 7800X3D, and the 9700X.", "Chromium code compile is up now. We explained the memory capacity change for high-end parts and the frequency limit on the ", " in our ", ".", "In this one, the 245K required 134 minutes to complete the compile. That’s tied with the 14600K. The time requirement reduction for the 245K from the 9700X is 10% here, with the latter at 149 minutes. It’s also predictably better than the 7800X3D.", "The 13700K (watch ", ") reduces the compile time to 105 minutes, or a reduction in time of 21%.", "Using the Puget Suite, Adobe Premiere lands at 9824 points for the 245K. That has the new CPU sandwiched by the ", " and ", " above and the 13600K and 14600K below, with a more meaningful gap over the 9700X and 7800X3D. The $250 i7-13700K gives the 245K a serious run for its higher cost though, at 10616 points. ", "The 285K posts a large uplift over the 245K, at 15% higher in score. This was one of the more favorable tests for Arrow Lake with the 285K. That’s true too of the 245K, but there are better value alternatives (like the 13700K - especially now that Intel claims the microcode issue is fixed).", "Adobe Photoshop is dominated by AMD in the current iteration of the software and Puget test. The 245K and 285K are far down the list, both behind the 13700K, 14700K, and almost everything modern from AMD. It’s not much of a contest here.", "Here’s how it all breaks down: First off, we think you should probably just wait a week and see what the 9000X3D CPU does to the pricing and market. ", "That out of the way: It’s clear that Intel has, in fact, reduced its power consumption. That doesn’t mean, however, that it makes sense to purchase an Arrow Lake CPU. ", "Even catching the ATX12V power changes on our ASUS board, the CPU is lower power consumption and higher efficiency, even when it sometimes regresses in performance. Some games saw improved performance and lower power consumption, like Stellaris, which resulted in larger uplift than areas where we saw heavy performance regression, like Final Fantasy XIV: Dawntrail as compared to CPUs like the ", ".", "In production workloads, we saw regression from the ", " in 7-Zip compression (though it still beats the ", " there, so that’s impressive) and a few other areas. In Photoshop, the 245K improved on the 14600K technically, but AMD still holds a massive lead in this particular test. Premiere was a cleaner victory for the ", ", improving on the 14600K and reducing power draw.", "Gaming had the ", " down around the ", " levels in Baldur’s Gate 3 and ahead of the ", ", but getting crushed by the ", ", 5600X3D, and obviously the ", ". Although the 245K’s relative positioning against the ", " and 14600K flip-flopped, like in F1 where it was remarkably non-competitive, the global constant was that X3D outperformed the 245K. Fortunately for Intel, AMD doesn’t have any modern platform X3D CPUs that are in this price range. Until it replaces the ", " in price with an AM5 part, Intel will at least have an advantage in fully modernized I/O despite disadvantages elsewhere like in raw performance as compared to something like an AM4 platform build, which is also just building into a close-to-EOL ecosystem.", "Intel’s strongest argument right now is in the non-gaming workloads, but like the ", ", we just think the 245K has too much fierce competition to make sense at the moment. The efficiency improvement is important, and we talk at length about the power cost savings in the ", " to calculate it across several years of ownership. It’s good that they improved there. It’s just that this platform (1) isn’t really ready, having already half a dozen major bugs leading into launch, and (2) is embattled on all sides by similarly priced or cheaper options."]},
{"title": " ASRock & 9800X3D Instability and Failures | Report & Summary So Far", "paragraph": ["ASRock & 9800X3D Instability and Failures | Report & Summary So Far", "Last Updated: ", "The Highlights", "ASRock motherboards seem to be experiencing ", " (read ", ") failures at a higher rate than other motherboards.", " reports his CPU dying after two months. ", " experienced failure after two days. And ", " reported a dead 9800X3D after a week, and then claims his replacement 9800X3D also died after a week.", "This ", ", compiled by Reddit user u/natty_overlord, consists of over 80% observed on ASRock motherboards.", "Steve Burke", "Vitalii Makhnovets", "Tannen Williams", "Jimmy Thang", "Google Form results, collected by u/ofesad, who granted us permission to share his results, show numerous failures sharing the same CPU batch/lot number. This highlights possibly bad batches from AMD, but we think it’s more likely a BIOS issue.", " claim they “revived” their seemingly dead CPU by downgrading to a previous BIOS, and ", " that resolved their issues, but asked them not to share it.", "If these issues keep happening and AMD and ASRock can’t get to the bottom of it, we’ll do first-party, hands-on testing with some of the boards and CPUs that might be affected. But we think it looks like they’re getting to an answer so we’re going to monitor the situation because it looks pretty close to a resolution. This appears to be a couple possible issues. BIOS is definitely one of them. We’ll also talk about the batch thing, which seems a little shaky. ", "We’ll be able to use this piece later if ASRock and AMD can’t resolve the situation. This story offers a quick recap. We’ve compiled all the information we could find out there so far on the specific issues and failures so that you’ll have all of the evidence. If this helps you research any issues that you’re running into then we’ll also present a couple of solutions we found or we’ve thought up. ", "We’re making this because we compiled all of the research for it but we haven’t done a first-hand testing deep dive on it yet because we’re basically at a stage where we’re trying to figure out if that’s necessary. This is a new approach for us, where we’re compiling all of our research and we’re just going to put it out there and hopefully it helps someone. Likewise, hopefully some of the people who are running into problems with this issue might contact us with potential leads on where to go next.", "This is also Tannen’s first research piece and he’s done a great job compiling everything, digging through the forums, and putting together this report to share with you all and to hopefully help some people who are running into this. We plan on following up on this as we learn more. It may be contained to just hardware news, but if a lot of people inform us of potential leads then it may be possible that we revisit this with hands-on testing.", "Failures in any CPU line happen, but Intel’s recent issues were uniquely bad. We don’t see that too often. ", "The ", " a few months ago is also in recent memory, but after doing some forensics on that one, all evidence pointed toward crushing the socket at an angle and not being correctly oriented when the clamp was closed. That CPU also died immediately and before the user was ever able to boot, further reinforcing that 12V shorted to ground because it just died on boot.", "These ASRock and 9800X3D failures are ", ": They’re happening sometimes months into use, meaning that the systems did work, but ", ".", "Generally, CPUs are among the most stable components, and so it’s easy for the story to run away with the social media cycle -- but dozens of failures on one platform in a relatively short time span does cause questions.", "For perspective, though: Retailer ", " alone has sold over 20,000 9800X3Ds, leading us to estimate the worldwide units sold are in the hundreds of thousands. ", "There’s a very small chance of experiencing these issues yourself, even if you’re using a 9800X3D and ASRock motherboard. Both the number of reported failures and ASRock’s seemingly higher incident rate both stood out to us.", "Here’s what’s going on: Some user systems with a 9800X3D are able to POST, or power-on self-test, and run as expected. The time until failure ranges from under an hour to 3 months. Those with debug displays encounter a “00” error code, which commonly indicates a CPU problem. ", "There seems to be two root causes: First is a possible bad batch of CPUs from AMD; second appears to be ", " with system boots as well as motherboard settings possibly leading to potentially unstable CPUs.", "One of the things we came across here was a potential for voltage that was too low, which shouldn’t hurt anything. It just wouldn’t be able to boot. So that’s actually good news because that means you don’t have to, hopefully, worry about the CPU exploding. ", ".    ", "One challenge is that there are some dead CPUs out there with burn marks. Currently, the research we’ve been able to do makes it unclear how connected these issues are. We just want to be very transparent about that. Right now, it is impossible to differentiate with our current research between those possible failures without some more hands-on testing. We’ll keep monitoring to see if we need to more aggressively bring in components for testing, but with the pace ASRock has been working on this, we suspect they’ll hopefully have a fix before we could root-cause it since the lab team is bogged-down with other failure analysis right now.", "Strangely, we also noticed that ", " note their boards work fine with other processors either prior to or after their reported 9800X3D failures. ", "Let’s get into the causes of failure we found across the posts.", "All reported failures produce the same initial symptoms of failure, making it challenging to establish the source. Adding to the complexity, not everyone using a 9800X3D and ASRock motherboard experiences failures. We’ll start with findings from all failure types before covering specific cases where the origin is more easily identifiable.", "In the ", " of 42 9800X3D failures at the time of writing, the boards affected include: 34 ASRock, six ASUS, one Gigabyte, and one MSI. Chipsets include: 30 X870s, six B850s, four B650s, and two X670s. It appears to be distributed across multiple chipsets and multiple motherboards but the distribution seems to match what people tend to buy right now. Failures occurred on BIOS versions: ", ", ", ", ", " , ", " (beta), and ", " (beta), though it’s unclear if failures were necessarily caused by those BIOSes. For the time before failures: six weren’t specified, 15 occurred in a week or less with four of those happening in less than a day, 14 took place in the range of one week to one month, and seven took over a month before failing. ", "Also, four listings report the CPU showing burns or markings, which is what caught our attention.", "It’s hard to parse what might be causing those specific burns versus everything else so we’ll start with BIOS issues.", "At least four users fixed their presumably dead 9800X3Ds by flashing back BIOS to a previous version, which means the CPUs weren’t dead, and ", " remedied ", " by updating to a “special” BIOS sent to them by ASRock.", " noticed failure after updating to BIOS 3.16. ", " experienced the issue after updating to BIOS 3.18. ", "’s system malfunctioned shortly after installing Windows with the motherboard running 3.15 out of the box – turning the computer into a truly fancy potato. This was also the same BIOS ", " was using when he encountered failure.", "These user reports indicate failures typically happen after a BIOS update and suggest versions 3.15, 3.16, and 3.18 may cause boot issues.", "Three of those users claimed a BIOS flashback to an older 3.10, 3.11, or other old versions resolved their issue.", " explained that a 3.10 flashback didn’t immediately solve the problem, but after a second attempt at a 3.05 flashback, Eldaroth was able to “revive” the system. From there, the user flashed back to newer BIOSes and found 3.10 was the latest option working for the build.", "This suggests that the issues may not be killing the CPUs (except for the ones with the scorched marks, but that’s a different story), but that it may be a boot issue. The hope would be that a botched BIOS is just causing issues booting and not causing any damage to the CPU itself. It’s rare for a BIOS to damage a CPU, but it can happen. We saw that with ASUS previously on the 7800X3D, which is why everyone is so sensitive to this issue.", "At the time of writing this, we haven’t spotted any 9800X3D boot issues occurring on BIOS 3.10, possibly establishing it as the most stable option currently. Users who reverted to 3.10 reported their systems being fixed.", "As for the users who received a BIOS from ASRock: According to one, ", ", “Attached is the new BIOS. Please do not spread this yet. It will probably be released soon. This BIOS is not related to the dying CPUs. But it can help with some other boot issue. If you can try it that would be great. After the update, please remember to give the system a few minutes to see if it boots.” ", "That’s likely a reminder that memory training can also look like a boot failure. Especially in some configurations, memory training can take 5-10 minutes in some situations.", "The other user with the new BIOS ", ": “ASRock confirmed to me that 3.18.MEM03 that they provided to me increases the voltage to 1.2V for the 9800X3D and that allows it to boot and fix the 00 debug code. The issue is that not enough voltage was applied for some 9800X3D units and it was not stable.” Both users reported this BIOS resolved their situation.", "This would be better than the possibility that it was overvolting the CPUs, which would be the only likely way the BIOS would actually inflict damage to the CPU. Too little voltage likely won’t hurt, but it’d also be unstable. If this is the case, then this would be one of the better failures to have.", "On February 24th, ", " with the description stating, “Improve minority proportion of AMD 9000 series CPU boot issue.” We assume this was the same BIOS previously sent out to those select users. ", "To be clear, BIOS updates won’t “revive” a literally dead CPU, but they can potentially solve boot issues causing your CPU to appear as dead. We think some users experiencing boot issues and concluding it’s a dead CPU might’ve partially contributed to ASRock’s disproportionate CPU failures, and actually what they might have been seeing instead was just that it wasn’t booting without the CPU being dead, though we can’t fault the users for believing that.", "Moving on to the failures possibly caused by a bad CPU batch.", "As seen in the “9800X3D fails” Google Form results, out of the nine users who included their CPU’s batch/lot number in their response, seven are from batches CF 2443PGY or CF 2442PGY. ", "But remember that this could be completely coincidental and doesn’t necessarily guarantee bad batches. We at GN have CPUs from both of these batches and they’re fine. There is a lot of coincidence here: AMD’s 9800X3Ds have been in high demand and they haven’t been out too long yet. We don’t know how many batches there are, but we wouldn’t think it’s a crazy amount. Likewise, people experiencing any kind of failure, whether that’s caused by the board or the CPU, would be likely on a similar batch if they’re all building and buying around the same time. ", "We wouldn’t definitively state that there is a bad batch, but it’s still worth exploring and considering in case this develops and more people report failures from these batches. CF 2443PGY and CF 2442PGY would be the 2 codes to pay attention to.", "In those seven responses of the exploded CPUs, the motherboards include: three ASUS, two ASRock, 1 Gigabyte, and 1 MSI, illustrating an expected distribution of failures. ASUS is the largest vendor by market share.", "If you have a definitely dead CPU and you want to check the batch number, here’s how to identify it. This is also useful for warranty claims. ", "The CPU batch number can be found in the image above, outlined in red. The batch number begins with two letters, which we believe to indicate CPU stepping. ", ", the letters are followed by four digits specifying the year and week the CPU was manufactured, and ends with three letters specifying ATMP and wafer production location.", "In the case of the “CF 2443PGY” batch, these were produced towards the end of October 2024 and assembled in Penang, Malaysia.", "There’s been something of an ASRock response, though as of writing this, they’re still investigating.", "Current boot issues are addressed by the company’s most recent ", ", though its efficacy has yet to be determined on a large scale.", ", which has been machine translated, states issues occur after updating BIOS on already stable systems. ", "If we jump back to u/Fancy_Potato1476, mostly because the name conveys a certain opulence that we appreciate, the fancy potato didn’t update BIOS and still experienced boot issues, seemingly contradicting ASRock's claim. The ASRock post further explains:", "The issue is caused by some older DDR5 RAM and certain memory controllers on X3D CPUs, as well as the impact of Agesa.” ", "The first part of that wouldn’t really make sense because if the system is working and then it stops working, that doesn’t really link up to RAM that was stable and then just suddenly wasn’t, but what might connect it is the Agesa part, which is the binary that AMD distributes that’s part of the BIOS and that would affect memory behavior. So if there’s any truth to that statement, then it’s the Agesa part that’s key.", "When asked if it’s AMD or ASRock who’s responsible, the company stated via translation, “It is caused by a very specific combination of components.” ", "The post ends by repeatedly expressing, “Do NOT update the BIOS if it’s running stably.” ", "Generally, we’d agree. These days, new BIOSes can offer important security patches; however, broadly speaking, we prefer not messing with BIOS if everything is working well and there’s no strong security reason to. ", "It looks like a combination of issues. There’s definitely a BIOS problem. There’s potentially a problem with the voltage being too low, which is causing inoperability at attempted boot that shouldn’t harm anything physically, so that’s a good problem to have as far as problems go. There’s also a potential bad batch issue. The BIOS issue could have multiple sub-issues, including too high voltage. Some users reported excessive VSOC via HWINFO, but these numbers aren’t always accurate and should be double-checked with physical measurements. ", "Some general advice for anyone running into things like this: First, you’d want to rule-out memory training on initial boot. AMD systems, in particular, may require additional time to complete memory training where it’s essentially tuning your memory timings. Memory training normally only happens on the first boot. This shouldn’t take over 15 minutes with a new configuration and should finish much faster for configured systems.", "For those using a ", " on an ASRock board, we’d follow ASRock Japan’s recommendations of not updating BIOS unless something appears unstable. ", "If something does appear off, we’d advise a flashback to version 3.10 or 3.11 if 3.10’s unavailable. These appear to be the most stable versions of BIOSes in relation to the boot issues. We’d temporarily hold off on updating to the latest 3.20 beta BIOS (unless you have issues already, in which case you should just update) mainly because it’s extremely recent, and beta BIOSes are generally less stable.", "Use Flash Back if you already are on an unstable BIOS. This allows a BIOS flash without stability of the platform via a USB key.", "If your system’s failing to post after previously working, we’d first recommend inspecting the CPU for any markings before going forward. We’d also advise checking your batch number at this point while your cooler’s uninstalled. ", "For the handful of users with another compatible motherboard, we’d suggest using it to test your CPU’s ability to post. This would determine whether your processor’s dead or if there’s a boot issue. If your CPU’s unable to boot in the secondary motherboard or if you don’t have access to one, we’d advise flashing back to BIOS 3.10 first, then 3.20, and finally 3.05, in that order. After each flashback, give your system a few minutes before attempting to boot. If any of these resolve your issue, we’d suggest staying on that version.", "If these options don’t go anywhere, you’re unfortunately left with returning the parts to the retailer if you have a warranty or going through an RMA with AMD. Luckily, we haven’t found any claims rejected and ", " after submission. ", "If you’ve experienced a failure with one of your components and you don’t think it was something that we’ve already covered, you should email us at ", ". Conversely, if it’s something we’ve covered and we’re just not done yet, like with this story, for example, then let us know and we might be interested in buying components. We’re also doing an RMA rescue series on our ", ", where we’re basically buying people’s failed components and then pursuing the RMA instead of them having to go through the process of having to do it so that we can test a manufacturer’s warranty process with an actual failed component from an end user. ", "Moving forward, we’ll keep following this story if anything develops further."]},
{"title": " More Marketing BS: NVIDIA GeForce RTX 5060 Ti Review & Benchmarks vs GTX 1060, 4060 Ti, & More", "paragraph": ["More Marketing BS: NVIDIA GeForce RTX 5060 Ti Review & Benchmarks vs GTX 1060, 4060 Ti, & More", "Last Updated: ", "The Highlights", "The shortest possible conclusion upfront is that the 5060 Ti is about 13%-27% better than the ", " at 1440p, typically in the range of 20-25%. At 1080p, the new card is 11-24% better, typically about 18-20%. ", "Against the ", " from 5 years ago, the 5060 Ti at 1440p is 16-39% improved, depending on the game. 1080p posted 21-40% gains, with a huge exception in Black Myth with ray tracing enabled, where there was a 56% uplift. The 3060 Ti was also the card that the 4060 Ti sometimes lost against.", "For older devices or possible used candidates, the closest alternatives (by performance) to pay attention to in our charts will be the 3080 (watch ", ") and 3070 Ti (watch ", "), which often flank the 5060 Ti, and the ", " (read ", ") or ", " (read ", ") on AMD's side.", "Steve Burke", "Mike Gaglione", "Jeremy Clayton", "Vitalii Makhnovets", "Andrew Coleman", "Jimmy Thang", "But pricing is the big challenge today. NVIDIA says that this card has an MSRP of $430, with the 8GB variant at $380 and RTX 5060 non-Ti at $300, launching in May. The 5060 Ti cards launch today with the reviews. We only have the 16GB model right now. We might look at the 8GB version later.", "Full transparency up-front. We’re keeping this review as simple and focused as possible, mostly because we’re currently ", ". We still have dozens of gaming charts, but we wanted to be clear on that. ", "We’re also going to keep our concluding thoughts simple because we need to see how the actual pricing shakes-out before making firmer judgments, which means there’ll be more discussion in the coming weeks -- likely in HW News or potentially another dedicated story.", "With that out of the way, here’s a quick version of the specs:", "The short version is that NVIDIA’s RTX 5060 Ti ships in either 8GB or 16GB variants. The review samples we’re aware of are the 16GB model. There shouldn’t be any difference between these beyond the memory, from what we’re told. These cards have 4608 CUDA cores, 144 TMUs, and a gacha box of ROPs. Memory bandwidth is rated at 448GB/s with a memory bus of 128-bit, which is why we have the multiples of 8GB for memory.", "The ", " technically has a lower memory capacity at 12GB. Theoretically, they could do a 24GB model, but these options stem from the bus width and controller choices.", "The RTX 5060 non-Ti will ship in May and have 3840 CUDA cores with an 8GB framebuffer, also on a 128-bit bus.", "AMD’s competition will include the, in theory, RX 9060 series, for which we don’t have full details yet. We’ll hear about that more likely next month.", "We’re keeping it simple today, so let’s just get into the benchmarks.", "Final Fantasy 14 at 4K is up first.", "This one was bad for the RTX 4060 Ti, with the card landing at an abysmal 41 FPS AVG as compared to the 3060 Ti FTW3’s 48 FPS AVG. RIP EVGA. We explained this regression in our ", " previously, which we titled “Do Not Buy.” Spoiler alert: The conclusion was to not buy it.", "The 5060 Ti isn’t really competing with the 4060 Ti here: It’s competing with the 3060 Ti, and against that, we see an uplift of 12% to 54 FPS AVG. The improvement over the 4060 Ti looks more impressive, but that’s because the 4060 Ti sucks. The uplift over its 41 FPS AVG was 31%. The RTX 5070’s 78 FPS AVG has it about 43% ahead of the 5060 Ti.", "Used RTX 3070 (watch ", ") and 3070 Ti cards might be worth exploring: We saw completed and sold listings on eBay ranging from $270 to $340, which would put them below the 5060 Ti if it even hits its marketed MSRP, which it probably won’t. The 3070 is about equal to the 5060 Ti, with the 3070 Ti slightly ahead.", "AMD’s RX 7800 XT is its closest performer to the 5060 Ti, landing at 58 FPS AVG and leading the 5060 Ti by almost 7%. ", "AMD’s ", " (watch ", ") falls way down the chart and runs at 32 FPS AVG. But then again, AMD does overall poorly in this particular game, with its ", " (read ", ") down below the RTX 5070. We talked about that in our ", ".", "Finally, NVIDIA’s claimed 50x performance increase over the GTX 1060 (watch ", ") doesn’t come to fruition when not arbitrarily enabling and disabling favorable settings. The 1060 ran at 16 FPS AVG. 16 x 50 is 800 FPS, which would be 4x the performance of an ", " (read ", "). We’ve gone beyond an RTX 5070 = ", " and to a RTX 5060 Ti = RTX 9090. In reality, the 5060 Ti is 236% ahead. That’s still a big jump, but no need to stretch the truth about it.", "At 1440p, the RTX 5060 Ti landed at 104 FPS AVG, which has it functionally tied with the 3070 Ti’s 108 FPS AVG and only slightly ahead of the 7700 XT’s 98 FPS AVG or ", "’s 97 FPS AVG. The lead over the 3060 Ti is now 16%, or about 25% ahead of the 4060 Ti. These gains are down from 4K. Lows are where you’d expect them for each card, with no meaningful differences.", "The 5070 is about 47% ahead of the 5060 Ti, slightly up from the lead at 4K.", "AMD’s ", " ran at 126 FPS AVG here, producing a 22% advantage. The MSRP is higher, but then so is everything, including the companies that set these prices.", "The GTX 1060 ran at 33 FPS AVG here, the 1650 (watch ", ") at 23 FPS, 6500 XT (watch ", ") at 31 FPS, and 3050 (watch ", ") at 45 FPS AVG. Predictably, the 5060 Ti is a big improvement over all of these, but again, not 50x.", "At 1080p, the 5060 Ti ran at 160 FPS AVG. That’s about the same as the 7700 XT and slightly ahead of the 3070 Ti. It’s finally moving up the relative ranking compared to Ampere. We think you’d still be better off with a used card right now. ", "The 4060 Ti ran at 133 FPS AVG here, so the 5060 Ti improves by 20%. Against the 3060 Ti, the 5060 Ti is about 25% better. The 4060 Ti is finally better than the 3060 Ti when at 1080p, so those two have flipped as well.", "The lower-end round-up includes the GTX 1060 at 51 FPS AVG, 3050 at 66, 1070 (watch ", ") at 70, and 2060 (watch ", ") at 83. The 6600 (watch ", ") ran at 86 FPS AVG and AMD’s ", " ran at 107 FPS AVG.", "Black Myth: Wukong is up now, first at 4K. The 5060 Ti ran at 31 FPS AVG. That’s obviously unplayable and is because of the resolution and settings, but it’s still useful for relative scaling.", "The result has it about equal to a 7800 XT. The 3080 leads by 18%, with the 5070 leading by 29%. The 3070 Ti ran a lower framerate than the 5060 Ti in this one.", "Let’s move to something more playable.", "At 1440p, the 5060 Ti ran at 57 FPS AVG and landed right between the 7800 XT and RTX 4070 (watch ", "). These are all effectively tied. The 5070 held a 72 FPS AVG, or 27% ahead. That’s slightly down from 4K. The 5060 Ti is ahead of the 3070 Ti by 13%, the 4060 Ti by 27%, and the 3060 Ti by 34%. This is one of the games where the 4060 Ti and 3060 Ti are right next to each other. ", "AMD’s 7600 ran at 31.6 FPS AVG and isn’t really in the same class of card as what we’re reviewing today. Its 7800 XT and 7900 GRE (read ", ") are the most comparable, but in theory, the inbound 9060 XT should be fighting in this territory.", "At 1080p, the 5060 Ti pushed 81 FPS average with lows where you’d expect given the average. There is no particularly special frametime consistency benefit.", "The 5060 Ti ends up at about the same level as the RTX 3080 and RTX 4070 (watch ", "). The 5070, ", " (no matter what NVIDIA says), and its 98 FPS AVG puts it 21% ahead of the 5060 Ti.", "As for the last generations, NVIDIA’s new 5060 Ti leads the 4060 Ti by 24%, or the 3060 Ti by 40%. ", "AMD’s 7900 GRE is its closest card here, slightly ahead of the 5060 Ti, with the 7800 XT just behind. ", "Intel’s ", " cards are at around 46 FPS AVG, which has them similar to the RX 7600.", "In Starfield at 4K, the 5060 Ti ran at 41 FPS AVG with lows at 34 and 29, proportional to the cards around it. This puts the 3080 ahead of the 5060 Ti and the 5060 Ti ahead of the 3070 Ti. ", "AMD’s 7800 XT outdoes the 5060 Ti by 18%, with the more expensive 9070 non-XT up at 63 FPS AVG.", "The RTX 5070 ran at 54 FPS AVG here, 32% ahead of the 5060 Ti. We’ll move to 1440p for prior generations.", "At 1440p, the 5060 Ti landed at 65 FPS AVG. Unfortunately for NVIDIA, this is a terrible result: The 4060 Ti was at 58 FPS AVG, narrowing the uplift to only 13.4%. That isn’t a big improvement. The lead over the 3060 Ti’s 50 FPS AVG is 30%, also not that impressive for two generations.", "AMD’s 7800 XT leads the 5060 Ti by 15.5%, with the 9070 (read ", ") obviously way ahead given its higher theoretical price and positioning.", "For those considering used options, the 5060 Ti only outdoes the 3070 Ti by about 8%, making it a reasonable alternative that might save some money.", "At 1080p, the 5060 Ti held an 82 FPS AVG with lows positioned about the same as everything around it. The 3070 Ti’s 76 FPS AVG encroaches on the 5060 Ti’s result and, from an actual human perspective, would look about the same. The 4070 outperforms the 5060 Ti by 16%, with the 5070 ahead by 26%. ", "The 4060 Ti’s 74 FPS AVG means the 5060 Ti is about 11% better, overall a boring generational jaunt. The uplift over the 3060 Ti is 28%.", "Dragon’s Dogma 2 at 4K is up next.", "The 5060 Ti ran at 40 FPS AVG, so it’s nearly exactly tied with the 3070 Ti. The 0.2 FPS AVG advantage is well within run-to-run variance. Lows are also tied. AMD’s 7800 XT is 17% ahead of the 5060 Ti’s average FPS, with the 5070 ahead by 41%.", "We’ll move to lower resolutions to look at the prior generation 60 and 60 Ti-class cards.", "At 1440p, the 5060 Ti ran at 70 FPS AVG, planting it right in the middle of the 3080 and 7700 XT. The 3070 Ti is right behind with a 65 FPS AVG, with the 4060 Ti at about the level of the 3070. The new 5060 Ti leads the 4060 Ti by 22% and the 3060 Ti with its 53 FPS AVG by 32%.", "AMD’s 7600 is far down this chart, so it’ll need something newer in the 9060 class to compete here. Intel’s B580 is also down near the RTX 4060 and RX 6600 XT (watch ", ").", "As for what’s better than the 5060 Ti: Other than the 3080, the 4070 is about 12% better and 5070 is about 37% higher average FPS.", "At 1080p, the 5060 Ti ran at 93 FPS AVG, landing between the 3080 and 7700 XT again. The improvement over the 4060 Ti is just 19%, followed by the 3060 Ti’s 68 FPS AVG for an uplift of 36%. The 3070 Ti gives the 5060 Ti just a 10% lead, doing better than the 4060 Ti.", "As for the GTX 1060, considering 50x its performance would put it over 1,100 FPS, we’d say NVIDIA missed the mark on this by orders of magnitude.", "Cyberpunk 2077: Phantom Liberty is next. This is newer data, so we haven’t re-run the 4060 Ti, 4060, and 3060 series cards through here yet. We’ll show it anyway for the other comparisons.", "At 4K/Ultra without RT first, the RTX 5060 Ti ran at 31 FPS AVG. This has it meaningfully ahead of the 3070 Ti by percentage, improved by 19%. The 7800 XT leads the 5060 Ti by about 10% here, with the 5070 about 30% ahead of the 5060 Ti.", "At 1440p, the 5060 Ti ran at 68 FPS AVG, putting the 5060 Ti between the 3080 and 3070 Ti. The 5070 ends up about 30% ahead with its 88 FPS AVG, meaning that, if we just pretend that the MSRP numbers stick, you’re paying about 1% more money for every 1% more performance between the 16GB 5060 Ti and 5070. ", "At 1080p, the 5070 is down to a 27% lead over the 5060 Ti. The 5060 Ti now leads the 3070 Ti by 20% and the 3070 non-Ti by 27%. The 7800 XT is about 8% ahead of the 5060 Ti here.", "Let’s move to something where we have last-gen numbers.", "Dying Light 2 at 1440p is one of the situations that was bad for the 4060 Ti versus the 3060 Ti: The two cards are indistinguishable, with performance identical between them. The RTX 5060 Ti ran at 74 FPS AVG, so it outperforms the 4060 Ti (and therefore 3060 Ti) by about 23%. It took them two generations, but they’ve finally beaten the 3060 Ti in this game. The 4070 is about 6% better than the 5060 Ti here, with the 7800 XT about 14% ahead. The 5070 leads the 5060 Ti by 44% here, so if anything, the 5060 Ti stands to make the 5070 look better. Against the Intel B580’s 63 FPS AVG, NVIDIA’s 5060 Ti is about 17% better in one of the better B580 showings. ", "1080p has the 3060 Ti and 4060 Ti again roughly adjacent to one another, with the 5060 Ti leading the 4060 Ti by 19%. The 5060 Ti’s lead has diminished from the 1440p result. The 5060 Ti is similar to the 7700 XT’s performance here, including in lows, with the 4070 leading the 5060 Ti by almost 9%.", "Against older cards, the 5060 Ti improves on the GTX 1060 by not 50x, to nobody’s surprise, and instead by about 3.8x. Even with MFG, you would not get 50x. Maybe with DLSS at Ultra Sh*t quality and upscaling from 144p, we’re not certain you could squeeze 50x out of this lemon, though. You’d have to go out of your way to hurt the 1060.", "For those still on an RTX 2060, you can expect about a doubling of performance to the 5060 Ti in a scenario like this. ", "Resident Evil 4 is up now, first at 4K and without ray tracing. The RTX 5060 Ti ends up performing about the same as the 7700 XT. The RTX 4070 leads the 5060 Ti by about 10-11% here, at 63 FPS AVG to 57, with the 5070 leading by 38%. That’s similar to what we’ve seen elsewhere so far. The 3060 Ti also launched for $400. Adjusted for inflation, that amounts to $491. The new card is $430. So things haven’t changed that much. The price is similar/slightly lower and performance has hardly improved. The improvement over the 2060 is about 135%. ", "At 1440p, the 5060 Ti leads the 3070 Ti by 13% and the 4060 Ti by 23%, followed by the 3060 Ti at 36.5%. The reduced resolution has benefitted the 4060 Ti marginally, allowing it to distance itself from the 3060 Ti. The B580 (read ", ") is actually around the 3060 Ti’s performance, excepting 1% lows.", "As for the RTX 5070, which remains not a 4090 (watch ", "), NVIDIA’s biggest lie leads the 5060 Ti by 36%. ", "AMD still doesn’t have a new and direct competitor here, but probably will in May in the 9060 series. For now, the 7700 XT is the closest and outperforms the 5060 Ti slightly.", "Ray tracing is up next. These games are generally a heavier load, so we have a mix of upscaled benchmarks and of native resolution benchmarks, but all of them are with RT on now.", "In Black Myth: Wukong at 4K upscaled, the RTX 5060 Ti landed at 29 FPS AVG. That has it ahead of the RX 9070, which is more of a problem for AMD than it is a positive for NVIDIA. We already knew this about this game and AMD, though. The 9070 XT ends up about tied with the 5060 Ti here, and actually, the 3090 non-Ti (watch ", ") at 29.8 FPS AVG is only about 3-4% ahead of the 5060 Ti. This game remains heavily favored for NVIDIA, especially with ray tracing. ", "The RTX 5070 has a large lead at 40 FPS AVG, although its memory capacity can prove problematic in some of these heavier scenarios. The 5070 leads by 39% here. The 5060 Ti also shows more meaningful gains over the 3070 Ti in this test than in some of the raster tests, at 31% improved.", "At 1080p upscaled, the 5060 Ti's 74 FPS AVG has it ahead of the 9070 XT, 3090, and 3080. It also leads the 4060 Ti by 19% and the 3060 Ti's 48 FPS AVG by 57%.", "The generational RT uplift is helping the 5060 Ti distinguish itself more here than it did when rasterized.", "Against the first-gen ray tracing 60-class card, the RTX 2060, we're seeing a 175% improvement.", "In Dragon's Dogma 2 at 4K and with ray tracing, the RTX 5060 Ti ran at 35 FPS AVG and roughly tied (but technically led) the 3070 Ti. That has it better than the 2080 and 2080 Ti of years past, although the 3080 still manages to best the 5060 Ti. AMD's 7900 GRE outperforms the 5060 Ti slightly, with its newer 9070 cards performing up around 3090 Ti levels -- but at a higher theoretical base MSRP than the 5060 Ti.", "At 1440p with RT, the 5060 Ti ran at 62 FPS AVG and kept the lows consistent with the average. There's nothing particularly impressive or bad for the frametime consistency and lows. It’s just kind of where we’d expect it. ", "The 4070 and 7800 XT are about 9% ahead of the 5060 Ti. And for that matter, the 3080 is around that same area. The 5070's 82.8 FPS AVG is around 34% ahead of the 62 FPS for the 5060 Ti. We've seen higher in other games.", "As for the lower-rank cards, the 4060 Ti ran at 49 FPS AVG and yields a 26% uplift to the 5060 Ti. The 3060 Ti isn't far behind the 4060 Ti in this one, but at least they're in the order you'd expect them to be. ", "At 1080p, the 5060 Ti's 82 FPS AVG landed it between the 3080 and 7700 XT again. This has been consistent. This result gives it a 20% improvement over the 4060 Ti and 37% improvement over the 3060 Ti.", "Dying Light 2 is up next. Dying Light 2 at 4K upscaled with ray tracing has the 5060 Ti at 31.8 FPS AVG and exactly tied with the 7900 GRE for average and 1% lows. The 5070 improves to 43.7 FPS AVG, or 37% once again. This seems to be a fairly consistent percentage improvement to the 5070.", "At 1440p upscaled with RT, the 5060 Ti ran at 60 FPS AVG. We haven't yet re-run the 4060 Ti or 3060 Ti in this one, leaving us to compare instead with the 7900 GRE -- where they're about equal -- and the 3080, which remains a bit ahead of the 5060 Ti. The 5070 leads at 81 FPS AVG, or 34%.", "At 1080p, we re-introduce the 4060 Ti and 3060 Ti. The 5060 Ti's 87 FPS AVG has it about 20% ahead of the 4060 Ti, which itself was only 11% ahead of the 3060 Ti. The B580 is actually somewhat close here, roughly tying the 3060 Ti. As for AMD, the 7900 GRE remains the next closest to the 5060 Ti.", "Resident Evil 4 is up with ray tracing now, first with 4K and upscaled. The 5060 Ti's 67 FPS AVG has it tied with the 7700 XT, including in the 1% and 0.1% lows. The 4070 and 3080 lead these results, as they have for the past games. The 5070 leads the 5060 Ti by 36%, close to prior results. As for the 4060 Ti, its 52 FPS AVG gives the 5060 Ti a lead of 30% for one of the larger gaps.", "At 1440p, the 5060 Ti again falls between the 7700 XT and RTX 3080. The lead over the 4060 Ti is narrowed to 24% now, with the uplift over the 3060 Ti at 39%.", "In Cyberpunk 2077: Phantom Liberty at 1080p RT Medium, the 5060 Ti ran at 63 FPS AVG and sat between the 7900 GRE and 7900 XT. The lead over the 3070 Ti is about 10 FPS AVG here, or 17%. The 5070's 82 FPS AVG has it 31% ahead of the 5060 Ti, down in relative improvement from other benchmarks.", "At 1080p and with RT Ultra, the 5060 Ti ran at 50 FPS AVG (which is really not bad when considering how heavy this workload is), or just ahead of the ", ". The 3070 Ti hit 40 FPS AVG here, with lows suffering for the 0.1% value. The 5060 Ti's lows are OK in this one, supported by the 16GB capacity.", "We’ve provided the benchmark numbers above. At the very least, you have the data you need to figure out if an upgrade makes sense for you. This is going to be one where we withhold full value judgment until it properly launches because we do not trust the MSRP to persist for the majority of purchasers.", "It certainly isn’t going to 50x a GTX 1060, though.", "The 16GB RTX 5060 Ti’s MSRP is set at $430, whether or not we see it at that. That’s better than the previous 16GB 4060 Ti’s launch MSRP of $500, which was atrocious. The 4060 Ti 8GB model was $400, so 8GB more memory used to be a $100 upsell, but no one bought that, so now it’s a $50 upcharge. ", "Accounting for inflation favors the 5060 Ti over the ", " for the 16GB models with MSRPs. ", "Nearest performance neighbors to the 16GB RTX 5060 Ti are typically the RTX 3080 and RX ", " above, and ", " and RTX 3070 Ti commonly below.", "We’d love to dig into value comparisons between the 5060 Ti and its current competitors, but the availability of GPUs at retail in this price bracket ($380-$480) is terrible. ", "Using Newegg as a representation shows only 9 SKUs of any video card sold by Newegg in stock in that price range, and only one of them is actually brand new. It’s an EVGA RTX 3060 XC (not a Ti) for $440, which is an awful price.", "So without any new cards to buy in this price bracket, we can look toward used options -- and this is where we think people should be seriously looking.", "The RX 7900 GRE was around $627 average for sold listings, followed by the RX 6950 XT and 7800 XT at $556-$575 on average and the RX 7700 XT at $472 average.", "There’s a potential edge case where a good deal on an RX 6950 XT could be an interesting higher-performing wild card – but that’s only if you’re entirely focused on raster performance, and you’re willing to hunt for a deal on one around $500. Higher power consumption is also something to consider. NVIDIA’s 5060 Ti is more efficient.", "A used RTX 3070 Ti at $358 average would be a good lower-performing budget option below the MSRP of a new RTX 5060 Ti of any capacity. We found some that were in the upper $280-$290 to lower $310 range, which would be worth seriously considering. VRAM may be limiting in some situations. The RTX 3080 is going for around $449 and typically beats or is close to the 5060 Ti. The 3080 isn’t cheap enough on the second-hand market yet to get our strong recommendation in this specific scenario. That’s doubly the case for used RTX 4070s at the time of writing, which are newer and have been selling for $621 on average.", "And that brings us to what we’ve said a lot in the past: if your computer is doing what you need it to do and if you don’t feel a need to upgrade, then we’d say hold off. But some people do either “need” to buy new devices to replace aging hardware or just really want the escape of building a PC, which we also appreciate and relate to. It’s just going to come down to your price tolerance.", "Right now, we really don’t have the answers. ", "We’re trying to figure them out, which is why we’re currently flying all around the US at our own expense to talk to companies about the pricing situation. We hate to not be able to give a value judgment at the end of a review, but until this card is actually available -- which will coincide with the launch of this review -- we just can’t know what it’s going to cost.", "Once it is, we’re going to do a recap either in the news or standalone.", "Just for context: We just met with a distributor that buys hundreds of thousands of GPUs per year. Last week, we saw their cost to buy RTX 5090s. The cheapest was around $2,400 up to $3,000, and that’s their cost. That means $2,000 is impossible. We’re not sure to what extent that’ll affect the 5060 Ti cards, especially after the launch period where pressure to maintain the price is off.", "Now maybe that’ll change with the partial tariff exemptions, but those are up in the air."]},
{"title": " This Case is a Disaster | Tryx LUCA L70 Review", "paragraph": ["This Case is a Disaster | Tryx LUCA L70 Review", "Last Updated: ", "The Highlights", "This case has the most build quality and assembly issues we’ve ever encountered out of the box.", "There were gouges in the aluminum feet, a corner that was severely bent, deformed fan rails, and other more minor issues -- like the entire motherboard tray and rear panel assembly being bent, bottom support for the hinged door being bent down, and an aluminum plate over the front I/O that was bent. Even if some of these were catalyzed by shipping impacts, Tryx is responsible for not only packing the product in a way they can ship it, but also ensuring that their design is resilient enough to withstand the basics of transit.", "Steve Burke", "Patrick Lathan", "Vitalii Makhnovets", "Tim Phetdara", "Andrew Coleman", "Jimmy Thang", "At least one fault is inherent to the case design: the top panel sagged down, misaligning the snaps for the side and front panels. ", "Its snaps were already loose, but knocked out of alignment, they can barely hold its panels on. There's a reason that cases often have a support pillar in the front corner, or at least something like the ", "’s ", ".", "So we think the build quality is overall worse than the $34 Zondda-O we ", ", except the Tryx LUCA L70 costs $240.", "Tryx is a new company, which may partly explain why we were given a special, later embargo of today. Today is the launch of the case. Strangely, some reviews were selectively permitted to go live before us, something we were not made aware of until they posted. This doesn’t affect our bottom line since you all come to our case reviews for our work, which we appreciate, but it does reflect on what appears to be teething pains for a new company. Some of those same growing pains are seen throughout the case design, and today, we’re reviewing the LUCA L70 case from Tryx, a company which has major funding behind it despite being new. And our hope is that the company can learn from our review for its future projects.", "Some quick backstory: Tryx is a brand new manufacturer that first came on the scene with its ", ", but it also more recently ", ", including the LUCA. The LUCA L70 is the first to market, with a mesh-fronted ", " variant likely following at a later date. ", "Tryx is a vaguely cosmic-y themed company. “LUCA” stands for “Last Universal Common Ancestor”; as for the other cases that have been revealed so far, ", " is the name of what could be the oldest known animal fossil -- fitting for a case with a front panel essentially made out of future dust.", "But despite being new, Tryx is not inexperienced. The company was founded by former members of ASUS, Cooler Master, and Asetek. Asetek is the forlorn water cooling company that has been largely replaced in the DIY market. Asetek has put some serious marketing effort behind Tryx, which is its premiere partner for the new generation of pump in its Panorama cooler. Tryx also hosted an expensive influencer event for its launch in China, where it featured space-themed set dressing and hosted influencers from Bilibili.", "So the company has some money to it and isn’t just some small, fresh startup; in fact, the former Cooler Master General Manager of the Case Business Unit is a co-founder of Tryx.", "That’s the backstory. Let’s get into the case.", "The L70 is priced at $240 for the two variants, black and white. The ", " states that under normal airflow conditions, the case will not experience negative pressure that could cause an explosion, which we really hope is a joke about… spaceships, or something. Regardless, the L70 non-Air doesn't ship with any fans, so explosion danger is minimal.", "The Tryx L70 has an ASUS ROG look to it, specifically reminding us of the old ", ": it's big, it's expensive, and there are huge chunks of aluminum, which is an expensive material. We weren't impressed by the ", " based on its price and thermal performance, but we've also kept one in our set background for months because, like the L70, it's impressive to look at.", "If any part of the case's appearance is divisive, we expect it to be the top panel with its toilet bowl angles centered on the shiny stainless-steel nameplate. Or maybe the aluminum side that extends all the way to the floor.", "Now with the top panel, there’s a good idea there. We don’t get too much into the subjective, but this case sort of demands it: We feel like a more seasoned company might try to pull this motif across more of the case, but as it stands, it is an almost random-looking assortment of materials and geometric patterns. We do think there’s something in that top panel design and like it overall, despite our issues elsewhere in the enclosure.", "We’ll start with a flyover of the negatives. We're going to be nitpicky here, because there are a lot of small problems that are hard to get past at $240.", "We already listed the litany of issues with gouges, bends, deformed rails, loose snaps, and caving-in panels near the top of the review. Those complaints remain -- but we do have more. ", "We’ll start with this one: Tryx ", ", but large parts of the bottom of the case are surrounded by an impenetrable aluminum curtain. The bottom fan bracket sits on top of redundant fan mounts built into the case. The bottom vent is a typical design with punched holes backed by a filter, but it would have benefited from being more open, like the ", ", to allow those fans to breathe.", "Tryx also makes the claim that the case is “-13% smaller desktop footprint.” Now, you might ask, “13% smaller than what?” After asking, we learned that this is apparently in comparison to dual-chamber cases. Now, again, the natural inclination is to ask about which one. It’s made-up. No one knows.", "Regardless of how many percentage points smaller than something imaginary the L70 is, it’s still large. With our test system installed, the whole PC weighs almost 24kg, but the weight is only really a problem because it causes flexing when picking up the case, especially with the lack of support between the two glass panels. We complain sometimes about completely toolless glass panels, but this is the first case we've reviewed in a long time that has felt like a panel might actually fall off. And actually, while we were taking b-roll, the glass side panel did pop-out when we repositioned the case.", "We repeatedly had problems with the I/O cables not being long enough as routed out of the box, which is worsened by needing to route cables around the hinged magnetic SSD mounting bracket. The small plate that extends the motherboard tray also made things worse; we installed it because that's what the manual shows, but at the bottom of the motherboard it partially blocks cutouts that are needed for I/O and fans, and at the top it partially blocks off cutouts that are needed for CPU power on non-back-connect motherboards. It seems like this was either never built in or not thought-through.", "There are multiple locations in the case where captive thumbscrews are used inappropriately: On the motherboard tray, they're used to fasten two sheets of steel that are nearly flush, so the threads wedge the two pieces together as the screw is removed. Another is used to fasten the PSU cage in place, but it has to be completely removed in order to move the cage despite being captive. Both the motherboard tray and the PSU cage use tiny flush-head screws in addition to the thumbscrews, so you have to use a screwdriver no matter what.", "There are 9x 2.5 drive mounts in the Tryx, 3x on the SSD Mounting Bracket and 6x on the SSD/HDD Mounting Bracket, which can alternatively mount 2x 3.5 HDDs. Cable covers are unnecessary, but doubly so when you can't even see through the side panel: they chop up the huge 63mm-deep cable management space for no reason, requiring routing around them, and mounting drives to the covers requires leaving cable slack so that they can hinge open. ", "The SSD bracket can either open or close the side vent; in the closed position, the cables point the wrong way, and in the open position, cables can't fit past the other bracket. None of this was designed well in our opinion. If you do get a drive in there, you won't be able to access the cable retention clip. The other SSD/HDD bracket has raised areas that conflict with some of the 2.5 mounts, and depending on the case configuration, the slots at the  back may strain your cables to their limits.", "We'll skim through the rest of our list quickly. The rubber cable grommets are easy to accidentally pop out and harder to get back in. There are no fan screws included at all. The tolerances between the frame that screws onto the PSU and the PSU cage are annoyingly tight and we have to fight to get it installed every time. The listed maximum PSU clearance is 190mm, but that would bend cables at a very sharp angle, and any PSU longer than 150mm will begin to block the cable cutout on top of the cage. The product page notes that the case supports ATX and M-ATX BTF motherboards, but only with the top PSU configuration. Finally, the power button just sucks as it’s really stiff and has to be pressed directly in the center.", "And now we’ll get to the neutral aspects.", "When we got our first look at the L70 back at Computex, we reported that there might be some engraving service offered for the nameplate, but that's not currently an option. Instead, Tryx told us that there's intentionally space left under the existing engraving so that customers can add their own. There’s some HYTE-style filler about discovered an unknow so that customers can add their own. Oddly, this is now the third time we’ve seen a company misuse this word, now ticking the boxes for both misuse as a noun and as a past participle used as an adjective. Intel’s A380 had into the “unkonw” and “into the unknow.”", "The nameplate-handle-thing is paired with a hidden handle at the rear of the case. They're sturdy enough to lift the system, but the case is very tall and very heavy, so it's far more practical to lift it from the bottom if you're trying to put it on a desk. We feel the same way about the Helios' weird velcro luggage handles (read our ", ").", "The PSU cage can be installed either above or below the motherboard: in the top of the case, the PSU can either pull air through the filtered top panel, or (as shown in the manual) pull CPU exhaust out of the case the old-school way. ", "As a result, the whole motherboard tray can be removed, which is actually pretty useful for installing and testing components outside of the case before committing. This is probably the best thing in the case.", "Cable management space is cavernous at 63mm, so that’s good. There's no question that the L70 has enough space for cables. There are smaller quality of life touches as well, like the magnetic top panel, built-in GPU support, and the spring-loaded expansion slot clip (although all the expansion slots include screws anyway).", "We don't have information yet on the ", ", but there are definitely cutouts for fans behind the glass front panel in the L70. Both the theoretical L70 Air and the existing L70 have hinged front panels that make it easy to access the inside of the case for quick adjustments without clearing your desk and taking the side panel off.", "With the bottom PSU configuration, Tryx claims support for 420mm radiators simultaneously on the top and side mounts. The top radiator and fans would overlap part of the side mount, so tube routing would need to be planned accordingly, but the top mount in particular has a ton of space to work with as long as the PSU is installed in the bottom of the case.", "Finally, Tryx draws a dotted line on the outside of the cardboard box for a cat door. There's nothing that makes this particular box a better cat toy than any other, but it's cute, so Tryx gets a point here. We actually liked that.", "Although Tryx does sell fans, the LUCA L70 doesn't come with any. Our method of dealing with that is to run all tests with our standardized set of three Noctua fans (two 140mm intake, one 120mm exhaust).", "For our baseline test, we ran the case as it shipped with the PSU at the top of the case. We kept the PSU fan-side-down as depicted in the manual, which means it should help with CPU thermals by pulling exhaust out of the case. The PSU's zero RPM mode is always turned off during our case thermal tests.", "For tests with side intake through the aluminum side panel, we kept the hinged SSD mounting bracket open. For tests with bottom intake, we kept it closed.", "Tryx plans to release a dedicated vertical GPU bracket for the L70 in Q4 of this year, but it doesn't exist yet, so we haven't tested it.", "As for competitors, the Tryx is most similar to the over-the-top halo products from ASUS ROG (Strix Helios, ", ") and Cooler Master ( The Berserker ", ", ", "), but it's been a long time since we reviewed one of those. Among the cases we have tested, the ", " has the most overlap and closest price, followed by the ", " non-touch. We're thinking of big, pricey cases without stock fans that are designed to be conversation pieces: cases like ", " and ", " and ", " are more competitive from a price and functionality perspective, but they don't look as crazy.", "We chose the side intake configuration as a baseline in order to give the L70 the best possible chance. The two 140mm intake fans were positioned low in the case to get some active airflow under the GPU, and the 120mm was positioned as exhaust behind the CPU cooler as usual.", "This first test is noise-normalized and for CPU thermals, with noise established at a matched 27 dBA threshold in our ", ". The average CPU temperature across all cores was 50 degrees Celsius above ambient, while the P-cores alone were 54 degrees over ambient. That makes it slightly warmer than the ", ", which averaged 49 degrees all-core and and 53 for P-cores in a similar side intake configuration with the same fans and at the same noise level. Despite being OK, the L70 is in company of some of the lower performers on this chart so far. ", "The ", " under the same conditions was even better, up at 43 degrees all-core -- and that’s with the same fans at the same noise levels, so it’s as like-for-like as it can be. This is a test that favors traditional front-to-back airflow: the bottom-intake C8 is tied with the L70, while the new ", " has a significantly lower all-core average of 41 degrees above ambient.", "Now we’re moving to standardized fans in all tested cases on the chart, all set to 100% fan speed, with the CPU and GPU fans remaining controlled and fixed as always. This means every case on here has the same fans, which also means some cases -- like the Antec Flux Pro -- will be worse than stock, as we are reducing the fan count. The test is still useful for looking at standard airflow patterns in a controlled way and is one we run specifically because our audience heavily requested it.", "With the baseline setup, average GPU temperature was 42 degrees Celsius above ambient with the memory junction at 48 and the hotspot at 55. Moving the PSU to the bottom of the case resulted in temperatures about one degree lower in each category, whereas keeping the PSU at the top and moving the intake fans to the bottom made temperatures significantly worse, with GPU averaging 47, memory junction 55, and hotspot 62 degrees above ambient. This is a massive increase and suggests that it may be best to only have one option.", "The change may seem counterintuitive since the bottom intake slots are directly beneath the GPU, but those slots are far more restricted than the side intake ones, to the extent that one of the fans is basically useless. ", "Removing the central section of the aluminum base helped a little, lowering temperatures by 1-2 degrees versus unaltered bottom intake, but the side intake results remain far superior.", "Using the baseline side intake numbers for comparison against other cases, the L70 actually did fairly well, with the Y70 averaging 41 degrees above ambient for the GPU (versus the L70's 42) and the O11D EVO XL averaging 44. ", "In the same standardized fan tests at full case fan speed, the CPU temperature averaged 45 degrees Celsius above ambient and 49 on the P-cores in the baseline configuration. The bottom PSU configuration had no significant effect on CPU temperatures: if we didn't already have a dedicated case fan for exhaust, using the PSU to pull hot air would have a more significant impact. Bottom intake was worse for CPU thermals (as it usually is with our test bench), with all-core rising to 50 and the P-cores to 54 degrees above ambient just because the fans are pretty far away from the actual cooler. As with the GPU temperatures, removing the central section of the base improved those temperatures by about one degree, but still not enough to match the side intake results.", "The L70 doesn't compare as well on this CPU chart as it did on the GPU one, with the Y70 side intake averaging 43 degrees above ambient all-core and the O11D EVO XL side intake a step beyond at 41 degrees, a relatively large improvement.", "In our standardized fan tests, side intake may work well for GPU thermals, but front intake is better for CPU thermals. For example, the Flux Pro averaged 38 degrees here, and almost all of our front intake results are below 40.", "Back to the noise normalized test and with stock case fans where present, the GPU averaged 43 degrees above ambient. That’s better than the O11D EVO XL side intake at 45 degrees and the Y70 side intake at 48 degrees. Memory junction and hotspot temperatures followed the same order. The other cases on this chart used their own stock fans if available, which means cases like the ", " and Flux Pro that ship with serious out-of-the-box cooling gained back an advantage that they lacked in the standardized fan test.", "Finally on the CPU, tested with stock fans where present and at full speed, the Tryx L70 lands far down on the chart. It’s at about the halfway point when tested with a bottom-mounted PSU and side intake, with two of three of the worst results secured at the very bottom, depending on configuration.", "Finishing the noise normalized testing, the average VRM temperature in the L70 was 33 degrees above ambient and the SPD Hub sensor on the DRAM averaged 27 degrees above ambient. That puts the L70 right in the middle of the chart, neither unusually good nor bad, and between the cooler O11D EVO XL side intake and the warmer Y70 side intake.", "We like it when case manufacturers try something different, and the L70 is something different. But it still needs to nail the basics.", "If performance is something you're concerned with, you should watch our ", " or ", " reviews instead. That's not the L70's focus. It's possible to get decent airflow through the L70 if you don't rely on the bottom mount, but like the ", ", the performance only needs to be good enough to enable a cool-looking build. ", "Looks are so subjective that we don’t want to comment on them much more than we already have. It’s really this simple: If you like the way it looks, and this goes for any case, then that’s all that matters as long as it ticks all the functional boxes. It doesn’t matter much what we think about the looks. This teeters somewhere in the void between “weird” and “cool,” depending on who you are, but one thing it definitely is not is “plain.” If you find that appealing, then great. Our biggest concern is its build quality, where we think the case simply fails. ", "We'd only recommend the L70 if you're dead-set on its appearance and you're willing to deal with inconveniences and problems we associate with far cheaper cases, like $200 cheaper. If you have your heart set on this because it fits some theme, and if you can put up with the rest, then Tryx is the only place you’ll get a case that looks like this.", "The ", " and ", " are big and flashy too, but they're also way easier to build in and from tried-and-true design lineages.", "We don't want to make it impossible for new companies to start up and try new things without all the established resources of a company like Fractal Design. We want to provide good feedback and encourage those companies to improve, and based on how responsive and helpful Tryx has been through this review process, we have hope at least that they might listen. At least on the comms side, Tryx has hired the right person for the job and someone we have faith in. We only know two of the Tryx people from previous companies, and we think both of them do good work. The hard part with a company is getting all those individual pieces to click together, and that only happens with time and practice. We’ll see how things go for Tryx.", "While we can’t recommend this one, we hope to see the company refine its design and take this to heart. There are two ways to approach a review like this. Cooler Master, despite its issues with our ", " initially, did eventually make massive changes that resulted in us fully recommending its fixed variations of that product. Hopefully Tryx launches a revision 1.5 of this case with some changes."]},
{"title": " Fractal's Excellent Era 2 Case: Review, Thermal Benchmarks, Cable Management, & Quality", "paragraph": ["Fractal's Excellent Era 2 Case: Review, Thermal Benchmarks, Cable Management, & Quality", "Last Updated: ", "The Highlights", "The brand new ", " case is heavy on the mechanical features.", "The entire case disassembles without screws or traditional snaps: Its walnut panel pops up on press, its dust filter acts as a locking mechanism for its shell, and then its shell removes in a single piece on slides. Its spring-loaded latches release the radiator mount to fully open up the case for building, and 4 screws can be loosened to move the central spine between 3 positions to trade-off between GPU and CPU cooler clearance. There’s also a single screw that controls a rail-mounted dual SSD cage.", "But the case also does some weird things and has some problems: For one, our wood panel is cracked. This is primarily concerning because it’s a point that Fractal really pushed when it unveiled the case, stating that it had a reinforcement that specifically prevented cracking. Second, the PSU exhaust and bottom intake are in conflict with each other.", "Steve Burke", "Jeremy Clayton", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "We made another ", " to help explain the configuration that Fractal created where the power supply fan is fighting the intake fans. We’ll talk about this down below.", "So, it’s mechanically complex and costs $200. We’ll go over build quality and thermal performance in this review.", "Let’s go over the basics and competition first.", "The ", " comes in blue, black, or silver and is a sandwich-style ITX case. The case has two pre-installed fans in the bottom for intake, room for a 240mm or 280mm liquid cooler in the top, and a continuing trend of higher cost ITX cases. A good portion of that cost is probably tied-up in the stylized aluminum shell and slotted walnut wood top panel. ", "The side panels have ventilation via a hole pattern that ranges from sparse to useless, mixing an artsy approach with at least trying to hit the basics of cooling. These holes are a good indicator that Fractal is looks-first on this case. We’ll talk about thermals later in the review.", "The ", " is a smaller case with a similar look, but also one which Fractal has openly told reviewers it felt it had underperformed on. The company is trying to fix its shortcomings with the Era 2. ", "Internally, the Era 2 has a lot in common with the $180 ", ". The motherboard, GPU, and PSU are in the same basic layout on a moveable spine, but the power supply is rotated 180 degrees in the Era 2. This results in the cables facing up – nice for ease of access – and the PSU exhaust facing down, which is awkward from an airflow standpoint. ", "Other than its own ", ", competition to Fractal’s Era 2 would include these cases:", "The $150 ", ", which is smaller, more rectangular, has no extra fans, and still supports a 240mm liquid cooler. A much larger and cheaper comparison would be the ", " we ", ", but they exist in totally different market segments. We did like that case, though. We also recently reviewed ", ", but would ", " the case; its thermal performance was overall poor and some of its compatibility choices were odd. The M1EVO (watch ", ") is another relatively expensive, specialized ITX case you could look at. ", "Getting into the dimensions and compatibility: The Era 2 is 365mm long, 165mm wide, and 315mm tall, which calculates to a 19L volume and is nearly spot-on with Fractal’s own measurements. ", "If you’re keeping track of our ITX reviews at home, add one more to the tally for “not lying on the spec sheet.” That’s not as common a tally as it should be.", "The movable spine has a major impact on internal fitment and can be set to three predetermined, stepped positions. This is a big difference from the stepless nature of the Terra’s spine adjustment. ", "Position 1 gives the most CPU-side clearance and fits up to 70mm tall coolers while reducing GPU-side clearance to 48mm (or just 2.4 slots) of available thickness. Position 3 changes those values to 55mm for the CPU side and 63mm (3.1 slots) for the GPU.", "Maximum GPU height is 137mm regardless of spine position, but you’ll want to be aware of the cable bend also. Fractal recommends a max GPU backplate thickness of 4mm. Bear in mind that larger GPUs will restrict air movement within that side of the case and power cable management can become problematic with larger cards. As always, just because it fits doesn’t mean it is a good fit.", "As another point of reference, the ", " fits, but will have its flow-through cooler heavily limited due to having only 11mm of clearance behind the card in spine position 3. So we’re back to “it sort of fits” but isn’t necessarily a good choice.", "For cooling: The top bracket can hold 280mm radiator and fan combos up to 52mm thick. 240mm liquid coolers can be slightly thicker depending on exact placement, but will quickly encroach on power cables and their own tubes.", "Both SFX and SFX-L PSUs are supported. Space for cables is greatly hampered by SFX-L, so we’d favor standard SFX.", "Internal drive support is pretty good for the size. There are 4x 2.5” mounts in total – two in the rail-mount drive cage (blocking off a large portion of the intake fan below it) and two on the spine behind the PSU, though are only usable with the spine in positions 1 and 2, and would be detrimental to flow-through GPUs. 3.5” drives are not natively supported in the case.", "Time to run through positives and negatives. We’ll start with positives.", "There are a lot of things the Era 2 does right, and the build process was relatively straightforward for ITX standards. The top radiator mount was a major help, as was the PSU orientation with the internal terminals facing up. Accessibility overall is excellent, which is a major factor in ITX cases.", "The GPU side of the case is essentially wide open, and a cutout at the front helps with installation of the longest supported GPUs. You’re able to angle the far end of the card into the hole first, then move the PCIe slot side into position.", "Cable management is also excellent overall and is one of the most difficult things for an ITX case to accommodate successfully. There are tie-down points and small channels for cables everywhere – like around and in between the bottom fans. Even in the most GPU-biased spine position (3), you end up with just enough space around the edge of the motherboard to get the job done tidily for cable management. The manual is also well-made and offers actually helpful cable management tips.", "Fractal’s attention to detail in the design of the Era 2 is overall great, as it was able to make an objectively complex case remain easy to use through thoughtful engineering.", "There’s a number of other small features that we thought were well done. To quickly go through them:", "Moving on to the negatives, one of the only difficult aspects about the build was access to the motherboard’s top edge. Since it’s inverted in the Era 2, it ends up down at the bottom. You may want to pre-connect cables there before installation or get comfortable with using a plastic spudger to poke them on after the fact.", "The wood top panel on our sample is cracked in one place between the edge and the interior slats. We don’t know at what stage the wood cracked -- possibly at the factory or maybe in storage and shipping as it crossed climates, humidity, and temperature gradients. Either way, wood is a relatively sensitive material, and this makes us concerned about the durability of the part, despite the steps Fractal took to reinforce it. Fractal emphasized in its early meetings that it was reinforcing this panel with metal to prevent cracking in a way that seemed like shots taken at competition, but now we wonder if it was actually because of their own experiences. Using two separate pieces of wood might have avoided this, despite creating a seam. This isn’t extremely noticeable, but it is disappointing. ", "By pressing the sides together, we see the crack fit perfectly back into place. This makes us think that Fractal may be better off with 2 crossbars rather than one, as it seems like the wood curing and aging may have pulled apart horizontally. Another crossbar to hold the sides uniform to each other might help.", "Also in the realm of build quality, one of the side panels on our sample is Tesla-like, in that it doesn’t line up perfectly with the panels around it, resulting in a visible jump from one to the other. These are both QC issues at the core, and are things Fractal should definitely look out for on a $200 case.", "A final minor annoyance is the fact that the shell has a crossbar at the bottom of the rear I/O area, meaning that you have to remove all of the cables before you can slide the shell on or off. Fractal could have built this in a way where it’d be easier to get into the case for maintenance without that bar, though this may be a sacrifice for rigidity.", "For the potential airflow downside, we turn to ", ".", "As we mentioned before, the PSU’s exhaust side faces the intake fan. The case orients the power supply for the easiest cable management at the cost of potential airflow conflict between the PSU’s exhaust and the bottom intake. Most modern power supplies stop spinning the fans when load isn’t sufficient, so at idle, this should actually work pretty well. It’ll force air “backwards” into the power supply, allowing it to flow past the PSU’s passive fan and out the traditional “bottom” of the power supply. That air will then exit through the perforations in the side of the chassis. That much is good. When the power supply fan becomes active, it’ll suddenly directly fight the force-fed air from bottom intake, and it’s likely that bottom intake will overpower the power supply fan. There’s enough of a gap where it won’t cause major problems, as opposed to a directly attached opposing fan, but this could still be sub-optimal for some power supplies. It’s going to be highly PSU-dependent. It’s not something we think is a critical issue, but it is one that was a little odd.", "Now we’ll take a look at the thermal performance of the Era 2. As a reminder for anyone new to our ITX reviews, our current ITX testing methodology prohibits competitive comparisons between cases, but allows us to be much more flexible when it comes to testing a single case against itself in multiple configurations.", "For the Era 2, all testing was performed with locked frequency and power on the ", ", locked fan speed on the ", ", and 100% fan and pump speeds on the 240mm CLC and case fans. We treated spine position 1 as the default, since it’s the intended setup for this size GPU.", "Starting with CPU thermals, all of the tested configurations resulted in a narrow band of only 2.1C. The stock result has a slight lead with the P-cores at steady state average at roughly 45C over ambient.", "Removing the top panel didn’t result in any meaningful thermal change, showing us that despite appearances, it isn’t actually restrictive to flow, at least not in this configuration.", "Setting the spine to position 3 hurts CPU thermals slightly, but not significantly. We were curious if the holes on the side panels actually did anything, so we covered them with tape. The answer for CPU thermals is “no,” since it’s tied with the position 3 result.", "The biggest impact was from populating and installing the lower drive cage, resulting in 46.8 degrees over ambient on the P-cores. If you have just a single SATA SSD, we recommend mounting it to the forward-most spine mount behind the PSU to avoid this blockage.", "Generally speaking, the two sets of fans at full speed are somewhat brute-forcing the situation, but the noise levels aren’t actually that high or unpleasant due to the fans’ middling 2000RPM maximum. ", "GPU thermals are next and post a wider range. Results are also consistent here and well within normal operating ranges. The stock results have the GPU die at 50C over ambient at steady state, with roughly 68C hotspot and 43C on the VRAM. Removing the top again has no appreciable effect.", "The spine position 3 result isn’t meaningfully outside of variance, but suggests that keeping the GPU’s intake fans closer to the side panel is helpful.", "Installing the drive cage raises core temperature of the core by about 2C, but could be further exaggerated by larger GPUs that need all the airflow help they can get.", "Blocking the side ventilation and moving the spine to position 3 to allow the GPU best access to internal air shows us that the holes do actually help, as the temperature did climb.", "For VRM and RAM temperatures, we see actual scaling between configurations. Everything is kept in check by the fan blasting air directly at the top edge of the motherboard.", "The stock position 1 result is the best at just 20C over ambient, and moving the spine to position 3 gives the worst result. This makes sense considering the proportion of intake air is reduced on the CPU side of the case when moving from 1 to 3. Interestingly, blocking the side panel actually lowered VRM temperature by a couple of degrees. We suspect this is because taking away those exit routes forces the intake air in that region to flow only over the motherboard.", "The ", " has a great combination of features, ease of use, and performance. The single largest downside is the price. $200+ isn’t uncommon for high-end, boutique ITX, but it’s pretty steep for the mass market. A lot of that money is probably in the material choices of walnut and moderately thick aluminum, but it’s also just the ITX world.", "ATX cases at this price can be really impressive too, inherently have more flexibility, and they cost more to ship. As always, ITX is all about wanting the form factor.", "In terms of construction, we think the ", " displays a mastery of stamped steel as a medium. There are numerous features and fine detail touches all over the stamped parts that indicate use of complex, multi-step tooling, and nothing is left sharp. Fractal is reaching an impressive level of tooling engineering maturity.", "The exterior aluminum shell and walnut top panel come off as the weakest parts in this regard, with our sample having both a crack in the wood and a misaligned side panel. This shows possible execution issues despite strong fundamentals.", "Speaking of the shell, Fractal could use this as an opportunity to make visually and functionally distinct versions of the case by just making new exteriors. That opens up the avenue to do more colorways or seasonal colors going forward.", "We were most impressed by the mechanical features and smart implementation of them:", "Thermals are good all around, despite strange PSU orientation.", "The Era 2 sits at the opposite end of the spectrum from how tedious and clunky the NCASE M1EVO is. The only thing going for the M1EVO in this comparison is its extreme versatility and ability to fit even the largest of GPUs, making it still a more versatile and customizable solution, but one which we think is less refined. The versatility has benefits, but they’re for a different kind of build.", "For the money, we think the Era 2 makes the $180 ", " (read ", ") look less appealing on paper, since the $20 gets you two fans and much expanded capability in cooling and drive mounts. That said, the ", " is smaller and has a unique look and its own mechanical complexities that might just be more to some people’s liking. They are different enough, especially in size, that anyone who wants a Terra specifically may find the Era 2 non-viable. But if you think either could work and you’re on the fence, we’d favor the Era 2, at this point.", "Those who want similar capability for less money should look at the ", ", but should be aware that it’s more difficult to build in due to its reduced size.", "The ", " is also an excellent case (read ", ") for relatively cheap (by modern standards). It’s a totally different style and not directly comparable, but you should be aware of it if you’re OK with a larger size and simpler case.", "Overall, we think the Era 2 is well-executed."]},
{"title": " $68 Case with 4 Fans: SilverStone 515XR & $100 514X Case Reviews", "paragraph": ["$68 Case with 4 Fans: SilverStone 515XR & $100 514X Case Reviews", "Last Updated: ", "The Highlights", "Today we’re reviewing the $68 SilverStone FARA 515XR with 4 included rainbow fans, not traditional cycling RGB. It was intended as an Asia-exclusive case, but SilverStone is experimenting with bringing it to the US as a budget option. We’re also reviewing the SilverStone 514X, this one has 4x traditional ARGB fans and is priced at $100 to $110.", "There was a period of time where Silverstone made our #1 recommended sub-$100 case with the RL06 (watch ", "). It’s been a few years, but we’re back to see if they can repeat.", "Steve Burke", "Patrick Lathan", "Mike Gaglione", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "The ", " is a conventional mesh-fronted budget case, the kind SilverStone ", ". ", "As for the ", ", SilverStone has been reluctant to bring it over to the US because the company feels this market has different expectations -- primarily for size, as this isn’t as deep as typical towers. This is a unique opportunity for us to compare a normal budget case versus the absolute minimum viable version and see what it takes to shave off that final $30.", "We’ll start with the ", " and move to the 515XR to look at what cost-saving they did.", "The 514X is doing what the majority of competitive cases were back in 2019, which is shoving four fans into a $100 ventilated box. This is done with careful cost saving and has become more difficult in recent years, though there are still good options: We’ll soon be reviewing the ", " as a budget high airflow case, as another new example.", "In the 514X, there are several areas of obvious cost-saving, and SilverStone directly acknowledged some of them to us: the expansion slots have punch-out disposable covers and there are no rubber grommets on cable cutouts. SilverStone pointed out that it still made an effort to ventilate the slot covers, even though they're disposable, but disposable slot covers on a $100 case does seem a little bit too cheap even for this configuration.", "As for the lack of grommets, SilverStone advertises that a steel cover plate hides the cutouts and the cables routed through them. That's the theory, at least; we couldn't get the cover installed in its stock position. Fortunately there are two options for placing the cover (or it can be removed entirely, although the built-in GPU support relies on it. It's our policy to leave everything in place as much as possible for stock testing, but we were forced to shift the cover forward to get the 24-pin power cable connected. Moving the cover only requires removing one screw.", "The HDD cage itself is only compatible with 3.5 drives: 2.5 drives must be mounted behind the motherboard tray.", "The fan ARGB hub uses a SATA power connector and takes input from a button on the front panel (for built-in patterns) and an ARGB header (for external control). ", "The hub doesn't have PWM speed control (though there are unpopulated pads for it), and even if it did, all four case fans are 3-pin. That’s not something we see very often these days. We always connect case fans to motherboard headers for thermal testing, which always allows speed control via voltage. The only advantage of the hub is that SilverStone uses it to pre-manage the rats' nest of cables.", "Each of the fans has a daisy-chained ARGB connector, so if you have one free ARGB header and four free fan headers, you can get rid of the hub and connect everything to the motherboard. ", "The front fan mounts are limited to 120mm exclusively. We’d recommend planning to use the stock fans with the 514X. On the plus side, there's space to move the front fans back into the interior of the chassis, which would give additional intake surface area at the cost of GPU clearance.", "There's support for radiators up to 360mm on both the front and top mounts, but the front mount is easier to work with due to the case dimensions. We had to angle the top in. ", "There are a couple of other minor budget-related points: no thumbscrews for the expansion slots, a loose square of mesh for a PSU filter, and a chassis that was originally built for a different case, evidenced by the unused side panel snaps and slot for a PSU shroud extension that doesn't exist. ", "On the other hand, the 514X's front panel is almost entirely metal, including the snaps, and a GPU support is included with the case. The snaps are good, and although a GPU support in that location isn’t the most helpful, it doesn't hurt. ", "In spite of the low price, the front I/O includes a USB Type-C port. The Type-C port in particular is ", ", so we're happy to see one here.", "We've ", " about colors and pricing. Black has been the most broadly popular color for years, so it's the most common and the cheapest. Low-margin budget cases are the most likely to reflect paint price differences in retail prices, like the ", ", where it’s a little costlier for ", ". The white version of the 514X also costs $110 whereas the black version costs $100. ", "Let’s move on to the 515XR, which is the cheaper of the two.", "The 515XR is much cheaper than the 514X, about a 33% price reduction when comparing the like-for-like color SKUs. It's not necessarily worse than the 514X, but there are a few reasons that SilverStone has been reluctant to bring the 515XR to the US market, like the case’s shorter depth, which won’t fit longer GPUs. The company has been very open with us about this release being a trial run.", "SilverStone is also concerned that the rainbow fans are going to lead to confusion and returns in the US market. In Asia, we’re told that rainbow fans are common and are understood. ", "The fans in the 515XR aren't ARGB, which is fine, but since most cases are photographed with a rainbow pattern for RGB now, this will lead to confusion. The term rainbow fans combined with marketing images of multicolored fans implies baked-in RGB lighting patterns. ", "Instead, each of the fans has a set of static non-animated multicolored LEDs that can't be turned off since they're powered by the fan connectors. This is an older school approach for price. We wouldn't mind some old-school solid-color LEDs with that, or no LEDs at all, but we’re not sure about the rainbow choice. According to SilverStone, rainbow fans are more common in the Asian market from which the 515XR originates.", "Out of the box, the fans are all connected to a single 4-pin Molex adapter. We recommend leaving this alone: the fan cables are too short to reach anything on their own, and if you drop fan speeds, the LEDs dim (they run on the same circuit). Those of you who built computers in the early 2000s will remember this behavior from the older LED fans.", "The 515XR is nearly identical to the sawed-off form factor of the old ", ". The ", " was a case that came out back in 2017 (watch ", "), in the brief span after optical drive bays and before really massive GPUs. This is 2024, though, and ", "s exist, so SilverStone is worried that the 515XR is only compatible with GPUs up to 350mm long. ", "We don't see this as an issue. Most people buying a $68 case are probably not buying super long video cards. We recommend limiting GPUs to ~300mm to give the case fans some space: if your GPU is bigger than that, there are better case options.", "Like the 514X, it doesn't make sense to replace the 515XR's stock fans; however, unlike the 514X, the 515XR has 140mm front mounts. ", "The 515XR's drive support is also more flexible, since the drive cage can mount either 2.5 or 3.5 drives. The cage has a removable sled with vibration damping, and the dedicated 2.5 mounts are separate and held in with thumbscrews, all of which are improvements over the 514X. The PSU mount in the 515XR also has foam supports that the 514X lacks, and there's a single reusable expansion slot cover.", "The 515XR has two internal 120mm fan mounts on top of the PSU shroud. We generally don't see much thermal improvement from shroud-top fans without careful planning, like in the ", ". The 515XR's shroud is mostly sealed. Still, it's an option that the 514X lacks.", "We do not recommend putting a 360mm radiator into the 515XR. There's only a 32mm gap left in the shroud for a radiator (with the stock fans installed), and the drive cage may also interfere with the available space depending on which drives are installed. The top slot technically fits radiators up to 280mm, but this would make it difficult to use any of the cutouts at the top edge of the motherboard.", "There are some cheap quality of life improvements we'd like to see. First, the cutout nearest the 24-pin power header is almost too small, and the cutouts along the bottom edge of the motherboard are partially blocked by the PSU. Second, the reset and power buttons aren't marked. Finally, the rear fan is positioned so that it needs to be fully removed before installing motherboards with built-in rear I/O covers.", "As a final note, we asked SilverStone why the black version of the 515XR is 20 grams lighter than the white one, assuming it could be a typo. Its product manager says that white paint requires a thicker coat, and that the white fans also weigh slightly more than the black ones, so the 20 gram difference is real.", "We're covering two different cases in one review, so most of our comparisons here will be between the 514X and the 515XR. We don't have many sub-$100 budget cases on the charts yet, so these will serve as a starting point as we add more, like the upcoming ", ". Of the cases that have been tested with our current methodology, the aging ", " is the closest match to the SilverStone cases, so we'll be using that as a representative example of existing budget mesh-fronted enclosures. We've seen the ", " drop as low as $50 for the non-RGB variant. Montech's ", " and ", " cases are usually strong competitors in this space, and we'll add those to our charts as we test them.", "Our first test is for noise-normalized thermals, where we set all cases to the same noise level in our ", ". Neither the 514X nor the 515XR offer fan control out of the box, but we were able to perform noise-normalized tests by connecting the fans to motherboard headers as usual.", "The 514X averaged 48 degrees Celsius above ambient all-core and 52 degrees for the P-cores, while the 515XR was significantly worse at 53 all-core and 57 P-core. The 515XR's dual-layer front panel is more restrictive, while the 514X's front panel is a single layer of steel mesh. ", "The 514X isn't especially impressive outside of its price when compared to the rest of the cases on this CPU thermal chart, but it's tied with the Pop Air RGB (watch ", ") -- which has been on heavy sales lately. The 515XR has some of the worst results on the chart, tied with the stock ", ". This is a letdown, and it's not at all what we expected: we've seen plenty of cheap mesh-fronted cases punch above their weight, like the ", ", ", " and ", ", and several Phanteks cases like the P400A (read ", ") with the mesh front. We’re adding the 216 back to the charts later this week along with the 207, so that’ll help give some perspective as well.", "The industry has moved away from using multiple layers of material in mesh front panels, which has led to better performance in many cases. The 515XR could be something special if it had not made this design decision.", "Our standardized fan test replaces all stock fans in each case with the same set of three Noctua fans: two 140mm intake, one 120mm exhaust. We have explained why there are limitations to this testing, such as worsening performance of cases which include more or larger fans. However, we run this test due to popular demand from the audience. You can find our methodology and limitations of this testing linked ", ".", "This is the perfect chance to see how the stock fans affect the performance of the SilverStone cases, versus the designs of the chassis themselves.", "GPU temperature in the 514X averaged 43 degrees Celsius above ambient, 49 on the memory, and 56 hotspot. That puts it in the middle of the chart, tied with several other similar mesh-fronted front intake configurations like the ", ", ", ", and Pop Air RGB. That's confirmation that the 514X's front panel and general layout are at least as good as other cases in the same category. The 515XR averaged 49 degrees, 57 on the memory, and 64 hotspot, which puts it among the worst results on the chart for the second time in a row. Again, all of these results were recorded using the same set of fans, so the difference comes down to the 515XR's front panel. The 514X seems fine. The 515XR is a let-down.", "In the same test, the 514X's CPU temperature average of 40 degrees above ambient still came close to the other mesh-fronted cases, but the Flux Pro (read ", "), ", ", and Pop Air all averaged 38 degrees with the standardized fans. The 515XR was again worse at 44 degrees, but the bottom of the chart is stacked with bottom-intake configurations, so it's not among the worst results. Front or side intake is significantly better for CPU thermals with our test bench.", "Back to the noise normalized results, neither of the SilverStone cases did well for GPU thermals. The 514X averaged 50 degrees above ambient, 58 memory, and 65 hotspot, with only two previously-tested cases doing worse, one of them being the Pop Air RGB. ", "The 515XR is the new hottest result on the chart. We express all temperatures as degrees above ambient to account for fluctuations, so the average GPU temperature of 54 degrees above ambient translates to a logged steady state temperature of 75 degrees. That wasn't enough to cause any throttling, but in a warmer room, the GPU might lose some boost headroom.", "This is the full speed chart with the stock fans.", "The 514X's stock fans topped out at 1300-1400RPM, while the 515XR's were 1100-1200RPM. Those limits are a little low for 120mm fans, which makes them relatively quiet, which is important given that both cases are set up to run all case fans at 100% speed out of the box. With all four fans maxed out, average all-core CPU temperature in the 514X was 44 degrees above ambient while maintaining a noise level of 34.6dBA. It matched some louder cases, like the 36.8 dBA ", ", but only slightly outperformed the quieter 31.3 dBA Pop Air RGB. ", "The 515XR tied the Pop Air for noise but had worse thermals, as usual. The front panel design really prevents it from doing as well as it could.", "In noise normalized testing, VRM and RAM thermals aligned with the CPU thermal results. The 514X averaged 34 degrees above ambient for the VRM and 28 degrees for memory, putting it in the middle of the chart, while the 515XR averaged 39 for the VRM and 32 for the memory, the hottest results on the chart in both categories.", "The ", " is an extremely normal case: it costs about $100, it has the basic features you'd expect from a budget case, but it also has a full set of four ARGB fans. Thermal performance doesn't look amazing compared to the rest of our chart, but we haven't yet fully populated our chart with comparable $100 cases. Performance is similar to the ", ", so you can look back at that review for a rough comparison versus a wider selection of older cases. The ", " isn't bad, but we aren't excited about it, and we've seen the ", " on sale recently for as low as $110. Anyways, the 514X is okay.", "We were excited about the $68 515XR mostly for the price, especially after seeing that it has almost every feature we care about from the 514X (except the Type-C header). Sub-$68 is the domain of DIYPC and SAMA, and there are few name-brand options with reasonable ventilation at that price. Unfortunately, it reminds us strongly of the Thermaltake Versa J24 (watch ", "). The J24 was extremely similar to the ", " in several ways, but most importantly it had a layered front panel that hurt its performance. For that review, we were able to remove a filter and improve the J24's performance without changing its appearance, but that's not an option with the 515XR. The 515XR is almost a really competitive case at its price. We’re just a little hung up on its front panel. We have to admit that there aren't easy alternatives to recommend at this price (other than cases on sale, like the ", "), but the 515XR could have had a wholehearted recommendation with some alterations to the front panel."]},
{"title": " Lian Li Lancool 207 Airflow Case Review | Cable Management, Build Quality, & Benchmarks", "paragraph": ["Lian Li Lancool 207 Airflow Case Review | Cable Management, Build Quality, & Benchmarks", "Last Updated: ", "The Highlights", "The ", " is the new best-performing case on our thermal charts -- and it’s $80. The case shoves the power supply to the front to accommodate 2 shroud-top fans that are closer to the floor of the case, providing intake directly into the GPU. The front of the case has a shaped front inlet for 2x 140mm fans cooling the rest, and the back is entirely ventilation to allow exhaust. ", "From a usability perspective, it struggles in some key and basic areas: Cable management is challenging. Closing the right side panel isn’t always easy, especially if you have more cables, thicker gauge wire and sleeving, or accessories that add a ton of cabling. The side panel is tool-less and the back compartment is shallow, with the PSU’s orientation complicating power supply length and cable bends.", "Steve Burke", "Patrick Lathan", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "The ", " is an exercise in compromise, but some of those compromises didn’t need to exist.", "We’re reviewing the Lancool 207 with our new case testing methodology. Previous Lancool cases were similarly priced and also heavily competitive for thermals. Repeating that price in 2024, with the gradual climb of pricing for everything, shows a highly aggressive Lian Li.", "The new Lancool 207’s $80 MSRP comes close to the (originally) $70 ", " that impressed us back in 2020.", "We saw the 207 ", ". We've spotted a few changes to the case since that Computex showing: the weird removable plate at the bottom of the front panel is gone, the bottom intake fans are conventional rather than reverse-blade, and the side panel vent is smaller. None of these changes are meaningful from a consumer perspective. The removable plate never had an assigned function other than to possibly be “DLC” add-ons, the bottom intake fans look basically the same, and the functional area of the side vent hasn't changed.", "We like the Lancool 207, and we have a lot of good things to say about it, but we consider the power supply situation to be plagued with oversights. Overall, we’re positive -- so we’ll start with the basics and positives, then spend some serious time talking about the unfortunate cable management and power supply situation.", "For the basics: The case pulls apart in 3 primary panels, including the typical left and right sides and a lower quarter-panel that is perforated for intake into what would traditionally be the PSU shroud. Rather than elevating the floor and pulling through that, Lian Li pulls through the rear and sides. This allows the floor to be available for hard drives and SSDs. Even with a 3.5” drive installed, there’s still plenty of room between it and the sunken fans to pull air through.", "The panels are also exceptionally sturdy for a case of its price. The top panel snaps into place with heavy-duty studs and uses folded-over columns of steel to reinforce it. This avoids that cheap stamped steel wobble we see on some sub-$100 cases -- and on ", ". ", "This also appears to be a direct response to ", ", where there was around a half-a-centimeter depression in the top panel. They’ve fixed that issue here.", "The front panel also uses a folded-over steel, which doubles as a catch for the magnets at the top of the easily removable filter. This should make it trivial to clean. We’ve always been advocates for ultra-fine mesh panels rather than dust filters, as these serve the same purpose as a dust filter, but are much better for airflow. ", "The entire front panel can be removed, but there's no reason to do so. If you do it anyway, the I/O cables have been screwed down to the corner of the panel for strain relief. ", "The porosity on the back of the case is also at insane levels for mostly good reasons: We typically see much smaller holes with thicker steel, resulting in a lot less breathability. Because this case is fully positive pressure, we don’t need to worry much about dust ingress from the rear of the case. It’ll get pushed out naturally. This shows an attention to detail that illustrates Lian Li actually understands why you’d make decisions like denser holes for intake and wider for exhaust. ", "There is one missed point, though: The very bottom of the rear of the case will serve as intake, not exhaust, as it is separately chambered for the shroud-top fans. Lian Li should be filtering these or using ultra-fine mesh.", "Overall, Lian Li has come a long way since we criticized some of its older cases for airflow and is really starting to show a mastery of thermal design with the small details.", "The only fit-and-finish issue we noticed were some imperfections and scratches in the infinity mirror fan hubs, but these aren't visible while the fans are spinning.", "The motherboard tray is offset from the standard, creating an ATX-sized indent. This means that the case is absolutely not compatible with any so-called “E-ATX” boards and that there's only about 1cm of clearance behind the motherboard tray, but it also means that compatibility with motherboard edge connectors is excellent. Lian Li also claims that the offset better aligns the GPU with the bottom intake fans, but cable routing is the more tangible benefit.", "Front I/O is extremely basic: 2x USB 3.0 Type-A ports, 1x USB 3.1 Type-C port, 1x audio jack, and the power button. The flat, flexible Type-C cable in particular is the least annoying one we've ever worked with. The case also has a convenient all-in-one front panel connector, but we'd actually rather have the old-fashioned two-pin connector here, since it's just for the power button. There is no reset button. Typically, these would combine power, reset, and power LED.", "The case has two vibration-damped drive mounts in the floor for a single 3.5” or 2.5” drive each. The drive mounting holes are suboptimal: SATA cables have to be bent at an uncomfortable angle to fit and the 2.5 mounting holes could easily have been moved to alleviate this. ", "Each pair of fans has 1x four-pin fan connector and 1x three-pin ARGB connector, and the two fans within each pair are linked by proprietary connectors. We'll begrudgingly accept this as a compromise since it cuts the number of fan cables in half. The downside is that it's impractical to replace or reconfigure individual fans, contributing to a larger downside of having to go through Lian Li for replacements if one breaks. The front and bottom mounts aren't compatible with any sizes other than the ones that are preinstalled (140mm front, 120mm bottom). On top of that, the front mount is built around Lian Li's 30mm-thick fans, and all four stock fans are attached with radiator screws. If you still want to replace any, Lian Li includes 16 additional screws sized for 25mm-thick fans. All of this is non-standard and will be unfamiliar to experienced builders. It’s workable, but it will impose atypical limitations on fan compatibility if you want to change them. For instance, you’d typically have 120mm options where 140mm fans install. Here, that’s not the case. The upside is that there’s one less set of rails obstructing intake at the cost of flexibility, so Lian Li is going for the focused airflow approach.", "Lian Li describes the 207 as a compact M-ATX-sized case with ATX compatibility, which is only true by Lian Li standards. The Lancool 207 is the size of a normal mid-tower; it has almost exactly the same dimensions as a ", ". In fact, it’s really not much different than most of the cases in the comparison image above. The ", " is an example of a truly compact ATX case, or ", ".", "Now to the power supply:", "The 207 has an unusual layout with the PSU rotated 90 degrees and placed at the front of the case rather than the rear. This means that there's a 160mm size limit for PSUs, but even our normal 150mm unit was cramped. Without dropping out of the ATX spec, 150mm is about the smallest you’ll typically get.", "Because of the rotation, cables are pointed at the tool-less side panel and have to bend sharply to route. Using flat cables helps, but this is a situation where you’ll need to consider how the cables in your power supply are sleeved. We’d also strongly recommend sticking to 150mm rather than using the maximum 160mm under the spec. We’d also strongly recommend modular power supplies for this case.", "The PSU shroud is effectively a fan mount, and even if you could find a way to stick extra cables under it, it'd interfere with the intake fans and the entire point of the design. ", "All of this would only be an inconvenience, except that the steel side panel is tooless. If you're using bulkier cables with individually braided sleeves like in our example, it is possible to choose power supply and cable combinations that make it nearly impossible to snugly close the side panel. It’s possible, and we did it with our bulky sleeved cables to prove that, but this took a good amount of time to manage and flatten.", "We’d strongly recommend flat cables like the ", ". The more accessories and PCIe power cables you run, the more difficulty you’ll have managing the cables in this particular case. ", "Screws for the side panel would have helped this by allowing more tolerance for cable bulge. ", "The manual illustrates installing a Lian Li ", ", which looks like it could help; however, the 207 is $80, and the cheapest EDGE PSUs cost at least $130 to $140. It’s a mismatch of the most likely buyer for the case if Lian Li expects most to use these power supplies.", "The illustration also shows the EDGE PSU being installed fan-side-up, which isn't an officially supported option for other power supplies. The usual arrangement of mounting holes requires installing standard ATX PSUs fan-down in the 207, with only 1cm of clearance above the table.", "In another major concern, in Lian Li’s quest to move the power supply, it has overlooked both cabling and cooling considerations. With the bottom filter installed, which we’ll come back to, the power supply is given mere millimeters to breathe with a bottom-oriented fan. We don’t currently run power supply thermals during our testing; however, this will cause the power supply to heat up, objectively, and it may result in the PSU fan running at a higher RPM (if it is a power supply that bases fan speed on any internal temperatures).", "Removing the filter functionally doubles its breathing room, but ultimately, we think this is a major design shortcoming. Lian Li’s pursuit of minimizing the case size has limited its area for power supply intake. This is making us consider running a thermocouple wire to our power supply for future case reviews.", "The PSU filter is another small design fault: It’s easiest to lift the case to remove the filter, which isn’t a dealbreaker, but could be fixed with a more accessible tab. ", "On the cable management side on the back of the case, the attachment points for the built-in velcro straps are angled so that the straps curl over as they're inserted, which is a much bigger quality of life improvement than it sounds like. The manual describes intended cable paths, most of which are obvious, but there are specific routes for 24-pin STRIMER cables and for CPU 8-pin cables. The 8-pins are held in by plastic hooks, but the hooks might work better if they were flipped. There isn't a suggested path for GPU power cables in the manual. This is something we would have liked to see for new builders.", "As for vertical GPUs, the expansion slots are bridgeless, so other vertical GPU add-in kits may work, but Lian Li specifically markets ", ". As ", " using this vertical bracket will block the bottom intake fans, and we don't recommend it. ", "It may technically be possible to get a 280mm radiator installed in the front of the case, but it'd need to have exactly the right hole placement. Lian Li doesn't claim any formal radiator support anywhere except the top of the case, and we agree. 120mm-wide rads fit more easily than 140mm-wide ones, which may make the CPU power cutouts difficult to reach.", "As we've covered, it's inconvenient and pointless to replace the 207's stock fans. Still, we had a couple of alternate configurations we wanted to test that didn't involve altering the fans. We also did a pass with the small mesh section on the steel side panel taped off. The bottom intake fans have a larger section of mesh available on the other side of the case, as well as a wide-open vent at the rear, so we suspected that taping off this little vent wouldn't matter much.", "The 207 is one of the cheapest cases on our charts currently. Out of our recent reviews, it lands between the $100 ", " and the $68 515XR. We also retested the older ", ", which is still available for around $100. In terms of fan layout, the 207 is most similar to the more expensive Antec Flux Pro.", "We only ran basic tests in standard mode on the ", ". There's also an air cooling mode, but in our original review, we found that this helped GPU thermals while simultaneously hurting CPU thermals with our bench hardware. Check ", " for more detail on alternate configurations, including an external fan bracket attached to the back of the case.", "The 207 is a loud case with all fans at full speed, but we'll start with noise normalized results. For this testing, all case fans are lowered to reach a target noise level of 27 dBA measured at 1 meter in our ", ", with CPU and GPU fan speeds controlled and constant. ", "We’ll start with noise-normalized GPU thermals since those bottom fans should help there.", "The GPU temperature averaged 42 degrees above ambient, 47 on the memory, and 55 hotspot. That's one degree better than the 216 in each category, but still close. Impressively, the ", " remains the leader in this particular test. That’s not always true, but it is here. It has its own bottom intake fans that feed the GPU directly, which help. ", "We haven't always seen a benefit from shroud-top intake fans, but cases like the 207 and the ", " that commit to building the case around that concept do show good results. If anything, it's a testament to the 216's cooling that it comes so close to the 207 without any shroud fans.", "The ", "'s average GPU temperature was about one degree cooler than the 207's.", "There's no contest versus the ", " and 515XR, which fall on the complete opposite end of the chart. The 207 is in a different class in many ways, but Lian Li has priced it so aggressively that we have to make the comparison; it undercuts the 514X and is only $12 over the 515XR.", " is another price-competitive case, but lands at the bottom of this chart. It’s still a good case, and when it’s one sale, it is impressively cheap, but the 207 is thermally superior.", "Here’s the CPU noise-normalized chart: Instantly, the Lancool 207 is tied for chart leader in CPU thermals. The average all-core CPU temperature was 41 degrees Celsius above ambient and 44 degrees on just the P-cores. The 216's numbers round differently, but its results were near-identical to the 207's and within error. The 216 was one of our all-time best performers for noise-normalized CPU cooling when we originally reviewed it, so that's good news for the 207. The 207 technically tops our updated chart within error of the 216, but the Antec Flux Pro is also within a one-degree margin. The Flux Pro is at least $180, though.", "In comparison to the more closely price-matched 514X at 48 degrees all-core and 515XR at 53 degrees all-core, the 207 has a massive lead. So far, the 207 looks like another Lancool with an unbeatable price-to-performance ratio.", "At full speed, the 207 sounds like a server rack. The 41.6dBA result ties the 216. The 216 is the best performer when allowed to brute force its performance by fan speed, roughly tying the 207 when we remove its front panel to test restrictions. With the panel, the 207 ran at 41.6 degrees for P-cores, or about 2 degrees warmer than without a front panel. As far as restrictions go, that’s pretty good: The panel is not substantially hurting performance, unlike some other cases we’ve tested. If you buy the optional filter, that would change. ", "Using two layers of gaffer tape over the small mesh section on the steel panel would affect GPU thermals if anything, so it's no surprise that it had no effect on CPU thermals.", "The 207 at 41.6 degrees ties the Flux Pro for performance. Again, though, the noise normalized results are better for case-to-case comparison.", "Now for GPU temperatures at full speed. In the same test, the GPU was 38 degrees above ambient. Taping the side panel vent did nothing. We think this is simply because the bottom intake fans have plenty of other ventilation available through the mesh on the opposite side of the shroud and the wide-open unfiltered vent at the rear of the case. If these inlets had been minimized, it might have mattered more. It still doesn’t hurt to have more mesh in these areas, especially if you shove drives down there, but it just didn’t matter for our GPU.", "GPU thermals effectively tied the Flux Pro, but with some back-and-forth over the memory and hotspot temperatures. No matter what, though, the 207 sits alongside the ", " and Flux Pro at the top of this chart. The 216 fell behind here with an average GPU temperature of 43 degrees above ambient, which is still excellent, but not as good as the brute-force bottom intake of the 207.", "Our standardized fan tests use three Noctua fans, always the same ones: two 140mm front intake, and one 120mm rear exhaust, all at 100% speed. We regularly explain the limitations of this testing. You can learn more in our methodology piece ", ". This allows us to remove stock fans as a variable and compare just the enclosures. With cases like the 207, the comparison is theoretical (since it doesn't make any sense to replace the stock fans), but people request it, so we wanted to provide the data.", "Our standard fan configuration was obviously worse for GPU thermals than the stock configuration. With the standard fans, average GPU temperature was 43 degrees above ambient, 48 degrees for the memory, and 56 degrees for hotspot. ", "On the CPU with standardized fans, we measured CPU temperatures at 38 degrees above ambient all-core and 42 degrees for the P-cores, within error of the top-scoring Torrent. Mesh fronted cases with straightforward front-to-back airflow patterns do well in this test, and the 207's CPU thermals are particularly good because the front fan slots are biased high, sending more air above the level of the GPU backplate. We usually try to position the intake fans for a better balance with GPU thermals, but that's not an option in the 207.", "The VRM and system memory are located close to the CPU in our test system, so it makes sense that a case with good CPU thermals would have good thermals in those two categories as well. The 207 slightly outperformed the Flux Pro for lowest memory temperature at 21 degrees above ambient, tied with the Torrent. VRM was tied with the Flux Pro at 27 degrees, but that's tied at the top of the chart. The 216 was warmer for both sensors, 23 degrees for the system memory and 28 for VRM.", "Like the ", " and ", ", the ", " is a well-built case with chart-topping performance while simultaneously managing to be one of the cheapest cases on our charts. The cases that perform equivalently are more expensive, like the ", ", and the cases that are in the same general price category perform worse, like the ", ". Lian Li already has some strong competition in this area, including its own ", ", but the ", " is even cheaper than the 216.", " coming out soon and those should give the 207 some competition, but they’re not here yet -- and they might end up a little more expensive, but we’re not sure yet.", "The ", " remains a good quality ultra-cheap case when it’s on sale, which has been frequently lately, but it’s just a totally different class of performance. The 207 holds the new crown for the best performance for the price -- nothing else that we’ve tested anytime recently is even close when you factor in the price. Lian Li’s 216 is the closest competitor, but is frequently around $100, making it $20 more expensive than the 207.", "The biggest problem with the 207 is the cable management and power supply fit: The problem with getting the side panel on over the PSU is potentially a huge obstacle for some cable-heavy or thicker cable configurations and is not shared by any of the other cases we've mentioned. If you buy this case, we recommend choosing a 150mm deep PSU rather than 160 and opting for slimmer cables. Depending on your PSU and the cables you use, there's a serious risk that the side panel won't fit and you'll get annoyed enough to send the case back. Flat, slim cables have a better chance of working.", "This is its only major issue that we encountered. Build quality of the panels is overall excellent, especially at the price, and thermal performance is among the best. The 207 gets a strong, but caveated recommendation, with the caveat again being related to cable management (especially for less experienced builders). If you plan ahead and have patience to thoroughly route cables, and if you can stick to a shorter PSU, we think this case is one of the most competitive on the market for its price. There aren’t a lot of well-built options in this price class."]},
{"title": " A New Type of Computer Case | HAVN HS 420 Thermal Benchmarks & Review", "paragraph": ["A New Type of Computer Case | HAVN HS 420 Thermal Benchmarks & Review", "Last Updated: ", "The Highlights", "This is the most excited we’ve been about a case in a long time. HAVN's case focuses on trying to innovate on cooling performance. In the vertical GPU orientation, the bottom-mounted fans install at an angle and direct the air towards the glass and use an included glass flow guide to direct the air away from the GPU. That might seem counter-intuitive, but this will be easier to explain using our ", ".", "HAVN -- that’s the name of the brand for this case -- is separating the hot exhaust air out the bottom of the GPU from the cooler intake, pushing intake at the glass side panel of the case and almost sort of “bouncing” it into the front of the video card. There are trade-offs, but it’s a novel approach for a case.", "Steve Burke", "Patrick Lathan", "Mike Gaglione", "Vitalii Makhnovets", "Tim Phetdara", "Andrew Coleman", "Jimmy Thang", "The case also comes in a standard horizontal GPU configuration, which effectively disassembles the entire bottom fan tray solution into a more traditional, elevated flat bottom case. It’s quick to pull the VGPU option apart entirely and reconstruct it. We’ll come back to these animations when we explain the airflow patterns.", "There are two spots for rear fans, enabling a lot of combinations of intake or exhaust -- the rear-bottom has a dust filter, indicating the intent. The top is more usual, and the side can be either fully filled with fans or filled with drive cages in a sort of spine-like setup.", "The case also has large, well-made panels that are heavily ventilated, including an interesting rails system that glides the panels into place. ", "We noticed some similar manufacturing techniques and processes to Hyte, and checking with Hyte, they use the same factory. The two companies aren’t related, but the panel quality shines through from the shared source.", "This case is called the ", ". HAVN is a new brand that’s part of ProGamersware, which is part of the CaseKing company group. CaseKing is one of the largest computer hardware retailers in Europe. ", "The HAVN HS420 is $200, with the HAVN HS420 VGPU at $270. That’s a big jump and accounts for the PCIe riser, bottom fan tray, and additional glass.", "We’re excited to test this one, so let’s get into it.", "The first HAVN case is pretty cool.", "We actually found the case interesting enough that we’re doing our first fan optimization guide in years. We used to do these a lot for major case launches, but we’re basically testing a ton of alternative configurations in addition to the 6 or 7 we did for this review. That’ll be a separate story later since it requires a ton of additional testing. But for now, we still went heavy on configuration testing.", "HAVN says its team members include people with experience from Fractal, NZXT, Cooler Master, Sapphire, and others. In addition to having previously worked for some of its now-competition, HAVN also has a hit list of cases it’s targeting:", "HAVN has called-out a list of competitors for its HS420, including the ", ", Lian Li O11D XL (not the EVO), ", ", ", " (2023, assuming they'll introduce a new one), and the ", ". For the ", ", it's the ", " (although the ", " may be more fair). These are the cases that HAVN intends to outcompete at launch.", "As for our own list, we’d also bring attention to price competition from the ", " non-touch, the ", ", the ", " with 6 fans, and the ", ". We’re highlighting these primarily for proximity in price to the $200 case while still being good cases.", "The HS 420 is an unusual-looking case. The headlining feature is the panoramic glass panel, which is bent at a 90-degree angle with a tight radius. There’s a jutting-out cable management area that sticks out under the motherboard, a design consistency with rounded edges even under the case, and rubber string-like cable management suspension in the grommets.", "The panel rolls into the case with four plastic wheels, then slots into place with support along the whole bottom edge. It takes some getting used to, but HAVN includes stickers detailing removal. The manufacturing precision required to get this working, and working well, is beyond what we're used to seeing and is executed expertly. ", "All of the exterior panels are firmly magnetically attached and all include optional screw holes for extra security while shipping. You hear in most of our reviews that we favor at least optional screws for panel security to prevent issues.", "The visual theming is consistent throughout the whole case. It even has lots of ", " -- vocabulary that we haven’t had to bust out since the ", ".", "The case’s sharp angles are rounded off, like the edges and corners on the PSU enclosure and the bottom fan bracket in the VGPU SKU. ", "The HS 420 was impressively packed with a level of care that we usually only see with pre-builts: It has instructions on the box about how to correctly unload the case, a big START HERE label for the manual and accessories, and even a custom-shaped piece of foam under the fabric loop on the top panel to hold its shape. The manual itself is well done and reminds us of how Fractal does its own manuals, which we’ve praised several times.", "The accessory kit includes a VESA mount, ESD-safe gloves, and extra combs for the rubber cable organizers inside the case. The only really important things that are missing from the accessory kit are spares for the variety of unusual screws used throughout the case. We're used to seeing screw organizers in $200+ cases, but HAVN instead includes labeled reusable bags… with unlabeled disposable bags inside. ", "The only difference between the HS420 and HS420 VGPU is the vertical GPU hardware. The cheaper non-VGPU model comes with a normal fan tray in the bottom of the case and a GPU support bracket, neither of which are included with the VGPU (since they're replaced by other parts). ", "The bracket is solid cast zinc alloy, braced against a completely rigid section of the PSU shroud to support the GPU at its furthest corner. It works better than most GPU supports and we liked it. Our only complaint is that the support can only work as shown in the manual for GPUs up to ~300mm long: any longer and the bracket can't reach all the way to the end.", "As for the VGPU model, it comes with a preinstalled four-slot vertical GPU bracket and what HAVN claims is a PCIe 5.0 riser cable. Currently, there are no PCIe 5.0 consumer GPUs; however, it’s possible the 50-series may go in this direction. There is not a great non-enterprise way to validate the 5.0 claim from HAVN and performance impact is yet unknown, but likely minimal.", "The VGPU kit isn’t sold separately at launch. ", "The VGPU model’s bottom fan bracket is replaced with an angled bracket for 3x 140mm fans and a curved glass pane intended to direct the air. The GPU bracket can be adjusted back and forth, which is necessary in order to get the corner of the GPU flush with the curved airflow shield as shown in the manual. Our ", " isn’t fat enough to get as close to the shield as HAVN suggests. Using it precisely as intended requires a GPU with a cooler that's four slots thick.", "Even without the VGPU hardware, HAVN recommends an unusual airflow pattern for the HS 420. Top exhaust, side intake, and bottom intake are all typical, but all of HAVN's recommended configurations show the lower rear slot as filtered intake and the upper rear slot as exhaust. We had tested this even prior to checking HAVN’s recommendations, as it does make sense to flow the air in and around the GPU.", "There are 11 total fan mounts regardless of SKU, all of which can accept either 140 or 120mm fans except the VGPU's bottom mounts (which are 140mm only). No fans are included with the case, but two PWM splitters with 6 outputs each are included, so up to twelve PWM fans can be controlled from two inputs.", "To help explore airflow in this unique enclosure, we made a ", ". ", "There are a ton of potential airflow paths with the way this case is built. Our custom 3D animation we made will help explain some of the more unique ones.", "First, let’s look at how the VGPU kit will direct air. ", "This will cover the theory, but we’ll talk actual performance and impact to thermals and acoustics in our charts soon.", "Mounting the fans to the VGPU fan bracket at the bottom of the case angles them toward the glass side panel, resulting in an indirect flow path to the GPU fans. The bracket itself is at about a 30-degree angle. The shortest and most direct path to the GPU would be flat fans on the bottom pointed straight at the video card, but that path would sort of “collide” with the hot exhaust coming out of the bottom of the card. This designed and angled path tries to almost “bounce” the air off of the glass or flow it out and nearby, at which point the video card fans will pull that air in. There are two interesting challenges here:", "First is the absence of a wall: Vertically-mounted video cards, which is the intended use with this kit, with vertically oriented fins will eject the hot air down out the bottom of the card and up. In this orientation, that means hot air shoots straight down into the intake fans, theoretically getting mixed-in with the cool intake as it is shot at the glass. But since there’s no wall, the air will also enter the GPU more directly and at a wider spread at the front of it, including some potential exhaust, and likely at higher speed. Thanks to Bernoulli’s Principle, the general idea is that air increasing in velocity will decrease in pressure and vice versa, although there are exceptions. ", "The upside is that the air will be directly fed to the GPU. ", "Adding a glass shroud to the fan tray acts as a flow guide, but will also require the air to now make multiple turns to get to the GPU. The glass attaches to the back of the angled fan tray. This flow guide will push cool air at the glass side panel, at which point it’ll either physically deflect or will be overpowered and pulled-in by the GPU’s own fans. Likewise, hot air exiting the GPU bottom out of vertically oriented fins will now get shoved behind the glass and behind the fan tray. The back of the fan tray is fully enclosed by steel and glass, so there won’t be any hot air ingress. The glass shroud walls the hot air off. Instead, it ends up in a small chamber between the cable management shroud and the fan tray. This air will need to find a way out, and the most likely pathway is the bottom-rear fan. We’ll come back to that.", "This results in the intake air now making multiple turns, which will affect both air velocity and air pressure: Velocity will decrease at the point it enters the GPU fans as a result of the turns and indirect path. Because the fans themselves are angled, the air ends up making close to a 90-degree turn -- shallower than if they were flat in the bottom with a flow guide, but still a big change in direction. ", "The glass shroud itself has two points where it bends and a straight section: The first is a 40-degree angle, then about a 50-degree angle. These bends will help reduce resistance as compared to harder angles.", "Back to the hot air from the card that was stuck behind the tray, glass, and between the cable management indent: In theory, as exhaust, a rear-bottom fan should help pull hot air trapped under the video card and behind the tray out of the case. It’ll also steal some of the cool intake from the back-most bottom-mounted fan in the tray, but the angle of the tray should reduce this impact. ", "If the back fan is flipped to intake, it might help push that hot air through and toward the front of the case, where it’ll likely slowly be pulled up and out by the CPU cooler fans or top-mounted fans.", "Flow-through video cards like most modern cards, including ours, will exhaust their hot air through the right-side of the card and effectively straight at the chipset and RAM area of the motherboard. A CPU tower cooler will pull this air out. In absence of that, a top-mounted liquid cooler with exhaust fans could remove it.", "As for video cards with horizontally oriented fins, there’s no real downside with this setup since they can typically neither breathe nor exhaust through the bottom of the card. It would mostly exit the right and left sides, typically out the rear PCIe slots. These fin orientations are less common these days.", "HAVN clearly thought about the configuration with the fan tray and the glass. There are a lot of intentional angles and flow direction is clearly intention. This configuration was thought about. We’ll have to test how much the glass and angled intake actually do by running thermals against just standard flat-bottom intake fans.", "Let’s visualize some other setups in 3D: This configuration uses a vertical GPU, removes the bottom fans and the shield, and installs 3x side intake fans, 2x rear exhaust fans, and 1x top-front intake positioned about 30mm away from the front of the tower cooler. ", "In this orientation, flow follows this path: It mostly enters the side, at which point that air is pulled toward the tower cooler and vertical GPU by the fans on each. The GPU hot exhaust will mostly get pulled out of the way of intake through the bottom-rear exhaust fan, which also helps provide the currents needed to pull intake toward the GPU from both the bottom of the case -- passively through the floor -- and the lower side intake fan. The rear exhaust fan at the top helps remove exhaust from both the CPU tower cooler and the vertical GPU fin stack. ", "Finally, front-top intake is interesting: We always see people asking why you’d “fight” physics, but the rate of passive molecular through heat rising is incredibly slow. The truth of the matter is that a 1000+ RPM fan will overpower just about any natural air movement, and so what matters more is its access to external air, not whether it’s at the top or bottom of the case. Top intake would provide direct, external air straight into the CPU cooler. ", "Putting a top exhaust fan here will mostly serve to steal cool side intake and exhaust it before it ever hits the front of the CPU tower cooler, reducing cool air available to the CPU tower. Now, you could instead move that fan back to be rear exhaust after the CPU tower cooler, and that’s a test we actually did run.", "There are a ton of other configuration options in this case. We’re just showing what you can do with 6 fans in our animation. We have about 5 other configurations we ran, but we’ll go through all of those in our testing section.", "There are tons more combinations and testing this will be complicated, but this should at least get you in the mindset for thinking about it as we work through the benchmarking and optimized layouts.", "The HS 420 is a big enthusiast case that exists in an era where big enthusiast components are dwindling (GPUs aside). Despite HAVN repeatedly referring to the HS 420 as a mid tower, it's imposingly large at 18-19kg (empty).", "If you want a big case, you have to find something to put in it. Multi-GPU is dead, which removes some motivation for ridiculous open-loop setups, and 3.5 and 2.5 storage drives are becoming less common. Despite its size and claimed support for motherboards up to 277mm, we don't recommend installing E-ATX boards in the HS 420, as they'll overlap the cable cutouts and look messy. That brings us, finally, to the VESA mount.", "The mount can optionally replace the side fan bracket with a 14-inch screen inside the case, which could pull some consumers away from the ", " at the cost of some drive support.", "Even if you don't need the drive trays, though, they look cool enough to keep installed. Each of the four boxes can fit either one 3.5 drive or two 2.5 drives, with one mount recessed for cable clearance. ", "Cable management is laid-out logically and has plenty of velcro straps, although cables need to be managed tightly to keep the flexible center of the side panel from bulging out. The ATX 24-pin, EPS12V, and potentially GPU and SATA cables all share a single channel, which requires more effort to manage. The screws and magnets are more than enough to keep the panel from popping off, though. The rubber strips in place of normal rubber grommets are also different.", "At the rear of the case, the motherboard and GPU I/O is hidden within the rear panel, making it difficult to see or reach the ports. This is an unfortunate combination with the minimal front I/O, which consists of 2x USB Type-A ports and 1x USB Type-C, along with a single audio jack. On a positive note, the internal cable for the USB Type-C port is a flat ribbon cable that's easier to manage than the round kind.", "Thermal testing is complicated this time.", "The case doesn’t come with fans. Because it endeavors to compete with the best cases on our charts, we needed to see if it could actually beat the best. We decided to standardize against a set of fans from one of the best cases on the charts: The ", ", which comes with 6 fans and has held the #1 rank in some tests recently. We pulled all 6 of its fans (4x 140, which is perfect for the bottom intake configuration and 2x 120 reverse blade), which allows us to make a direct head-to-head comparison. We’ve noted for a long time the limitations of our standardized fan test methods in cases, so for this review, we decided to experiment. We might start instead standardizing against a case that competes in a similar class, which would give fewer individual case reference points, but allow us to test against head-to-head competition in a controlled way with the same fans in a more optimized setup.", "So this marks sort of a new trial in our case reviews. It also enabled us to do more configurations for this case. Let us know if you like it and we’ll apply it to some future cases as well.", "Here are the 8 configurations we ran. We only had a few days working on this case with Arrow Lake coming up, so we might do more later.", "The tests labeled “A” are with some form of bottom intake. A1 has the angled tray and glass, A2 ditches the glass, and A3 goes flat-mount ditching both. The rest of their setup is the same.", "Tests labeled “B” are with side intake. Remember, the budget is 6 fans to match the leading Flux Pro, so we stopped there for now. For this, we experimented with variations on the single 140mm fan in the top, moving it either in front of the cooler as intake or behind it as exhaust. We also experimented with the rear-bottom fan, swapping to either intake straight into the GPU or exhaust.", "This quick table shows the rank of each configuration in GPU thermals and CPU thermals. We’ll look at actual results in a moment, but this is a summary of the 6-fan budget. ", "The best combined performer here was configuration B1, which had a vertical GPU without bottom fans, 3x side intake fans, 1x mid-front intake up top, and 2x rear exhaust fans. The best performer for GPU thermals was B3, which has a horizontal GPU, side intake, no bottom fans, and intake in the rear-bottom of the case, but it was at the cost of CPU thermals ranking 7th of 8 configurations. The best CPU performer was B2, which has a horizontal GPU, side intake fans, rear exhaust, and the top fan arranged as CPU tower intake.", "Let’s move to individual data for inspection with just the HAVN case first.", "Here’s the chart for GPU thermals at full speed.", "The total spread is 4.6 degrees, which is actually pretty wide for GPU thermal differences in our testing.", "Starting with the glass flow guide: Our direct comparison of A1 vs. A2 has identical setup aside from the guide. On the chart, A1 with the angled fans and glass shroud performed the worst, with A2 performing 1.8 degrees better for GPU average temperature. That’s a real difference and outside of expected variance. A2 is identical but removes the glass shroud.", "The best performer for the GPU was a horizontal GPU and side intake with B3. This isn’t too surprising. Horizontal GPUs often breathe better, but if you truly wanted a vertical GPU for display, our best-performing vertical setup was B1, which uses side intake, a top intake fan in front of the CPU cooler, and two rear exhaust fans. A3 is next, this time with 3x bottom intake fans but mounted flat rather than in the angled tray. This is a direct comparison to A1 and A2 without any changes. In our testing, it appears that the special bracket for the bottom fans and all the complicated curves and turns and glass are hindering performance. This makes sense. Air shooting straight in and without reroutes is just performing better with A3. ", "Looking at CPU thermals in detail: Configurations B2, B1, and A3 are functionally identical. A3 with the flush-mounted bottom intake fans did better for the CPU than those where the fans were angled at the glass. Config A2 was about 2 degrees worse than B2, so the total spread here is largely inconsequential. It’d make more sense to choose based on GPU performance than CPU tower performance between these configurations. Side intake is favored.", "For VRM and memory thermals, there’s another relatively wide spread of about 6 degrees on system memory. B1 runs at 13 degrees over ambient for DDR5, which is impressive. B3 runs at 19 degrees over ambient -- totally fine, but 6 degrees warmer shows an inefficiency. The cooler result benefits from an intake fan immediately above the RAM and VRM.", "Time to get into the competitive benchmarks.", "This chart is for GPU thermals with the fans at full speed. We’ve removed all configs for the HAVN case except the best and worst. You can find the full HAVN data in the prior charts. ", "Again, remember that the HAVN case does not include fans. Because of this, its performance is basically whatever we want it to be, based on fans we choose. We normalized to the Antec Flux Pro, so that’s our direct comparison.", "And the Flux Pro wins. Antec’s thermals are superior for the GPU while maintaining roughly equivalent noise levels, functionally noise-normalizing HAVN for the Flux Pro. The HAVN case still does well and ranks right alongside the ", ", which has remained an impressive show of force for Fractal. It’s just that HAVN isn’t dominating the charts as much as we’d have liked for a case so thoughtfully focused on new approaches to fan placement. It’s a good start, though.", "A1 has the bottom intake bracket and VGPU and landed lower down the chart. We’d favor the horizontal GPU solution. The HS420 HGPU B3 is outperforming the ", ", but only slightly outperforming the Hyte Y70 with half the fan count.", "For CPU thermals, we’ve added B2 to this chart as it was the best for CPU performance.", "At full fan speed, the HAVN with the best configuration we’ve tested so far landed functionally tied with the Flux Pro using its alternate PSU mount. Noise levels are about the same. This has the HAVN HS420 led by the Flux Pro with standard PSU orientation, the 216, and 207. The ", " is also about tied with the HS420, but is much louder at 45 dBA, where these HS420 configs land closer to 39-40dBA. The Antec comparison is the most relevant since the fans are identical.", "The case does fine. It’s sad to see it not do better with all the special tuning, but looking back at our emails, even the HAVN team itself thought that the horizontal GPU configuration would do better in our testing. They were right. The vertical GPU setup, as fancy as it is, is still about balancing looks. Vertical GPUs are often disadvantaged, and HAVN hasn’t defeated that here.", "Thermals are our focus. From a pure thermal performance standpoint, HAVN has not become the new best on the charts. The ideas are there, and for a first case, they got close -- but it is beaten by cheaper cases on this front.", "Cases aren’t all about thermals, though. Despite that being our top priority, all 3 of us (Patrick, Mike, and Steve) who were hands-on with the case would consider buying one.", "We all spent a lot of time personally working on this case. Each of us has gone through full assembly at least once on the system. All 3 of us were in total agreement that the quality is overall phenomenal and that we can’t overstate the attention to detail put into the ", ". For length, we cut a lot of commentary from this review. As a rapid-fire list, some small details we liked: ", "The top cover of the case has structural ribs that are specifically spaced to align with the hubs and edges of top-mounted fans, minimizing overlap with the fan blades. The right side panel does the same, intentionally aligning the blockages from structural elements with the dead zones on the fans. This is awesome attention to detail that we don’t commonly see. There are protective rubber dampers on everything: on the screws and the tabs that attach the fan trays to the case, on the 120mm adapters for the rear fans, on the posts that the bottom fan mounts rest on, on the airflow shield, and under a fragile corner in the middle of the rear panel. There are color-coded stickers with recommendations for routing cables through certain channels, and these stickers are placed over molded outlines. The case has optional screws everywhere, magnets to help click panels into place, and guides that are sturdy and well-built. The rear slots were thought-through with an optional filter on the bottom and none in the top, since blocking exhaust is pointless. The vertical GPU, despite its weaker performance, is positioned to maximize viability for hot cards.", "It's easier to point out areas where this attention to detail is lacking, since we only really found two: first, there's no vibration damping for HDDs despite all the rubber washers elsewhere in the case, and second, the bottom filter is flimsy and doesn't eject smoothly.", "The other main downside was just doing reconfigurations with the vertical GPU mount, which can make accessing cables along the motherboard challenging. Most people won’t do that more than once, though.", "Case testing is complicated: It’s possible that a configuration with a different GPU, such as a 4090 Founders card, would behave differently. But based on our data, simpler might be better -- and the case would be $70 cheaper. Patrick and Steve both feel the same way, which is that we’d buy the $200 version of this case. It is much more competitive with direct peers at $200. At $270, it’s really only something you’d do for looks.", "While the $200 case is worse than the ", " thermally, the build quality and ease-of-installation features are far superior and the case is more future-looking with its concepts. The Flux Pro does well on tradition, and that’s just fine too. We like both cases. If you want something less traditional, HAVN manages to at least hit the basics while advancing the industry.", "We don't want to beat a dead horse here, but this feels like the case that TRYX wanted to make with the LUCA L70 (read ", "). This is a weird new design from an unknown company with some big money behind it, it's roughly the same size case as the L70, and the LUCA's price falls right between the two SKUs of the HS 420. The HS 420 is more solidly built, it's more practical, it has better cooling (once fans are added), and in our opinion, it looks better too.", "Patrick said this about his concluding thoughts: “I would personally buy this case retail if I didn't need to fit a ton of drives; I haven't felt that way about a case we've covered in several years.”", "Mike and Patrick both are hopeful that HAVN branches into smaller and cheaper cases. Patrick said, “I hope they don't just make a CLC. It feels inevitable that a company like this is going to make a CLC.”", "The VGPU version is not really our thing. We think the cheaper one looks better and works better and is more widely compatible.", "Wrapping things up, this is a great first showing from HAVN. The case represents a fantastic starting point for a platform to try and do some cool things thermally."]},
{"title": " Best PC Cases of 2024: $80 to $800 Airflow, Cable Management, & Thermal Leaders", "paragraph": ["Best PC Cases of 2024: $80 to $800 Airflow, Cable Management, & Thermal Leaders", "Last Updated: ", "The Highlights", "We’re looking at the best cases available right now. ", "We broke back into case reviews this year and have added to our case collection. This round-up highlights the best cases we think are available in 2024 based on our thermal benchmarks, acoustic tests, build quality evaluation, and cable management testing.", "This year was packed with excellent cases -- but of course, a few that were really problematic as well.", "Steve Burke", "Patrick Lathan", "Vitalii Makhnovets", "Jimmy Thang", "Welcome back to the Best Of Round-Up series. These are our favorite pieces to run annually and help you quickly get back into PC components if you haven’t been paying attention, but also give us a reason to go back through all the cases we’ve tested recently and remember what was the best. ", "These are meant to be more of a fly-over story in the round-up series to help simplify and highlight the key points. If you want the full in-depth reviews with all the nuance, check the links in the description below. We’ve linked each case review and have also provided all the usual affiliate links with them.", "We already published ", " and the same thing applies here: Sometimes, the best case or CPU in 2024 might be something that launched in a previous year. We look at the total market and what the best options are now, not just what launched this year. As a reminder as well, we took about a year off of case reviews in 2023, so we launched back into it heavy this year and we’re excited to be back to the Best Of series for something positive.", "Let’s get into it.", " ", "Awarding the best overall case is difficult this year, which is a good problem to have -- that means cases don’t suck. This category requires a strong offering on all fronts: Value, thermal performance, acoustic performance, aesthetics, build quality, ease-of-installation features, and cable management.", "We’re giving it to the ", " & ", ". Although other cases are superior in some individual situations, like the ", " (by a slim margin) in thermals or the ", " in mechanical aspects, the ", " and ", " are masterful executions of a standard computer case.", "This is bolstered by prices that have been lower in recent weeks, typically down around $125 to $140 for the North (watch our ", ").", "The Fractal North was the first case to successfully kick-off the wooden trend at scale, with everyone else in the industry scrambling to follow. InWin gets credit for initially attempting this years ago, but it failed to find a way to bring it to market and execute. Fractal pulled it all together and cleaned up the idea.", "The North comes with either a glass or mesh side panel, which includes options for additional side mounts to further boost cooling performance. Actually, in our ", ", you can see such a configuration for one of his machines.", "Fractal’s fan support on the XL is also effectively whatever you want it to be: The company cleverly uses standard hole spacing for its rear ventilation (and even PCIe slot covers and top of the power supply shroud) so that you could mount a fan basically anywhere you want in the case. The cooling options are really opened up because of this. ", "Ease-of-installation options are also great: Because the top panel so easily slides off to remove, and because Fractal doesn’t put a ton of other metal in the way, you can get clear access through the top of the case for builds. The extra width in the XL also makes larger radiators easier to work with up top, reducing board clearance issues.", "The North XL (read ", ") is what we prefer to the North, mostly for its increased size for easier building and for our style of build, but both are good takes on the theme. Visually, the wood look doesn’t look like the slapped-on Vinyl style we see in other cases. It looks more purposeful. Fractal also does great work mixing different tone wood coloring with different panel coloring, including matching the black case with gold accents and the white case with silver accents.", "And finally, even in cooling performance, the North XL is routinely at the top of the charts for thermal benchmarks. It’s not the best -- that’ll go to two other cases this year -- but it’s regularly at the top, and that plus all the other features, plus the value, get the North cases the Best Overall award.", "The next award is for the Best Mechanical Design, which we give to cases that may not have won in other categories, but truly innovated for the physical and mechanical elements of the case.", "This year, it goes to newcomer HAVN and their ", ". The HS 420 (read our ", ") exhibits a mastery of mechanical features.", "The HS 420 doesn't include fans, it's not fully airflow-focused, and it isn't cheap at $200 for the horizontal GPU model. That makes it a tough fit for our price- and performance-focused award categories, but it needs to be recognized, because it's one of the most interesting and downright good cases that we've reviewed this year.", "Mechanically, it’s excellent. The curved tempered glass panel is the most significant feature. The panel is installed by sliding it back and down into the case on plastic wheels, where it then comes to rest on the bottom edge of the chassis. It takes some getting used to, but it's a clever and secure way of getting the huge glass pane seated. It's also proven to be durable, surviving multiple build/unbuild cycles through the filming process without serious wear.", "There was a lot of thought put into airflow, something we illustrated in ", ". The HS 420 VGPU includes a curved glass deflector that's intended to direct incoming air around and into vertically-mounted GPUs. It was a clever idea and a fresh approach, which we appreciated, but it did not help performance in our test system. That’s also why we're specifically giving the award to the $200 base model, which is cheaper and sheds the hardware that didn’t do much. ", "Even with the base model, though, HAVN planned for an unusual airflow pattern with intake at the bottom of the rear panel and exhaust at the top of the same panel, and included 120mm plates on each mount that are isolated with rubber vibration damping. In fact, every fan tray is padded with rubber, including the side mount that doubles as drive storage. The drive storage alone is pretty cool. It creates a spine-like structure that can be removed for more fans.", "The case's construction is clever and precise in areas like the tightly-spaced storage bays at the front and the rounded edges of the PSU shroud and motherboard tray. The simple GPU support that ships with the non-VGPU case variant is one of the sturdiest we've seen, cast from solid metal and braced against the PSU shroud. The cable channels are not only labeled, but color-coded in what is an excellent feature, as it helps new builders understand where to route cables.", "There are a ton of other small attention-to-detail elements, like the fact that HAVN matched the structural reinforcement for the panels to align with fan hubs, or the dead zone, rather than obstructing air intake. You can check our ", " for all the other details, including our full charts with 7 or 8 different fan configurations.", "Before closing out this category, we want to give some recognition to ", ". The ALTA D1 is an $800 halo product that's finally hit retail following our first encounter with it at Computex 2023 and again at Computex 2024. The price is ridiculous and very few people will buy the case, but the mechanical design hopefully inspires some more affordable cases: It has modular bays on rails everywhere, including 5.25 drive support, socketable radiators, a slide-out motherboard tray, SSI-EEB support, 11 expansion slots, large fan mounts, repositionable power supplies, and a true home server setup. It's beyond what we could recommend in a serious review if only for the price, but we may come up with a fun project for the ", " in the future and we respect its mechanical design.", "We’ve had a category for years for the “Best Budget Case,” but the amount of quality cases in the $60 price point and under has really declined in recent years. Honestly, at or below $60 right now, we think used cases are typically a far better deal than something new at the same price.", "So this category has become Best Sub-$100 case, which we’re giving to the ", ". ", "There were a lot of cases to consider for this category: When we were deciding this year's winners, although there are a lot of sub-$100 cases, there just aren’t any that defeat the Lian Li Lancool 207 (read our ", "). In the current market, $80 is dirt cheap for a name-brand case: there are cheaper cases available from companies like SAMA and DIYPC, but we're confident that none of them come close to the Lancool 207's frequently chart-topping thermal performance.", "When we ", " the SilverStone 515XR, we were aware that SilverStone had pulled out all the stops to offer a case with four fans at $68, but the performance gap between it and the 207 is massive. There’s also differences in quality-of-life features. ", "The same goes for the ", " and the ", ". Both cases have been added to our charts recently. The ", " is supposed to be closer to $60, but has been out of stock lately and often more expensive when it is available.", "The ", " is a solidly-built case with sturdy toolless panels, which is unusual at this price point. The most unusual aspect, though, is at the bottom of the case, where two 120mm intake fans are positioned directly underneath the GPU, while the PSU is mounted at the front with an extension cord. The shroud is ventilated on both sides as well as the rear in order to provide an airflow path for the bottom intake fans (although adding drives and cables to the case reduces that ventilation, but the ample intake through the rear counters this). In addition to the two bottom intake fans, 2x 140mm ARGB front intake fans are included with the case. ", "They may not sound significant individually, but the fact that the 207 has a full suite of basic quality of life features like reusable (and bridgeless) expansion slot covers, rubber grommets for cable cutouts, a USB Type-C port, ARGB fans, built-in velcro straps, and toolless panels is impressive in combination with its price and thermal performance. It's rare to see that full combo in a case, especially one which is also a top thermal performer. The fact that the 207 also wins our objective, numbers-based Best Thermals category is also part of why it lands here.", "We have two big issues with the 207: first, the toolless side panel won't stay on without meticulous cable management. There's no way around this, but sticking to flat cables and minimizing the number of cables used will help. There's also room to improve PSU cooling in the case, as most PSUs will be oriented fan-side-down with barely any clearance above the table surface. The cable management is the one to be aware of. You can watch our review for more on that.", "Still, at $80, Lian Li is being brutally competitive.", "Next up is the award for the Best Mid-Range case. We’re looking for something that isn’t too wild or out there. We want relatively standard, but a good price-to-performance and overall build quality. We’re also looking for something a little bit better than the budget case. For this, we’re giving it to the ", ".", "Antec has had a strong year. It had 2 showings this year in our list we have today, but it was the ", " that first signaled to us that the company was worth paying attention to again after a decade of fading into irrelevance. ", "MSRP is $150 for the ", " with fans included, but it's been long enough since the case's June launch that we're beginning to see discounts. The fan-less variant is regularly available with promo codes around $100. ", "This mid-range award category gives us some room to consider quality of life and aesthetic features, not just raw performance-per-dollar, and the ", " is well-balanced in those categories.", "The C8's dual chamber layout isn’t new, but Antec impressed us with the level of care that it put into details like molding text into the fan frames, color-matching all the components in the white SKU, and the accessory kit. Small touches, even ones that aren't functional, add up to create a product that feels worth the price. The C8's appearance reminds us of the clean designs that made ", " (and ", ", and ", ", et cetera) so appealing, but we much prefer Antec's case to the directly comparable ", ".", "Functionally, the usual benefits of dual-chamber design apply: there's plenty of space to work with in both chambers, including storage space for cables and drives. Dual chamber cases frequently have cable channels so deep that it's difficult to reach tie points at the bottom and effectively bundle cables, but the C8's removable air duct partition solves that problem.", "The centerpiece of the C8 ARGB (read ", ") is the bottom fan mount, containing two unusual 160mm x 35mm reverse-blade intake fans (with an additional conventional 140mm exhaust fan at the rear of the case). These two 160mm fans are placed over a completely open vent, meaning that the removable bottom filter is the only obstruction to incoming air. Antec was aware enough to not obstruct this intake path, unlike many other companies. ", "This makes GPU cooling in the C8 ARGB excellent, although CPU cooling with our test setup was predictably lackluster due to the lack of front or side intake.", "We prefer the C8 ARGB to the fanless base model, but the less expensive SKU may make more sense for liquid-cooled builds since the ARGB's 160mm stock fans won't match any normal radiator. The case can fit up to 3x 360mm radiators simultaneously, most easily in the side and bottom slots. For air cooled builds, the $20 upcharge for the ARGB variant with the extra fans is worth it. Many of the dual-chamber cases we've reviewed have followed in the footsteps of the O11 Dynamic by not including any stock fans, so having a choice is a welcome change.", "Our next two awards are for thermals. The next one is for Best Noise-Normalized Thermals, while this one is for Best Out-of-the-Box Thermals. The difference is that noise-normalized is focused on one category, whereas Best Thermals looks for the best performer in all tests we ran and at all fan speeds.", "The raw all-fans-maxed stock performance is a tie between the ", ", represented in the sub $100 category, and ", ", which is represented in the next category. These cases have similar layouts, each with front intake fans behind a mesh panel and bottom intake fans mounted on top of a ventilated PSU shroud. Our test bench hardware uses air cooling with a flow-through GPU cooler and a CPU tower cooler, which we've chosen to be as broadly representative as possible and as controllable as possible. This hardware benefits from simple, direct airflow: cool air from the front for the CPU, cool air from the bottom for the GPU. These two cases are the ideal realization of that airflow pattern.", "The ", " and Lancool 207 both averaged 38 degrees Celsius above ambient all-core and 42 degrees on just the P-cores. ", " and North XL are both within one degree of this result, but the Flux Pro (read our ", ") and 207 pull slightly ahead in other categories.", "Moving to GPU thermals, both the Flux Pro and the Lancool 207 averaged exactly 38.2 degrees above ambient, although the 207's memory temperature averaged slightly better at 41 degrees versus 43, while the Flux Pro's hotspot temperature was a little lower. The Flux Pro's stock configuration is set up to mount the PSU rotated 90 degrees in Antec's iShift mount, but we found that mounting the PSU in a more typical orientation with the plug at the rear of the case slightly lowered overall GPU temperatures for a best-case 37 degree delta above ambient.", "The 207, on the other hand, logged our best temperatures so far from the VRM and RAM sensors at 21 and 17 degrees above ambient respectively. These two cases are extremely close in performance, and we can't declare just one winner between the two of them.", "The next award is for Best Noise-Normalized Thermals. This is a pure performance-driven category, but it combines 2 metrics, which is acoustics and thermals. Fortunately, its winner is also just a good standard case to build in: The ", ".", "Noise-normalized thermal tests are the most important performance benchmarks we run on cases. With the current iteration of our bench, we place the case on a table in our ", "with a mic pointed directly at the center of the front panel from one meter away. Then, we lower the speed of the case's stock fans in tandem until we hit our chosen threshold of 27 dBA SPL. This allows us to level the playing field so that the cases with the loudest fans don't automatically land at the top of every single chart by brute force. It creates a control.", "The ", "'s front panel doesn't block much noise, but it's so well-ventilated that the three 140mm front intake fans don't need to work hard and don’t generate much noise to begin with. There isn’t much resistance and so they can spin slower, while the 2x 120mm shroud-top fans assist GPU cooling. The Flux Pro's PSU shroud is open on all sides, including the bottom, which maximizes airflow without directing significantly more noise towards our mic.", "CPU thermals are tied at the top of the chart with the Lancool 207 at 41 degrees Celsius above ambient all-core and 45 degrees on just the P-cores. Some of our other high-performing cases like the North XL and ", " come close, and the ", " (watch our ", ") is tied in this one, but the Flux Pro is the best overall when taking all results into account. ", "In the noise-normalized GPU thermal test, it outperforms the Lancool 207 and ties the Torrent (watch our ", ") for GPU die temperature. ", "In VRM and DDR5 memory thermals, the Flux Pro is the chart leader by a technicality, but again is functionally tied with the 207. Both the Flux Pro and 207 offer excellent cooling at the noise levels, but the Flux Pro technically takes more lead spots than the 207. But the 207 is well-represented already.", "We also know from our full speed results that it's possible that the Flux Pro could perform even better with its PSU mounted in the typical orientation rather than the stock rotated iShift mount.", "The Flux Pro was an excellent return to form for Antec and offers a standard layout case for strong fundamentals. It is deserving of the Noise-Normalized victory while still offering the basics and foundation required for a good standard PC build in a non dual chamber case.", "Our Most Innovative Case award goes to the case that has the newest and most different design, even if it doesn't work perfectly, because innovation pushes this industry forward. This goes to the ", " Mini-ITX case.", "Despite its generic, boxy exterior, the Meshless AIO (read our ", ") is one of the most innovative cases we've ever reviewed.", "The Meshless AIO (now apparently listed with a formal launch name as the “", "”) is built around a cylindrical crossflow fan, like a smaller version of the fan in a mini-split wall unit. We found the case design curious enough that we built this ", " to help explain and educate on how these work. The basics are that the crossflow fan shoots hot air out at the upper edge of the side panel, and theoretically pulls cool air in everywhere else: towards the GPU fans from the side panel, through the radiator, and over the motherboard and PSU from a tiny strip of ventilation along the bottom edge of the case. In practice, we found that the GPU was better cooled by taping a couple of normal 120mm case fans to the top of the case, but these had other downsides in other tests. ", "Thermal performance was at least adequate, and considering there was a single fan handling everything, overall impressive for what was done on a single fan that you might not normally find in a PC case. We were concerned about the PSU's lack of direct access to cool air, but otherwise, everything was getting fed air.", "There are some other creative aspects to the MD280’s construction outside of the fan: the main portion of the case is a single piece of extruded aluminum, and other elements like the fan, radiator, glass side panel, and handle slide into the open ends. This is an excellent and compact design that works well. Another cool feature is the lever that’s accessible from the rear of the case, working to slide the PCIe riser cable up and down. It presses the slot into place to improve accessibility. It's an ambitious and creative project, especially since Meshless Design informed us that it's an independent outfit driven by one man: Hank Lin. This is the work of an engineer who turned an idea into an actual product with overall good execution.", "We need to issue a buyer beware warning here: it looks like the Meshless AIO's price has been increased to at least $450, a big jump from what we were expecting, and we have no way of vouching for the company's ability to deliver on pre-orders. Unfortunately, that price kills the case for us, as there are simply too many other good competitors in ITX at half the price. ", "But it still gets an innovation award.", "We have an Honorable Mention for this category as well: ", " ATX case. Dubili is an anagram of iBuild, an abbreviation for InWin's DIY iBuild iShare brand, as well as an abbreviation of Do Believe. The instruction manual comes in the form of a dedicated single-purpose app with animated 3D renders, which is absolutely required if you order the flat-packed build-it-yourself DIY edition. We like the ", " for its unique look, high-quality build and materials, and the modularity of the paneling. That it flat packs is also a cool aspect to the case, creating a fuller DIY experience. The color scheme is also different: A sharp silver-and-orange or a Noctua-style cream-and-brown with gold screws. The case doesn’t win over the Meshless AIO, but we like it enough that it deserves a mention.", "The Biggest Disappointment is up next. There are a lot of options to consider for this category: Between the ", " (read our ", "), the ", ", the ", ", and more. We had our work cut out for us.", "The award goes to Corsair for the ", " series of cases. Although Tryx’s case was a mess, it ultimately doesn’t have the same expectations attached to it as Corsair. To be a disappointment requires some level of expectation.", "Corsair wins the award handily: Broadly speaking, Corsair has continued to disappoint ever since it took on huge investment. Like the assets of its corporate overlords, its disappointments are diversified: They bought Origin, which sold us a $6,600 computer that had the CPU ", "; they made the ", ", which had heatpipes so unlevel they sheared our pressure paper. But the company also shipped some excellent products in recent years, and those came from its case division.", "The Corsair 4000D (watch ", ") was commonly $80 and one of the best sub-$100 cases available for a while. The ", " (watch ", ") was an OK follow-up to that, scaling-up the useful features to a larger size. Corsair was finally doing well with cases again, following a long drought of basically nothing.", "But then it launched the 6500 (read our ", ") series this year, attempting to jump onto a hype train that had already left the station, and doing so with substandard build quality. The Corsair 6500D and 6500X were $200 without fans, both featuring superbly bendy panels without any reinforcement -- which we found totally unacceptable for a $200 so-called “Premium” case. There were lots of plastics, misaligned panels, and build quality issues. ", "The 6500D had a number of slapped-on features that didn’t work together. They tried to accommodate back-connect motherboards, but doing so required punching what seems like a completely random hole into a drive cage, which was then entirely left out of the original manual. If you used one of Corsair’s own SHIFT power supplies, you’d have to remove the drive cages completely and move to only NVMe drives. We found build quality issues, design oversight, and a high price to be not only disqualifying from any considerations on our lists, but also deserving of the Biggest Disappointment after falling from the grace of the ", ".", "Corsair is a big company and has the resources to fix this, but it’s a matter of whether they choose to.", "Since our critical review, Corsair has dropped the price of the 6500D closer to $150. It’s still worse than an Antec C8 ARGB, which often costs the same or less."]},
{"title": " Montech King 65 Pro Case Review & Benchmarks: Cable Management, Thermals, Noise", "paragraph": ["Montech King 65 Pro Case Review & Benchmarks: Cable Management, Thermals, Noise", "Last Updated: ", "The Highlights", "Today we’re reviewing the new $100 ", ". The coolest feature of the case is its side-mount fan tray, which can be released with two screws and pivoted out for easy cable routing or fan and radiator installation. It’s well-designed so that the tray is loosely secured by the cable grommets, which use their chamfered edges to guide it into place in a way that almost feels like there’s a guide wheel.", "This dual-chamber case comes with 3 pre-installed fans: 2x 140mm reverse blade ARGB side fans and 1x 120mm ARGB rear fan. Looking around the case, we can find remnants of the ", ". That’s because a lot of this case is the same, but cheaper.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Tim Phetdara", "Andrew Coleman", "Jimmy Thang", "But for those of you who have used the ", ", a lot of this case will be familiar: It’s intended to be a cheaper variation of the theme. There are some paneling changes, like the top panel, but a lot of the interior is familiar. ", "Because we never formally reviewed the King 95 as it was during our case benchmarking rework, we’ll treat this as the first look at both the 95 and ", " features and review it fully. Since there’s shared tooling, some of the discussion will apply to both.", "Let’s get into the review.", "We’ll start with the competitors in this price range.", "Currently, the ", " is $140 to $150, including its 6x ARGB fans. The ", " is the same case, but drops to 0 included fans and is currently around $110. At $100, the King 65 Pro swaps some panels but adds 3 fans back. ", "Somewhat confusingly, we found Montech’s own King 95 on Newegg for $90 at the time of writing this. They’re calling this a “holiday sale” -- it’s October 10th as we write this and we have absolutely no idea what holiday that is for, maybe “Newegg Needs Money Day,” but the point is that $90 makes it cheaper than the brand new King 65 Pro and may lead to some product cannibalism. Adding 3 fans wouldn’t be that expensive.", "In price and ignoring form factor, the King 65 Pro competes with the ", ", the $80 case we just ", ". The Lancool case is a more traditional design, while this is a dual-chamber fishtank, so they have different looks. Lian Li’s Lancool is an excellent thermal performer with some cable management challenges.", "The ", " is another case around $100 that the King 65 competes with on price, but is totally different on style.", "The ", " is $80 and comes with 4x 140mm fans in a standard form factor case as well.", "As for actual style competition, the ", " is currently $130 to $140 and doesn’t include fans, but would match for the general design.", "The King 65 Pro adds a bolted-on front plastic piece to square out the front/bottom of the case. This is in contrast to the curved design of the ", ". ", "Aside from the glass, the top panel also features curved edges as compared to the King 65’s straighter-edge design. The King 65’s top and back side panel also features a more standard mesh ventilation as compared to the King 95’s Hyte-inspired sweeping design. The King 95’s ventilated side panel also features a built-in dust filter, whereas the King 95’s solution does not. ", "There are also differences between the fan hubs of both cases. The King 65 features 6 total connections whereas the King 95 Pro has 10 total ports. ", "Another difference includes the fact that there are rubber grommets within the King 95 Pro, which are absent from the King 65 Pro. ", "Those are the key differences. Now we’ll get into build quality and panels of the King 65. A lot of this discussion will also apply to the King 95.", "Overall, panel construction quality is good on the King 65, but there are some caveats.", "At ", ", we noticed that the front panel was very slightly misaligned with the decorative plate for the I/O side. This is somewhat of a nitpick, but that’s because it’s rarely an issue. ", "The cases that we got resolve this issue and have the two front panels level, so that was nice to see. ", "The front decorative strip is actually just plastic with a brushed look to sort of fake an aluminum appearance, serving as a cheaper gimmick to emulate the ", " and ", " (read ", ") look.", "As a downside, the top metal strip for the supporting backing of the glass front panel was bent up on our black King 65 Pro. We always include damage in our reviews, whether that’s quality control or shipping. This particular damage looks like something that happened at the factory, not in shipping. It could be easily pressed back down with a flat edge.", "As a positive, the panel gap between the front and side panel is flush, which wasn’t the case with the show model we saw 5 months ago. Cheaper cases often have problems with panel alignment.", "The side panels are secured with thumbscrews, which we always like to see just as a security feature when moving the computer around for cleaning and maintenance. The front panel pops out easily once the side panel is removed.", "Like we saw on the ", ", the King 65 uses a reinforced rectangular piece of steel to support the snaps to the frame.", "The front corner of the top panel is also relatively strong, unlike the ", ", because Montech designed it properly. The Tryx case top panel was caving in not from shipping damage, but from design issues, and we want to make sure that plot doesn’t get twisted because it’s important. The King 65 is relatively stout, which helps reduce the top panel length to provide strength, and is also supported by a more significant anchor to the deeper secondary channel, meaning a lengthier attachment point to serve as a counter support on that front edge.", "The top panel itself is of sturdy build and has butted-together steel around the edges to give clearance from the fan rails while adding structural rigidity, but lacks the mesh we saw in the King 95. ", "The final side panel is a little floppy from lack of thicker supports, but has no functional downside. It’s also ventilated for air intake through the side. ", "Removing that panel, there’s a cable management cover tray with 2x 2.5” SSD mounts in it. Two screws can be removed to hinge the door outward, giving access to the drive mounts and two additional fan mounts with rails in the door. And this is where we get into an area that Montech could improve.", "Both sets of fan mounts have heavy obstructions. By accommodating both 120mm and 140mm sizes, Montech needs two sets of mounting points. Unfortunately, in the process of creating these, it has covered up to about 20mm per side of the fan blade, or 40mm total horizontally obstructed. This is a huge amount of intake area loss. Montech could still support two sets of rails, but at least cutting a hole right in the middle would be better -- or even running the rails the entire length of the fan so that there’s some room for air. This is an oversight that likewise extends to the King 95. The King 95 Pro did OK in most of our tests, but falls behind other cases with similar fan count. This is a large contributor to that.", "For cable management, the King 65 continues the trend of including velcro cable ties that secure behind the motherboard tray, which itself is already deep enough to provide functionally limitless cable space. Although we’ve since built in the cases, we liked how the fans were pre-routed and arranged out of the box.", "The power supply sits elevated atop a rubber-damped pad, providing clearance on all sides while hopefully absorbing vibration that could cause noise. Although the exterior of the hard drive cage has rubber dampers, the drive sleds themselves do not. If supporting 3.5” drives, we’d like to see rubber dampers at the contact points where the drive meets the plastic or metal. ", "Access is through the rear for drive installation, which mostly makes things easier. They aren’t hot-swap cages with pre-wired backplanes or anything fancy like that, but the rear access does make things easy to get to.", "As for radiator, GPU, and fan support, it’s the same as the King 95 Pro: Montech’s GPU support is up to 420mm long, so basically any video card, and radiator support is up to 280mm or 360mm top, 140 or 240mm side, and 175mm tall air coolers.", "We’ll start with noise-normalized CPU thermals under a full torture workload.", "Unfortunately for the King 65 Pro, it’s the new worst result on the charts. These fans just aren’t powerful enough to provide the cooling necessary, and likewise, extra noise created by paneling choices, such as the sharper angles and the obstructions, leads to a need to reduce speed to normalize for noise.", "The King 65 Pro lands at 57.6 degrees over ambient for average P-core temperature, putting it behind even the ", " (watch ", ") in the baseline setup.", "The ", " runs about 3 degrees cooler, which is significant, although it carries a $50 premium. The same-priced Silverstone 514X (read ", ") runs about 6 degrees cooler with its own stock fans. The ", " (read ", ") does well here, but costs $80 more than the King 65 Pro, so it’s not a fair comparison. We know, that’s hard to believe since they’re both pros.", "The Lancool 207 is $20 cheaper than the King 65 Pro though and manages to completely dominate it on this chart. At 44.5 degrees, it’s not even close. The King 65 Pro is just not a great thermal performer.", "The King 95 Pro with the glass front ran at 50 degrees over ambient, which is over a 7 degree reduction without even using mesh. That’s a lot of impact from the extra fans and panel changes.", "Here are the GPU thermals for the same noise-normalized test.", "The King 65 Pro gets destroyed here. It is not only at the absolute bottom of the chart, but it’s several degrees worse than the previous worst: The FARA 515XR set the floor at 54 degrees over ambient previously, with the King 65 Pro at 57 degrees over ambient. For GPU testing, that’s a big swing. The GPU is not normally as sensitive to the case changes as the CPU in our tests.", "The $150 Antec C8 (read ", ") is an impressive 15 degrees better than the King 65 Pro. The $80 Lancool 207 is also about 15-16 degrees better than the $100 King 65 Pro.", "The next test is where we pull all the included fans and swap them for 3 standardized fans. Some cases are worsened by this, as we’re removing more abundant or better fans; however, this is useful for evaluating changes to the chassis structure itself. ", "As a perfect example: The King 95 and King 65 are suddenly exact equals when we swap to the same fans and positions. They’re within 0.4 degrees of each other for P-core average performance, which is impressive. That’s a testament to our new methodology and is great to see.", "The ", " with comparable side intake lands at 46 degrees, outperforming the King 65 and King 95 alike. Because we’ve normalized to the same fans and in the same positions, we can confidently state that the King 65 and King 95 have paneling that obstructs the fans enough to worsen performance. Montech could boost itself by changing its porosity and all the small obstructions to airflow that add up, like those earlier rails we discussed.", "GPU thermals when using standardized fans are also within roughly 1-degree ranges between the King 95 and King 65. The curvature of the glass theoretically should help improve air access to the GPU, but this gets into areas where we’d need CFD to know for certain. Regardless, at about 1-degree difference, they’re functionally the same.", "The Antec C8 with side intake again climbs ahead, up at 42 degrees for GPU temperature against 44.6 on the King 65.", "Back to the included stock fans and at 100% fan speeds, the King 65 Pro landed at 37.8 dBA as tested in our ", ", aligning it most comparably with the Antec C8 ARGB, which was 37.11dBA. That’s the same noise level.", "The C8 outperforms the King 65 even with both at full fan speed, at 49 degrees to 54 for the average P-core temperature. The cheaper ", " is quieter than both, at an impressive 35 dBA and 47 degrees over ambient. The Lancool 207 sounds more like a vacuum cleaner at 41.6 dBA when running at full speeds, but pushes to 41.6 degrees over ambient.", "Noise-normalized VRM and RAM thermals position the King 65 Pro at 36 degrees for the VRM and 26 for the RAM. These results have it toward the bottom of the chart, though better than the ", " with its stock configuration. Both the VRM and RAM thermals are completely acceptable, it’s just that it isn’t as competitive.", "Thermally, the ", " is just not impressive. It can’t overcome the limitation it has on its panel and case design. Its 3 moderate fans are just not sufficient for it to get anywhere impressive on our thermal charts and it’s at the bottom of some of those charts.", "In terms of build quality, in some places, it’s pretty good. The actual core of the chassis is good overall. There’s a lot of space to work with the cabling. There’s also some cool features like the side-mount fan tray, which is also on the ", ". Overall, the build and panel quality are fine. It’s just that at $100, it has to be really competitive and one of the things it's competing against is the King 95 Pro without any included fans. ", "This makes it hard to recommend the case in any one category. Overall, the ", " is okay. We don’t hate it, but against standard form factor cases like the ", " or even the ", ", which we weren’t thrilled about but we thought was fine, those are better options at this price. They are also better thermal performers, though the King 65 Pro is certainly a lot easier to build in than the ", ". ", "In terms of other competition, the ", " is similar in design to the King 65 Pro, but it’s wider and its non ARGB variant without fans is similarly priced.", "Within $20 plus or minus of the King 65 Pro, the case kind of gets its ass kicked in either direction thermally."]},
{"title": " Innovative: be quiet! Light Base 600 Case Review & Benchmarks", "paragraph": ["Innovative: be quiet! Light Base 600 Case Review & Benchmarks", "Last Updated: ", "The Highlights", "Today we’re reviewing the ", " by be quiet!. It’s a big deviation from the company’s monolithic towers with foam padding and is their first dual-chamber case. Be quiet! has gotten attention for designing this case with three presentations in mind: Standard, flat in traditional, old-school “desktop computer” design, and inverted. All of these have been done before, but be quiet!’s approach is simple and overall brilliant: To go flat, you remove the feet by turning them (like screws). To go inverted, you swap the feet to the other panel, which uses a slot-and-groove solution to notch them into place. This is fast enough that you could change it just because you’re bored of it or want to present the glass to a different side of the room.", "Steve Burke", "Patrick Lathan", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "The ", " is a dual-chamber with four SKUs, ranging from $150 to $195 in price. Our variant is $195 because it’s white and comes with case fans. The ", " is a larger variation on this. We’re reviewing the 600 since testing for these reviews is a big commitment, but the general concepts apply to both, just scaled up on the ", ".", "be quiet!’s key competitors for this include basically everyone, since dual-chamber cases have been so popular in recent years. If you’re thinking of buying this case, other cases you should know about include this quick list:", "And tons of others. We’ve left a lot out, but you get the idea: This is a crowded segment. A lot of these cases are in the $150 to $220 price range. A few are cheaper, like the empty Montech King 95 cases at $90 to $120 and the empty Antec C8, similarly priced.", "It’ll be a big fight, but be quiet! does at least immediately differentiate itself with some unique features, one of which is their giant light bar that wraps the case. It was done this way so be quiet! could achieve the rotation without losing symmetry when you move the case around. In fact, all of this case had to be designed with symmetry in mind. That’s what gives the cheaper flexibility than more mechanically-intensive inversion processes from other cases -- but it’s also limiting in some areas.", "For the basics: Our version of this case includes 4x 120mm fans pre-installed as side intake and rear exhaust when it's in its traditional configuration. You could also shift these to the bottom as intake in a traditional orientation or, if rotated flat, they could be used as a side-to-side flow path. This on its own is pretty interesting and is one of the tests we ran. ", "Other small fit-and-finish issues include a panel gap between the glass front and side, which is large enough that you’d need a taxi to get from one side to the other... The glass panels also diverge as they approach the bottom, with the bottom edge protruding slightly despite a flush top edge. We’ll come back to the fit-and-finish detail later though.", "Getting into the big details:", "We've criticized be quiet! in the past for its complicated case inversion processes. When we reviewed the Dark Base Pro 900, ", " to figure out disassembling and reassembling the case and sorting through the ridiculous variety and amount of screws and hardware. be quiet! must have taken that criticism to heart (even if 7 years later), because the Light Base 600 can be inverted in under ten seconds with no real screws at all (the design doc says 30 seconds, but that's with a system inside). ", "The case feet can be pulled off by rotating them 90 degrees, then either placed on the top panel to invert the case or on the side panel to flip it on its side. It's not perfect: the feet don't lock and they go crooked as you slide the case around. They also feel fragile enough to damage by hand if positioned in the wrong spot. The ease of use outweighs the downsides, but the downsides were avoidable in design. Either way, once it’s done, these concerns go away.", "This case also includes one of the simplest vertical GPU conversion systems we've seen. You take out all the horizontal slot covers, screw a bar across the back of the case, and adjust the built-in GPU support down a couple of notches.", "The horizontal orientation is the most unique in the current era of computing, though it definitely ", ". This old style is so liked in the retro scene that SilverStone made an ", " that accidentally became popular enough that there’s some real demand to make it.", "The downside is that the Light Base 600 isn't a particularly small case, and because of its dual-chamber design, it's more than 32cm tall on its side. The 900 has even larger dimensions.", "Backed against a wall, the case requires a minimum of 50cm up to the front edge of the case, requiring a deeper table to comfortably accommodate a keyboard and mouse if placed directly in front of the case. ", "The dimensions make it impractical to use in the old ", ", but if you want to try it anyway, we recommend using a monitor arm rather than resting weight on the glass panel. We wouldn’t recommend setting it up with a monitor directly on it, especially since tempered glass can shatter without impact in some situations.", "With the total monitor arm and monitor configuration, the setup could be made to look pretty unique -- we like the concept like this. Most of our desks are either 24” or 30” deep, with a few at 36” for filming. With that old-school setup with the computer right in front of the user, the 30” deep desks would only have 10” (or 25 cm) to spare for the keyboard and mouse. Plan your desk sizing appropriately. It’d obviously not be a problem if the system is off to the side of the keyboard and mouse. ", "The desk in the image above is 30” deep and the lowest monitor can conflict with the top of the case, but this gives you an idea for sizing. You could definitely build a good-looking retro setup with the right color lighting and furniture, not that the 600 is confined to that style, but it would look good. You would just need a deep table. ", "Fittingly for a case called the Light Base, there are dual LED and fan hubs in the back chamber. These have a total of 12x 4-pin fan and 12x 3-pin ARGB connections. The 600 LX's four stock fans occupy four of each type of plug (no daisy-chaining), but that still leaves eight unused pairs. Each hub has its own power and control inputs, allowing for two separate zones.", "Our key focus is performance, but when LEDs are done, we still look for quality. We think the lighting is executed excellently; the diffuser bars work well and the LED animations are smooth. It looks good in a night-time or lights-out setup. ", "Out of the box, all LEDs are set to be quiet! orange. The manual provides a full table of built-in lighting effects and instructions for syncing with external input. We thought the manual was well-written here. The cabling for the stock ARGB fans is a little overwhelming, but the light bars and their associated wires are tucked completely out of the way. ", "Our one complaint is that the LED button and the reset button are exactly the same size and have no labels - though you’d probably only make that mistake once.", "The Light Base 600 is another case without a support pillar between its two glass panels, giving us a top panel that could theoretically bend down. In practice, the top and bottom panels are interlocked with the front panel, keeping it solid as long as the case is assembled.", "The steel side panel is fully ventilated, although the side intake vent and the PSU are the only areas where that's necessary. The side filter is removable for cleaning or additional airflow, which is an advantage over related designs like the ", " (read ", ") and ", " (read ", ") where the side filters are glued in place. We’re happy to see that flexibility from be quiet!. Unfortunately, the top and bottom filters aren’t as flexible and are built into their respective panels: if you set up a horizontal build, some fans will exhaust through a filter that isn’t intended to be removed, which will create unnecessary impedance.", "Primary radiator support in the case’s traditional orientation is at the top and bottom of the case, which both support up to 360mm sizes. 360mm radiators aren't officially supported in the side mount and most won't fit at all with the 39.6cm of clearance between the top and bottom of the case.", "The Light Base 600 has cutouts for back-connect boards, but normal ATX boards overlap all the cutouts along the bottom edge. Small fan and I/O cables can be snaked through the back-connect holes anyway, but we expect clear, premeditated cable routes. The storage behind the motherboard is deep, as is typical for dual-chamber cases, but it can be difficult to work in once that space is occupied by cables. The cable tie points are hard to reach once PSU cables are in the way, with the cable cover, HDD bracket, and fan and lighting hubs contributing to a cramped feeling. We ended up just wadding all the cables into the channel and snapping the cable cover shut on top. It’s still easier than the ", ", at least (read ", ").", "We'd like to see a way to screw the cover down, but the cable channel is deep enough that it's unlikely to be necessary.", "Drive storage is a complicating factor for cable management. The stock Light Base 600 only supports 2x 2.5 drives and 1x 3.5 drive, with the two smaller drives mounted to the cable cover, which requires leaving enough slack to open it. The stock bottom bracket can only mount a single 3.5 drive, but it has room for a ", " (purchased separately) which fits either an additional 3.5 drive or two 2.5 drives. Using the bottom bracket at all reduces access to cable cutouts and one of the two fan and lighting hubs.", "There's a gap between the two glass panes; it's a matter of personal taste as to whether that's a problem, but it's definitely intentional and known since the case shipped with a strip of cardboard in that gap. ", "The gaps where light bars meet (top and bottom) definitely aren't intentional, though, and be quiet! didn’t do anything to minimize that.", "This is the most brightly-lit, attention-grabbing area of the case, and it needs to look perfect. The gaps don't belong on a $195 case the way our case is set up, and the deviation at the top and bottom edges of the glass makes for a messy execution where other areas are done to a higher standard. The panel gap isn’t great for looks, but could contribute to dust ingress, especially in a horizontal orientation where it would be exposed directly up. We all know how dust collects on glass surfaces.", "Some smaller points we want be quiet! to address in future iterations: First, the PSU fitment was unnecessarily tight, to the point that we had a harder time than necessary getting it installed. ", "Second, even though the GPU support still works when the case is inverted, it may be weaker since it can't be flipped. ", "Our model came with 3 reverse blade fans on the side and a traditional fan on the back.", "We have a few key configurations of the Light Base 600 that we’re testing:", "We’ll start with a chart of just the Light Base results.", "With all case fans at full speed, the Light Base 600 LX averaged 48 degrees Celsius above ambient all-core and 52 on the P-Cores in its default configuration. Removing the optional side filter reduced the all-core temperature by 1.7 degrees, which is a large drop for a side filter only. It’s relatively restrictive.", "Fully inverting the case didn't change temperatures enough to exit the margin of error, which is encouraging since, for the most part, it shouldn’t. The GPU would be most prone to change here.", "Flipping the case on its side definitely hurt CPU thermal performance, with an all-core average of 51 and P-Core average of 55. Left in their stock positions, the three intake fans are obstructed by the desk surface when the case is put on its side. We intended to fix that with the left intake/right exhaust horizontal configuration, but with a focus on GPU thermals, so CPU thermals didn't change significantly versus the first horizontal result. You can see that here.", "Flipping the case on its side with the intake fans against the desk surface also raised the noise level up to 32.1 dBA, versus 30.9 dBA in the stock or inverted configurations. This is actually noticeable. It’s also really cool: Previously, our less precise testing approach to acoustics would not have been able to surface this difference in numbers even though you’d be able to hear it. That’s because we were limited by the noise floor and measurement tools. Now, with our ", " that the audience has helped us build, we can actually detect with tools what the human ear can already hear. That’s why we have this chamber. People forget that ears are incredible at their job and that representing it with a microphone is very difficult, so when they ask why we’d build such a chamber, this is exactly the reason. We can get closer to measuring what you actually perceive.", "Here’s the full chart.", "It's fitting that be quiet!'s case is among the quietest on the chart when at 100% speed, bracketed by the ", " at 30.1 dBA and ", " (watch ", ") at 31.3 dBA, but there are no obvious noise-damping features other than the use of Light Wings fans.", "The Y60 (watch ", ") may be equally quiet, but it's also much hotter with just its stock fans, averaging 51 degrees all-core versus the 600 LX's 48, so that is an advantage for the LX. We know based on past experience that the ", " is the dual-chamber case to beat in terms of overall thermals, 46 degrees in this particular test (albeit with a higher noise level of 37.1 dBA), while the (glass-fronted) King 95 Pro (read ", ") averaged 43 degrees (at 36.8 dBA). We'll get to noise-normalized thermals in a moment.", "GPU full speed is up now: ", "The Light Base 600 LX kept our GPU at 52 degrees Celsius above ambient with the memory temperature at 60 and hotspot at 68. Removing the side filter improved temperatures by 2.2 degrees for the GPU, which is a huge climb for just a filter. be quiet! has room to improve this area. ", "Inversion had a mildly negative effect, raising the GPU average to 54 degrees. The horizontal configuration was worse still at 55 degrees for the GPU, 63 for the memory, and 71 for the hotspot. Keeping the case horizontal but shifting to the left intake/right exhaust configuration dramatically lowered temperatures, down to 41 GPU, 44 memory, and 53 hotspot. This is the equivalent of a bottom-intake configuration in a case that's oriented normally, but with unobstructed intake.", "Here’s the competitive chart. All of the results with the fans in their stock locations are among the weakest on the chart, with the baseline out-of-the-box result falling behind even the Y60. The left intake/right exhaust configuration performed significantly better, tying the C8 ARGB's 41 degree GPU average and significantly outperforming the King 95 Pro's 46 degree average. As a reminder, this was done with just the included fans. All we did was move them. We didn’t want to add fans because it starts to become arbitrary and potentially unfair, but moving them really helped here. The horizontal configuration has the greatest potential for cooling, since a clear unidirectional airflow path can be created without obstruction. You’re not dealing with angled intake from the side, so there is a huge amount of potential here.", "The Light Base 600 LX's low noise at full speed means it has a shot in our noise normalized test, where all case fans are tuned down to hit our 27 dBA threshold. We normalize these in our hemi-anechoic chamber to get the granularity needed for a fair test.", "50 degrees Celsius above ambient all-core and 54 P-Core ties the Antec C8 ARGB (read ", "), but the King 95 Pro averaged 47 all-core, and cases with simple front intake like the ", " (read ", ") and ", " continue to dominate the top of the chart. ", "GPU thermal performance was already weak with the case fans at full speed, and with reduced fan speeds, the 600 LX is the hottest case on this chart other than the ", ". This is a strong argument for the horizontal left-to-right airflow configuration. These were all at the same noise levels. We’ve normalized them for this test. This is not a good result for be quiet!.", "Because we were forced to mount the 140mm fans in the bottom of the case for our standardized fan test, we have an opportunity to see the case's bottom intake performance. ", "An average GPU temperature of 44 degrees Celsius above ambient is more competitive than the other GPU thermal results we've seen from the 600 LX so far, close to the King 95 Pro and C8 ARGB's tied 43 degree averages, but that still only places the LX in the middle of the chart. This is also effectively a test of the Light Base 600 DX, since we would have performed all tests on that case using our standardized set of fans.", "Finishing off with VRM and system memory thermals during the noise normalized test, the 600 LX's performance is again unimpressive. 35 degrees above ambient for the VRM is warmer than the C8 ARGB's 33 degrees and the King 95 Pro's 31 degrees, and although the stack is ordered differently for memory temperatures, both the C8 ARGB and King 95 Pro were cooler than the 600 LX's 27 degrees. We also know from our full speed results that these sensors didn't respond strongly to the horizontal left intake/right exhaust reconfiguration.", "The ", " is on the expensive end of dual-chamber cases with included fans, especially when taking into account the thermal performance of the ", " and ", ". Both of those cases also have fanless SKUs that are cheaper than the Light Base 600's fanless SKUs. ", "The primary reason for buying the ", " over any of those other options (including the ", ", which we haven't tested) is the wraparound light bar, so we're at least happy to see that the light bar looks good in person, with bright, evenly-diffused LEDs. It was critical that they executed on this feature well and they did do a good job on it. There were a couple caveats surrounding the fit and finish, like the panel flushness.", "The horizontal option is also a unique selling point, but it's one that few people have the desk space to try. But this is a well-liked presentation layout, it ends up looking better than you might expect when looking at it vertically, and it’s a unique feature that is also executed overall well. It’s also mechanically simple. You’ll just have to plan your furniture more than typical, which isn’t so bad once you’re aware of the sizing.", "If you do buy a Light Base 600 and you want to maximize thermal performance, we suggest using the horizontal configuration with side intake fans pushing directly into the GPU and exhaust fan(s) pulling hot air out of the opposite side. ", "A few things to be careful of: If using a closed-loop liquid cooler, or “AIO,” with a pump in the block, you wouldn’t want to bottom mount it when the case is on its side. You should never bottom-mount a liquid cooler with the pump at the highest point in the loop, which that would do. Mounting the radiator to the side -- which was the “top” before going flat -- would be best. This will still put one side of the radiator tank at the highest point, which can create some bubbling noises in loops with less liquid or as they permeate over a 5-year period, but wouldn’t lead to catastrophic failure like a bottom-mount will.", "All of this changes if you have the pump somewhere else in the loop, like the radiator.", "It's good to see some movement from be quiet!, but although back-connect compatibility is fairly new, dual-chamber cases and ARGB LEDs are years-old trends. It'll take some time for the company to become a leader in cases again, rather than a follower. The company has also deviated from some of be quiet!’s expectations, which isn’t a bad thing. Fractal deviated as well and it worked out well for them. ", "We like the case overall for its unique presentation. It is mechanically simple and it works well. Aside from that, there are no revolutionary changes to the build process or features. ", "But once cases clear a bar for acceptable performance and for functionality, what matters most is that you like the way it looks. This case clears those bars. If you’re a big fan of the layout, we’re not seeing any major detractors to advise against a purchase."]},
{"title": " The Weirdest New PC Company: Tryx '3D' Panorama Cooler, Paracord Case, & Luca", "paragraph": ["The Weirdest New PC Company: Tryx '3D' Panorama Cooler, Paracord Case, & Luca", "Last Updated: ", "The Highlights", "Tryx is a brand new company that’s made up of several people from the industry including employees from Asetek, Cooler Master, and Asus. The company formed to create some cases and coolers that are pretty different. ", "We first heard about the company after it showcased its “3D” panorama cooler, which the company showed off at Computex along with some other cases. Let’s check them out.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "Starting things off, we have the Luca case. ", "It has a hinged door as a front panel, and its airflow variant comes with two 200x38mm dual-ball-bearing fans. That’s on the thick side for fans, comparable to the fans on the Torrent. The hinging is the most interesting thing here, and it would be phenomenal if Tryx could move to pogo pins or pin-to-pad contact for the fans instead of wires, but we don’t know what the pricing impact would be. ", "One interesting thing about the case is that it features a massive, thick aluminum structure on the bottom that acts as the feet. One criticism we have here is that it appears to obstruct airflow for the bottom fans, especially where the middle fan would be. ", "The Luca’s side panel has an indent that, once you push it in, allows the side panel to hinge and hang down, enabling you to remove it.", "The Luca is also semi modular. Its power supply chamber can be removed from the bottom and moved towards the top of the case. ", "Users can also remove the motherboard tray via some screws, which enables you to shift the board up and down. ", "The top of the case has a handle, and Tryx says it will offer some engraving customization options, though we don’t have much further details than that at the moment. ", "The back panel is made of aluminum and has ventilation. ", "It also has an indent at the rear of the case that allows you to pull the panel off. ", "Once you open that part of the chassis up, you’ll see that there are two swinging cable covers, both of which provide access to storage drive installation. ", "The case will come in two variants. The airflow version will cost $220 and come with its two front fans whereas the glass version will cost $200. It’s expected to release in Q3. ", "Now we’re moving on to the product that made us aware of the company. There are two versions of Tryx’s Panorama coolers. The more expensive pro version uses pogo pins that connect the screen to the chassis. ", "The Pro model also has a VRM fan.", "The cheaper SE version is plastic and has a wired connection. ", "When we asked the company why they don't have a socketed version since it uses USB 2, they said this implementation allows you to rotate it, which makes it reconfigurable.", "According to Tryx, it uses an Asetek cooler with an 8th-generation pump solution.", "For its screen, it uses a 6.5-inch AMOLED display. They’re trying to get an anamorphic look, which would make it look like the visuals are slightly popping out of the screen.", "In terms of cost, the price range is roughly $300-$400 for a 360mm AIO.", "Next up, we have the Spes, which is a Mini-ITX case. It’s a small form factor chassis that is relatively large and seems to be reconfigurable to some extent. What we saw is only a prototype but what makes it interesting is that it is trying to get a 15.6-inch 1080p display on the side of the case, like the ", " case we saw years ago.", "Finally, there’s the Otavia case, which feels like it belongs in the 70s with its experimental fabric that makes it feel like you just did some psychedelic drugs. ", "The fabric is almost like a paracord material, which we think would be restrictive to airflow. ", "The side of the case underneath the glass also has an odd carpet-like material."]},
{"title": " Phanteks' Liquid Freezer III Competitor, Patent-Avoiding Fans, & P400A Successor (G400A)", "paragraph": ["Phanteks' Liquid Freezer III Competitor, Patent-Avoiding Fans, & P400A Successor (G400A)", "Last Updated: ", "The Highlights", "Phanteks had several new products to show at Computex 2024. Highlights include the company’s upcoming $100 Eclipse G400A case, a prototype for its dual-chamber aquarium concept chassis, a budget air cooler, and an AIO liquid cooler with a built-in downdraft fan for VRM cooling. Let’s dive in.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "We kick things off with the Eclipse G400. It’s the successor to the P400A (watch ", ") and there will be two variants: the $100 G400A and the $130 G400N, the latter of which will have 2 tempered glass side panels and comes with a cable comb cover over the cable management system and a controller on the back.", "Both versions will come with 4 pre-installed 140mm fans with 3 in the front and 1 in the back. ", "What makes the case unique is that it features a heavily molded and shaped front panel, which is designed to prevent the re-circulation of air. The Bitfenix Enso (watch ", ") was a notably bad offender here, where the case would basically suck the air back out after it had been heated and recirculate it through the case.", "The case will come with an ultra fine mesh magnetic front panel. It will also come with a mesh panel dust filter that will have up to 20-25mm of space behind the front panel. This spacing should, in theory, cut down on issues relating to blocking performance and noise.", "Phanteks has a couple top-mounted fan options on the power supply shroud. Its closest competition here would be the Lian Li Lancool 207, which ", ", because it moves the power supply to the bottom front of the case and has ventilation on both sides of the chassis. Phantek has its PSU in a more traditional location here but also has perforated sides for where the PSU shroud is.", "The Eclipse G400 also has an RGB strip on its PSU shroud.", "Inside the back of the case feels fairly standard but it does include a cable management channel.", "Next up is a concept for a case called the Evolv X2. It’s a dual-chamber aquarium concept that has been shrunken down to a more normal foot print. It has 3 fans mounted on top of the power supply shroud and, visually, it reminded us a lot of NVIDIA’s Founder’s Edition shroud design, though this isn’t done and is subject to change. Phanteks does intend the base to be made of aluminum, however.  ", "The power supply location itself has been sunken and shifted a little bit to allow more intake for the fans at the bottom of the case. ", "The case comes with a stand that gives it some elevation with a plastic bottom. Its back panel has punched-out channels for cabling, which reminds us of an ant farm. ", "The Evolv X2 will also have back-connect motherboard support. Phanteks is aiming for a roughly $150 price point and a Q4 release.", "Phanteks is releasing a budget single-tower, single-fan air cooler with its ST4 DRGB. It’s a budget cooler targeting the $30-$40 price point. Its main competition in this price range would come from ", ", which is a dual-fan solution that costs around $34 and is one to beat. ID Cooling also has some unfathomably cheap solutions as well.", "The ST4 DRGB uses a 4-heat-pipe design and pretty standard direct contact cold plate. ", "It uses one of Phanteks’ new interlocking fans, which makes it unique as it twists into place and requires a screw to anchor it in place. The unit we saw featured a 3D-printed plastic spring on the bottom for the fan to sit down onto and twist into place, but that design is subject to change. ", "From a looks perspective, we’re not big on the overhanging plastic on the edges of the cooler. Phanteks could try to pull the plastic down further to encase the heat sink but that poses some thermal problems.", "The ST4 DRGB is set to launch in late Q3.", "Phanteks showed off its upcoming Glacier One M25G2 360 AIO liquid cooler which features a downdraft fan for VRM cooling and has some molded channels to guide airflow.", "The top of the VRM fan comes off. The version we saw, which isn’t final, features 3 screw points. It also uses a 3-pin cable. ", "The Glacier One M25G2 360 AIO uses a standard thickness radiator and standard thickness 25mm fans. It is set to launch late Q3.", "Phanteks also showed off its updated interconnecting fan solution. It daisy chains fans and has a channel that hides cables. A pack of 3 will cost $30 and the fans interlock with some plastic molded-in clips. This is a cheaper option compared to more expensive solutions like ", " that include separate PCBs that bridge between fans and use pins and pads to connect everything. Like the ST4 DRGB air cooler, they do have overhang screw holes at the end of them."]},
{"title": " Best PC Cases for 2024 So Far: New Designs & Round-Up (Computex)", "paragraph": ["Best PC Cases for 2024 So Far: New Designs & Round-Up (Computex)", "Last Updated: ", "The Highlights", "The last few weeks of case announcements have been completely overwhelming -- and a lot of them look actually pretty good. One of the case manufacturers described the current case market as “a bloodbath,” saying that budget, high-performance airflow cases are getting so cheap and good that it’s hard to compete. Some of the most interesting cases at the show included Lian Li’s LanCool 207 with its sunken-floor intake fans for GPU cooling, be quiet!’s Light Base 600 and 900 cases with their flat style layout, Montech’s $64 XR glass fish tank and $70 XR Mesh airflow cases, Phanteks’ G400A for a budget ultra-airflow case, and SilverStone’s Alta D1 for some mechanically impressive functionality. And then there’s the usual showstopper from In Win, this time using a 180-degree bend of straight-up glass -- not even tempered -- with aluminum and a linear actuator to open it all. And the actual showstopper: Fractal’s PiNorth case that uses actual North wood paneling for a Raspberry Pi, but technically isn’t launching. But that’ll change now.", "Steve Burke", "Vitalii Makhnovets", "Jimmy Thang", "This article will recap some of the best cases we think are coming out over the next few months. We still have to review each of those as they launch and our case methodology has already relaunched with new reviews -- ", " of the ", " series -- so we’ll have a busy year with cases. In the meantime, there’s been an explosion of interesting cases ranging from dirt cheap to very expensive, featuring some weird ones in between. This rounds-up everything we saw at Computex into one big Best Cases So Far article to help you get caught up on the dozens of new cases.", "We’ll focus on everything coming out over the next 6 months and won’t cover cases that launched before Computex. Let’s start with ATX cases.", "The Lian Li Lancool 207 is first and immediately impressed us for its $80 price point, making it instantaneously relevant given the recent lack of higher quality airflow cases with decent build quality at sub-$100 prices. It set the tone for the revival of the budget case market this year.", "This case is function-first: Lian Li is sinking the bottom fan tray in the case to get closer to the floor, which will give the fans closer access to outside air to improve GPU cooling performance. The PSU has been moved to the front of the case in order to accommodate this. The case is overall compact and tries to get as close to micro-ATX as possible while still fitting ATX components.", "The 207 will include 2x 140mm ARGB front fans as intake behind the mesh front panel with another 2x 120mm reverse blade fans in the bottom to act as intake. The case uses perforations in the lower side quarter panel to help pull air through the lower intake fans, showing a serious focus on designing the chassis around air cooling performance, which is especially important on budget cases since users are more likely running air cooling.", "That said, Lian Li also shifted its motherboard tray down to better accommodate thick radiator and fan combos up to 65mm. This detail isn't fully finalized yet.", "The Lancool 207 is expected to ship in August of this year for $80. We intend to review and benchmark it fully.", "Lian Li had two other ATX cases at its showcase: The first was another O11D Vision variation with some swappable top panels. We're not interested in that one, as it's just another rehash of the O11 series. ", "The more interesting of these two  is the Lancool 217. The 217 is currently a prototype using walnut wood paneling to match the aesthetic created by (to our knowledge) In Win and later popularized by Fractal. The prototype had several scuffs on its misaligned wood panels, but Lian Li tells us that these are related to the hand-made nature of the prototype unit.", "The 217 uses a rear 140mm fan and a strange mix of 2x 170mm large fans in the front panel. We've seen 160mm fans on some cases, including Lian Li's own, and 180s are popular on several popular cases (including the ", "), but 170s are rare. Lian Li chose 170s for the simple reason that they're the largest size that'll fit without scaling the case wider to accommodate 180s. The company also lined the fans up with a separating block in between, shifting the lower 170mm fan down further. This forces its air into the PSU chamber to eventually find its way up into the GPU side of the video card, theoretically more evenly distributing air across the full surface of the video card rather than focusing it primarily on the power side.", "The 217 has also set back the dust filters inside the case to improve dust capture, coupled with a reverse spin feature for the fans that’s intended to shake dust loose.", "The company intends to ship the case in September for $120.", "Be quiet! brought two new cases to Computex: The Light Base 600 and 900 cases use a clever foot mechanism to lock four posts into the protruding ridges of the outer shell, mixing function with form. This allows the feet to be quickly re-positioned so the case can change between a standard layout, horizontal layout like older PC cases, or invert the system. This solves a big problem in invertible cases historically, which has been overly complex hardware to flip the center of the chassis. Cooler Master also improved on this in recent years with its NCORE 600 and we’ll come back to that one below.", "Rotating the Light Base to rest in a standard horizontal position moves the top and bottom panels to become the new side panels, with a side-to-side air path while the glass becomes the top and front of the case. The top and bottom panels (in the normal configuration) are symmetrical, allowing them to swap cleanly for the variations. be quiet! did well to design for the invertible element without making it a pure gimmick, which happens a lot on modular cases.", "The be quiet! cases range from $150 for the Light Base 600 without fans to $195, depending on the fan configuration. The Light Base 900 ranges from $180 to $240, again depending on fan type and count.", "Both cases have a large LED diffuser that’s integrated into an exterior panel. The Light Base 600 has around 1.2-1.3m of LEDs while the 900 has 1.5m, all running through that diffuser panel. Differences between the 600 and 900 include fan and radiator size support, which goes larger on the 900, and the fan tray that's included in the Light Base 900 but not the 600. The cases should launch around October.", "Up next is Antec's return with the Flux Pro. The Flux Pro uses entirely new tooling and has an American Walnut wooden outer border combined with a rippled mesh front panel, reminiscent of its prior Flux cases. Antec is getting competitive on price with these cases: It intends to ship the larger Flux Pro with 6 fans, at 4x 140mm and 2x 120mm reverse blade fans, for $170-$180 in August. The direct price and size competition includes the larger ", ".", "The Flux Pro feels like a more traditionally competitive airflow case, just with some wood strapped to the front. That's purely looks, so we'll let you decide how much you care about the wood aspect.", "Antec’s shroud-mounted reverse blade fans aren’t sunken like the Lancool case, but Antec perforated the lower portion of the side panel to give more access to air. We plan to test and review this case once it's ready, so check back to see how the GPU cooling does in particular -- especially against the 207. The other fans are in the front and rear of the case.", "The Flux Pro also has a simple digital display on the side that reports GPU and CPU temperature, similar to what we've seen on older EVGA cases in the past. Drive support offers 2x 2.5 SSDs and another set of 4 cages for 3.5 or 2.5 drives.", "The company also had a non-Pro smaller Flux, which ditches the display and reduces fan count to a still-high 5 fans. The non-Pro is 70-80% new tooling. Antec plans to sell the non-Pro Flux for $110 to $120 in July or August, depending on shipping timelines. ", "Finally, they had a ", " with alternate wood or aluminum panels -- our C8 review is in the works now -- and a C7, which we didn't care much for. We'll also talk about Antec's ITX case later in this article.", " and seems to be taking a swarm strategy to cases. We have two we'll focus on, but the quick run through is this:", "The company had its new ultra-budget case, the XR, at $64 to $70 with 3 fans on the cheaper and 4 total fans on the XR Mesh. They also showed the new King 65 Pro chassis, which is a cheaper ", " of similar size. Then there was the King 95 Mega Pro, which plans to hit the $200 mark with 7 fans included while also bearing a name that belongs in Quake III. ", "Montech had prototypes as well, like its Sky 3 with dual sunken 80mm fans and its HS01 case -- accompanied by the HS01 purse case, which... well, not all ideas are winners.", "We'll shift focus to the XR first: The Montech XR case comes in either a glass fish tank style with 3 fans or a mesh panel, wood-embellished variant with 4 fans named the XR Mesh. The fish tank is $64, the Mesh is $70. The XR Fishtank includes 2x 120 reverse side fans and 1x 120 back fan, all ARGB. The tooling is somewhat repurposed: Montech says it took its Sky 2 tooling and scaled it. The Mesh variant has 3x 120mm front fans and 1x 120mm rear fan, with a wood plate that feels thrown on for the trend, but simultaneously doesn’t look bad. The interior chassis is incredibly plain and has no ease-of-installation features that are particularly strong. It’s basic. The strength of the case is brute force air movement as cheap as possible, which has been an underserved market for the last few years. The XR just released and we plan on buying one to review as soon as our schedule clears.", "Moving to the King 65 Pro, this case will ship in September for $90 and includes 3 fans, sized at 2x reverse 140s and 1x 120 rear. The King 65 Pro makes use of the dual-chamber tooling of the King 95, but reduces cost by eliminating the curved glass (sticking to just a 90-degree intersection) and changing the top panel design to be a simpler circular mesh. You can learn more about these and other Montech cases ", ". ", "The ", " finally brings a successor to the Phanteks P400A Digital that we ", ". For those who don't remember, Phanteks used to be dead-set on completely obstructed panels like on the P400 non-A that we could just never recommend. The P400A Digital, though, with its mesh panels and high fan count resulted in a regular recommendation in our round-ups for cases. It's been years since the P400A launched and is due for a replacement.", "The G400A is meant to be that replacement. The case will be $100 and includes 4x 140mm fans, with 3 in the front and 1 as rear exhaust. The case is mostly new tooling, with the exception of a few parts shared with other cases.", "The G400N variant will be $130 and ships with a controller hub, dual glass side panels rather than one, and a cable comb cover (but both cases get the cable management guides). Both cases release in Q3 of this year. We should have a review up for the G400A once it’s ready.", "Phanteks also had a workstation variant of its Enthoo series cases, some refreshed NV-series cases with back-connect support, and its new Evolv X2 prototype fish tank that it hopes to sell for around $150, which would make it pretty competitive in that market. ", "Other Phanteks products included 3 interconnecting fans as a pack intended to sell for $30, which would make them some of the cheapest interconnecting fans on the market. They also had an Arctic competitor liquid cooler that'll use those fans. We'll talk about the cooler in a future review. Back to the cases though, the Evolv X2 would be promising if it can hit that price of $150. The prototype uses aluminum for the interior shroud, which would definitely make it expensive but looks good.", "We'll switch it up with SilverStone. SilverStone had some normal cases that'll be G400A competitors, a cheap XR competitor at $60, and then some absolute mammoths of stature and design (and price).", "The Alta D1 is one of those. ", ", but finalized this year. The case is a brilliant showcase of mechanical design with fully modular cages and mounts. Each modular cage can be rotated 90-degrees to either install the cages vertically side-by-side or stacked atop one another. These cages can be used for optical drives, hard drives (including those externally accessible with hot-swap backplanes), radiators that slot-in across the top of the case and take the spot of two drive modules, or fans -- including up to 2x 180mm fans in the bottom of the front and room for 1x 160mm fan up top in the front. The motherboard tray is also completely removable to form an instant test bench or be assembled externally.", "The Alta D1 is a taller form factor tower that's big enough to need a cross-brace across the center of the chassis for stability. SilverStone doubles this as a mount for the vertical GPU support bracket. The D1 uses thick aluminum for some of the panels, like the top, and uses a split rear side panel for better structural support and cost. The front panel is hinged and has a keyed latch. The D1 will launch soon and has an unknown price at the moment -- but SilverStone openly told us that it'll be high. We were told to expect closer to $1,000 than not. Despite its inevitable low viability for most people, we wanted to highlight it for doing something unique while remaining functional.", "SilverStone had a number of other cases of varying affordability. You can check out our ", " for some of those, but we'll give a quick recap here. For the more normal cases, the FARA 514X will be $100 and includes 4x 120mm ARGB fans with a hub. It uses a chamfered front panel for structural support of the mesh and for enough fan clearance to support fans both inside and outside the chassis.", "The SETA H2M is a micro-ATX variation of the same theme while still fitting 2x 360 radiators. ", "The 515XR is a shorter case in depth while retaining normal height, giving it an older feel. The 515XR is meant for the Japanese market, where space for desktop computers is reduced. SilverStone is considering it for the rest of the world, but wants people to know it won't have the depth to fit the longest video cards. The case should be $50-$60 while somehow still including 4x 120 fans.", "As a final note, SilverStone also had a new HTPC chassis in 5U form factor called the CW04, or Crown 04. ", "The new Alta T1 is also a spiritual successor to the TJ07 from 2006, using an extruded aluminum panel along the front, top, bottom, and some of the back. ", "A new CS383 made an appearance as a home server or NAS box as well, priced at $400. We think SilverStone’s showing this year illustrates a lot of variety and function-first designs.", "Cooler Master is also back this year. It's been a long time since Cooler Master turned-around its case design by departing from the H500P and moving to the ", ". We strongly recommended the Mesh and later ", " and ", " as a result of Cooler Master's significant improvements in its design. Since then though, they haven't had as much exciting stuff because a lot of their cases got kind of smashed by the tax and tariff changes, which eliminated them from the markets.", "We found Cooler Master's new ITX cases the most mechanically interesting, but the new MasterBox 500 and NCORE600 revive its ATX side.", "The NCORE 600 will fight in the now-burgeoning $180 to $220 market. The Prestige model is $210 and will include 2 glass panels and 1 mesh panel. The glass and mesh are symmetrical with each other and can be swapped between sides and the front, as this modular fishtank style exposes basically 2.5 panels. The panels each pop out individually and relatively easily for the same reason as be quiet!'s Light Base: Simple invertibility, as a total of 6 screws allows the case to flip upside down and present the system to the other side. This is a massive improvement on Cooler Master's flawed prior invertible cases. Neither of the NCORE 600 models include fans and both models use an angled fan tray to help direct air toward the components while also looking different. The Standard edition will be $180 and include just 1 glass and 1 mesh panel, but is otherwise mostly identical.", "The MasterBox is a relatively uneventful case in that it matches other cases in its price point. The Box will be $140 for the glass variant and $120 for mesh. Both include a rear 120mm ARGB fan and the Mesh model includes 3 additional 120mm ARGB fans, totaling 4. The cases share the same tooling. Cooler Master intends for the LED side panel to be customizable, so the angsty LED lettering should be swappable to other pixel-based designs in software.", "We'll change things up again. Thermaltake had a ton at its booth this year, but we wanted to highlight what’s technically an older case. The ", " case has had its tooling refreshed for the new AX700 workstation case. The case is an absolute monster and it remembers why big cases exist. Rather than a big empty glass cube, Thermaltake still includes a lot of drive cages. The show build had space for 12 hard drives mounted to the vertical rail, but another 2 drives could be mounted without the radiator in the way, and the backside of the motherboard tray would support at least another 2 drives from what we could see at the show. ", "The large panel doors have latches to secure closed and use foam pads for a better seal, showing more attention to detail in small areas. The AX700 has a TBD price and will probably launch in Q4. It's not final yet.", "Since this is technically a refresh of an existing case, we’ll move on to the next one.", "Which is Corsair's 9000D, another refresh: This one builds on the ", " case, but has about 30% new tooling, according to Corsair.", "The show build had about 32 fans installed and two systems (one ITX and one ATX), but doesn't focus on the functional storage afforded by the AX700 as much. This is another one where we liked the smaller attention to detail: The pre-greased rails and actuation for the fan and radiator trays were nicely done and the small fan size markings on the rails makes installation clearer, reviving the 1000D highlights of the past. Corsair doesn't reach SilverStone levels of pure mechanical functionality and quality of life features in a huge case, but it also comes in cheaper -- but still not cheap. The 9000D will be around $500, but is expected to be a lot cheaper than Silverstone’s D1.", "But Corsair had two cases on show this year: We didn't like the 3500X that much, but it’ll fight in that $100ish fish tank arena.", "Our next entry in the ATX category is the LUCA. This is from the brand new company ", ", which made its public debut just this year and launched its Panorama liquid cooler. Tryx is founded by defectors from ASUS and Cooler Master and is supported by Asetek. ", "The Tryx LUCA is intended to be $200 for the glass model and $220 for the unit that includes 2x 200 x 38mm fans with a hinged door mesh front panel.", "While it has some oversights, like the restrictive airflow design of the bottom foot, its heavy use of aluminum paneling and futuristic styling gets it on the map, plus being $200 for a case with a full aluminum side panel and foot is uncommon. It seems Tryx is willing to run at a lower margin than its competitors to get some recognition and market share. The case is also semi-modular, allowing the motherboard tray and PSU cage to be swapped positionally. It’s coming out in Q3.", "Let's end our ATX section with In Win's signature cases. This isn't something that'll be for sale in any kind of volume or maybe at all, but deserves a mention for being basically an art piece.", "The new Signature case uses a 180-degree bend in a sheet of straight-up glass, it’s not even tempered glass. It's 110cm long and treated with an anti-shatter film and bent around the entire chassis, sort of appearing to interlock with the aluminum. The designers told us that their objective was to artistically represent aluminum and glass embracing. Like the In Win H-Tower of yore, the new Infinite signature case opens on a button press and unfolds the motherboard tray out to present it.", "The case uses a motor to push the enclosure open and a gigantic aluminum foot to hold everything securely in place without anything tipping. The glass is a feat of manufacturing and requires long cooling cycles to make the shape without shattering.", "There were a ton of other ATX cases at the show, like MSI's that we briefly showed in a ", ", but these are some of the most interesting ones that we encountered. The $100 market is definitely exploding, or will be later this year, and the $180-$220 market will remain popular as well. ", "Let's look at some mini-ITX cases.", "Cooler Master's mini-ITX concepts start us off. The unnamed BTF ITX concept case is currently built to enclose the GPU in a cage atop the main body and present it openly. Although shown with the ASUS BTF solution to run power into the foot of this particular GPU, Cooler Master intends to optionally punch a hole for the GPU power cable to come up through the chassis.", "The case uses a locking mechanism to latch the top cage into place and the concept is a relatively fresh take on showcasing a component. We’d like to see some ventilation punched-out between the GPU and the floor and, likewise, you’ll need to keep an eye on dust in the card. Still, it’s a new take and we can respect that.", "Cooler Master also had the favored NR200P except in a new variant, where the side panel is cut for the GPU. Our viewers pointed-out that this is fulfilling the meme of cutting cases to fit 4090s. Both are expected out in the last half of this year. Prices aren't known yet.", "The Fractal Era 2 case also gets a spot on our ITX list. ", ". The Era 2 is where we’ll focus on ITX cases now. We’ll reserve commentary on the fabric-covered Mood since it is currently in our reviews process.", "The Era 2 uses wood and aluminum for a $200 price-point. Fractal noted that its wood has been treated in a way that should prevent any cracking or damage from use. ", "The Era 2 has clever mechanical design to allow the exterior chassis to easily lift off after a bottom filter is unseated, making the chassis easy to get into for building or maintenance. The top panel also has some mechanical latches that release it for full access inside the case. It’s an 18.9L case with 2x 120mm basement fans included, a PCIe Gen4 riser, and a Terra-style spine that shifts slightly side-to-side to better accommodate GPU or CPU cooler clearance.", "As for the wood, it’s reinforced underneath to prevent bowing while still filtering air.", "Thermaltake gets a mention for its TR1 ITX case, which it intends to design specifically for travel. To truly hit the travel market, we think it needs some screws to lock the panels in place and definitely a strap or handle of some kind, but it’s still in design stages. Overall, we liked the color combinations and execution. They’re trying to hit the $100 to $120 price point. This case isn't final yet and will be expanding in depth, so since it still needs some time to bake, we'll move on -- but it's on the radar. ", "The biggest thing Thermaltake did this year was expand their color palette across all of their cases, so we’re excited to see how that’s received beyond the usual black or white solutions.", "Finally, Antec also had an ITX case present: The Performance 1M uses a red interior frame and a mixture of aluminum and steel to create a back-to-back style ITX build. From our hands-on with the prototype, the mechanism isn't as refined as the Terra, but we did like the red accent and saw potential in the design. The case fits a 3-slot GPU with adjustable depth to bias toward the CPU or GPU cooler, as with the Terra and other similar cases. Antec is still finalizing the case."]},
{"title": " Silverstone's Cases Are Wild: Alta D1, CW04, Fara 514X, & $60 515X", "paragraph": ["Silverstone's Cases Are Wild: Alta D1, CW04, Fara 514X, & $60 515X", "Last Updated: ", "The Highlights", "Silverstone often has some of the most unique and mechanically advanced cases at Computex. We most liked the Alta D1 for its modularity and ability to swap components all around the case with a simple rails system. Silverstone also had some new budget PC cases, like a $60 Fara 515X, $100 Fara 514X airflow case, and more. Let’s dive in.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "The Alta D1 is our favorite case from Computex 2024, and it was at Computex 2023, but now it’s finally getting done. Overall, the Alta D1 has excellent mechanical design that is interesting and different.", "It has 5.25” drive support, which is rare, but what makes it interesting is that things pop in and out pretty easily using a rail system. The Alta D1 also has space for an optional, secondary power supply up top, which also uses the same rail.", "At the show, we saw the case with a 360mm radiator that’s able to slide into place and hook into the chassis. It also has latches that secure it to the case.", "The motherboard tray is removable and uses bolt action screws on the back. Personally, this design makes it cool for us as a test bench. ", "The front of the case has 2 180mm fans, which can be removed. You could also install an additional 160mm fan above it as well. It also has a magnetic dust filter in the front.", "The back side panel is split into 2 and has buttons that allow you to slide them off.", "We think the objective with the case is to be for workstations, which isn’t as popular as ATX cases or consumer-gaming cases. There’s no price yet but Silverstone tells us that it will be expensive. We think it will be in the high hundreds, as in approaching $1,000, but we’ll have to wait and see. ", "Next up is the CW04, which Silverstone says stands for “crown.” It’s another expensive case and we wanted to talk about it because it’s super cool, interesting, and different.", "It’s an older school HTPC case that’s big with its 5U sizing and can fit modern GPUs. The chassis also comes with a GPU support with large plastic feet that can be manipulated to hold video cards in place if needed. The GPU area also has some pass through ventilation in the rear for airflow. ", "The front of the chassis also has a nice opening mechanism. It also has a cover for the hard drive activity LED.", "The CW04 has 360mm liquid cooler support on a central rail that can hinge up and come out of the case. It also has 3 fan slots on the side and 1 fan towards the middle rear of the case.", "The case is topped off with a large aluminum panel that has a dust filter on it. ", "Pricing is TBD and Silverstone is currently targeting a Q4 release. ", "We’re quickly going to highlight the SUGO 15 mostly because it’s one of NVIDIA’s new “SFF-Ready” cases we’ve seen. If a case and video card have the “SFF-Ready” badge, then that indicates they are compatible.", "We covered Silverstone’s Fara R1 case years ago (watch ", "). At $100, the Fara 514X is the company’s attempt to get back into the more midrange market. It will come with 4 120mm ARGB fans along with a hub. ", "The case has a chamfered, almost trapezoidal front panel. Its bends here should support its edge-to-edge mesh to offer some structural support. It also allows the front of the front panel to jut forward past its fans, which are mounted on the exterior of the chassis. This allows its fans to breathe a bit more.  ", "Silverstone also had a Micro ATX case called the H2M that should cost about $100. ", "Next up is the 515XR, which Silverstone is targeting at the Asian market. The company is still trying to figure out whether it wants to ship the case to the US. ", "What makes it unique is that the case is relatively short front to back, which makes it feel like an older style tower from decades ago. Its biggest limitation here would be in regards to fitting modern video cards. Silverstone is worried people might buy the case and find out that their video card doesn’t fit.", "The 515XR will include 4 120mm fans, which Silverstone says are rainbow style. The case is expected to cost around $50-$60.", "We built a storage server for our office with a ", " case, which was a relatively flat chassis. Silverstone’s new CS383 is a different variation on that but is still in the same family. We wanted to call attention to this case because we really like the CS381, which we built with Wendell from Level1Techs back in the day. The layout we saw had two sets of four 3.5-inch drives. ", "The sleds pull out and it has connection options in the back pre-installed. It’s basically a home NAS type of option or mini server.", "The top of the case has space for a 5.25” drive bay.", "The bottom of the CS383 has an optional space for a second power supply, which comes with a removable cover plate. Users could also use that space to put in another set of 4 drives.", "Within the case, it has a very rigid GPU support structure and the chassis fits huge motherboards.", "The CS383 is aiming to release in Q3 for $400. ", "The Alta T1 is the spiritual successor to the ", ", which originally launched in 2006 and was sold for 10 years. It has a huge extruded aluminum unibody, which starts in the back and comes all the way around the bottom and ends on the back again. ", "Silverstone is technically wrapping 4 sides of it. It’s made by first extruding a gigantic sheet of aluminum, and then the company uses a press multiple times to get its shape. There’s also some manual fine tuning at the end of the process to get it all into position. We wanted to call attention to the really interesting manufacturing the case poses. They’ve also partnered with ", " on it…"]},
{"title": " Well-Built Mini-ITX Case: Cooler Master NCORE 100 MAX Review & Benchmarks", "paragraph": ["Well-Built Mini-ITX Case: Cooler Master NCORE 100 MAX Review & Benchmarks", "Last Updated: ", "The Highlights", "Today we're reviewing the Cooler Master NCORE 100 MAX Mini-ITX case. It comes with a swappable top panel, which is interesting as it allows the case to become either smaller or larger. Going larger allows it to fit the Gigabyte AORUS MASTER RTX 4080 (which is quite large) in an ITX case, and the card itself sort of becomes structural once you install it.  ", "The swappable top panel allows you to fit larger GPUs. The side panels are made out of aluminum and pop out - there is also an interesting central spine on the front of the case (depending on your orientation), which allows better access to the system and also allows for the reconfigurable component. ", "Steve Burke", "jeremy clayton", "Vitalii Makhnovets", "Tim Phetdara", "JACK REITMAN", "Jeremy Clayton", "The next feature (underneath the removable top panel) is a pre-installed 38mm thick radiator.  The case is really interesting, and we’re going to be reviewing thermals, acoustics, and of course the build quality and actual building process for it.", "The price - $400 - seems higher than maybe it is in reality because it comes with a cooler and a power supply, making it the most expensive ITX “case” we’ve reviewed. However, once you take out the cost of the power supply and the cooler it comes down a little bit.", "The ", " has a relatively small footprint just in terms of actual square area, but it is tall – basically a mini-ITX tower. It’s more similar in some ways to the ", " for layout and for the general form factor, although Cooler Master’s is taller and hopefully doesn’t catch on fire like the NZXT did originally.  ", "What Cooler Master did for layout was basically a vertical sandwich, so they’ve got the motherboard on one side, the GPU on the other, and the power supply above the motherboard and GPU, which exhausts out the top through the shared radiator.  This way the I/O ends up at effectively the same back of the case as you would normally have, so that it remains accessible. However, the GPU ends up with its display out at the bottom, so that’s routed underneath via a channel.", "The MAX part of the name here is because it comes with other parts, so there is not a non-MAX version of this case right now. Cooler Master had the ", " previously which also came with additional components. The NCORE 100 MAX includes a 120mm liquid cooler, which would normally be concerning because it's just not that powerful. We would typically recommend that you instead use an air cooler because almost all air coolers we would recommend in the $30 plus range will outperform a 120mm CLC these days. ", "The reason why this one gets by is because they have a thicker radiator at the 38mm thickness we mentioned earlier -- the extra surface area allows the cooler to deal with the heat. This creates a big impact for cooling performance - it’s actually the same approach Arctic took with the Liquid Freezer 2 as well, and is part of the reason that series was so competitive when it came out.", "The included power supply is rated at 850W, with a native 12VHPWR cable. We will discuss this more below, but one of the things that we really didn’t like was just how bent the cable ends up being to get the GPU installed. This creates a little more risk of pulling the cable out, and we already know how sensitive 12VHPWR connectors are, which need to be socketed as well as possible.  Cable quality is also a higher concern due to how close it is to the spec.", "The included CLC and PSU drive the price up to $400 (or $380 on sale at the time of writing). Removing the typical price of a cooler and PSU from the total cost, the price of the case itself is more like $170-180 to the consumer. That’s on par with the ", " and just above the ", ", and less expensive than boutique cases like the NCASE M1EVO or FormD T1. The obvious downside is that you’re forced into using the two parts they provide, so if for some reason they’re not desirable, there’s no great compromise, or you just end up wasting money on parts that will not be used.", "The case also comes with a single 120mm exhaust fan high on the rear panel to get some hot air from the GPU out before it makes it to the radiator up top. It theoretically helps on the motherboard side too, but it’s heavily blocked by the PSU.", "The NCORE 100 MAX also has a focus on toolless mechanisms, only requiring use of a screwdriver for the motherboard and GPU in standard configuration. The “expanded configuration” makes the case wider to allow for extra thick GPUs like the ", " or even the gigantic ", " with a little more tweaking. We tested each of these GPUs and they do technically fit, although you’ll become increasingly thermally constrained as the space inside of the enclosure continues to get filled by larger cards.", "The ", " is the kind of case that makes proponents of the “footprint” metric really excited. As compared to more traditionally oriented cases like the Fractal Terra, the NCORE 100 MAX doesn’t take up very much desk surface area at all -- but it is a relatively imposing monolith. It measures 212mm long by 155mm wide in normal mode.", "However, the case is 481mm tall, meaning it’s taller than the length of the other ITX cases we’ve reviewed are long, and brings the volume to 15.7L in standard mode. We measured the case ourselves, as we always do, and got the exact same numbers as advertised. That holds true when the case is set up in expanded mode as well, where the width increases to 172mm and the volume goes to 17.5L.", "Cooler Master earns the distinction of being the first ITX case we’ve taken a look at that doesn’t mess around with excluding protrusions or case feet from its dimensions. That may be due in part to the fact that it doesn’t really have any protrusions, but mild congratulations are nonetheless in order. Great job Cooler Master, you didn’t lie on the spec sheet.", "Overall the NCORE 100 MAX is easy to build in, and the manual is pretty good. The exterior panels are removed just by pulling and are attached to the case with pushpins that give a stable hold. They’re made of 2mm thick aluminum that’s perforated with holes and bent into shape. Metal mesh is attached to the interior side of the panels with plastic pieces that just pull off to allow for the fine mesh to be removed for cleaning.", "The top panel is made of plastic and is covered in a more rigid metal mesh, so it looks like one of those fine mesh panels you would get on the front of a Phanteks ATX case where they use that really fine mesh material. This works great because it eliminates the need for a dust filter but is super breathable - the panel itself is rigid and provides good structural support. The downside is that it’s more restrictive on airflow than a finer mesh solution that is not structural.", "It comes off in a similar fashion to the side panels, and definitely shouldn’t be used as a handle or to lift the case. That mesh top has to be removed prior to removing the locking front pillar, as there’s a nub of plastic on the top panel that interfaces with the pillar.", "And that same pillar has two toolless latches that lock it in place, which are sturdy and easy to use. It then swings out of the way and comes off entirely to give better access to the motherboard side of the case and cable management along the front. This pillar gives one of the exterior panels a place to attach and lends some additional rigidity to the case overall.", "The motherboard drops into place below the power supply pretty easily, and leaves plenty of room to connect the various cables required around the motherboard. The pre-installed power cables are flexible and the CPU 8-pin is extremely short, which is mostly a good thing here. They know roughly where the EPS12V connector will land and can reduce slack cabling. ", "Moving to cable management: the NCORE 100 MAX gives the builder lots of areas to tuck cables out of the way and has tie-down points everywhere. We appreciate these features, given the small space, and Cooler Master did a good job with cable routing options.", "CPU cooler installation is standard for a CLC and includes a tube of thermal paste that looks pretty generous, but only has a tiny amount actually in it once you peel the deceptive sticker back. It’s not like it’s less than what you get in the small 1g tubes, but it definitely feels worse given the misleading size of the syringe.", "Installing GPUs up to 337mm long, 180mm tall, and 62mm (about 3 slots) thick is supported out of the box. The case gives a good deal of access to the GPU side and we don’t have any real complaints about the process. However, be aware that the more you fill the actual GPU space, the more challenging it will be from a thermal standpoint. As the volume in the chamber is filled with GPU and the fan moves closer to the side panel of the case it increases the pressure needed to overcome the panel.", "Additionally, for GPUs that have a flow-through Founders Edition design, air will simply be blown through the cooler and into the wall behind the card, which makes the case unable to leverage the benefits of the modern flow-through design in video cards. The majority of the exhaust from the GPU will be pulled out by the case's rear fan.", "The rear fan on the case is particularly important because even though the pump and the block for the CLC is mounted to the CPU, it is sharing the total cooling capacity with the power supply and GPU because the radiator is mounted to the top of the case. The CPU and power supply are exhausting up and out, along with the GPU, for whatever is not taken away by the rear fan.", "The bottom GPU fan (in this orientation) doesn't blow all the way through the card - it spread air in a sort of spiral around the inside of the case. We've shown that in some of our Schlieren photography in the past. Some of that air will find its way out of the panels, some will get properly exhausted, and some of it will simply circulate around.", "The air from the flow-through portion of the GPU is most likely going to split through the top and the back. This will contribute a little bit to processor temperature, just because the actual radiator temperature and liquid temperature will be elevated by the fact that they're sharing a cooling solution indirectly.", "GPUs thicker than 62mm require converting the case to expanded mode. That’s done by first removing the rear corner pillar by taking out two screws – there are no latches on this one.", "Then one set of case feet are repositioned to a wider stance before reattaching the rear pillar into an outer position. After that, the top panel is replaced with the wider alternative included in the accessory box. This is a clever design because it mostly relies on reconfiguration rather than extra parts, and it doesn’t disturb the aesthetics of the case.", "To accommodate graphics cards longer than 337mm, the PCIe bracket and riser have to be relocated to a lower position. We assume the only reason this isn’t standard confirguration is that it reduces the space available for display cables underneath the case. Having the case set up in expanded mode plus the lower bracket position allows for GPUs 357mm long, 180mm tall, and 79mm thick, which Cooler Master calls “3.9 slots.” The enormous ", " is barely able to squeeze inside, inadvertently becoming a structural beam in the process.", "The ", " comes with a 90-degree 12VHPWR cable preinstalled, which is marked as only being capable of 450W, meaning no raising the power limit on a 4090 or using one with a vBIOS that boosts it higher than default. The 450W spec is concerning regarding cable quality and we also don’t like that it presses against the central spine when used in our 4070 Founders Edition card, plus the bend and contortion that we get when routing it. For GPUs that don’t use 12VHPWR, Cooler Master includes 3 PCIe 8-pin cables in the accessory box.", "After finishing our build and testing, we spotted an undocumented hidden feature. There’s a thin removable panel to the left of the motherboard I/O. The manual doesn’t mention this panel at all, but after removing it and taking a look around the case, we wondered if it’s there to facilitate moving the motherboard tray (the case’s “spine”) over a few millimeters.", "We emailed Cooler Master with the question, and the company confirmed this:", "“Yes, the removable plate near motherboard I/O is for making it adjustable. At first, [we wanted] to keep air-cooling mode for non-MAX version. Since it can extend 17mm for 3.9slots GPU, [shifting] the M/B tray 1 slot can make Ncore100 [support] up to 67.3mm air-cooling height with 2.9slots GPU support.”", "- Cooler Master to GamersNexus", "The reason Cooler Master doesn’t call out that capability is because there’s currently no plan for a non-MAX version of the case without the PSU and CLC. So, in other words the spine can be adjusted, but there’s not really a point to doing that with the built-in cooler.", "We tested the ", " against itself in various configurations, and especially since it includes its own cooling solution we mostly tweaked the panels on the case and the configuration of the video card for testing.", "We’ve locked the 13600K to fixed frequencies and power levels for all these tests, and set the fan on the RTX 4070 Founders Edition to a static 44%. As usual, these temperatures are represented as delta T over ambient.", "Remember that all of this is comparative. The component temperature will change based on your fan speed and components, the voltage of those parts, what’s set to auto versus controlled, and so on. Our testing is highly controlled - it is designed to evaluate how various layouts of the case and its panels affect airflow.", "CPU thermals are first. The GPU fan speed is unchanged in all tests, so references to fan speed are for the included fans with the case and the cooler. With the fans at 100% speed and in the stock, smaller configuration, the P cores averaged 50 degrees Celsius delta T over ambient at steady state, or 45 for all cores averaged. Removing the top panel was an experiment to look into how much impedance the panel was causing, similar to our front panel removal tests on ATX cases. That dropped the temperature to about 47 degrees over ambient, illustrating that the panel does get in the way, but not enough to ruin performance.", "Moving the GPU to the outer position had no meaningful impact on CPU thermals here and was within variance. We also ran a test with the cooler closer to 27 dBA for the total configuration (as evaluated in our ", "chamber with a noise floor of about 13.6dBA during testing). That would have us in the 80s after factoring in ambient, so there’s still some room for quieter configurations if running a mid-range CPU like an i5, but it would struggle with a 14900k running at 300w. This test helps show there’s some scaling room in the cooler, despite being a 120mm solution, but it is still ultimately going to be limited by size.", "This chart is for GPU temperature in the same test. In this one, the stock configuration had the GPU at 51 degrees Celsius over ambient when tested with our fixed fan speeds. We didn’t change the GPU fan speed when dropping the case and cooler fan speeds, but as they’re the only fans circulating externally, they affected GPU thermals and led to a 3 degree increase.", "Removing the top panel posted marginal improvement, while shifting the GPU to the outer position was the most beneficial.", "This isn’t nearly as much change as we saw on the ", ", where moving the GPU shaved nearly 7C off the core load temperature. What this tells us is that the ", " is better at removing the warm exhaust air from behind the GPU by default than the A4-H2O without moving the card. All that said, this move is only possible with GPUs thin enough to sit in that outer position, with or without the case expansion.", "Wrapping it up -- it's very easy to build in, and ease of installation was a good factor for the ", ".  The toolless focus outside of the motherboard and GPU mounting was good and we thought some of the solutions, like the expansion of the case into the larger configuration were well executed.  They were put together in a clever way that minimizes the amount of additional parts they put in an accessories box that you'll inevitably put on a shelf and never use again after you first build it.  Having a lower count of useless accessories in one of two configurations is good. Cooler Master is able to make use of the same two side panels for the expansion configuration without really creating any big gaps or holes in the case in the process.  We thought it was cleverly mechanically designed.", "As for the looks, that's totally up to you. It is a small footprint physically on the desk surface, however it is quite tall. GPU IO at the bottom is not convenient, but because you're probably only plugging in monitors maybe once or whenever you upgrade, it seems fine as far as trade-offs go.  It's definitely better than having the motherboard USB less accessible.  ", "As for the the CLC, 120 mm liquid cooler was able to keep up with a 13600k at our fixed clocks and voltages, but it is not something we would recommend for a 14900K or any similar processor with a higher power draw. The CLC will struggle to keep up with that class of processor, especially as you increase the GPU capability and therefore the GPU heat inside of the case. With an increase in CPU heat the cooler will become overwhelmed, so you will need to spec the CPU more in the mid-range side of things.  ", "Note that AMD CPUs consume a lot less power right now for similar gaming performance, so if you're building a gaming PC and you use a 7800X3D, you're going to be fine. It's just those hotter configurations that are going to be problematic, like a 7950X or anything from Intel's 14700K or 14900K.  ", "The GPU compatibility we thought was great as it fits pretty much anything. We did not like the 12VHPWR cable in general, based on how it bends and because it's one of the lower rated cables (maxing out at 450w), and you wouldn’t want to raise the power limit on a 4090, given the spec of the cable.  ", "Pricing is a little tricky because its $400, but you get two of the other components (CLC and PSU). From one ITX perspective that's kind of taking away part of the fun – you don't get to configure the power supply or the cooler and you don't really get to install them in the same way. Whether that matters to you is dependent on how much you enjoy the process of speccing out every single part and building the entire thing from scratch. From a pure pricing perspective, you could think of the case cost as being more equivalent to around $180 once you look at the price of a comparable power supply and cooler.", "Overall we liked working with the case; this is better than the old Phanteks Evolv Shift which had a tower case that would position liquid coolers in sub-optimal layouts. The NCORE 100 MAX places the CLC pump below the radiator, which is a healthy position for CLC longevity, so we don’t have any concerns about CLC longevity. The biggest considerations are ultimately going to be CPU choice and making sure that it will fit within the limited cooling capability, and perhaps a non-MAX option in the future (based upon the small removable panel) that could use air cooling instead.", "That's it for this review, and we'll see you next time."]},
{"title": " Antec's Case Comeback: High Performance Cases, Wood Panels, & AMD Handheld", "paragraph": ["Antec's Case Comeback: High Performance Cases, Wood Panels, & AMD Handheld", "Last Updated: ", "The Highlights", "With 9 things to show off at Computex 2024, Antec is back, which made us ask: But why is Antec back?", "Antec represented many of our first computer cases as they used to be wildly popular. The Antec 900, for instance, was a revolutionary case, and then the company just kind of disappeared for a while. ", "Now Antec is back and making a serious effort at making computer cases with a new case product manager, who has been with the company for around 20 years. ", " ", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "We were sad to see Antec go by the wayside but are happy to see the company coming back.", "The ", " case is out (watch our ", ")and is a relatively new case from Antec. ", "Where it competes is in price. The cheapest model is $100 after discounts and doesn’t include any fans. The 3-fan model costs $160. Antec seems to be taking a page out of Montech’s playbook with hyper aggressive pricing to compete with incumbents in the industry.", "The case comes with panel options that include a darker wood and aluminum, which is similar to ", ". There’s also an ARGB version, which comes with fans. ", "Antec also has a version with a curved tempered glass. It sounds like glass yields have gone up in recent years as this type of curvature wasn’t really a thing years ago. The case is like a traditional ", " but there are some tooling differences the company had to accommodate due to the curve. The top panel is also different and it has deep chambers for cable management.   ", "The C7 is a new case from Antec that’s an aquarium style case with a glass side and front. Its bottom side panel pops out, which provides a little more access to air.", "The case comes with 3 fans on the side and one on the back.", "The back side of the case features 2 swinging doors that are held in by large Phillips #2 screws that have a rubber grommet around them. ", "Antec is introducing 2 cases in its Flux lineup. They feature a wood motif that everyone seems to be jumping into. Inwin’s attempt didn't make it to market and Fractal ultimately popularized it with cases like the ", " and ", ". Corsair now has some wood you can throw onto its ", " case.", "The Flux Pro uses walnut wood and new tooling. It includes 6 fans, four of which are 140mm fans (there are three on the front and one on the back). The case also offers 2 reverse 120mm fans on top of the power supply shroud. There is mesh ventilation on both sides of the PSU shroud, and the porosity looks good from just eyeballing it. ", "The Flux Pro has your standard rubber grommet pass throughs with relatively deep cable management but it does include a CPU and GPU temperature display. The case uses a standard chambered design rather than a dual chambered one, which are everywhere now.", "Antec is targeting $170-180 for the case with the aforementioned 6 included fans and it’s aiming to ship it in August. The Flux Pro will compete with the ", "/", ", the ", ", ", ", and ", " cases, the latter of which is relatively new and is more comparable in size.", "There is also a non-Pro Flux case. It’s smaller and the fact that it's cheaper at around $110-120 is its main selling point. It includes 5 fans, which is a lot. There are 3 in the front, one on top of the PSU shroud, and one in the back. This is a pretty standard layout with the exception of the fan at the bottom.", "Aside from offering back-connect support, the backside is pretty standard. There is a fan controller and some velcro straps to help with cable management. ", "In a cost-savings measure, there is no CPU/GPU temperature display.", "There’s not a lot of detail on this case yet as it’s still in the design stages. The interior frame is red, which we like as an accent.", "It’s a sandwich style case that has a movable tray in the middle, which can be repositioned to a couple different locations. Like the ", ", you can adjust it based on video card depth, and it supports 3-slot cards. The CPU cooler clearance is 65mm at the small end, and you can adjust that at the cost of sacrificing GPU clearance.", "The Performance 1M is mostly made up of aluminum with some steel mixed in.", "The case’s top panel has a color accent pull tab and the top panel was an off-green color, but Antec isn’t sure about its color choice just yet. ", "The company suggests the Performance 1M might be released in Q3.", "The Core HS is a handheld made by AYANEO in collaboration with Antec. Antec approached AYANEO as the company makes numerous SKUs of handhelds.", "The Core HS uses a 7840U processor, which every handheld basically uses right now.", "What makes it unique is that its screen pops up. You can even see the coil mechanisms on the back that allow it to do so. It’s also a smaller handheld with the screen being about 6 inches. Most competing handhelds use 8+ inch screens. Its smaller size might make it appealing for traveling when space is limited.", "The Core HS also has a physical keyboard like past GPD handhelds. We found them okay depending on what you’re doing.", "For cooling, the Core HS appears to have a relatively large blower fan on the back. Its fin stack at the top of the device appears to be a taller height. There is potential here for a good cooling solution, though we don’t know how good it actually is without testing it, especially since it doesn’t have ventilation anywhere else on the device.", "The Orbit is a prototype fan that has LEDs coupled with an infinity mirror in the middle. ", "The Nova is an LCP fan, which is a solution to combat the issue of fans stretching out over time, causing them to clip to the sides of their frames. Antec is looking at 0.4 to 0.6 mm or so of spacing in between the fan blades and the frame.", "The Nova fans come with fluid dynamic bearings. It also comes with a toggle that offers 3 different fan speeds. ", "Antec’s recently released ", " case has made the company probably more relevant now than it has been in a decade.", "The company used to be an important brand in the industry. If it can figure out how to push through and get relevant cases on the market again, that would make for an exciting comeback story."]},
{"title": " Surprisingly Good: Antec C8 ARGB Case Review, Thermals, Cable Management, & Noise", "paragraph": ["Surprisingly Good: Antec C8 ARGB Case Review, Thermals, Cable Management, & Noise", "Last Updated: ", "The Highlights", "Today we’re reviewing the ", ", which is a $150 case that includes three stock fans. 2 of them are larger 160mm bottom intake fans, making for a unique take on the dual-chamber glass box design popularized by Lian Li. After ", ", it seems this is the new meta -- if a bit delayed -- but Antec has at least taken a different approach with its fan configuration. Going with 160s always immediately interests us. They’re rare, but often do well. Lian Li deftly pulled off 160s with its ", " previously.", "The ", " has fan-less models as well that ship as low as $100 with temporary discounts applied, or commonly $130. At $100 for the fan-less C8, the case is immediately competitive and almost seems to be taking a Montech approach to establishing itself as a higher quality budget brand.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "Some quick history: We were surprised how many of our viewers didn’t know the “Antec” name when we did a recent visit to their office in Taipei. ", "Antec’s dominance of the PC case industry peaked before we ever ", ": at least, that's the way it felt, and perception matters to customers. GamersNexus was founded in 2008. Antec was founded in 1986. The first case Steve personally built in was the Super Lanboy, followed later by the Antec 900. But Antec disappeared due to changes in executive leadership, which pursued Bluetooth speakers and battery packs for years instead of components.", "To us, Antec was an aging giant that was sliding into irrelevance with cases like ", ". We paid ", " attention to its output over time.", "That's why we were surprised when we first went hands on with the ", ". It's not the case we're reviewing today, but at a glance, it's clear that Antec put some real investment into its design and manufacture. ", "Because of that, we accepted Antec's next offer for a review sample of the C8. ", "The ", " is a conventional dual-chamber design that doesn't break new ground, but it impressed us with touches that are uncommon at its price; little details like the painted or embossed labels all over fans. The HDD cages and brackets aren't functional, but they create a feeling of quality. On the white version we're reviewing, everything (even down to the cables and connectors) is white with silver accents. It’s a good attention to detail.", "On the functional end, the bottom fans are of a unique 160mm reverse-blade design with minimal airflow obstruction around them. These are 31mm to 35mm thick, depending on where you measure. That extra thickness will also benefit the performance. The fans are also recessed into the floor of the case, which will significantly aid with access to cool air. Antec biased both back toward the GPU, so the CPU will end up warmer in this case with the default configuration. If going for a liquid cooler, the focus on the GPU makes sense.", "Radiator compatibility is good, with up to 3x 360mm rads supported simultaneously. The glass panels have beveled edges so that they mate together closely and the steel panels are sturdily constructed despite being ventilated (unlike the ", "’s). Again, this case is $130 for the base model or $150 for the ARGB one. That just makes Corsair look bad.", "A $20 bump for three stock fans is impressive given how unique the fans in question are. To start with, all the fans in the white SKU are completely white, including cables, sleeving, and vibration damping. The rear exhaust fan is a conventional Tranquil 140x25mm ARGB PWM, but the two bottom fans are Tranquil 160x35mm ARGB PWM Reverse Fans. The extra 4mm comes from the lip jutting out from the fan housing. On top of that, all the fans have different cable lengths in order to reach the built-in ARGB and fan hub without slack. Taken together, these small details demonstrate special effort and attention to detail that we’ve appreciated of competing brand Hyte in the past.", "Along the same lines, there are labels molded and printed throughout the case that remind us of the ", ". Antec is molded into the cable grommets, labels like SSD STORAGE UNIT and HDD STORAGE UNIT are pressed into the drive cages, and AIR DUCT PARTITION is printed into the…air duct partition. They're small details, but we like them.", "The 140mm and 120mm adapters for the bottom fan mount are both labeled as well. As it ships, the ", "'s 2x 160mm fans are installed in the bottom of the case, which is wide open for 160mm support with zero crossbars obstructing intake (even on the filter, which could probably use them). For smaller fans, the adapters need to be installed, but this approach means that Antec gets a wide open, really clear path to intake and that's rare.", "Antec claims support for 120mm, 140mm, and 160mm fans at the top of the case, but there are two additional sets of mounting holes in between that would line up with 130mm and 150mm fans. ", " playing around with 130mm fans, but that’s not something you really typically see.", "The attention to minutiae extends to the accessory kit (also marked with an Antec logo -- so truly competing with Hyte). ", "In addition to an extra set of white velcro straps and white zip ties, there's a full set of extra rubber dust plugs for the front I/O. We'd skip those: every time you take off the top panel, the USB-C dust plug comes with it.", "Antec advertises ", " in the C8, by which it means that the combined thickness of radiators and fans in the top mount is 70mm, side mount is 100mm, and bottom mount is a massive 135mm, all simultaneously. The true amount of space for the bottom radiator depends on how many add-in cards are installed and how big they are. If you intend to use all three 360mm mounts simultaneously, you should definitely buy the base model C8 rather than the ARGB since the two unique 160mm fans would need to be removed.", "The built-in fan hub is designed with the expectation that you won't add to the stock fans. It's SATA powered with one PWM input and one ARGB input, and these are each split into three outputs. One of the bottom fans has daisy-chain connectors, so that leaves one open slot on the hub. It's the tidiest possible solution if you don't want to make any changes, but we prefer the Fractal approach of leaving a bunch of open headers and making the fan cables extra long.", "Because the C8's fans have very specific cable lengths, moving them around may require wire extensions, and one of the bottom intake fans has an ARGB connector that's only intended to connect to the other fan. Also, the ", " comes with two different sizes and types of fans, but the hub only accepts one PWM signal and only outputs one tach signal, which we think is a shortcoming because the actual percent will influence the fans in different ways at different sizes.", "As for the cages, each of the 2x 2.5 cages holds two drives, as does the 3.5 one. The ", " is one of the few cases we've seen lately that's bothered to put rubber vibration damping in the HDD cage, and it's color matched with the gray rubber elsewhere in the case. On a more critical note, the 3.5 cage isn't officially compatible with 2.5 drives, but you could make it work. Also, it doesn't use sleds and it requires a screwdriver to remove. We’d like to see some toolless options at the back of the case because some thumb screws for the drive cage work out pretty nice. The mounting points on the case also aren't cross-compatible with the 2.5 cages. You can’t take one of the 2.5” cages and put it where the 3.5” cage normally sits, but you almost can -- and there’s no good reason not to accommodate it.", "Unlike the ", " series cases that we ", ", Antec relies on the panels themselves for filtration without an extra nylon layer. ", "These panels are rigid 1mm thick steel reinforced with folded-over edges, so the level of flex is insignificant. All panels are toolless, including the glass panel; as usual, though, we'd like a backup method to screw the panels down. ", "The side and front glass panels are also beveled so that they can fit together perfectly in theory. We did notice that there’s a little play in the toolless mounting, but the beveling and the point of connection is overall well done. ", "It's not enough to be obvious, but the seamless edge is the C8's headlining feature, so ideally we shouldn't see any gap at all. Typically, case manufacturers put a supporting pillar at the front of the case, especially if they have toolless panels, although the ", " has been a notable recent exception. Don't put too much weight on that top corner of the C8, though.", "Side-interface PSUs are compatible with the C8, but we also see no advantage to using one for this case. Cable management is already better than it is in some other dual-chamber cases: there's a deep channel next to the PSU as usual, but the air duct partition is very easy to remove, which makes the tie points inside the channel much more accessible than we see in some cases.", "If you've been paying attention to our recent case reviews, you may have spotted the Antec C8 on the charts. The C8 ARGB is in the minority of dual-chamber cases that we've tested recently in that it includes fans, unlike the various ", "s, ", ", or the (non-iCUE) Corsair 6500s. We'll be focusing on stock results, but the standardized fan results are also important to pay attention to, since the cheaper base model C8 doesn't include stock fans and falls into the same category as those other dual-chamber models. The Antec C8 and C8 ARGB compete most closely with the ", " and ", ".", "We'll start with CPU noise-normalized thermals, with the case fans reduced to bring the total noise level down to our threshold of 27 dBA for all cases as tested in our hemi-anechoic chamber.", "The C8 ARGB's stock fan configuration is weighted towards GPU cooling with the 2x 160mm intakes positioned directly below and obstructed by the GPU. There's no intake aimed directly at the area where our CPU air cooler sits, just the exhaust behind it, so it's not really a surprise that the CPU thermal results are at the hotter end of the chart. 50 degrees Celsius over ambient for the average of all CPU cores and 54 degrees for the P-cores effectively ties it with the bottom-intake Y70 and 6500X configurations, although its larger and more powerful fans give it a small boost over the ", "'s stock bottom-intake setup, which averaged 53 degrees all-core. The ", "'s performance here was much better than the C8's, at 47 degrees average all-core and benefited by fans closer to the CPU.", "Side intake is generally better for CPU thermals with our test hardware, but moving the 160mm fans to the side of the C8 ARGB isn't an option. We'll cover that in the standardized fan test instead.", "As we just mentioned, the stock fan configuration of the C8 ARGB benefits the GPU. With all case fans at full speed, our GPU averaged 41 degrees above ambient with the memory at 45 degrees and hotspot at 53. The GPU average is very good, close to the ", "'s chart-topping 39 degree result, but its noise levels are significantly lower, putting it in the same category as the side-intake HYTE Y70. That makes Antec’s C8 more acoustically efficient, as we call it, as compared to the ", ". It’s an impressive result for Antec.", "Montech's King 95 Pro was warmer with a 46-degree average with a noise level that tied the C8 ARGB.", "The C8’s large bottom intake fans help it when noise-normalized for GPU thermals as well, at 42 degrees average versus the Torrent’s leading 40 degrees. It’s another good result for Antec. The larger fans can move more air at a given noise level, which is also a large part of the reason why the Torrent scores so well. The King 95 Pro fell behind with a 48-degree average, which goes to show that filling all the fan slots doesn't guarantee the best possible performance, especially when controlling for noise. The C8 ARGB shines when noise-normalized for GPU thermals.", "Our standardized fan set fits in the C8's side mount, so we have side intake numbers now. With the standardized fans installed in the same bottom intake slots as the stock fans were, the average all-core CPU temperature was 47 degrees above ambient and 51 degrees for just the P-cores. Side intake dropped that to 42 all-core and 46 P-core. The C8's CPU thermals are good among side-intake dual chambers like the Y70 at 43 all-core and the King 95 at 45, with only the ", "'s side intake result beating the C8's at 41 degrees. That's just side intake, though: cases with conventional front intake layouts like the Torrent are still better for CPU thermals with our test hardware. Obviously though, it’s not as simple as “front intake better,” since it all depends on the design of the case, the front panel, the fans in the front, and the hardware used.", "GPU thermals with standardized fans show that not only did CPU thermals drop with side intake, but GPU thermals slightly improved as well, down from 43 degrees above ambient with bottom intake to 42 with side intake. If you buy a base model C8 rather than the ARGB, we'd recommend starting with the side intake slot for air-cooled builds. For the C8 ARGB, that's not really an option with the inflexible stock fan layout.", "42 degrees is among the best results on the chart, with a particularly strong result from the HYTE Y70 with side intake beating it by one degree. That’s basically margin of error.", "The C8 ARGB's average VRM temperature during noise-normalized torture testing was 33 degrees, right in the middle of the chart. The top panel is mesh and there's plenty of breathing room above the motherboard, but there's also not much active airflow over the VRM area other than from the rear exhaust fan.", "The DDR5 SPD reading was similarly middle-of-the-road, but 24 degrees is better than the other bottom intake results on the chart, like the Y70 at 27 degrees and the 6500X at 28.", "The ", " undercuts the competition, with the $130 base model frequently discounted down closer to $100. The ", " is the cheapest dual-chamber case on our chart at $100, but the ", " variant with fans costs at least $150, tying the ", ", and color variants cost more. The ", " comes with twice as many fans as the C8 ARGB, yet the C8 uses its fewer fans more effectively. The C8 is the case that we wish the ", " had been, and at a significantly lower price. If nothing else, this is an embarrassment for Corsair, and hopefully a kick in the pants for it to get back into top-shape with its cases.", "When choosing between the ", " and the ", ", consider whether you want to alter the fan layout. If so, just buy the ", " and pick your own fans. The C8 ARGB's 160mm bottom fans can't easily be repositioned or used with a radiator, and the fan hub only has one open slot.", "Thermally, the C8 ARGB does exceptionally well with GPU thermals as a result of its sunken bottom intake fans. The CPU thermals are on the warmer side, but acceptable. Flow-through will help at least some air get up to the CPU.", "The C8 doesn't do anything completely new, but it's a solid reflection of existing high-end dual-chamber cases at a lower price."]},
{"title": " Fractal Fumbles: Mood Case Review, Thermals, & Design Oversights", "paragraph": ["Fractal Fumbles: Mood Case Review, Thermals, & Design Oversights", "Last Updated: ", "The Highlights", "The brand new ", " is wrapped in airflow-impeding fabric that stifles performance and makes it look more like an air purifier than a computer. It can also sound like one.", "One of the noises it makes is an oscillating tone that’s only present when the shell of the case is on, and goes away with it off.", "Steve Burke", "Jeremy Clayton", "Vitalii Makhnovets", "Jimmy Thang", "One of the better aspects of the case is the mechanical design -- sometimes. The back panel pops off and the entire exterior shell lifts off in one piece, revealing a huge 180mm exhaust fan that takes up the entire top of the case. It’s priced at $150, which is middle of the road in the ITX world.", "So, the Mood has some really interesting acoustical characteristics, along with unique materials choice and construction. ", ", we also thought that -- if executed well -- the design could be good for thermals, but it all depends on the execution of the concept.", "The Mood’s pitfalls include potentially guillotine-ing the cables with the exterior of the chassis if it drops down too fast and there are dangling cables protruding out of the case, and its top-mounted SSD bracket can impact GPU thermals in a big way. A bad way.", "We were ultimately let down by the Fractal Mood: While it has a unique aesthetic, the case falls short in many areas.", "Let’s get into it.", "The entire exterior shell can be removed in two pieces. It’s toolless, which we like for ease-of-use, and there are two screws on the rear to lock the shell in place for transport. Small attention to detail like mylar tape helps prevent unpleasant scraping on shell removal. This is one of the best things about the case – there’s pretty much unobstructed access to the parts inside with the shell removed.", "The parts are arranged in an upright/tower sandwich layout with the motherboard and PSU on the front side of its stationary spine. The GPU is on the back side, connected to the motherboard by an included PCIe riser. The entire top of the case is taken up by one of Fractal’s 180mm Dynamic fans to pull out warm air from both the CPU and GPU sides of the case. This creates a negative pressure system where air is pulled in through the side panels.", "The Mood continues Fractal’s experimentation with alternative materials outside the norm of what is typically found on computer cases. The ", " and ", " both incorporated wood into the cases in successful ways that ultimately ignited an industry trend that has taken off in its wake.", "Now Fractal’s trying out fabric. Its ", " case in 2022 started this with a small panel of fabric on the front, following the InWin Alice previously. The Mood has fabric wrapped around nearly the entire outside of its exterior shell, which creates a unique look for a PC case and is reminiscent of Google’s Home speakers. It’s well applied and it's not loose. Even directly beside where we cut the panel, it’s still firmly in place with some kind of adhesive.", "The weave of the external decorative layer on our sample was misaligned across the front, which could be disappointing to users who want the super clean and symmetrical look. ", "Underneath the exterior layer is a structural weave, and underneath that is a layer of perforated plastic with holes that align with the holes in the panel. This plastic also seems to act as the adhesive holding the fabric in place. Only the front and rear of the case has ventilation for intake – the sides are totally solid, which is intentional. ", "At first glance it seemed restrictive to airflow -- and that’s because it is. You’ll see that in our thermal tests.", "We can’t objectively comment on aesthetics for obvious reasons. You can make-up your mind on the look. Subjectively, we think Fractal is almost getting to the point of over-pandering to its “grown-up gamer” audience. That doesn’t factor into our critiques of the review, though, as it’s ultimately subjective and up to you. There’s enough to criticize without worrying about the look. The Mood is just the other end of the style scale opposed to things like the ", ". ", "In both the wood and fabric instances of alternative case materials, it was InWin that did it first, but Fractal that made it successful. InWin had wood-accented versions of ", " that it showed off in 2017, but as far as we know, they never came out. Then it had the ", " with a full fabric cover, which did launch but was of limited success due to its hamper-like appearance and limited marketing resources.", "The Mood is $150, which is way below its closest competition – the ", ". The NCORE 100 MAX is currently $350, but comes with a power supply and cooler. The prices could be somewhat comparable once you factor-in those costs. ", "Other loosely similar cases include the ", " and ", " – both of which are cheaper and don’t use PCIe risers.", "The build layout leaves all of the main I/O from the motherboard and GPU oriented downwards, so the case has to be tilted over to connect or disconnect anything. This is something the ", " did better by having the motherboard I/O still face the rear of the case. There’s about 67mm of space underneath and we didn’t run into any issues with cables fitting, but it’s possible that the bulkiest of USB or display cable plugs may not fit.", "Front I/O is just about as good as you can expect on an ITX case, with two USB type-A ports, one type-C, and a combo audio jack. We typically like to see two jacks that include separate headphone and microphone ones. Since all the standard I/O is on the bottom, we would have liked to see one or two more USB ports – maybe via a built-in hub.", "The Mood measures in at 213x213x453mm. Fractal states 212mm for width and depth, but ours is 213mm. We’re glad Fractal is being realistic with its measurements. The volume calculates to 20.55L, which breaks the imagined 20L SFF barrier that some uphold. The Mood is tall, but it doesn’t take up much space on the desk – it’s at least SFF adjacent.", "Fractal isn’t clear on what the maximum CPU air cooler height is – it’s either 114mm as shown on its ", ", or up to 120mm as shown in the manual, or 110mm as we were told in-person. Based on our measurements, it seems like 114mm is more accurate. For air-cooled tests, we used the 110mm tall ", ", and there’s just a little bit of room to spare with that. If a short enough air cooler is used, a fan could be installed over the top of it using the radiator bracket. It could be an interesting solution for downdraft coolers and would hit the VRM pretty well.", "280mm and 240mm liquid coolers are also supported, with a maximum radiator plus fan thickness of 67mm, and up to a 60mm tall block. The thicker the cooler gets, the less room there is for air to actually get out, and cable management gets more difficult. There wasn’t much space left with our ", ", which cuts down on the efficacy of the top exhaust fan and caused some issues for the GPU that we’ll get to in the thermals section.", "GPUs can be a maximum of 158mm tall (excluding the cable), 325mm long, and 56mm thick (including the backplate). That pretty much keeps the build limited to 2 and 2.5-slot GPUs – roughly around the ", " level. It’s unfortunate that a case of this physical size is so limiting like this in the GPU department.", "The case pillar nearest to the top of the GPU is actually removable, giving easier access for installation and removal. It’s a helpful touch.", "A 3-slot Founders Edition card shouldn’t fit based on Fractal’s measurements, but it actually can with minimal effort. However, there are only two expansion slots in the bottom of the case, restricting the slot-side exhaust.", "The Mood comes with a couple of drive mounts – one for 3.5” drives that attaches to the upper front fan bracket position, and two for 2.5” drives. One of them attaches to the side near the PSU cables and is totally fine – even beneficial to help with cable management in that area.", "The other is the top mount we previously mentioned. It goes between the PSU and the top exhaust fan, and requires temporary removal of the fan to install. This is a pretty weird spot, and the bracket isn’t ventilated at all, and contributes to blocking off the Mood’s only exhaust. That’s especially true for the PSU exhaust, which ends up significantly blocked. This has a big thermal impact that we’ll get to later.", "Thermals start with CPU results under a full-system torture workload. CPU frequency and power is locked, as are fan speeds. As usual for our ITX reviews, the data here is not directly comparable to any other case we’ve run in the past.", "The stock result with the 280mm CLC at 100% speed came in at 41 degrees Celsius over ambient across the P-cores. ", "Removing the outer shell resulted in a massive, nearly 10C reduction in the P-core average. This tells us that the outer shell is hugely restrictive for both intake and exhaust. Internally, there just aren’t many places for the air coming out of the CLC’s fans to go. The air gets shoved into a tiny chamber with limited pressure pulling it out, and taller blocks reduce that volume even further. This poor performance is reinforced by the “Top Fan Off” result only causing the P-core average to rise by 2C. The top fan can’t really pull air up through the narrow passage between the internal components and the cooler’s own fans. It’s just not doing much in this chamber.", "Switching to air cooling with the ", " at 100% fan speed results in a P-core average of 58 degrees over ambient. The point of this isn’t to compare a tiny tower cooler to a 280mm radiator -- that’s just a cooler review, which we do separately -- but to see what happens when we take away the intake air restriction presented by the fabric cover.", "With the front side of the shell skinned, the P-core average dropped by 4C. That’s a lot for just removing the front fabric. This proves that just the fabric is very restrictive on its own. Fractal chose to leave performance on the table in pursuit of a certain look.", "The top SSD mount has effectively no impact on CPU thermals, but does for the GPU, so let’s get to that.", "The fans on our 4070 FE are locked at 35% unless otherwise noted.", "The air cooler config actually gives the best GPU thermals, with the GPU core at 49C over ambient and memory at 40C. The stock setup with the 280mm CLC is about 5C warmer on the GPU, despite more fans and better CPU cooling. Here’s what’s happening: The exhaust air brought in from the CLC is fighting for anywhere to go, and that includes going into the GPU side of the case. The GPU gets fed this pre-warmed air, maybe even causing a slight re-circulation effect.", "Removing the shell drops GPU core temperature by 2C – so not nearly as impactful as it was on the CPU side, which is because the GPU side does not have the restrictive fabric (and the GPU fans are also right up against it). ", "Adding the top SSD mount underneath the exhaust fan has a huge and negative impact on GPU thermals, raising the core by 9 degrees, which is massive. For a GPU, this increase is phenomenally bad. It forced the GPU clock speed down by almost 150MHz, so without clock throttling, the temperature increase would have been even higher. Fractal’s design here is poorly thought-out and does the GPU a huge disservice.", "GPU exhaust from the flow-through portion of the card normally is able to go into the PSU and then out through a slot above it, but the SSD bracket blocks off a significant amount of that slot. Between that and the CLC fan actively blowing air towards the PSU exhaust, it doesn’t have a fighting chance of helping to evacuate the GPU’s exhaust. It’s possible to flip the PSU around so the fan faces the other way, but then the GPU would just be blowing into a wall.", "Raising the GPU fan speed to 66% with the top SSD mount in place brings the core temperature back down to stock levels. This mount is just bad and should be avoided.", "Finally, we can see that the top exhaust fan is actually integral to GPU thermals, as turning it off had the GPU running 12C warmer than the stock setup, with even lower clock speeds. Fractal has poorly balanced the behavior of its two chambers.", "Moving to VRM and RAM thermals again shows us how restrictive the Mood’s shell is, with the no shell result coming in much lower than anything else. The bottom end of the CPU side of the case just doesn’t have anywhere for air to go, which can affect VRM temperatures and RAM.", "Other than that, the liquid cooler has an advantage over the air cooler due to the former having a fan blowing directly onto the motherboard.", "Now onto the acoustic testing in our chamber.", "We found something really interesting while going through the data after noise testing. Things like this are made possible by our ", ", and building it was only possible via the huge support that we’ve gotten. To continue supporting our efforts to expand accurate testing that uncovers phenomena difficult to explain without specialized equipment, head over to ", " and grab one of our PC building anti-static ", " with PC wiring diagrams, screw tracking grids, and reference materials. You can also grab one of our ", " there to show support.", "Here’s the result.", "With the 280mm liquid cooler installed, the outer shell of the Mood seems to have a resonant type noise around the 180Hz area, with peaks also forming at the multiples of ~360Hz and ~720Hz. This is clearly audible in the recording, even without isolation. It’s the slow rising and falling drone that sounds something like a distant lawn mower. When the shell is removed, the lower frequency droning sound is gone. You can see that in our frequency spectrum plot, where the shell-less test, despite losing the blocking wall, is quieter in some of the lower and mid frequencies. The wall helps block some of the higher frequencies, as expected.", "The noise also wasn’t present during our testing with the NH-D9L air cooler, so some aspect of the CLC fans makes the behavior arise and it’s probably the fact that they are right up against the shell. This could be a blade passing frequency impact.", "Here’s an ", ".", "“Distant lawnmower” really is our best description for it.", "If you want to learn more about odd acoustic behaviors like this, check out ", ". ", "The ", " is a looks-focused case that prioritizes form over function, specifically in regards to thermal performance and airflow.", "It is easy to build in but requires extra care when it comes to cable management. ", "One of its design flaws is that its fabric is restrictive to airflow. We proved this by cutting out one side of the chassis’ fabric and saw a 4 degrees C drop in CPU temperature. A more traditional metal mesh version would be better. The case would also benefit from ventilated sides to allow air to get out near the bottom.", "Another design flaw is that the top SSD bracket ends up being restrictive to GPU thermals due to blocking off the PSU exhaust when the PSU is oriented to help with flow-through GPUs. As is, the Mood is better overall as an air-cooled case than with a liquid cooler.", "Looking at a competing solution, we think the ", " pulls off the ITX tower concept better, despite locking you into a bundle of parts."]},
{"title": " Best PC Cases for 2023 So Far: New Designs & Computex Round-Up", "paragraph": ["Best PC Cases for 2023 So Far: New Designs & Computex Round-Up", "Last Updated: ", "The Highlights", "The amount of cases announced in the past few weeks is insane: We’ve seen a huge increase in Micro-ATX cases, like an open frame from Montech, Antec’s new foray into the enthusiast market, and the ", ". We’ve also seen the ATX towers get increasingly complex and advanced, like Lian Li’s new vision for the stand-up platform narrow tower design. This article recaps some of the best cases coming out over the next few months. We still need to review the cases individually, of course, but the market is booming with interesting options. Some are cheap, like the Montech X4 at $65 for 6 fans, and some are on the very expensive side -- like Silverstone’s $1,000 Alta F2 flagship case. We’re rounding-up everything we saw at Computex into one big best cases (so far) article.", "This article won’t cover cases that have already launched this year and instead focuses on everything coming out over the next 6 months. Of course, we’ll run a best cases piece after testing all of them too, closer to the end of year. ", "We’re starting with ATX cases and will go through form factors from there. The amount of cases at Computex was unbelievable and it’s an exciting time for PC enclosures, so let's get started.", "Steve Burke", "Jeremy Clayton", "Vitalii Makhnovets", "Mike Gaglione", "The Lian Li SUP 01 case is up first. We were more excited about this one than most of Lian Li’s other offerings, most of which are variations on the existing ", ". That’s not bad, it’s just not as fresh.", "The SUP is a completely new series for Lian Li, with SUP meaning “Stand-Up Platform” and building as narrow of an ATX case as possible while allowing a front-mounted GPU for a unique display of the most expensive part of most builds. Lian Li took what it learned from Mini-ITX and applied it to make the smallest ATX tower it could while still adding unique features.", "The Stand-Up Platform makes some major changes with the computer case: First, most of the cooling is actually on the right side panel behind the motherboard tray, which we’ve never seen before, with 6 fan mounts available to serve both the GPU exhaust and the CPU AIO cooler. You’ll likely need an AIO because there’s not great access to air with a tower cooler and because that chamber is short anyway. The case is heavily perforated on the right side, the front, and even the back. Fortunately, the lack of pressure in the motherboard chamber will encourage some air ingress through the rear holes to the VRM area, but we suspect that VRMs and M.2 SSDs may run warm in some configurations with this case. A small fan or VRM fan would help with this.", "Lian Li will be including a ", " molded Riser cable, but with an LED, and is using a mirrored tray in the bottom to provide some extra perceived depth since the GPU has been relocated to the front. Small touches are everywhere, like the Lian Li logo doubling as power and reset buttons and an adjustable tray for varying GPU lengths and thicknesses.", "This case will require a lot of specialized testing when we get it: We think it has a lot of promise to be an excellent performer with a truly unique presentation of the GPU. At the same time, though, it’d be possible to build an extremely poor performer in a case like this. They’re giving you all the tools to build a good or terrible computer with minimal hand holding. For example, some GPUs may suffer from dry out in this configuration, and likewise, boards with weaker VRMs having limited access to air could cause longer-term problems.", "But innovation can’t come without some discomfort as standard designs are departed. This is one of the cases we’re most excited to work with, and we like the direction Lian Li is going. The company must feel a lot of pressure as it has established its reputation as a brand that deviates from normal layouts -- to the extent that nearly everyone now has an O11 clone.", "The SUP-01 will be priced at $150 and will ship in Q4 2023. You can watch our video featuring the Lian Li CEO and designer ", ".", "For a quick runthrough, Lian Li also had 3 other cases. The largest was the ", ", which we detailed heavily back in December and is most interesting for its vertical GPU mount and heavy emphasis on mechanical aspects. The company also showed off its ", ", which is an updated O11D Evo with RGB LEDs and an optional kit to mount 160mm ", " fans. The final was its ", ", an edge-to-edge tempered glass design relying on magnets and some glue to still have sufficient structural support. The top glass panel is a one-way mirror with the mirrored side pointed down. It also has an adjustable and removable motherboard tray, taking some inspiration from the 216 previously.", "Now for the ", ". We didn’t cover this one independently at the show, so it’s the first time we’re talking about it on GamersNexus.", "This is Phanteks’ smallest (so far) of the NV series of cases, shaping-up more like a standard mid-tower size. The NV5’s primary unique feature is its angled bottom, using a 10-degree tilt. This aligns with the cutting angles on the front of the case, where the glass cuts across and follows the same 10-degree angle while opening up some of the bottom support.", "The designers noted that this endeavor is largely for looks, despite some functional benefit. On the functional side, the tilt allows a larger inlet for air toward the back of the case by increasing distance from the fans to the floor, thus reducing impedance to flow. Realistically of course, this could be achieved by just raising the entire bottom level to the floor -- but that wouldn’t look interesting. ", "As we filmed it, the case was loaded with an LED lighting kit that Phanteks aims to sell separately for $70. This includes strips on the bottom, side, and top, all of which are mounted magnetically. Phanteks is also making a magnetic LCD attachment for $130, using a small 1440p screen with HDMI and mini-USB hookups. It’s the accessorization of Phanteks. They, like many other companies, have long realized that add-ons make money.", "The case itself is what we came to see, though: Other than the bottom tilt, the case is notable for its support of up to 2x fans in the rear, including radiator support, as well as space for bottom, top, and side-mounted fans. Non-modular PSUs will be difficult to manage in this case, but the upside is the fan support in the bottom with open access to air. As for cable management, most of that is handled by the cable cover on the back-side of the case. ", "The NV5 will sell for $130 and should be available in August of 2023.", "Up next is the ", ", which the company says stands for “do, believe” and makes as part of their iBuild, iShare initiative focused on enabling PC DIY all the way down to the assembly of the case. InWin noted to GamersNexus that it started this initiative out of interest in bringing new aspects of PC building to a younger generation.", "That’s all very commendable, but what brings us to the case is the product itself.", "We saw the Dubili ATX case in InWin’s design center in a ", " on our channel, which itself is super worth watching for some behind-the-scenes on a cool location.", "The Dubili is a chassis largely made of aluminum and defaulting in silver, white, and orange coloring for the primary case styling. InWin is playing with champagne and other colors as well, but is seeking community feedback before pursuing them.", "The Dubili uses a function-focused ventilated front and rear panel, solid aluminum construction, and optional handles and extensions for the front and back side plates. These handles are modular and can be swapped with other styles of handles, removed for a handle-less design, or accompanied with leather grips that InWin is experimenting with.", "InWin plans to ship with 4x 140mm fans by default and noted that it can fit radiators up to 420mm in the front and up to 360mm in the top. Fan mounts are also present in the rear and bottom of the case, with up to 2x 120mm or 1x 140 in the bottom. ", "Rather than rivets, InWin is using allen key screws to hold the panels together. This makes it ultra modular and modifiable by users with access to fabrication equipment (or InWin’s future accessories). ", "InWin will have options to ship these flat-packed, similar to the POC series, to heavily cut down on lost shipping volume in containers, reduce environmental impact, and bake-in a DIY feature by eliminating rivets. Unfortunately, InWin told us that this doesn’t lower the price for consumers yet -- but it might in the future. We mostly like it for the mix of function-driven design with clean, unique aesthetics between the white/silver/orange and champagne colorways.", "Price is TBD.", "Montech’s Air 300 and 3000 Max also land on the list for being function-forward and using space well. The front panel is mesh, but Montech used some plastic bars in almost ", "-like spacing for a different look.", "Cases have mostly moved away from more than 2x 3.5” drives, but the Air 3000 accommodates up to 11 drives using both the space on the back of the motherboard and modular add-on drive cages behind the front intake fans. Most are sold as add-ons to reduce initial MSRP of the case. This used to be more common, but since most people have abandoned hard drives in their builds, modern options for cases with support for lots of them have dried up.", "The Air 3000 Max prototype also has a set of cutouts on the motherboard tray to accommodate the reverse-cable motherboards that several motherboard manufacturers showed off this year; however, because there’s no standard for the reverse cables, it’s difficult to anticipate every area that would need a cutout, but Montech did what it could without sacrificing too much structural rigidity. This is accompanied by 30mm of clearance behind the board to help with cable management. ", "The Air 3000 Max will come with 4x 140mm ARGB fans included, following another trend we noticed this year of most manufacturers moving to 140mm fans -- finally -- because they’ve had to deepen cases to allow for new GPUs. The case also has a pop-up dust filter that sockets into the front, something Montech is proud about with this design.", "There’s also a smaller version called the Air 300 Max that’s designed for Micro-ATX motherboards. It ticks most of the same boxes as the larger 3000, just with support for fewer drives and smaller radiators.", "Montech’s other cases are most interesting for their affordability in a market filled with expensive cases. Most interesting is the Montech X4, which we first talked about back in December. It’s the successor to the X3 case and keeps the budget price point alive at $60 for the black case and $65 for the white one. The case includes 6 fans, just like the X3, and now uses ARGB fans while moving away from the Molex Centipede we ", ". The case has also moved to a thicker steel this time around and will ship around October.", "Next is the ", " – a very O11-style case with a few Montech tweaks like the curved LED bar along the front. It comes with two front panels to give the choice between curved glass or mesh, although we favored the mesh front not just because of airflow, but because it’s a more unique execution of this style. The right side fan mounting is going to be changed to rails instead of holes, as doubling them up will only hurt performance and they serve no function, so it’s still in development. It’ll be available without fans for $110, or with 2x 140mm in the right and 1x 120mm in the rear (all ARGB) for more. Montech’s King 95 pricing scales from $110 to $160, depending on color and fan count. It will be available in November. ", "Deepcool also had an interesting entry into the case market. A lot of Deepcool’s past cases haven’t been particularly unique or they’ve been on the lower-end of the performance scale, but the company is pushing hard into higher quality cases now.", "The Morpheus is a pseudo-modular case that the company introduced, alongside other trending pseudo-modular designs from be quiet! and Lian Li. Each panel can be completely removed, so the case can be built in either a standard ATX layout or in a dual-chamber layout, with a significantly deeper cable management channel and a relocation of the PSU and drive cages to the back of the case.", "The aqua teal color that Deepcool showed off was initially intended to be just a one-off for the unveil, but after seeing all the comments from press and from you all below -- yes, these companies actually read them -- we’ve learned that they’re now seriously considering the colorway.", "Fans are still TBD. Deepcool considered a single molded set of 3 fans, but this is kind of counter to a modular case and we hope it won’t follow through with it. The case also includes an LCD with CPU and GPU temperature read-out.", "The case is airflow-centric and has a heavily perforated right side panel to accommodate side-mounted fans or radiators, a perforated front panel, and a heavily perforated top panel. They’re also shipping a bag of plastic pegs with each case. These are just a fun and low-cost way to do something clever without being overly serious. They fit in the mesh holes and, as long as you don’t block most of them, won’t impact airflow meaningfully but do add some character for pixel art designs.", "The Morpheus will be around $220 to $230, depending on colorway. ", "We have a whole ", ", so we’ll keep this brief. Our favorite case at the booth was the RM600 – a large dual chamber case with 12 hot-swap drive bays and dual power supplies. We didn’t get much imagery of it, but it can be either rack-mounted or stood up on casters to make moving it around easier. There’s enough room inside and cooling potential to build a really nice homelab or office server.", "Silverstone also showed off its D1 case, which is aimed at the workstation crowd and supports dual-CPU motherboards with up to 11 expansion slots. It also has three of Silverstone’s new Air Penetrator fans on a hinged front panel to allow access to multiple drive bays. ", "Finally, the ", " is an ultra-enthusiast case with a 90-degree rotated motherboard, multiple video card mounting locations, and three Air Penetrator fans to move air from bottom to top. The F2 sits atop a large intake chamber to establish a top-to-bottom flow path, more similar to Silverstone’s old Raven series. These cases are both expensive, at about $600 for the D1 and $1,000 for the Alta F2. Go check out our ", " for more on its new cases.", "Be quiet! has 3 upcoming major case launches: The Shadow Base 800, which is its cheapest at $170-$230, the Dark Base Pro 700 in between, and the Dark Base Pro 901 at $300.", "We’ll focus on the 901 in this section as it’s the most complicated, but check out our previous ", " coverage for a cheaper (but not cheap) be quiet! case with new tooling.", "The ", " sticks with the invertible functionality of the chassis, but this time makes it much easier to do with fewer screws and panels to relocate. The case can be configured either in standard layout or flipped and inverted, and has a fully separable motherboard tray for this. The case includes a lot of optional pieces that contribute to its cost, half of which you won’t use because they’re one-or-the-other options. The front panel can be swapped for mesh or kept with a brushed aluminum plate, the top can use deadening panels or mesh (both included), the fan cages are fully separable as well, and other small mechanical elements are present everywhere in the case. The PSU shroud has a side plate that can be removed and has its integrated LED header molded-in and other cages and panels use pogo pins to reduce wiring holding plastics to the frame. In-line with wiring reduction, the GPU support also includes a channel for cable routing and works in either standard or inverted layout.", "The case goes heavy on I/O support, with 4x USB3 and 1x USB Type-C in the top, plus an option for a 5.25” bay in the bottom (or just more hard drives). ", "At $300, you’re mostly paying for flagship features and functionally 2 sets of parts for half the panels, since they’re replaceable with airflow or deadened alternatives. The case should be available within a few weeks.", "Next up is the more affordable ", "TG, priced at $100 to keep the lower-end market alive and launching within about a month. The case includes 3x 140mm ARGB fans and looks like it’ll be good for airflow. We liked Thermaltake’s attention to detail on the ", ", namely the bottom fan position having good unrestricted access to air, and the dust filters lining up well with the perforations in the top panels rather than accidentally obstructing them. Several years ago, we criticized Thermaltake for stacking up filters and panels in a way that severely hampered the fans, but that looks like it’s gone now – we like to see that growth in the designs. Colors are available in black, white, and the matcha green colorway. The main point of interest for this one, to us at least, is the inclusion of the 3x 140mm fans with relatively good ventilation while still being $100. With so many cases over $200, the presence of something more “normal” is critical to keep PC building affordable.", "Next up is ", ", using the company’s new case form factor that centralizes the motherboard and rotates it. This is a slimmed-down version of the recently launched C750 and is about 120-140mm shorter. This layout lets you fit radiators on both the front and back, unlike most cases, while still offering bottom and side mount fan support. Optionally, both the front and rear support mounting 2x 200mm fans instead of the radiators. The GPU can also be mounted flat on a riser in what would normally be called “vertical mounting” in a standard layout. The rear chamber is deep with plenty of room for cables and both 2.5” and 3.5” drives. Pricing for the C700 is $160 for the mesh version and $180 for glass. This one is most interesting for its potential as an open-loop system.", "Streacom’s SG10 also interested us at the show. This is a fully passive case that includes two pump-less loops for circulating refrigerant and will sell for around $1,000, priced that high because of the massive amount of aluminum going into building the included radiator (which is a structural part of the case), the loops, and the kit for adapting a GPU to this passively-cooled system. The fins are spaced wide apart to allow the heat to leave with minimal obstruction.", "We never covered this before, but our new understanding is that LTT covered it multiple times back when a different company was Kickstarting the project. In the time since, Streacom has stepped in as an experienced manufacturing partner to try and get it made. Streacom is best-known for its manufacturing of the Open Bench Table and, other than bailing-out Calyos, wasn’t involved in the original Kickstarter. We’ll probably talk more about the abandoned Kickstarter more when it comes time to review the case, but for now, this show was our first hands-on exposure to the concept.", "The SG10 uses copper tubes -- not heatpipes -- to cycle refrigerant through a loop. There are zero fans in the case and, as long as you adapt the GPU to be passive with the included kit and buy a passive PSU, there won’t be any fans in the system at all. It’s an expensive way to go fanless. The case is built of black aluminum fins, black structural steel vertically, and silver-colored aluminum blocks for some accents. Front I/O is movable to anywhere within the front or rear of the case as it’s just mounted between the structural support, and the bottom uses acrylic as a floor. ", "The next category is for Micro-ATX. The Air 300 won’t be in this one since we covered it in the Montech section, but everything else is here. Micro-ATX is finally getting attention for the first time in about a decade, and it’s because the extra slot length of GPUs spills over ITX anyway.", "Montech also showed an open frame case for Mini-ITX and Micro-ATX motherboards that’s extremely reconfigurable. It can be assembled in up to 5 ways ranging from as small as only the motherboard and PSU, to adding a CLC and a massive GPU on a riser, with other configs in between.", "One interesting thing is how the motherboard mounts – the standoffs face rearward on the frame, meaning you screw the board down from the back side. This visually recesses the board for a clean and integrated look from the front. Since the rear side has no sort of cover, it looks industrial at best - more like a test bench. The PSU mounts behind the motherboard in all configurations, but one option is a frame that can also hold the aforementioned CLC radiator. This makes for more overall width, but also more cooling potential without having to hang a giant tower off the socket.", "Most of the parts are made out of thick machined aluminum and held together with screws, so it seems sturdy. Between this and the customization options, it would be good for people who enjoy the assembly process itself. Montech is also playing with an option for a wooden base for more of the wood and metal aesthetic we saw at the show, but the type of wood and color isn’t final.", "Antec is up now, which is the first time we’ve talked about them in many years.", "Antec revolutionized the case market in the early 2000s, and was actually the maker of the first case some of us in the office ever bought. They fell off hard after the Antec 900, then lost their way by chasing mobile batteries and other products for a few years. Now, Antec is trying hard to make a return. The team we met was serious about it.", "The company had its ATX Performance cases present, but those have been out for a little while now. They’re considering shipping even higher performance variations with thicker fans, so that’s something we’ll return to.", "Antec’s main showing was the Constellation M-ATX 540, which itself is based on the same supply as the ASUS Prime AP201. This is a Micro-ATX case with a few design upfits to accommodate 40-series cards.", "The Constellation is lengthened for an extra slot for the GPU, supporting up to 5 slots. That also helps with additional spacing for breathability. The case has a small, simple display on it for temperature readouts, with the display connecting via USB 2.", "The case will be available in white with a tempered glass version, a full mesh option, and a solid “silent” option with foam damping.", "Pricing is $80-$100 (depending on SKU) and it should be available late quarter 3.", "Next up is the ", " – an updated and larger Tower 100. Thermaltake took a lot of our criticism from the original Tower 100 and put those insights into that final version and this new case targeting both cooling performance and somewhat showcase aesthetics.", "First off, The Tower 200 has been stretched just enough to allow for Micro-ATX motherboards, up to 4-slot GPUs, and a 280mm radiator on a removable bracket on the right. The case has an increased focus on airflow with the left side panel being entirely ventilated to allow access to fresh air for the GPU. There are lots of other vents and perforations elsewhere, like the 2 fan mounts in the rear of the case and one on the top to help exhaust hot air from the system. The rear fan mounts don’t look like they do anything since they’re against the motherboard backside, but there’s enough of a gap that they end up pulling air from the GPU exhaust.", "At the bottom front, Thermaltake included a removable panel to fit the same LCD screen it’s been using on other cases like the Ceres 500 and 300. The Tower 200 is launching in 5 colors, so those looking for options outside of black and white will have turquoise, racing green, and matcha green to choose from.", "Mini-ITX also had an increase in attention this year -- largely because manufacturers are re-designing to fit large video cards in while still allowing cooling.", "Fractal’s showing was one of the more refined Mini-ITX cases. The company had its ", " on display. This one is Fractal’s second smallest case, right behind the old Node series. The ", " primarily interested us for its mechanical construction: The case top panel pulls off with a strap and the side panels are Gull-wing door-style, both of which fold up and then can be removed entirely with a switch. This gives relatively free access to the case interior for the build, although there’s no getting around it ultimately still being cramped. The center spine in this sandwich-style is also mobile and can be biased toward either panel to allow for a larger CPU cooler or GPU cooler, using a free-movement system with guiding tick marks to adjust the tray.", "The bottom of the case can technically fit fans, kind of, but it’s likely you’ll run into cabling issues. This case primarily tries to cool itself by feeding air directly to the GPU via the side panel venting, and the same for the CPU. Regardless, it’s not a top choice for an i9 and RTX 4090 -- we’d recommend a build below that class just to limit thermal challenges.", "Visually, Fractal has black, silver, and this green color that we saw. The green version uses a darker wood accent on the bottom front, secured with screws to a thick aluminum plate with some detailed CNC work. You can learn more about that aspect in our ", ".", "The case is already out. Pricing is $180.", "InWin took part of its new ModFree series and turned it into a standalone Mini-ITX case with wood paneling. This is something InWin tried long before the Fractal Design North, but never had wide-reaching success with.", "The straightforwardly-named ModFree Mini is based on the module that holds the PSU in the regular ModFree ATX set, but was modified with mounting locations for a motherboard, SFX PSU, and GPU. It’s finished with wood slat side panels somewhat similar to the ", ", as well as brown top and front panels. It’s a clever re-use of an existing design that shows some of the creative spirit we saw while touring InWin’s design center. We don’t know what price the ModFree Mini will be and we’re uncertain of airflow at this time, but it’s clear that InWin wants to try alternative materials again.", "Another Mini-ITX case we saw was the InWin POC 1. It ships flat-packed for you to assemble yourself, including some bending. Rather than rivets and screws, the case uses velcro or possibly leather straps -- they’re still deciding -- and some shaping of the panels. Once you do that, you’ve got a case. We think this is a neat idea, but have some reservations about the GPU cooling and how much people will care about the self assembly if the price isn’t any lower than other ITX cases. The POC 1 is also experimenting with wood paneling, but it’s not final yet. This case follows-up the existing POC lineup, which has multiple bright color variations, like yellow, blue, green, and more. That case already launched, though.", "Last is the Acer Orion X, which checked out as a fully-assembled pre-built at the Acer design headquarters. Acer told us it plans to also sell just the case in the DIY market towards the end of the year. This is a sandwich style Mini-ITX case with some cool mechanical elements, like the latches to release the side panels (including intuitive labeling), a removable top panel for easier access during the build, and a hot-swap M.2 enclosure in the front that can also be used as a standalone M.2 drive. Some of it verges on being gimmicky, namely the top headphone hanger/handle, but in every respect, Acer is trying to be taken more seriously in design and get away from association with just cheap laptops.", "Acer is going for a “space station” inspired look, it told us. The price is the biggest challenge: At $300, that’s solidly in the same range as low-volume boutique ITX cases. Overall though, we like what Acer is going for with the Orion X and plan to review the pre-built separately."]},
{"title": " Water Cooled Mini-ITX Review: Dan Case A4-H2O Thermals, Noise, & Cable Management", "paragraph": ["Water Cooled Mini-ITX Review: Dan Case A4-H2O Thermals, Noise, & Cable Management", "Last Updated: ", "The Highlights", "For ", " of our ", ", we’re looking at the ", ". It’s specifically designed for accommodating, as the name suggests, liquid cooling in the form of a 240mm CLC. The name is H2O, despite the fact that ", " contains multiple instances of both H2O and H20. It also has some impressive GPU thermals for the size due to clever airflow management, but there are drawbacks, including the cable management.", "It’s available for $155 at the time of writing, putting it up against options like the ", " (that we recently ", ") and the ", ", with comparable prices depending on the exact model. At the time of writing, the Terra tends to be around $180 and the NR200P is around $145. There are tons of Mini-ITX cases out there these days and we’re only getting started rolling into more reviews of them. We wanted to get to this one next because, as another sandwich-style Mini-ITX box, it has managed to position itself as one of the mainstays.", "Steve Burke", "Jeremy Clayton", "Patrick Lathan", "Vitalii Makhnovets", "This design has roots that go way back, and Lian Li has brought it forward over the years, so this is going to be an important one for us to keep developing our test methodology. We’ll continue to iterate on our process, but we need to test a good cross-section of cases to establish future test parameters and conditions. There’s an exploratory phase to methodology development, and that’s what we’re doing now with Mini-ITX. The A4-H2O makes a good fit to follow our Terra review then, since it’s a more ‘traditional’ ITX design. Check out our Terra review for more discussion on how specifically we’re approaching ITX reviews as a whole.", "The A4-H2O has the components compartmentalized on two sides – similar to the Terra only in that respect, but without the moveable spine. They’re mechanically very different, and thermally of course, because of the cooler support. This deviates quite a bit from the Terra, which means some of the components in the test bench have changed, like the cooler. Interestingly, the video card actually ends up upside down inside the case, and it’s attached via a PCIe riser cable. The power supply mounts on the same side as the motherboard.", "The A4-H2O is a direct descendant of the ", ", but with what it calls “improved hardware compatibility,” which mostly means it’s larger to allow things like a triple-slot GPU. The main difference is in the H2O part – the ability to mount a 240mm liquid cooler radiator in the top of the case. The original A4-SFX only supported either 92mm or 120mm liquid coolers with heavy compromises. There are other tweaks versus the H2O’s precursor, but most of the focus is on the liquid cooling, given the name.", "Aside from the obvious potential for keeping CPU thermals more in check versus a small air cooler, having the 240mm CLC take up essentially the entire top of such a small case helps to prevent hot air from lingering inside. This has an impact on other components in the case that we’ll see the effects of in the thermal section.", "The biggest other feature is the removable bottom panel, which helps with access to the bottom edge of the motherboard and the limited cable management area under the PSU. ", "This makes it possible to add and remove modular power cables without removing the PSU. The panel comes off easily with 5 screws, although we’d like to see a larger hole here. It was still a little difficult to plug or unplug some of the PSU cables, and more clearance would help. Every millimeter counts in these small cases.", "The case measures in at 340mm long, 141mm wide, and 251mm tall, which is larger than the advertised 326x140x244mm. The difference between advertised and actual dimensions also means the calculated overall volume is 12L rather than the 11L number that Lian Li declares. This is another example of the manufacturer choosing to ignore protrusions like screws and case feet almost arbitrarily, and we again stand by our decision to include those protrusions. ", "This is a gripe we have with cases in general, this isn’t just a Mini-ITX thing. Sometimes they choose to ignore things that stick out the back of the case. There was one such instance at Computex this year. We saw a case, and we'll see if they come to market like this, where they were electing to not count an additional 1 inch protrusion out the back because it wasn't part of the structural case, it was just a hard drive cage or something.", "When it comes to these protrusions, using the case without them isn’t realistic. Even if not counting them toward volume, they should be counted towards exterior measurements. To choose to ignore certain protrusions is not only a slippery slope, but could mean someone just barely isn’t able to fit a case in a media console or corner.", "Part of the feedback we got on the Terra review was to include a “footprint” figure – meaning the 2-dimensional area the case takes up on a desk. We integrated a lot of the feedback from the community, as you’ll see in this review, like switching power supplies. However, there are some things we’re not integrating, and we wanted to use this as an example. An area calculation, in this instance, doesn’t make much sense as a review metric. Really, what you need is just simple length by width, and that’s kind of it.", "The A4-H2O’s footprint calculates out to 479cm", " – try to visualize that. We think it’s even less intuitive than volume, and that it mostly serves as a semi-arbitrary way to create a single number to rank cases. Footprint loses the directionality of length and width measurements, which are what matter for visualizing the area a case will take up on a desk. A theoretical case that measured 50mm wide by 400mm long would have roughly the same 200cm", " footprint as one that measured 141mm by 141mm. It doesn’t really tell you anything.", "Sometimes, we don’t need fancy reviewer metrics -- just plain old length by width already tells us the footprint, and it’s something you can read in the spec sheet and measure without needing us. Assuming the manufacturer is being honest about the dimensions, that is.", "Let’s get into the build quality details.", "The A4-H2O is designed around one specific type of build, resulting in a focused and intentional overall package. This is evident throughout the build process and the manual – it has limited options and choices. That’s not a bad thing though, as we can appreciate products that do one thing well over trying to do too much at once and failing.", "Both the PSU and the radiator mount to removable brackets within the case, which has become a popular approach in small and large cases alike. It gives flexibility to the designer and can have ease-of-use advantages for the builder.", "Once assembled, the radiator and bracket install without much hassle – as long as there aren’t too many wires to manage. These fans act as the only active airflow for the rest of the case as well, and there are no additional fan mount locations.", "There’s basically zero wasted space in the motherboard side of the case – everything fits extremely snugly. The ", " we’re using has a particularly bulky rear I/O cover that barely clears the radiator section at the top, and we had to angle the board in from the bottom edge first to make it fit. ", "The top edge of the board is barely accessible with the radiator and fans in place, but that can be mitigated by leaving the cooler out or not fastened in place until finished with the motherboard.", "Power supply installation is pretty straightforward, except for one note. Depending on where the on/off switch is located on your power supply, the thickness of the cooling solution, the size of the GPU, etc., it can affect the accessibility of the power switch itself. We would recommend toggling it on before you install it. However, if you didn't toggle it on, you can remove the four screws from the cooler bracket to get access to the power switch. With the cooler installed, we can still just barely access the outer edge of the PSU. Depending on the choice of power supply, and more importantly the length of the GPU, it may become less accessible. ", "Installing the GPU into position on the included riser cable is made easiest by turning the whole case upside down. We didn’t encounter any real problems with this process, and the space within the GPU chamber is generous considering the overall size of the case and the size of modern video cards. We’ll talk more specifics about GPU fitment a little later. Once the card is screwed in and the case is upright in its final position, the GPU ends up upside down.", "Thermally speaking, in most instances being upside down like this won't really hurt anything. A GPU with a vapor chamber is already in effectively its worst orientation when it's installed in a standard ATX case horizontally, because it’s fighting gravity at that point. So, the GPU being upside down in a vertical orientation like it is in the H4-H2O isn't going to hurt the performance of the cooler in any meaningful way – at least not based on what we've researched. You can see ", " with NVIDIA's thermal engineer Malcolm Gutenburg for more discussion on the topic.", "There’s some flexibility for 2-slot cards – two standoffs are included that allow the user to mount the GPU into the outer two slots rather than the inner two. This is intended to help by giving the GPU more direct access to fresh air through the side panel. We tested in both configurations for the thermal section later.", "Our main complaint with the A4-H2O is cable management – it’s more non-existent than it is bad. There aren’t any dedicated cable management features or tie-downs. Lian Li just throws in two cable-ties and an implicit “good luck.” Compacting the components this close together leaves the user with very limited areas to shove or tie up cables. There’s really only under the power supply or in any area of the GPU side that isn’t occupied by the GPU itself. It’s definitely workable. You’ll just spend some time to get it really nice -- but in ITX, that’s expected.", "Our Fractal Lumen S24 RGB has individual cables for the fans and RGB of every component, so fishing them into the case and later finding places for the excess length to go was a challenge. We could have managed the wires in a more tidy fashion elsewhere within the case, but we wanted to keep the GPU side uncluttered for GPU fitment testing.", "The motherboard side of the case leaves the user without any other choice but to lay cables over the top of the board until they can go to an area of free space. With careful planning and a lot of patience we’re sure users could end up with a clean looking build, but it’s not easy. We’d recommend against fans with individual RGB cables for a start, though.", "The case is constructed in a straightforward, almost formulaic way with flat exterior panels attached to an inner frame via pushpins. In this respect it’s similar to other Lian Li built cases like the ", " and the ", ".", "Despite the use of thin stamped metals throughout, the case maintains surprising rigidity. We were impressed with the overall sturdiness of the case. Thin internal pieces do flex when manipulated, but as assembled, the build quality is good. That’s important for a case that you might actually take from place to place in a semi-mobile setup. Lian Li has obviously gotten this method of construction down to a science – balancing simple materials and mature manufacturing methods to make a competent final product. ", "The CPU cooler clearance is only 55mm, but running an air cooler goes against the main selling point, which is support for 240mm liquid coolers. Though it is important to keep that clearance in mind for the CLC pump block – it’s best to opt for coolers where the tubes exit the side rather than the top. ", "The upper area where the radiator and fans sit measures at roughly 275mm long, 132mm wide, and 58mm deep. This is tight enough that users need to pay close attention to the dimensions of the cooler they want to use. The ", ", for example, doesn’t fit.", "The manual’s suggested tube routing represents an ideal case that isn’t easy to replicate with the ", " CLC we have. We ended up needing to squish down on the tubes with the side panel to make it close, but we don’t think it’s to a problematic degree. Users should definitely experiment with different mounting orientations and tube directions for best results.", "The GPU side of the case is spacious and forgiving compared to the motherboard side. GPUs up to 322mm long, 150mm tall, and 3 slots (60mm) thick are supported. There’s even considerable space (by ITX standards) over the bottom of the upside-down GPU.", "The front of the case has a hole that’s supposed to help with installing particularly large GPUs. Lian Li shows it being used to load the GPU in from the front of the case, but in practice it’s pretty awkward to do with the liquid cooler tubes in the way. More practically, the user can angle the long end of the card towards the hole from the inside, then bring it back in to slot the card.", "Installing the RTX 4080 or 4090 FE is difficult but not impossible. Once it’s in there it takes up almost all of the available space in such a way that makes us think the size of this cooler was a critical dimension during the design process.", "Since the vertical space is so generous, even exceptionally tall cards like the (obsolete) ASUS Strix Vega 64 fit fine. The ", " is too long to actually fit, but thanks to the open hole at the front it’s technically possible for GPUs of infinite length to slot in.", "Another piece of feedback we got after the Fractal Terra review that we actually agree with was that despite the power advantages of SFX-L, most small form factor builders still opt for standard SFX power supplies for ease-of-use sake.", "A proper ATX 3.0 compliant 850W unit is enough to power nearly any consumer build as well, so we’ll be opting for this ", " as our standard going forward. We’ll use the ", " for SFX-L fitment testing.", "All that said, the A4-H2O supports SFX-L models, with the obvious reduction of cable management space below the PSU. Users will need all the space they can get here, so we recommend sticking with regular SFX.", "As we get into this, keep in mind that our goal with ITX reviews is to review only the case, so we're analyzing things like the impedance caused by the panels, the airflow path, and the compactness of the components affecting thermals. Because of that, these results can’t be compared to our other ITX case reviews due to different coolers. That just becomes a cooler benchmark at some point, and we already do those separately.", "First up are CPU thermals under a full system torture workload. Our “default” setup for the A4-H2O has the system at a fixed 62% fan speed on the CLC, 100% on the pump, motherboard fans off, and the GPU in the interior position with fans at 44%. The GPU fan speed is chosen by the nominal speed of the fan under the standard VBIOS temperature targets, while the CLC fan speed is chosen based on noise targets. This results in 36.5dbA as measured in accordance with our old ATX case testing methodology, outside of the chamber in a noise floor of 26bA. Noise analysis from our hemi-anechoic chamber comes later.", "The default setup at steady state had the P-Core average at 57C delta T over ambient. Locking the CLC fans to 100% dropped it by 5.4 degrees, actually outperforming the no side panels result (with reduced fan speed) too. That and the small change between no side panels and the default result stand as a testament to the efficient airflow pattern the A4-H2O provides. All of the airflow is directed through the top-mounted cooler, pulling air over most other components, and the panels aren’t too restrictive, as shown by the “No Side Panels” test.", "Flipping the PSU around so the fan faces the GPU isn’t covered in the manual, but it is possible. In our testing, it didn’t change CPU thermals. The same can be said for running the 2-slot RTX 4070 in the outer position, but the data leans slightly warmer on the averages.", "That brings us to GPU thermals, where we have GPU die idle, load, hotspot, and memory temperature. The default setup is actually the worst on the chart, but the 53-degree-over-ambient load average is still completely fine -- we’re in the 70s when ambient is added in. Running the CLC fans at 100% didn’t move the needle for the GPU, despite extra air movement into the case, but flipping the PSU to aid the flow-through 4070 FE dropped 2C off the load and hotspot readings versus default.", "Pulling the side panels gained a little more, but as always, is just to illustrate impedance caused by case design. It’s not much. The real winner here is that outer mounting position for 2-slot cards. That setup gained us between 6.8 and 8 degrees off core load, memory, and hotspot. That’s a massive gain for a GPU, and that’s without any changes to fan speed whatsoever. That’s because the GPU is now in a position to draw in fresh air from directly outside the case, so the flow-through exhaust has more space to blow into, and that warmed air is immediately pulled out of the case by the CLC. This is what an efficient and less restricted airflow path can do.", "Noise levels are simple for this one. We’ve done a number of deeper explanations on our acoustic testing process now, including our ", " of the hemi-anechoic chamber, the ", " that followed, the ", ", and the ", " ", ". Check each of those if this process is as cool to you as it is to us.", "For this one, we’ll just look at one chart.", "Because this isn’t comparative against other ITX cases due to a change in components between the smaller Terra and the Dan Case, we’re only going to look at the noise characteristics between the choice we found most impactful: The GPU positioning. If you’re running a 2-slot card, especially one with a flow-through area, we’d strongly recommend the outer position. But we need to see if that meaningfully impacted our acoustics. This will vary heavily based on fan blade design of the GPU behind the panel, but the FE card uses a fairly standard modern blade design.", "Plotting the GPU stock position first, we saw the noise profile of the case from straight-on at 1m distance was loudest in the 500Hz to 900Hz range. “Loudest” here just in the comparative against other frequencies, but not actually in a bad way. Overall though, even in this range, the profile is not indicative of any deviations that would be perceived as particularly unpleasant to a listener. This makes sense: As the panels aren’t perforated in a way that causes a whiny or turbulent noise from the fans and air movement, we have a frequency spectrum that primarily represents the components chosen and doesn’t reflect much direct negative impact from the case.", "Adding the GPU outer position, there’s functionally no difference in results. Moving our card to the outer position had significant thermal benefit and no objective acoustic change. There’s really no downside to having it this way.", "The ", " is a focused and competent mini-ITX case. There’s not a lot of freedom or choice in how the system is built, but that’s not what this case is here to do. It wants to do one or two things well, and it succeeds. That’s fine as long as the user is aware of it. The case probably shouldn’t try to do too many more things at a size like this. The experience in both the design by DAN and the manufacturing by Lian Li come through.", "The thermals are good, bordering on impressive for the size – particularly for 2-slot flow-through GPUs like the 4070 FE. We wouldn’t recommend going wild with part selection, but compared to the Fractal Terra, we'd be more comfortable with running higher-end parts like a 13700K and RTX 4080. There’s some thermal headroom to spare from our configuration.", "Mini-ITX cases tend to run on the expensive side. The Fractal Terra was $180, and there are plenty of other cases in the $200 range, plus or minus about $20. The price for the A4-H2O at $155 ends up being one of the more competitively positioned cases. Yes, there are some options like certain ", " variants that are very worth considering, even today. We’re still adding cases to the list, and we’re looking forward to testing lower cost options as well. ", "Despite being cheaper than ", " or a FormD T1 Sandwich, the A4-H2O does feel a little expensive in our opinion – just strictly based on what it is in isolation, given the construction methods and relatively simple design. It’s just not out of line for the mini-ITX crowd. This comes back to two factors. One is economies of scale – lower volume leading to higher manufacturing costs relative to high-volume ATX cases. The other is being adjacent to the boutique side of the market, where enthusiasts are willing to pay.", "The people who might be the most frustrated by this are ones who want perfect cable management or those who want to retain unrestricted access to the motherboard. The removable bottom panel is a helpful feature in that respect, but ultimately has limits as to how much it can help.", "Overall, we recommend the A4-H2O for anyone who wants to get higher-end components in a small package. That comes back to the 240mm CLC, it really opens up options for the CPU and creates a pressure system within the case that sucks out lingering hot air."]},
{"title": " Fractal North XL Case Review & Benchmarks: Wood Panels & Mesh", "paragraph": ["Fractal North XL Case Review & Benchmarks: Wood Panels & Mesh", "Last Updated: ", "The Highlights", "It's been a year since we published our last case review, and in that time we've been updating our hardware and our methodology to better represent modern systems. This is the first one back. Our new case testing methodology is almost 100% complete, but we have even more tests that we’ll be rolling out that didn’t make it into this one. We’re working on a standalone case methodology piece that’ll be posted in the coming weeks, as we made some huge discoveries that we want to really document into a big research piece for everyone.", "That means we’re still working through the archives and backlog to get everything on the new charts, but for now, we're starting off with the brand-new, $180 ", ", both the ", " and ", " (TG) variants. The TG version has a glass side panel, while the Mesh version has a mesh side panel and an extra bracket for mounting fans to the side of the case. Otherwise, they're identical. This case can even fit 180mm fans up top, making it one of the more interesting cases to build in.", "Steve Burke", "Patrick Lathan", "Vitalii Makhnovets", "Jimmy Thang", "The original ", " is ", ", all the way back in February of 2023. It's a small, open-fronted mid tower in the style of the old ", ", or the newer ", " Compact. Following those naming conventions, the ", " should have been the North Compact, because the new ", " is close to a completely normal size. It has almost exactly the same dimensions as Phanteks' older ", ": large, but not extra large. The ", ", for example, is much bigger than the North XL by volume. Fractal already had to come up with Nano for its sub-Compact size, so if there's ever an even larger SKU, it'll need to be named the Giga North.", "At $180 for all SKUs, the North XL is priced between Fractal's own ", " and ", ", and on par with the ", " and ", " (the non-RGB variant). Out of those, Corsair's design is the closest to the North XL; ", ", but it's aging, and the price is being propped up by three years' worth of positive user reviews. As for new cases, $180 is just above the ", " (depending on the King 95's color). We'll compare thermal performance later in this review.", "We have to give some time to the case's appearance up front, because it's the reason the North has been so popular. The XL has the same wooden front panel slats as the original, still offered in oak or walnut with the white and black SKUs respectively. It looks great. ", "Our ", " was of a white North, but seeing both, we have come to prefer the darker variant with gold accents. ", "One warning from our original review still applies: case lighting is a waste inside the XL with the mesh panel. At best, it's invisible, and at worst, it silhouettes the reinforcements in the side and front panels.", "There are two main things that the XL's additional space gets you: more clearance for components and more flexibility for cooling. ", "Regarding components, the major change is that the XL can fit GPUs up to 413mm without removing any fans, which is enough to fill a 16-inch pizza. This is up from 355mm in the original. The 4070 Ti we use for case testing fits in the original North, but there's not enough space for Gigabyte's GPU support bracket; the XL, however, has enough space for both the support bracket and the GPU.", "The XL also reduces the problems with clearance that the original North's side fan bracket (exclusive to the Mesh version) had with both CPU and GPU coolers.", "To start with, there are only two possible positions for the bracket in the XL versus three in the original, which is more of a simplification than a downgrade. Putting the bracket in the upper position will mostly benefit downdraft coolers, but it can fit over tower coolers up to 155mm tall, which is enough to fit even the ", " that we use for case testing. Moving the bracket to the lower position focuses cooling on the GPU. ", "It's compatible with most GPUs, but it may put some strain on cables with extremely wide cards with power connectors on their edges, like the ", " or the MSI Twin Frozr model from our old case testing bench. This is one measurement you should check before buying: the total distance from the surface of the motherboard to the side fan bracket is 165mm.", "Fractal has used standard hole spacing on the entire rear of the case within its ventilation cut-outs, including in the PCIe slot covers and the top of the PSU shroud, meaning that case fans can be mounted in effectively any location where there's enough space—and since the XL has more space, more locations are viable. This really opens up cooling options in ways that don’t necessarily appear on a spec sheet.", "This does mean that the entire top of the PSU shroud is see-through, though, which doesn't help the glass-sided SKU to look its best. If your PSU cables don't match the color of the case, they'll be fully visible. The white variant would go best with custom cables unless going for a black-and-white theme.", "The holes also mean that the shroud top is no longer a possible mounting location for the two included 3.5 drive brackets, so although the North XL's total drive capacity is the same as the original's, there's one less choice about where to put those drives. ", "The official absolute maximum capacity is four 2.5 drives and two 3.5 drives, and that's with double-stacked drives.", "Still, the XL's size makes it more practical to actually use the mounts without competing for cable space, so that’s a big positive for those using non-M.2 drives.", "The original North was small enough that fitting anything larger than a 240mm CLC was ambitious, with a hard limit at 360mm. The XL can fit a 420mm radiator in the front, although we'd mainly recommend doing so with open-loop cooling. Closed loop coolers function best in a tubes-down orientation, and a 420mm CLC oriented tubes-down would be a tight fit in the North XL. This isn’t deadly for the pump in the same way that positioning the pump at the top of a loop is, but it is more likely to introduce bubbling noises as air at the top of the tank finds its way into the tubes. This will happen more as permeation increases. ", "For radiators over 240mm in size, fans must be mounted to the outside of the chassis and radiators on the inside in order to clear the PSU shroud cutout.", "As for the top mount, the space above the motherboard's top edge has been more than doubled, from 3cm to 7cm. That’s a huge size improvement for larger builds and leaves plenty of room for cables even when using the top fan mount, which now fits the aforementioned massive 180mm fans. Also, the extra case width shifts the top mount further from the motherboard, so mounting a radiator with fans in the top slot is now less likely to conflict with VRM heatsinks or RAM. Still, we'd always like to see a removable mounting tray just for ease of access. ", "The cutouts below the motherboard haven't really changed, but the width of the case makes them more usable, since previously they'd be partially blocked by an ATX PSU.", "The included fans are 3x 140mm ", " with a max rated speed of 1,700RPM. All three fans are mounted at the front of the case, completely filling the front slots with zero room to spare. ", "The built-in fan hub simply splits one four-pin PWM input across four channels, so there's one extra, but each fan also has a daisy-chain connector, meaning there are still four open plugs for additional fans out-of-the-box. ", "If you want to add your own, it'd be preferable to use four-pin PWM fans so that everything can remain PWM controlled.", "Fractal has a good track record for taking E-ATX support seriously and in a way that’s less likely to trigger another ", " from us. The North XL continues that trend with standoffs and cable cutouts to fit full 12x13 SSI-EEB boards. In order to support the additional standoffs, the motherboard tray is entirely flat rather than having a cable channel at the front. ", "As a result, the maximum cable clearance is very slightly smaller than the original North's (29mm versus 30mm by the spec sheet), but the XL maintains that clearance across the entire motherboard tray. ", "3cm is acceptable, not amazing, but fortunately, we exist in at least 3 dimensions -- and that’s not counting the 4th dimension that ", ". The total volume available is much greater than in the original. ", "There are six velcro ties included that follow the most logical cable management paths, as well as a seventh on the rear of the case to tidy-up peripheral cables. We'd borrow that tie to manage the CPU power cables instead.", "We only ran into minor fit-and-finish issues during our build: the slot for inserting the PSU into the rear of the case has extremely tight tolerances that may require some extra force. Also, the top panels on our review samples (especially the tempered glass variant) don't snap into place as tightly as the original's, which is a problem since the top panel can't be screwed down. The panel can slip around easily when you try to pick it up.", "To recap the areas we think Fractal did the best, there's more room for everything. The extra clearance at the top of the case makes it more accessible during the build process, and it opens up more cooling options like 180mm fans or radiators that won't get in the way. ", "Also, the side fan bracket that comes with the North XL Mesh is more usable, since it's much more likely to clear any given GPU or CPU cooler than it was in the original North. As for components, Fractal has done more than the bare minimum to support E-ATX boards, making this case a candidate for Threadripper workstations.", "It’s been seven or eight years since we’ve completely changed the hardware here. This makes none of the data in this review comparable to prior case reviews. We’re refining our methodology to provide more accurate info and will be able to show a lot of cool behavior with new types of approaches to cooling.", "For our graphics card, we’re using a Gigabyte AERO GPU, which has a flow-through cooler that has an impact on CPU thermals. This made it the main reason we switched hardware since that has clearly become the approach to video card design these days, which we want to represent in our testing. ", "For our CPU cooler, we’re still using an air cooler in the ", ", which we chose because it holds pressure really well. ", "We’re also using a ", " rather than paste, which helps with data consistency. ", "We’ll share more about our methodology in a subsequent piece.", "The first set of thermal data is for noise-normalized testing at a chosen 31dBA threshold in our ", ", tested at 1-meter distance and with a noise floor of about 13.6dBA. Noise normalizing in the chamber means that all cases are set to the same noise level, so they are unable to leverage extremely loud, super high RPM solutions to beat their way to the top of the chart. This makes the playing field level and fair, so they must compete on merits of the total case and cooling design, not just brute force.", "This chart shows CPU thermals first. ", "The ", " remains the chart leader here, ranking just marginally better and within error of our open bench for calibration. The Torrent is able to force air directly toward the CPU cooler, which has the bonus impacts of (1) clearing hot air from the GPU away from the CPU sometimes before it hits the tower, and (2) cooling the neighboring VRM components so that they don’t slowly heat soak the area around the CPU. Ultimately, these are basically within error. We put the ", " on here because it remains a case we consider the GOAT (watch our ", "), at least for its generation, and it proves that, even with an entirely different approach to testing and list of parts, it remains king of cooling.", "The case setting the floor is the ", ", down at 54 degrees Celsius over ambient. That’s still good in an objective sense, but gives us an 8-degree range to work with for differences so far -- and this isn’t even our final form. That comes when we re-test the ", " or the ", ". We actually had to bake extra thermal headroom into our results to accommodate hotboxes, otherwise our parts would throttle too soon to see a difference. This is a great start for showing range but leaving room for worse parts.", "Against competition: The ", " is close enough to the ", " to be considered about the same with this test platform. Switching to glass did nothing for thermals, leaving them functionally equal.", "Downsizing to the original ", " increased the temperature by 1.4 degrees P-core from the XL Mesh. The glass side had a similar behavior: A slight increase that’s within error.", "The ", " and ", " still do fine in an objective sense, just like the ", ", but have a larger gap formed. Noise normalization is a hard test for cases that just pack fans in every corner (like the K95 Pro) because they are dropping RPM to a point where static pressure will be affected. That’s why we have multiple kinds of tests. We’ll test the mesh variant of the K95 soon. The 5000D is the closest size and style competitor and is losing: At 53 degrees for Corsair, the North XL is about 6 degrees better. That’s a huge swing, and this is at the same noise levels. Corsair’s single central front fan and rear exhaust fan just can’t keep up with the wider area flow at the front of the North XL.", "Now for the GPU temperatures from the same test. ", "In this one, the open air bench sets the bar -- and that’s expected. Unlike the CPU, where it can benefit from forced airflow and from eviction of heat dump from the GPU, the GPU benefits from open air when compared to these cases so far. That’s because it is normally within a few slots of a power supply shroud or a panel, both of which restrict access to air. It can’t pull from all sides and its pressure is also reduced when in a case. Open air, it can pull from any direction and exhaust it relatively unimpeded.", "The Torrent leads: With a 41.6 degree GPU temperature and 27 degree memory temperature, which is one of our new metrics. It improves upon the North XL by 1 degree. The Mesh and Glass variations are within error of each other and cannot be stated as to be meaningfully different with this configuration. That would change with an alternate fan layout, such as mounted to the side panel.", "The normal North is actually a couple degrees warmer than the XL, helping establish range early. That’s great from a methodological perspective. The K95 Pro is next, still doing fine but not as well. After that is the 5000D Airflow and the Pop Air, about tied with each other.", "Here’s another new chart -- we weren’t producing these two data points at all in our prior reviews.", "This one looks at VRM thermals of a MOSFET and the SPD Hub thermals. Serial Presence Detect Hub is a chip on DDR5 RAM.", "The results have open air doing best, without enclosure to trap the heat around the machine, followed by 1 degree from the Fractal Torrent. The North XL is about tied with the Torrent when using the Mesh panel for VRM temperature, within 1-degree of the Glass variant.", "The North non-XL is next, about 2 degrees warmer than the North XL. That’s a meaningful result. After that is the King 95 with the glass panel, then the glass North non-XL. Finally, the chart closes with the 5000D Airflow and Pop Air.", "This data is great because it gives us a 7.7 degree range so far for the VRM numbers, which is a huge range. That establishes a big swing in thermals outside of GPU and CPU results and can start helping establish advantages we might not see in other components. Here’s one example: The K95 had better SPD Hub thermals than every other case, at 17.9 degrees, and yet its VRM thermals were overall average. That SPD Hub advantage comes from the position of its fans, which flank the memory basically on all sides. This is exciting data because we’d never have known about that particular design benefit with our old testing approach.", "Next up, this chart shows a CPU-only workload at 100%, with no GPU load this time. This is one of the charts we’re still establishing, so it currently only features the Fractal cases. We’re adding more to it.", "In this one, the North XL remains the chart leader, followed by the North XL with a glass panel -- these are the same result. The original North is next, then the Pop Air. The total range here is about 4 degrees which, considering it’s a CPU-only workload and these cases are all relatively good airflow, is a good start for range.", "The final set of thermal data is up now, with GPU thermals at full speed for the case fans with the same controlled speeds for the CPU and GPU coolers. ", "The Torrent leads again here, followed by the XL. We eliminated some other tests for time in order to accommodate the vertical GPU configuration instead. In this case, we did not see a meaningful change from going vertical. That’s great. There’s enough space offset from the glass panel that it’s still breathing and it’s also able to pull from the PCIe slot ventilation. The normal North descends the chart more in this one as other cases can ramp their fans more aggressively. The K95 ends up still in the middle. There’s a relatively wide gulf between the 5000D with a solid panel (at the bottom, which we didn’t test noise for) and the Torrent, giving us a huge almost 9 degrees of range between cases that are at least partially decent. We’re worried to see how much that’ll expand with worse cases.", "We think the Fractal Design North XL’s key competition include the ", ", ", ", ", ", ", ", ", ", ", ", ", ", and Fractal Design’s own ", ".", "We'd rather build in a ", " than a ", ". The ", " is a straight upgrade: more room for components is one thing, but even just having more space to reach in and move cables around is a quality of life improvement. XL is a bit of a misnomer relative to the largest cases on the market, though, so you should measure out your space before you write off the North XL based on size. ", "At $180, Fractal isn't trying to make this case a bargain. If you're trying to stretch your money as far as possible, Montech is the company to keep an eye on, and we'll likely have more reviews of its products coming soon, like the ", " and more. Fractal's price is based on the features and the unique appearance of the North, which we happen to like, but it also has the performance to back it up. It’s one of the best performers on our old charts and the XL, on our new charts, is also doing well. Of the limited cases we've tested so far, only the ", " outperforms it, even in noise-normalized testing. The ", "'s mesh side panel and side fan bracket didn't do much for our test system when we used them as intake fans but we still need to test them as exhaust fans to see if that makes a notable difference.", "Overall, this review is kind of easy because we've already reviewed the North and liked it. The North XL is largely that except bigger. ", "We think the closest competition comes down to the Torrent, which offers great high airflow and function but the North XL’s aesthetics make it a worthwhile consideration.  "]},
{"title": " Entire Case Company Built on Literal Theft", "paragraph": ["Entire Case Company Built on Literal Theft", "Last Updated: ", "The Highlights", "GameMAX likes stealing things, as is evident with its ", " case. Its box calls it a “modern aesthetic case” which is a description stolen from HYTE. On its website, even its description text is literally copy-pasted from Hyte.com, which ", ", “Chamfered molding on the top and bottom of the chassis ground the case visually and allows for glass-free displays; Our antechamber design hides unattractive cables, keeping your PC clutter-free, visually appealing, and running cool.”", "Its website is also inconsistent with its self description writing, “With over 15 years of experience creating PC cases” and then later writing, “With over 10 years experience creating PC cases.”", "Steve Burke", "Patrick Lathan", "Vitalii Makhnovets", "Jimmy Thang", "The company also has a slogan that sounds very Asus-inspired that reads, “", "” It also uses ", " like “Be Gamer !,” “Be ready, be GAMMER,” and “GameMAX is no where to change the world for good.” Finally, on a different GameMAX case, the company names its chassis the “", "” ", "We've criticized companies for ripping off designs before, but maybe we've been spoiled: the ripoffs we've covered have been ", " to avoid immediate legal action. GameMAX is here to show us what a REAL ripoff is with the ", ", a case that looks nearly identical to the ", ". ", "It makes the ", " look like a respectful homage. And the ", ". And the ", ". And the ", ". And the ", ". Actually, maybe we need to take a look at Gamdias next.", "The HYPE really has us dumbfounded. But then, everything in GameMAX’s catalog is at least a surface-level ripoff: ", "There are some ", ", some ", ", ", " ", ", ", ", ", ", ", ", ", ", and ", ", but none of them cross the line between similar and blatant imitation like the HYPE does, and some may be legitimate coincidences. GameMAX has ", " with ", " ", " ", ", but we're reluctant to review them if there's a chance they'll turn out to also be stolen. Actually, we'd be reluctant to review the Diamond C.O.C. regardless. That stands for “cooling & overclocking,” by the way, and they claim that it’s patented, but with a name like that, why bother?", "If you think we're being too hard on the HYPE, take a closer look at the box. ", "Not only is the HYPE logo a copy of the HYTE company logo, but GameMAX borrowed the exploded case diagram as well. The Internet Archive has the HYPE's page stored back to ", ", more than a year after the ", "'s March 2022 launch, so there's no mistaking who came first.", "The case starts out as a complete mess for getting its own fan spec incorrect on the product page.", "On ", ", the HYPE is listed as having 3 x pre-installed 120mm ARGB Fans- 2 beneath the floor, and one at the back of the case, which isn't true. That's the stock fan configuration of a HYTE Y60, not the HYPE, which shipped to us with two side and one rear exhaust. ", "Yes, all three stock fans are exhaust; this is ", ", so it's not a mistake. We bought our case on Newegg, where the same product description is repeated, although, at the time of publication, it’s listed as ", " with zero user reviews. GameMAX also uses the phrase Premium Mid-Tower ATX PC Case, which isn't necessarily unique to HYTE, but it is ", ".", "Let's now find some positives. There's a generic GPU support that looks sturdy enough, the metal side panel is technically ventilated, and the infinity mirror fans look nice, although you can find similar fans at very low prices on Aliexpress. Also, there are touches of construction quality, like snaps on the side panels and some captive thumb screws with rubber washers, as well as a decent number of loose velcro ties in the accessory kit. That's pretty much it. The case has some neutral aspects, but nothing else worth calling out for praise.", "The build felt like a throwback to ten years ago, but that's partly because we don't often scrape the bottom of the budget barrel, at least other than the DIYPC Zondda-O (watch our ", ") and weird one-offs like the Coolman Three-Body (watch our ", "), and Segotep EDI (watch our ", "). The EDI is maybe the best comparison, because although the HYPE is built cheaply, it is not cheap: it's currently at least $110 if it's available at all, and we bought ours for $150. The $110 models often have high shipping costs.", "But what we mean by throwback is cheap stamped steel, disposable PCIe slot covers, and magnetic dust filters slapped on as an afterthought. This is a new case, though, and it must have required brand-new tooling, which seems like it would be more expensive and difficult than designing an original product. The top panel on our unit was visibly caved in, the screws holding the cable bar were stripped to varying degrees, and the dust filter at the bottom of the case is impossible to fit correctly onto the vent.", "Some aspects of the Hype seem like they were copied without understanding Hyte's Y60. For example, almost every two-chamber case design has a spot for the PSU and a spot for two 3.5 drives at the rear of the case, and maybe an option to swap their positions. The HYPE just has a huge empty gap above the PSU, with mounting holes to slap a single 2.5 drive directly onto the rear of the case. ", "The only other drive mounts, one 2.5 and two 3.5, are on the O11D-style cable bar. Mounting drives to the bar sucks: there's not enough room, especially for full-size HDDs, and it makes cables untidy. Crucially, the O11D family of cases has alternative mounting options, while the HYPE doesn't.", "The Y60 was built from the ground up with vertical GPU mounting in mind, and although the result isn't great thermally, we can appreciate the visual effect. ", "Meanwhile, the GameMAX HYPE has a vertical GPU support, but no riser cable. The support is screwed into the bottom fan mount, so it conflicts with fans, and it's unnecessarily tall, so our test bench GPU couldn't fit in this configuration. Even if it had worked, the performance would have sucked: the vertical mount is as close as possible to the glass side panel, restricting GPU airflow and pulling the PCIe riser cable across the bottom case vent to completely block it. Drop-in mounting kits (", ") are not compatible with the HYPE because of the bars between the expansion slots.", "Cable management is bad relative to the size of the case. Normally, there's a direct relationship between how large a case is and how easy it is to work in it. The open spaces with tie points aren't located well, and there's too much metal and not enough access throughout the case, which makes it more difficult than it should be to reach anything.", "Whereas the Y60 has only low-profile horizontal expansion slots in order to keep its width down, the HYPE has full-size horizontal slots, making it even wider than the Y60. ", "The HYPE doesn't take advantage of this extra width in any way, and it actually has reduced fan support versus the Y60, with exclusively 120mm mounts in all locations according to the spec sheet. ", "The spec sheet is incorrect, though, and the HYPE does actually have 140mm and 120mm slots for side intake.", "The front panel is up-to-date with a USB Type-C port that GameMAX says is capable of 10Gbps speeds, and it also notes that 10Gbps is 20 times increasing versus 5Gbps, which isn’t how math works. ", "There's a single Type-A port, despite using a full USB 3.0 motherboard header on the other end. ", "As the spec table notes, the front I/O also features buttons, with the reset switch wired to the RGB controller out-of-the-box. ", "The lighting can also be controlled with a remote or a motherboard header, but it frequently fails to respond to the remote for mysterious reasons.", "For our thermal testing, we'll be focusing on comparisons to the ", " for obvious reasons. If the ", " has a chance anywhere, it's here: being a ripoff doesn't mean it has to have bad thermal performance, and the real ", " is weak in this area.", "As we mentioned earlier, the default layout of the ", " has one rear exhaust fan and two side exhaust fans. We did some tests with the two side fans moved to bottom intake in imitation of the Y60, but we weren't able to completely copy the Y60's layout since the vertical GPU mount in the HYPE is incompatible with our hardware (and we had to supply our own riser cable).", "All temperatures are expressed as degrees above room ambient, which is logged during all testing.", "We’ll start with noise-normalized thermals, which puts all cases on the same playing field by reducing their included fan RPM until the total system noise hits a 31dBA threshold in our hemi-anechoic chamber. This is done with the included case fans only.", "The first result is for CPU thermals in a torture workload. The best case on this chart was the ", " at 46.4 degrees Celsius over ambient. The Hyte Y60 shows a massive increase in thermals as compared to the best of the best on this chart, allowing almost a 10-degree climb from the ", ". That’s a huge swing, but we already knew the Y60 only ever achieved acceptable performance previously and was rarely among the best.", "The Hype, however, is actually terrible. It is officially the worst case we’ve tested with our 2024 methodology we debuted a couple weeks ago, so... congratulations? This case is the reason why we had to so carefully tune the testing, because any hotter and it’d be in throttling territory that limits how much visibility we have into its suckitude.", "At 66.6 degrees over ambient, its result is appropriately numerically representative of the temperature inside the case: Which is hell for the CPU, at about 89 degrees when including ambient. Even for a copycat, this area of performance has no excuse for being so bad.", "The GPU thermals in the same test had the Hype down at 54 degrees over ambient. The range for these results is generally fairly tight between average cases, with most in the 45-48 degree range and the best in the low 40s. The open air testing shows just how restrictive modern PSU shrouds and panels can be to GPU intake. But the Hype result is at the bottom. Hyte’s Y60 is predictably limited here as a result of its vertical mount, something we talked about in our ", " of the case, but is still at least acceptable for seating the card back as far as possible. But the Hype case just completely drops the ball, especially considering this is one of the key areas it changes from the Y60.", "This chart is one of our new ones that we’ve been excited about with our case reviews rework: It includes VRM thermals, so that helps show if the top area of the case becomes a hotspot, and it also shows DDR5 RAM thermals with the SPD Hub.", "The Hype continues to impress: It manages, once again, to be the absolute worst performer on the chart despite copying a case that was at least near the average in this test. The MOSFET we measured ran at 38 degrees over ambient. In an absolute sense, it’s fine -- that’s not bad for the MOSFET. But in the relative sense, that makes this case 10 degrees worse than the best on the chart and nearly 6 degrees worse than its “inspiration,” the Y60.", "Memory temperatures are also massively increased here, with a ginormous jump from the previous worst on the chart (the ", ") to 31 degrees over ambient. That’s about 10 degrees hotter than the Y60. That means if you're running particularly hot memory or you were trying to overclock while buying a ripoff case for some reason then you actually might limit the head room for the memory.", "Now we’ll increase the case fan speeds to 100% on all tested cases, leaving the GPU and CPU fans controlled. Looking at GPU thermals, the Hype case -- despite having absolutely terrible CPU thermals in this test -- managed to at least tie with the Hyte Y60 for GPU thermals. Moving to bottom intake instead resulted in a better outcome for the GPU, which makes sense since it gets intake closer to the card.", "But even still, as the Hype fails to even understand the mechanical attention to detail of the Hyte case and also fails to deliver better performance, but still costs $110-$160 before shipping (and shipping was as high as $200 from AliExpress), there are simply no reasons to buy it, but it was a great workout for our new case testing methodology!", "As a final note here, we found that moving the fans to intake in the bottom caused an audible sound of rushing and wind in the Hype case. This was a result of all the layers of steel and mesh.", "We knew going into this review that it would be an extended piss-take. It's not our job to defend the honor and intellectual property of case manufacturers, and it's not yours either, but even in a vacuum, the ", " is crappy enough that we wouldn't recommend it at $150 or $110.", "But with regard to the literal copy/pasting of the marketing text, in the US at least, that is definitely theft of intellectual property. But they don’t operate in the US, and it’s extremely unlikely Hyte would ever pursue a company internationally (especially when that lawsuit is unlikely to yield anything that matters).", "The lesson here is that GameMAX's time and money would have been better spent on designing and tooling up for an original design with an original name, rather than trading on the name of some other company's product. We really mean it when we say it's a shame because now we don't want to review GameMAX products after this, because even if GameMAX does come up with an amazing design, we're never going to want to risk implying that a stolen idea is a good first-party design. The line in this industry is very wide and very gray, but GameMAX marched all the way across it willingly."]},
{"title": " A Better Computer Fan - Sometimes: Cross-Flow Meshless AIO Case Benchmarks & Review", "paragraph": ["A Better Computer Fan - Sometimes: Cross-Flow Meshless AIO Case Benchmarks & Review", "Last Updated: ", "The Highlights", "The small form factor MESHLESS AIO case works by using 0 axial fans and 1 cross-flow fan, which works by creating a lower velocity air movement perpendicular to a longitudinally rotating cylinder, with a tangential flow path. The theoretical end result is a laminar, evenly distributed flow. In this story, we did some practical demonstrations with Schlieren imaging on the case. We also did a full suite of acoustic tests in our hemi-anechoic chamber. ", "All of this was worth doing because this strange idea works. It’s not the most efficient way to cool a computer and it doesn’t allow for the best value, but its performance is worth studying in depth.", "Steve Burke", "Jeremy Clayton", "Vitalii Makhnovets", "Jimmy Thang", "The case is innovative in other ways, too: It has a lever that moves the PCIe riser into place on the GPU to make it easier to install in the small space and it ships with a flow guide that easily mounts to the side panel of the chassis. ", "The MESHLESS AIO mini-ITX case is a fundamental rethinking of case airflow and doesn’t mimic or emulate any other case we’ve ever worked on before. The case has a solo designer who emailed us months ago, and we’ve spent all of that time thinking about and working on the testing. In this educational deep-dive to the MESHLESS, we’ll get an opportunity to learn even more about fans.", "The MESHLESS AIO should be coming some time in May for $360, according to its solo designer. That’s very expensive – no getting around that. However, it’s produced in an expensive way – it’s mostly one giant 4mm thick aluminum extrusion that forms a unibody. Since it’s all one piece of metal, it doesn’t need screws or rivets to hold it together structurally. This makes the MESHLESS AIO extremely sturdy, with essentially zero flex. The unibody is finished with CNC machining to add all the necessary cutouts and mounting points.", "Optional accessories include a flow enhancer and tiny RAM fan, both of which we’ll test.", "The MESHLESS AIO’s cross-flow fan sits above the GPU and below a CLC radiator by sliding in on integrated rails. The airflow pattern has air come in through the top radiator, the bottom three quarters of the right side panel where the GPU is, and through the mesh slot below the motherboard on the left side.", "The air on the motherboard side is drawn through the holes above the motherboard and PSU. There’s also holes cut out on the bottom of the case on the GPU side, which are meant to be passive exhaust holes for large GPUs. With our modestly-sized ", ", they probably end up as more intake. All of this air converges at the fan and is exhausted out through the upper quarter of the right side panel. When the fan is running at full speed, there’s a solid wall of directed air blasting from the whole length of the fan. ", "Make sure to watch ", " to see how we set up our Schlieren imaging. ", "And this is the Schlieren imaging we produced. ", "First, here’s the exhaust side of the cross-flow fan. You can see the air exits up at a 45-degree angle, which is great because it helps prevent re-circulation of hot air in through holes in the bottom or sides of the case. That’s excellent design to project it up and away rather than just straight out. ", "The flow enhancer is actually fascinating as well: With it on, you can see that the exhaust path doesn’t change much, but it does better angle the air away from the case. The other reason this works is because it is instead blocking the cooler air lower in the frame from being sucked up into the exhaust path and pulled away. This allows that air to instead find its way into the case through the lower two-thirds of the side panel.", "This orientation shows us air intake at the top of the case. When a hot object is held above the case without any air movement, the shifting air density is observable getting pulled into the top with a bias toward the right side of the case (or towards the fan’s mount and exhaust). The currents of the exhaust also help pull the air this direction.", "Using an upside down air duster, you can see that even when we move the output towards the left, the air still pulls right. One side of the radiator gets a higher speed of flow here. ", "We were curious if the rear was acting as intake or exhaust. You can see that it’s exhaust: The air is flowing out of the case thanks to the video card’s fans. There is some very slight air intake at the bottom-left of the frame at slow speeds.", "The MESHLESS is really serious about the concept of this fan and includes features like 3D printed parts to maintain a divide between the two sides at the cable pass through at the bottom.", "There are some downsides to this approach: We don’t think the GPU has enough space behind the back of it, especially for modern flow-through designs found in most NVIDIA cards that will run into restrictions. More on that down below in the testing.", "We wanted to take this opportunity to both learn and teach about how this kind of fan works. This style of fan is again called cross–flow, transverse, or tangential, and in the world of fans, they’re a relative newcomer at 131 years old since the first patent. The only case we could find that used one was the 20 year old ", ". ", " for general small form factor applications. ", "A cross-flow fan is divided into blocks that are separated by joint discs, constructed of cross-sectional curved blades in a circular pattern. In this configuration, a drum rotor sits on one end to provide power. There are also duplex cross-flow fans where two fans adjoin a central impeller, but that’s a different use case.", "We’ve been making some big behind-the-scenes moves lately to start introducing educational animations anywhere possible. You can check that out ", ". ", "A traditional and simple axial fan slices through the air to scoop and move it in the targeted direction. Choices in blade shape and design can dictate how wide or straight that column of air is, but the concept is the same. ", "Squirrel cage blower fans, or centrifugal fans, pull air into the center and then eject it outward along the blade path. This is useful in cramped areas to evict air quickly, like in handheld gaming devices or laptops where you need to exhaust the hot air out of the chassis as fast as possible. ", "For a cross-flow or transverse fan, the fan is a longer and narrower cylinder that rotates longitudinally, with air entering perpendicularly to the rotational axis and being evicted from the cylinder tangentially to that axis. Unlike the blower fans we normally see in laptops and some GPUs, a cross-flow fan doesn’t pull air in from the middle of the impeller. Instead, it has separate inlet and outlet sides across the entire length. The outlet is formed by this wedge or “vortex wall” stabilizing the air vortexes in just the right way to create directional flow through the impeller. These fans are used in situations where a constant laminar stream of air is desirable without the buffeting effect of large axial fans. ", "The total pressure of the fan is proportional to the square of its speed, according to research by ", ", and research in 1973 by Eck, et al. found that a reduction in the angle of attack improves the total pressure coefficient. Later research discovered a combination of tuning to the angle or curve of the blades across the length of the fan would further improve pressure. You can see this present in the modern cross-flow fan used for the MESHLESS PC case -- its angle gradually swoops from right to left.", "Cross-flow fans create lower velocity air movement from in-to-out and produce a laminar flow which gets evenly distributed across the length of the blade. You might find these in a common standing room tower fan, where the goal is to distribute air widely across the room, but not to direct it to any particular pin point. Cross-flow fans can also be found in certain HVAC products, refrigeration products, and outside digital signage and billboards. They’ve also been considered for aviation use inside the wings of planes, but the idea never really got off the ground.", "A cross-flow fan has that downside: It isn’t going to force as much air as fast into a single inlet cooling a single device, but it will more evenly force air into the chassis. ", "Let’s get into the thermal testing. For this, variables we’re considering include: the fan speed, which can be adjusted to 100%, 65%, or 45% with a switch; the optional flow guide; and the fan being replaced with our hacked-together axial solution just for comparison. ", "Testing is done with a ", " cooler without its fans unless otherwise stated. ", "Time for torture testing with a full CPU and GPU workload.", "At 100% fan speed and stock, the cross-flow fan kept the CPU P-cores at 35 degrees Celsius over ambient, with the all-core average 3 degrees lower. This had it running at 37.8 dBA at 1m in our hemi-anechoic chamber. Conveniently, this is almost the same noise level as when we taped the two axial fans to it instead, which ran 5 degrees warmer. That’s great news for the cross-flow fan, but a word of warning: ", "Because this case wasn’t designed for axial, the fans are blocked around the edges when held in place. It’s not a fair comparison, but we still wanted to run it out of curiosity. ", "In other words: a cross-flow fan won’t always be better. This entire case was designed ground-up for this solution, so axial fans will remain superior in most computer use cases, but when carefully designed for cross-flow, our data suggests it is possible to produce a better result. ", "The flow enhancer did improve performance from stock, dropping about 1 degree from the baseline result. It’s not just a gimmick. Adding the RAM fan didn’t change the CPU results outside of variance, but we’ll look at the RAM temperatures in a moment.", "Adding the seat belt boosted the temperature as it ends up blocking large parts of the radiator due to its floppy nature: The temperature increased over 1 degree from baseline.", "Dropping fan speed to 65% reduced the noise by almost 10 dBA, or a perceived effective doubling in noise when going from 65% to 100%. The temperature increase was only 3-4 degrees. Finally, the 45% result is close to “silent” at 25.3 dBA in our ", " with a noise floor of 13.6 dBA.", "GPU thermals aren’t as good, so this is the weak spot, especially with a flow-through cooler. The axial fans were actually the best here, despite being mostly blocked. The GPU ended up at 54 degrees for average load temperature with both speed variations of the axial fans, although GPU memory temperature was slightly better on the 100% test but within variance. This isn’t abnormal to see: The GPU isn’t in the direct flow path of the fans, but it is far enough from the cross-flow fan path that it performs better axially. This mostly has to do with the pressure system that's forming within the case.", "The first cross-flow appearance is the flow enhancer, which has the GPU at 55 degrees load. That’s improved from 56 without the enhancer. The handle hurts performance again, with fan speed reductions obviously impacting it the most. The bottom two results see a hit to frequency, where the 45% result drops 20MHz from the clocks.", "This is a less favorable set of results compared to what we saw on the CPU, and we suspect that the design of the case doesn’t do the ", " design any favors. There’s barely any room behind the flow-through portion of the cooler, and any air that’s ejected towards the bottom of the case has a strong likelihood of being recirculated.", "This could be improved on in a couple of ways. Number one would be coming up with some way to mount the GPU closer to the outer wall no matter how thick it is. Number two would be using a GPU with a more traditional cooler design where hot air is blown out the top and bottom edges of the cooler if you get one with a vertical fin stack, which would maybe allow the case’s fan to pull it out directly.", "This last chart looks at RAM and VRM thermals.", "The tiny RAM fan definitely does something: SPD Hub temperatures on the memory dropped to 14 degrees over ambient when using it with the cross-flow fan with the memory fan, which is an impressive reduction of 5-6 degrees against the most relevant results. The RAM fan had a small benefit for VRM MOSFET thermals as well.", "The axial fans otherwise did the best and were within error of each other. Using the cross-flow fan with the flow enhancer was 1 degree better than without the flow enhancer, but not as good as with the RAM fan.", "Let’s get back to the case and talk features and fitment.", "For features, the GPU installation is clever: ", "Since the GPU area of the case is closed off on all sides, the GPU is inserted from the back of the case. ", "This bracket goes onto the GPU, then the slots on the side of the bracket slide into place using screws under the motherboard as guides. ", "It works well.", "In order to attach the PCIe riser to the GPU, the MESHLESS AIO has a lever operated mechanism that lowers the riser slot down onto the connector on the card. Plastic 3D printed guides ensure that it lines up during the process. It can be a little stiff to move into place, but it’s a brilliant solution given the inherent space restrictions.", "The case measures 379x165x259mm, which is 9mm longer and 10mm taller than on the spec sheet. The rear PCIe bracket and case feet make up the differences. That makes the outer volume 16.2L – well within SFF territory but not incredibly small.", "GPUs up to 362x78x163mm are supported, which includes the massive Aorus Master 40 series cards. Those are the largest we’re aware of, so everything currently on the market should technically fit – obviously, do your own research to confirm and look for protrusions.", "As usual though, fitting doesn’t mean it should go in the case. The larger the GPU, the more it will struggle with constrained space and potentially drop clocks.", "CPU cooling is designed entirely around 280mm CLCs, and the bracket doesn’t even have mounting holes for 240mm radiators. The radiator itself can only be up to 30mm thick, which rules out Arctic Liquid Freezers, and the block can only be up to 56mm tall, which blocks a few options. We used the ", ", so we know that fits – but getting rid of the fans means some dead ends on modern CLCs with rats’ nests of cables on the block.", "For power supplies, both SFX and SFX-L are supported, with the usual reduced cable management space when using SFX–L.", "We like the execution. The MESHLESS AIO gives you a guided build experience with just one final configuration in mind, and does it well. And it’s unique. ", "The MESHLESS is more like the ", " in terms of maximizing one build style. If you boil it down to base elements, we think the ", " is the MESHLESS AIO’s closest competitor. The layout is very similar, but the H2O is half the cost and is manufactured completely differently. It also uses standard axial fans.", "We like the use of integrated rails: Internal components like the cross-flow fan, radiator, and optional handle mount cleanly install with these. The side panels hinge into place with small tabs and secure with screws, and unlike the NCASE, it’s way fewer screws. All these things work well.", "The 2.5” drive mount can hold two drives at an angle between the motherboard and PSU and is secured with a single screw. Above that, there’s a hook to help keep the CLC’s tubes in place. ", "There’s also a small hole in the rear panel below the motherboard I/O so you can run a wireless antenna back inside the case – we used it for a thermocouple wire. That’s a lot of thoughtful touches.", "As a last positive note, the manual is well done and helpful, even in its current unfinished state. The cable routing suggestions are particularly helpful.", "Now for some negatives. ", "For starters, the fan controller board on our sample broke loose from its mounting. This could be a one-off issue, but the method of soldering standoffs to the face of the PCB wasn’t sufficient for the one we have. We fixed it with screws.", "The PSU mount was another problem. It seems like the bracket’s design takes the exact placement and size of the AC plug and power switch for granted, as neither of our standard test PSUs fit perfectly. The end result is that we had to force it to fit, and the PSU doesn’t sit correctly in the machined area. This could be fixed if MESHLESS tweaked the bracket’s design.", "We’re also concerned about the PSU being starved of fresh air, considering that the vent doesn’t extend to underneath the PSU, and it’s surrounded by close glass and aluminum.", "We also found it difficult to plug GPU power into our standard height card. Larger bottom cutouts would make this easier, as would a taller GPU or longer cable. ", "Also, access to the bottom edge of the motherboard isn’t easy. It’s tolerable, but that’s about it.", "Whenever a solo designer contacts us about a product they've been working on, we carefully evaluate the situation. In this case, the MESHLESS AIO is a serious product with a really unique approach to airflow in a computer chassis. Cross-flow fans have been around for a little over 130 years. They have technically been used in computers but it requires that ground-up effort to shape the entire product around using it so it's not as simple as just throwing a cross-flow fan into a case and thinking that you’ll get a compact, reasonable performer. ", "Trying something weird and different like what MESHLESS did with this case is important because if no one ever tries something weird and different, we might never find out that there may be a better way to do things. Often, we find that there are better ways to do things and the crazy thing is that still happens in thermals and cooling, which seems like elements that should be mostly figured out but aren’t. In this case, the cross-flow setup actually works well overall.", "This isn't a definitive answer to all small form factor cases but we think it's a really good execution and we're surprised at how well it works to where there's not really a problem of building it, at least with the parts we used. ", "To summarize some general positives and negatives, there’s real innovation in case airflow. It's a smart execution. It uses an unorthodox solution, but it's very expensive at $360. It is, however, an expensive manufacturing process. We think ", " is the closest competition to the MESHLESS AIO. It costs about 155 bucks and is very similar aside from the fans but if you want something that looks similar externally and is more traditional, this is where we would point you. Make sure to check ", ". ", "The design of the MESHLESS AIO is very focused with lots of clever and thoughtful features. We wouldn't be surprised if its GPU mount finds its way into competing products eventually. The CPU thermals were very good. The GPU thermals are passable. We think dedicated flow-through card designs like NVIDIA’s Founder’s Edition aren't the best choice for the case, unfortunately. ", "Recapping areas for improvements, the bottom cut-outs should be larger for ease of use. The power supply mounting bracket doesn't work properly with some PSUs. We're also concerned about the power supply's access to air and the fan controller PCB broke off its mount. ", "Those elements aside, it's a really clever execution and we enjoyed working on the case. It’s super cool and innovative. It’s not prohibitively expensive if you look at the ITX market but it’s definitely expensive. If you want cheaper options, there's a lot of them out there but it's not like it's some insane $600 solo artist project."]},
{"title": " Hyte Y70 Case Review: Thermal Benchmarks, Cable Management, & Build Quality", "paragraph": ["Hyte Y70 Case Review: Thermal Benchmarks, Cable Management, & Build Quality", "Last Updated: ", "The Highlights", "Today we’re reviewing the ", ", a case from a company so wildly popular that ", ". This case has some of the best cable management pathways on the market right now and offers a ton of fine attention to detail, like high quality rubber grommets that form a well-managed channel between the main and secondary chambers of the case. The case also goes to great expense to integrate a panel-to-panel geometric flow dotted with Hyte logos to the mesh. And by “Hyte goes to great expense,” we mean you. You’re paying for it. The case is $220 and it doesn’t include a single fan.", "Steve Burke", "Patrick Lathan", "Vitalii Makhnovets", "Jimmy Thang", "Hyte burst into the ATX market with its wildly successful ", ", but the timing wasn’t great: The company began designing the case before NVIDIA’s advent of 4-slot GPUs, mitigating performance of larger GPUs to OK at best in the ", ". In came the ", ", which replaced an entire glass panel with an LCD. The Y70 Touch costs the same as a CPU made in a $20 billion fab at $360, which is insane to think about, and we never would have expected that it would become so popular that Hyte ", " of those LCDs before demand waned. In fact, Hyte is bringing an entirely new factory online exclusively for that screen.", "It’s clear that the industry’s mainstream growth has created a huge market for looks-oriented builds. That’s fine, but we’re here to evaluate the function. Today, we’re reviewing Hyte’s holdover model, the ", " non-touch, that it introduced because it couldn’t make screens fast enough.", "We’ve had a mixed history with Hyte. First of all, its parent company is iBUYPOWER…but that’s why it’s so much more impressive that Hyte doesn’t suck. ", "Hyte has made it exceptionally clear that it behaves like an entirely different entity, and we can tell you first-hand that’s definitely the case. It has iBUYPOWER funding, but it’s driven by engineers who seem to have an understanding of DIY PCs.", "Our first review of a Hyte product concluded with “we don’t hate it.” That was the ", " case. It wasn’t particularly noteworthy and felt like a remnant of its parent company iBUYPOWER. Next, we liked the Y60 (watch ", ") and thought it was a creative take on a dual-chamber design that meaningfully deviated from the trend of O11-like cases, despite middling thermal performance. Then we ", " the ", " and felt like Hyte had removed all the best parts of the Y60 while also worsening the thermal performance, leaving us with a disappointing follow-up. We had absolutely no reason to recommend the ", " and favored its many competitors over the case.", "The HYTE Y70 Touch launched late last year in the midst of our case review hiatus and the no-screen Y70 is relatively new. It's a scaled-up version of the Y60 with the same signature chopped-off corner and shrouded riser cable. The Touch has the addition of an 1100x3840 touch screen, which ", " describes as “4K” despite being almost literally HALF of the actual pixels of what everyone understands to be 4K. 3840x1100 is closer to 1440p than it is to 4K. It’s not great to start marketing with what effectively amounts to a lie. ", "Let’s get into the actual build quality.", "The Y70 differentiates itself from the Y60 with its four vertical PCIe slots, plus some extra. The Y60 has a strict three slot limit. That's a massive GPU compatibility improvement that’ll improve thermals. ", "The GPU is forced vertical with a built-in riser. Horizontal GPUs could be supported if Hyte went the route of others and added a rotating bracket like the ", ", but that’d add cost. Hyte is also going for the guided build approach.", "In the Y60, the front of the case is wasted space without installing a side-mounted radiator or fans, and that remains true with the larger Y70. Only the largest GPUs extend far enough to use this area.", "That’s where the monster that is the ", " comes in. It’s about 80mm of fan and radiator that Hyte built to occupy this space. Without going custom loop, to our knowledge, this is the only way to get such a fat combination of cooling. ", "But that’s not part of this review. The Y70 doesn't come with any fans. For large dual-chamber cases, that’s not unusual: the Lian Li O11 Dynamic (watch ", ") family, the Corsair 6500s, the ", ", and the ", " all have at least one fanless variant alongside their versions with fans. ", "This is a $220 case though, and HYTE has established a precedent by selling the $180 Y60 (original MSRP $200) with three fans included. It’s also in fierce competition with some serious contenders at the $180-$200 mark.", "If it’s not spent on fans, it’ll be spent on materials and attention to detail.", "As a dual chamber case, the Y70 has plenty of room behind the motherboard tray for cable management, but it's not an appreciable increase over the Y60. The extra size is more noticeable in the main chamber of the case, where it enables the extra vertical GPU slot as well as more accessible cable cutouts below the motherboard. The cutouts are larger and completely out of the way of the bottom fan mounts. The extra space also makes it easier to reach the front I/O cables, which are trapped in an inaccessible corner of the Y60. This is a small but important quality of life improvement. ", "Hyte has several velcro straps preinstalled in the Y70, aiding what we think is overall impressive cable management and routing.", "The Y70 claims support for EATX boards, but like the Y60 before it, this just means that there are no hard obstacles to putting an EATX board in the case. The motherboard tray is sized for ATX boards with ATX standoffs, and anything beyond ATX will overhang so it’s a bit of a stretch to say it’s compatible. The tray is bordered by elaborately molded single rubber pieces that cover all of the cable cutouts on the top and front edges of the board, and the rubber is perfectly sized to outline an ATX board. The attention to detail on this piece is great as long as it doesn’t sag or discolor with age.", "The side panels of the Y70 snap into place and can't be screwed down, as opposed to the Y60, which has thumb screws that hold both side panels in place. On the positive side, the snap is resilient and extremely easy to use; however, we’d prefer to have the option to screw panels down, which is how the front panel is attached.", "The bottom fan mount of the Y70 is an improvement for the most part, with a fan tray that's removable from the exterior of the case and can use standard fan screws rather than the special radiator screws included with the Y60. Make sure the screw heads are flat, though, or they'll bend the bottom filter. ", "The filter is more open than the Y60's, which was restrictive enough to have a significant effect on GPU thermals in our original review -- so they’re listening. The mount is still fully enclosed on both sides, but even though that's not ideal for airflow, it effectively hides bottom fans and protects them from any loose wires. As for water cooling, the bottom mount can’t be used for radiators.", "Both the side and top mounts are officially compatible with 360mm radiators at most. The top fan tray is removable with plastic springs that hold it in place firmly, and there's generous clearance on both the top and side mounts. The side mount has basically unlimited clearance depending on GPU length or up to 125mm (according to HYTE) if the GPU overlaps with the radiator area, which is a more conservative estimate than the Y60 got even though this dimension hasn't changed significantly. The top mount can fit radiators up to 68mm thick assuming standard 25mm thick fans as well.", "3.5 drive support has been slowly going the way of 5.25” drives, but it’s hanging in there. In this case, support is limited to the two drive sleds in the rear of the case, which can alternatively fit two 2.5 drives each for a total of four. They’ve definitely applied small touches of detail here as well, with unnecessary but appreciated shaping of the cages.", "There's no vibration damping, so the mounts are better suited to SSDs. These are the only drive mounts in the case. It's true that the Y70 is geared towards showy builds that are less likely to use SATA drives, but the Y70 is an XL version of the Y60, and it'd be appropriate to use some of that extra space for storage. We had a similar criticism of the ", " versus the ", ". ", "Companies are still making big cases, but appear to be forgetting why we ever had them.", "Let’s get into the testing.", "Our ATX reviews are now fully operational, and this is the first full review following our ", " and ", " pilot reviews. This data isn’t comparable to the previous two reviews because we’ve overhauled the methodology one last time and are using a different GPU with a higher heat load.", "Since our last case review, we've made final changes to our new case testing platform. It's now much easier for us to get consistent data, but the changes required scrapping our existing data and starting over (again), so the numbers on these charts are different from any published previously and are not comparable. Again, since the Y70 doesn't include any stock fans, the Noctua fans from our standardized fan test were used for all tests.", "We'll start with noise-normalized testing. All case fans are dropped in tandem to reach our target of 27dBA at 1 meter in a noise floor of 13.6dBA. This puts all cases on an even playing field and balances out the advantages of cases that pack in as many loud fans as possible. ", "The Y70's noise-normalized CPU cooling performance is weak, partially due to the pressure loss at the panels. All that plastic is necessary reinforcement for the mesh, but also impedes flow.", "The bottom intake configuration was already quieter, so it didn't require dropping fan speeds as much to reach the target, but the lack of direct airflow to the CPU cooler put the average core temperature at 51 degrees Celsius over ambient, and the P-Cores at 55 degrees. Side intake fared better at 49 degrees all-core and 53 degrees P-core. The ", " tops the chart at 42 degrees all-core and 46 P-core, establishing a best of class target for performance.", " is directly comparable since it was tested with the same fans in like-for-like spots. The ", " ran at 47 degrees for the P-core average, making it 6 degrees cooler than the Y70 with side intake because the O11 XL is guiding the airflow better. ", " tied the Y70's bottom-intake CPU thermals, which makes sense given the C8's bottom intake stock configuration although it does have different fans at 160mm. The C8 is worth paying attention to in the GPU thermals.", "The ", " improved about 3 degrees over the Y70 with side intake. That’s better, but not as much better as the six stock fans might lead you to expect. That’s the value of noise normalizing.", "Finally, the Y60's average was worse than either of the Y70's tested configurations at 53 all-core and 57 P-core. The Y60 ships with stock fans in a bottom intake configuration, which puts it at a disadvantage for CPU thermals.", "This chart is for GPU thermals at full speed with the noise levels next to each entry name. It’s an interesting crossroads of thermals and noise.", " is the best here for thermals, at 39 degrees GPU temperature and 42.3dBA for noise. The Y70 with side intake and our standard fans is better from a noise efficiency standpoint, though: It’s 2 degrees warmer (at 41C over ambient), but it’s also about 4dBA quieter. That’s a noticeable drop in noise for what’s likely an unnoticeable change in thermals but remember that these are fans we chose because the Y70 doesn’t include any.", "The Antec C8 is better still, down at 37.1dBA and the same thermals as the Y70. This is a good showing for Antec’s more serious efforts in the case market this past year. Maybe we’ll do a standalone review for this one.", "The Y70 with bottom intake is significantly quieter than the side intake configuration, dropping about 4dBA but also climbing for thermals. The noise reduction is due to a combination of the greater distance of the backmost fan and the loss of the side slat impact to acoustics. Interestingly, the O11D Evo XL (watch ", ") is also about 34dBA, but with a side intake configuration. The thermals are the same, so this and the Y70 with bottom intake have equal noise and thermals in this test.", "The Y60 was the quietest we’ve tested thus far -- that’ll change with time -- and it follows that it was also the warmest on this chart.", "On this chart, the same standardized set of three Noctua fans (2x 140mm, 1x 120mm) is used in each case, and at max speed rather than noise normalized. That’s why the O11D EVO XL and Y70 results are different from the first chart despite using the same fans. The O11D EVO XL still beats the Y70, now by 2-3 degrees for side intake.", "With the same fans in the same bottom-intake configuration, the Y70 and Y60 tied at 48 degrees Celsius above ambient for the average all-core CPU temperature and approximately 52 degrees P-core. Those are the warmest CPU results on this chart, tied with the Antec C8 with the same bottom intake configuration. This all makes sense: Forcing air past a GPU isn’t an effective way to cool a CPU. The Y60's bottom filter is more restrictive as well, but this should become more of a factor with GPU thermals.", "And here they are when noise normalized. The HYTE Y70 is more competitive when sorting by average GPU temperature. The ", " establishes the best performance again, this time at 40 degrees Celsius over ambient for the average GPU temperature. That’s a great result. The Y70 side intake configuration averaged 48 degrees, which is a huge loss in performance versus the Torrent (watch ", "). That’s a big range to establish. The bottom intake configuration with fans pointed directly into the GPU averaged 45, putting it in the middle of the chart. ", "The O11D EVO XL's average GPU temperatures with side intake are effectively tied with the Y70 bottom intake, so when taken together with the EVO XL's better CPU temperatures, the Lian Li case wins. The Antec C8 does extremely well here thanks to its aggressive focus on GPU cooling and its large fans in the bottom, landing at 42 degrees average. This is an excellent performance from Antec and borders on the Torrent. Where it’s weak in CPU, it’s strong in GPU. ", "The Y60 had the worst GPU thermals out of the limited set of data we've recorded so far, but it’s not awful. The GPU isn’t in throttling territory and still has plenty of room to breathe. It’s just the objective worst on the chart. We'll use the standardized fan chart again for a more direct comparison with the Y70.", "Moving to the full standardized fan chart, the Y70's side intake configuration is actually better than bottom intake for GPU thermals. Remember that side intake was also louder, so for the previous noise normalized chart, fan speeds were reduced more for the side intake result. On this chart, the standardized fans are set to 100%, which benefits the side intake configuration. This result is the best on the chart -- but standardizing the fans is a test our viewers requested, and we have a whole ", " detailing why this is a naturally flawed configuration. We run it due to popular demand. One of the reasons it’s flawed is that we’re removing fans that are naturally better in order to arbitrarily standardize: The Torrent has its excellent 180mm fans removed for this. ", "With enough airflow directed along the right path, the Y70 can hold its own, although the mesh-fronted cases have better overall performance when taking CPU thermals into account.", "The Y60 was at the bottom of the chart here, but still acceptable for GPU thermals. Both of the Y-series cases have multiple layers of material around the bottom fan slots, and the Y60's bottom filter in particular is closed-off. Removing the bottom filter proves this, where we reduce the temperature by 3 degrees on the GPU. That’s huge for just removing a filter.", "For something different, here’s the VRM and RAM sensor thermals when noise normalized.", "The VRM temperature in the Y70 averaged 35 degrees Celsius above ambient with bottom intake and 36 degrees with side intake. That's not much better than the Y60, which is currently the worst entry on the chart at 37 degrees. HYTE's competition did better, with the O11D EVO XL at 30 degrees and the ", " at 31. For comparison, the ", " is the current performance leader at 28 degrees.", "There are two SPD hub sensors in our test bench, one for each stick of DRAM. The one we average is the one tucked underneath the CPU cooler, sheltered from direct airflow. The HYTE Y70 and Y60 are both still on the warm end of the chart here, with a best-case average of 27 degrees for the Y70 with bottom intake. This is one instance where the King 95 Pro's pile of fans helped, with an average of 21 degrees, while the O11D EVO XL only slightly beat the Y70 at 25 degrees.", "One bonus set of data from the ", ": We noted an on-and-off quiet humming noise with the Y70 side intake configuration that pushed the average noise level up…somtimes. We think because of the closely-spaced slats on the Y70's side panel, ", ".  ", "It’s not particularly loud, but it seems to happen as a result of the blade passing frequency over the slats. Overall, this is highly dependent on the fans you use but it's just another reminder that the slat or whole design and the panels can really affect the noise behavior.", "The ", "'s biggest competition is the ", ". This isn't true for the Y70 Touch, since the Touch costs $360, while a Y60 and a Y60 LCD DIY Kit together cost $330 (and you still have to 3D print your own mounting hardware). Meanwhile, the plain Y70 at $220 has to compete with the plain Y60 at $180. ", "The situations in which a ", " non-Touch makes more sense than a ", " are very specific: you have a quad-slot GPU, or you have cooling hardware that won't fit in the Y60, or HYTE paints your favorite vtuber on the side of a Y70. HYTE has ", " with the option to buy a Touch upgrade kit later, but we can't recommend doing that. Either buy something that exists now, or wait for the Y70 Touch to restock.", "All of the Y-series cases compete based on appearance rather than performance, but that isn't necessarily a problem: the Y60 and Y70 Touch have both been extremely popular despite costing more than better-cooled cases. The triple tempered glass panels in the Y70 are best suited to a flashy liquid cooled system, which would make up for some of the thermal shortcomings. If you do need performance, the ", " fits into the same product category with potentially better airflow, much larger radiator capacity, and an invertible motherboard tray, while the ", " and ", " ARGB are both significantly cheaper and include full sets of case fans. Outside of dual-chamber cases, the ", " remains at the top of our charts for air-cooled performance."]},
{"title": " Corsair Forgot How to Make a Case: 6500D Airflow & 6500X Review", "paragraph": ["Corsair Forgot How to Make a Case: 6500D Airflow & 6500X Review", "Last Updated: ", "The Highlights", "In one word, ", " cases are “unfocused.”", "The company’s back-connect compatibility conflicts with its drive cage compatibility in ways that seems like one of the two was designed in isolation of the other. Corsair’s filters on the case are large and loose fitting without sufficient integrated support, which means they sag. To prevent this where there are fans, Corsair has included what we’ve branded as the “oh-s***-moment” with an afterthought movable plastic structure to reposition where the fans are. The filter also pulls out from under the plastic panel supports. Corsair used heavy steel in areas like the top to create a valley effect in the front panel, but then likewise went cheap on the mesh panels. Instead of reinforcing the outer edges with metal to stiffen them, Corsair used a plastic border. The end result is that every panel on this case sags, no matter how charitably you orient it. The touches of yellow accent are a nice touch that Corsair has done before, but since they didn’t follow it through in areas like the pull-tab, which they've done before, the USB ports end up just looking like an area of going cheap (despite actually spending more) because it stands out as the only point of accenting -- and it happens to be a color from PCs of the 90s. Applying this accent with more purpose would have a better effect. Open loop hardware is technically supported but not well documented, despite Corsair making its own open loop solutions.", "Steve Burke", "Patrick Lathan", "Vitalii Makhnovets", "Jimmy Thang", "These are the Corsair 6500X and 6500D. The styling feels familiar to the ", " series, the ", " and ", " cases, the ", ", and dozens of variations in between. But despite fitting in with this trend, Corsair isn’t purely a follower. It actually came before all of these.", "That was with the Carbide Air 540, which ", ".", "Let’s get started on the ", " series.", "About 10-12 years ago, Corsair was fighting fiercely in the case market. ", "The Corsair C70 and its edgy military theming had some highlights, like a flip-up button cover and heavy-duty panel latches. Corsair had the bulbous 600T and the popular 780T. Lately, the company has moved away from styling and feature development in cases. These days, Corsair’s strategy is to make “safe” styles that follow trends in the industry. ", "The ", " gets huge credit for keeping the more affordable market alive. The ", " remains available and was Corsair’s last mid-range case, launched in 2021. ", "The company tries to make cases that are timeless for at least a while, allowing it to spread tooling cost and R&D over more years. That’s a big business move. It also gives Corsair more room for price drops.", "The ", " and ", " Airflow are also calculated big business moves designed for longevity, which means less risk and more standard design. But big business moves can work.", "The ", " and ", " Airflow are both $200 cases without fans. This feels like a spiritual successor to the Corsair 680, which came out years ago now.", "Alternatives to this case include the ", " series, ", " (and ", " non-Touch), ", ", and Antec C8 ARGB. They are all in the same general form and price category, and we've got fresh data for those cases from our recent ", " to compare.", "Looking big picture first, this case is super heavy.", "A lot of that comes from swappable panels, which are steel currently and super thick. That’s cheaper for materials. We found that swapping them for the aluminum panels meaningfully reduced the weight.", "The 6500s have some frustrating design compromises and messy documentation, but are also built in a way that feels sturdy and of quality materials. ", "Let’s start with some of the weirder, small oversights.", "Let’s get into detail on the opening complaints, then we’ll get into the positives.", "The first weird one is compatibility with back-connect motherboards. Corsair is trying to satisfy this demand, but the whole thing feels like an after-thought that started part way through design.", "Corsair included a full set of cutouts for normal ATX boards and back connect Mini-ITX, microATX, and ATX motherboards from both ASUS and MSI. Corsair is ", " in its abilities in this regard.", "The problem with all of this unfolds in this awkward gap below the power supply and the hard drive cage overlaps the back-connect EPS12V cutouts. ", "This is why Corsair punched what otherwise seems like a totally random hole in the hard drive cage, which isn’t discussed in the manual at all. They have 2x 2.5/3.5” sleds in the drive and 2x 2.5” mounts on the side, which Corsair calls “expansive storage options.” BUT if you use one of Corsair's rotated SHIFT PSUs, which has been ", " series, the HDD cage ", ", eliminating ALL (official) drive support from the case. ALL of it. No drives except NVMe or whatever you lay on the floor of the case.", "If you just route CPU power cables through the cage but without a Shift PSU, one of the sleds is unusable. There's another spot in the bottom of the case where you can force one of the 2.5 mounts with some bending, but it's not officially supported. We recommend using the sleds inside the drive cage first, since cabling for the mounts on the side can press against the side panel. The 3.5 mounting is toolless, but lacks vibration damping.", "They designed for drives and they designed for back-connect cables, but they didn’t design for both. It’s a way to tick all the marketing checkboxes without any cohesion.", "For open loops, there appear to be pump or reservoir mounting holes next to the expansion slots and a drain hole at the bottom of the case. We say appear to be because Corsair doesn't mention these features in ", " (there is no physical manual), or the reviewer guide, or the ", " on their website. This is a premium case with ", " made by a company that has its own line of open-loop hardware, but Corsair's only acknowledgment of open-loop hardware in a 6500 is in ", " and ", " that accompanies it. Corsair needs to organize its materials: there are genuinely helpful blog posts, but finding specific information is a chore.", "There are two filters in the 6500X, plus an additional front panel filter in the 6500D Airflow. It's easy to pull the fabric layer away from the frame, and getting it flat again can require taking the whole panel apart. It's worse on the side panel. Corsair seems to be aware of this problem, since there's an additional magnetic plastic frame that clips over the mesh layer to keep it from sagging into fans. If you aren't using the side fan mount, the clip can be shifted to the rear of the case where it might help protect the PSU fan (also not in the manual). ", "We like airflow, and we like Corsair's triangular-vent-hole motif, but the mesh panels are unpleasantly fragile. It's a strange contrast with the complete overkill armor plating in other areas. Since all of the panels snap into place, removing them requires prying them up from one side, which unavoidably curls them.", "Interestingly, there are ", " available for the 6500 series and we actually don’t hate all of them. There’s some interesting ideas here. There’s a RapidRoute kit of cable channels and velcro ties that costs $15, a glass kit to convert the 6500D Airflow to a 6500X, which costs $35, a vertical GPU mount kit (including riser cable) that costs $75, as does a wooden Elite Panel kit, while the black or silver aluminum Elite Panel kits cost $100. Of those, we'd like to see the RapidRoute kit included with the case. ", "The Elite Panel kits replace four plates on the 6500D Airflow (three on the 6500X). The stock plates are extremely heavy 3.2mm thick steel. The single plate that the I/O attaches to weighs 1.3kg, while its aluminum equivalent weighs 0.4kg. Fresh out of the box, the 6500X weighs 14.5kg and the 6500D Airflow weighs 14.8kg, with the ", " plates making up a large share of those numbers. This case is heavy.", "Installing an Elite Panel kit isn't complicated, although it's hard to access the screws on the front plate. The tolerances on our samples were tight with minimal gaps between plates and around the I/O ports.", "The side fan and radiator mount is held in with a single screw, and the tray can be screwed down without being hooked into place properly, which stood out as the one example where Corsair's manufacturing (rather than its design) let us down. ", "This mount pictured above is 120mm-only, but there would have been space to fit a 140mm mount without expanding the case.", "On to less negative features.", "The side and bottom mounts in the 6500 series both support 360mm radiators at max, and there's no obstacle to using both mounts simultaneously. ", "Installing fans and a radiator in the bottom mount will reduce access to the bottom of ATX motherboards, but Corsair has oriented the cable cutouts in this location so that they can't be blocked. The front mount in the 6500D Airflow does have some overlap with the bottom mount, so we recommend focusing on the bottom and side for liquid cooling.", "We're happy with the glass side panel. We'd like the option to screw it down, but there is a screw on the hinge to keep it from sliding off. The side of our 6500X is impressively flush with the front, and there are metal guides along the top and bottom edges so that even if the hinges get misaligned, the panel should remain flush. ", "There are no fans included with the two less expensive 6500 SKUs that we're covering here, but Corsair has included fan screws. And they’re trademarked. They're the weird one-twist Quikturn® variety, but we're mentioning them because Corsair went to the trouble of painting the screw heads. The positive is that these are much faster to use. ", "The accessory kit also includes a color-matched splitter for front panel connections in case your motherboard doesn't have the usual layout.", "The rubber grommets are double-shot molded, with the inner portion made from a more flexible material while the outer ring is rigid enough to keep the grommet from popping out. This works, and it's excellent attention to detail, but it also means that the white grommets are a slightly different shade around the edges. We overall like this element of detail.", "Finally, the bar between the PSU chamber and the side fan mount is extremely easy to remove and is well designed. ", "The entire front panel comes off without much more effort, although that's another thing you'll need to ", ".", "Now for thermal testing. We're covering both the 6500X and the 6500D Airflow here, neither of which come with case fans, so we used the standardized set of Noctua fans for most testing. The exception is that the side mount only fits 120mm fans, so for side intake tests we changed out the usual two Noctua 140mm fans for two Arctic P12 Max fans.", "We'll start with noise-normalized thermal results, which are gathered by lowering case fan speeds together until the total noise level hits 27dBA, measured in our ", " from one meter directly in front of the case. We leave the CPU and the GPU fan speeds undisturbed for all cases. We noise normalize configurations separately, but there was only a tiny difference in noise levels between the 6500X side intake and 6500D Airflow with side intake, so those two configurations used the same fan speed.", "For CPU thermals amongst the Corsair cases, the straightforward front-intake configuration in the 6500D Airflow came out on top at 48 degrees Celsius above ambient for the average all-core CPU temperature and 52 degrees for the P-cores alone. The two cases were warmer with side intake, with both averaging about 49 degrees all-core and 53 for the P-cores. Bottom intake in the 6500X was the worst, since incoming air was blocked by the GPU. In total, though, the bottom-to-top range between all configurations for the all-core CPU average was less than 3 degrees within the 6500 series. The bottom intake configuration directed less noise towards our mic, which meant the fan speeds didn't need to be reduced as much to hit the noise normalized threshold, which helped to level out performance here. This is a level of precision our older methodology didn’t have, as now our chamber can identify sub-1 dB differences.", "Both of these 6500 SKUs are $200, which puts them close to the $220 HYTE Y70. For CPU thermals, the 6500X with bottom intake tied the Y70 with bottom intake, and both 6500s with side intake nearly tied the Y70 with side intake. The Y70 isn't capable of front intake, so the 6500D Airflow has an advantage in being able to more directly target the cooler. Among our other dual-chamber case results, the ", " did best at 43 degrees all-core and 47 P-core, and both it and the ", " beat all of the 6500-series results. The Antec C8 ARGB with its stock bottom intake configuration performed nearly the same as the Y70 and 6500X with bottom intake.", "Ignoring dual chambers, the ", " remains the GOAT.", "This chart is for GPU load thermals with the stock case fans (or those we’ve added to empty cases) at full speed.", "The 6500X averaged 45 degrees Celsius above ambient on the GPU with bottom intake, while the 6500D Airflow with front intake averaged 49 degrees. Both of these results were gathered with the standard Noctua fans; there aren't P12 Max results on this chart. The bottom intake configuration benefits GPU thermals as well as noise levels from the front, with the 6500X running both cooler and quieter at 35.6dBA versus the 6500D Airflow at 40.8dBA. Remember the last chart, though: CPU cooling was better with front intake.", "Front intake in the 6500D Airflow made it louder than the rest of the dual chamber cases on the chart, all of which were tested with side or bottom intake, but didn't put it at the same level of GPU thermal performance as the similarly loud 42.3dBA Torrent. The ", " remains unbelievably impressive, keeping in mind this is with included fans and it has an advantage there -- but even from a noise efficiency standpoint, it’s doing well.", "From the perspective of GPU thermals, the 6500D Airflow was both hot and loud in this test. The O11D EVO XL was about 1dBA quieter and 1 degree cooler, while the C8 ARGB and Y70 with side intake were both at least 1dBA louder and at least 4 degrees cooler.", "This chart covers our standardized fan test, where all cases use the same set of Noctua fans at full speed. These are not noise-normalized but do use the same fan speeds throughout the case.", "Bottom intake in the 6500X was still worse for CPU thermals than front intake in the 6500D at 47 degrees all-core versus 41. That’s a big difference and it makes sense.", "Removing the front panel from the 6500D showed what a difference unobstructed airflow path can make, with an all-core average of 37 degrees and P-core average of 41 degrees, cooler than any other logged results for both metrics. This is noteworthy because we’ve removed all that double filtering, so an improvement of 4 degrees is relatively large from the impedance of those filters and mesh double stacked.", "Sorted by CPU thermals, the best results for Corsair are with front intake, then side intake, then bottom intake, with almost no deviation from that order.", "Competing cases without removing panels would have the ", " advantaged, as with the EVO XL, and the Torrent also advantaged even without its huge 180mm fans.", "Back to the original noise normalized results but focusing on GPU thermals rather than CPU, the bottom intake configuration for the 6500X was the clear winner at 44 degrees above ambient on average, with the two side intake results again within variance of each other around 45 degrees, and front intake in last place at 47 degrees. The C8 ARGB was the clear winner among dual-chamber cases at 42 degrees average, an impressive result and attributable to Antec’s decisions on its fan placement and type. The bottom intake Y70 configuration came close to the 6500X at 45 degrees. ", "Back to the standardized fan chart, the 6500 series' GPU thermals didn't compare as well with all fans matched and running at full speed. The 6500X bottom intake result at 45 degrees above ambient was the best among the 6500 series, which is beaten by the O11D EVO XL and Y70 bottom intake at 44 degrees, and the the King 95 Pro and Antec C8 at 43 degrees. The Y70 with side intake also did unusually well here with a 41 degree average.", "VRM thermals for the 6500X fell within a tight 33-35 degree range above ambient for the most part, with the bottom intake 6500X on the cool end and the two side intake results tied at the high end. The SPD hub thermals for the memory were also tied with the two side intake configurations, and front and bottom intake results were within variance of each other.", "The Antec C8 remains a strong competitor here with its default configuration when noise-normalized, doing well for both the RAM and VRM thermals. Ahead of that, Montech’s King 95 Pro benefits from fan count blanketing the board with air, despite that not working as well for general CPU and GPU thermals (but still fine).", "Overall, the ", " doesn't have a large advantage over the ", " in air cooling, especially when noise normalized. Its main advantage is that it adds an additional fan or radiator mounting location with 140mm support, but otherwise the choice comes down to personal taste. Again, the two cases are identical other than the front panel.", "If you need an ATX BTF or Project Zero or MG-RC compatible case, the list is extremely short. Probably. The competing standards and confusing naming make it hard to get an exact count, but the Corsair 6500 series, ", ", and the InWin F5 are the most visible options made by third parties. The 6500 series has some promising touches, but it'd be improved if it was compatible with ", "normal motherboards ", "back connect motherboards, not both.", "If you don't need compatibility with back connect motherboards, there are cheaper dual chamber cases. The ", " costs as little as $90 without fans (we've seen discounts even lower) and it includes an optional mesh front panel, and the ", " ARGB should be available soon for less than $200. For that matter, all of the other dual-chamber cases that we've tested recently are close to falling within a $200 budget, even the ", " and the ", " (non-Touch)."]},
{"title": " Lian Li's Brilliant Airflow Design: Lancool 207 Budget Case, 217 Wood, & Wireless RGB", "paragraph": ["Lian Li's Brilliant Airflow Design: Lancool 207 Budget Case, 217 Wood, & Wireless RGB", "Last Updated: ", "The Highlights", "We visited Lian Li at Computex 2024 and walked away with 3 interesting things to showcase. ", "First up is the company’s Lancool 207. At $80, it’s a budget case, and we typically don’t see a lot of chassis in this price range anymore. It’s also compact and designed to be as close to microATX as possible while fitting a normal GPU and ATX boards.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "It includes 2 140mm ARGB fans on the front, but what makes it somewhat unique is that it has 2 reverse 120mm fans towards the bottom of the case and has its power supply area shifted to the front to give the PSU more access to air. This also allows the fans to move closer to the GPU.  ", "Lian Li has also shifted the 207’s motherboard tray down to provide roughly 65mm of clearance at the top, which enables the installation of larger AIOs and fans up top.", "The case’s backside panel has a mesh opening to feed air into the bottom fans. ", "There is an opening underneath the bottom fans to allow air intake, which users could use for storage drives, but that would create some pressure-resistance. ", "If you orient the GPU vertically, there is an option for a restrictive plate, and this does end up blocking a lot of the benefit of the bottom fan design.", "The Lancool 207 is expected to launch in August.", "Next up is Lian Li’s Lancool 217, which is a wood-themed case and seems to be a popular theme at Computex as we’ve seen 3 of them from different vendors thus far.", "Specifically, it’s got a Walnut wood theme and houses 2 170mm fans in the front coupled with an ultrafine front mesh panel.  ", "Lian Li has also incorporated a button on the case to reverse spin the fans to allow users to more easily shake dust away. ", "One interesting aspect of the case is that the dust filters are on the inside of the case behind the fans. Lian Li claims that it performs better this way. ", "The 217 also comes with a 140mm fan on the back and has the option to mount fans on top of the power supply chamber. ", "The case is expected to ship in September for $120. ", "Finally, Lian Li is releasing a “wireless” RGB solution that aims to get rid of RGB hubs moving forward while cutting down on annoying RGB cabling. ", "It does so by leveraging a receiver that connects to Lian Li’s new RGB fans, which connect to a motherboard’s 12-volt header. This provides enough power for both the fans and RGB lighting.  ", "The company’s RGB solution employs a USB stick that acts as the host and it transmits data over a 2.4 GHz frequency band. There could be some interference challenges as a result, but the company is currently attempting to finetune those issues. Lian Li also says that up to 8 RGB devices are able to connect to it.", "A pack of 3 “wireless” RGB fans will cost $89.99. The company is aiming to release it by the end of August."]},
{"title": " Fractal Terra Mini-ITX Case Review: Build Quality, Thermals, Acoustics, & Cable Management", "paragraph": ["Fractal Terra Mini-ITX Case Review: Build Quality, Thermals, Acoustics, & Cable Management", "Last Updated: ", "The Highlights", "Today, we're reviewing the ", ". It has some extremely unique features, but also some extremely unique noise characteristics as a result of the slat design on the panels. In the video, you'll notice that when we replace the side panel with something perforated hexagonally or circularly, the noise profile of the case is significantly better -- it’s not only quieter, but of a more tolerable frequency. We’ll show numbers for that in our noise chamber later. All the audio comparisons will be in the video.", "Slats are more prone to causing fan noise issues due to the angle of entry created – something true of the ", " also. But we’ll come back to that.", "Steve Burke", "Jeremy Clayton", "Vitalii Makhnovets", "The Terra is a “sandwich” mini-ITX case with unique features like removable gull-wing doors and top panel for access, a movable spine for flexible internal fitment, and touches of wood and leather for some style from alternative materials. This case is $180 in a forest green, silver, or graphite.", "*specs table taken from manufacturer’s website. This table has not been changed from the manufacturer's listing. Any issues we take with the table will be discussed below.", "Fractal has been on somewhat of a win streak with its cases. The Torrent led into the North, and both landed on our top recommendations for cases. That’s a big change from the older super toned-down Define series, and it’s revitalized the company in the DIY market.", "Ease-of-access on the Terra is good: The doors open, shut, and remove easily. The central spine runs from front-to-back inside the case and can be adjusted left to right by 30mm to allow for more room either on the GPU or CPU side. The adjustment points are marked 1 through 7, but there are no steps or catches, so it can be set between the marks freely. In general it works well, and the only con is that when tightening a screw, it tends to move the spine a little bit – so the freedom costs some structure there.", "The Terra’s direct competition would be the $220 ", ". Fractal obviously drew inspiration from this case, also a sandwich style, but with a more traditional mesh panel. The ", " is another direct competitor, which happens to be priced at $180 on sale at the time of writing – exactly the same as the Terra. There are also less expensive choices like this ", " at $155. ", "We’re working towards reviewing some of these as well. The DAN Case is already on our list. As we’re just restarting our ITX case testing, the Terra will be the one to start re-building our database -- but the experience from over a decade of case reviews all carries over here, just with renewed focus on trying to identify “pain-in-the-ass factor” aspects of the build process. That’s what really matters: The most important part of ITX reviews are the sections on the building process and ease-of-installation features.", "Getting into those: The Terra is a shoebox-sized “sandwich” layout. In this case, the components are back-to-back on either side of a 2.5mm thick steel “spine” -- for reference, a lot of ATX case motherboard trays max-out at 1mm -- so the structural support is definitely present. An included PCIe riser connects the main compartment with the video card. The movable spine means that GPU and CPU cooler clearances are variable based on spine position, enabling sacrificing space for one to give to the other.", "Simplifying the sliding scale, the maximum CPU cooler height is 77mm. ", "That would have the GPU clearance at 43mm depth, which would fit a 2.0-slot card with about 1-3mm of clearance, depending on tolerances. The maximum GPU cooler space is 72mm, which would have the CPU clearance at a heavily reduced 48mm. A 4090 FE is about 61mm wide - but it wouldn’t clear vertically. More on that later.", "At 77mm of CPU cooler clearance, coolers like the ", " would fit at 65mm or the ", " at 67mm (which is what we used). The 37mm tall ", " would fit in the 48mm clearance configuration. There are other options too, including from SilverStone, but you’re going to be extremely constrained on CPU choice if fully biasing to accommodate the GPU. It’d be an imbalanced build.", "For other dimensions, the Terra is 343mm long, 153mm wide, and 218mm tall, with an external volume of 11.4L. The Lian Li O11 Air Mini is 44.2L, the A4-H2O is 11.1L, and the Xbox Series X is 6.9L. ", "Methodologically, we’ve decided to stick with exterior dimensions including protrusions like case feet for volume calculations whenever we can. We think it’s disingenuous to use numbers that don’t represent the actual final configuration. It’s a talk for another time, but Lian Li wanted to exclude PSU and drive cage protrusions from its upcoming case from dimensional measurements -- but people still need to know about those true dimensions to make sure it fits in the room properly.", "For cooling, the Terra doesn’t come with any fans, and the manual only shows an optional step for mounting a single 120mm fan in the bottom under the PSU -- but that’s not possible with an SFX-L PSU. You can technically slot two slim 120mm fans underneath the case -- there are screw holes for them -- but it isn’t an officially recommended configuration. We’ll come back to cooling in the thermal section later.", "Time to get into fit & finish: The Terra’s overall build quality and finish are good. The front panel features a small strip of wood along the bottom where the limited front I/O is located -- the type of wood depends on the case color. The power button is color-matched aluminum, which is a nice detail. Front IO itself is extremely limited and doesn’t include audio, which we’d like to have seen.", "For materials, the aluminum exterior looks and feels high-end on this model, although the black version of the case that we saw at Computex seems like a future fingerprint and scuff problem. The Terra uses thick metals all over, up to 8mm in some spots, on both the outer panels and steel internals. This gives it a sturdy and rigid feeling while the case is empty. ", "Once loaded up with parts and moving it around, there’s some flex, but not to a problematic degree. The movable spine feels secure when all 4 adjustment screws are tight.", "One exception to the sturdy feel are the latches for the gullwing doors. They use a small nub of plastic to act as the end of travel for the door’s pivot. Lack of care in opening the door all the way or accidental pressure could probably break this off. We’d prefer to see an alternate solution that doesn’t turn the entire door panel into a lever against such a small plastic part. ", "Because of this, we recommend removing the door entirely any time you build or do maintenance that’s more involved than just plugging something in.", "The Terra comes with basic accessories, most notably a sled for an extra 2.5” drive and standoffs for the PSU mount – we’ll come back to those later.", "The manual is mostly good: It shows example configurations and major component clearances, although we don’t like its representation of how tightly folded the GPU power cable is.", "We already briefly covered cooler fitment, but there’s also ", "an option to install a 120mm radiator, but it severely limits how long of a GPU you can use. It just comes off as an afterthought or ticking a box for marketing. ", "Also, fitting the pump of a CLC through the cutout under the PSU isn’t possible without removing the entire bottom of the case, which is not an operation detailed in the manual and probably shouldn’t be done unless necessary.", "We noticed with our downdraft cooler that the cooler’s fan is partially blocked off by the solid portion of the side panel door. The vents should continue lower down the panel, but we think Fractal did this so that the end of the vents visually line up with the top of the wood on the front panel.", "The CPU cooler fan is loud and annoying when it’s right behind the slats in the side panel. Long slats are bad for noise, and a different ventilation shape would help. We did a quick test of some other side panels smashed against the case just for a quick demo. You can find that in the video.", "We found the fine mesh of the ssupd Meshlicious/Meshroom to have the most agreeable noise profile. That’s also a common material for ATX cases.", "Since you can’t actually replace the side panel short of removing it entirely, your options are to lower fan speed or move the spine to get the fan farther away from the panel. We’ll get to our detailed objective analysis in the noise section of the review.", "The entire left side of the case is devoted to the graphics card, so GPUs up to 322mm long will fit. Maximum thickness has some caveats, and depends on both the spine position and the height of the GPU. With the spine in position 1, GPUs vertically shorter than 131mm can be up to 43mm thick, and GPUs that measure 131-145mm vertically are limited to 33mm. With the spine in position 7 for max GPU space, those change to 72mm and 62mm thick, respectively. One slot of thickness is 20mm, for reference. The RTX 4070 FE we’re using for testing measures 244mm long, 112mm tall, and 40mm thick.", "We test fit a few other GPUs to see what fit issues may come up. The reference RX 7900 XTX fit with the spine in position 3 without issues. The tallest card we had on hand was this ASUS Strix Vega 64 at 139mm, and it fit with the spine in position 3 as well, but uses nearly all of the vertical space. The RTX 4080 FE required biasing the spine farther towards the CPU side, reducing the cooler clearance significantly. GPU power cable management can be tricky on the taller cards, and the ", "’s stock 12VHPWR cable is so stiff that we weren’t comfortable forcing it to bend enough to fit. If you’re interested in using a GPU this tall, you’ll need a more flexible individually-sleeved cable or some kind of 90 degree adapter.", "PSU support includes both SFX and SFX-L. The SF1000L fits, but the cables need to be preinstalled when mounting it because there’s not enough room below the PSU to comfortably plug one in after the fact. ", "The other downside is that SFX-L eliminates use of the floor-mounted SSD sled or fan mount. Unless you need the extra power SFX-L affords, we recommend sticking to true SFX PSUs in the Terra just for ease of use and flexibility. Fractal could have made this a little better by having the PSU bracket mount just a little higher within the chassis. There’s a few wasted millimeters of empty space between the 90-degree AC power cable and the top panel that should have been taken advantage of. When it comes to mini-ITX cases, careful and efficient use of space is very important – everything helps.", "We’d also recommend pre-installing the EPS12V cable with the motherboard end of CPU power. Our choice of CPU cooler and orientation prevented access once the board was mounted. Installing the cooler after the board is in could also work.", "Our methodological choices and details on our acoustic chamber, including our peer review process for acoustic data, can all be found in the ", ". We can also recommend this video to learn about our hemi-anechoic acoustic chamber:", "The main discussion point in the video is that mini-ITX cases are impossible to review in a fully standardized way without shorting some of the cases. A large part of the point of ITX is to fit the most in the least, and so standardizing cooler selection would mean limiting how useful -- for example -- the H2O aspect of the DAN Case A4-H2O is if we were to use a downdraft cooler. Likewise, switching coolers between cases and putting them all on the same chart effectively becomes a cooler review, not a case review, which we do separately. To control and limit variables as much as possible, we are largely looking per-case for ITX reviews (whereas our ATX reviews can be more standardized).", "Our test bench is below for ITX testing. Note that this particular bench is variable, and as such, there are multiple variations listed per component category. If any of the parts you see in our build interest you, you can likely find the links to their retail pages below:", "Let’s get started.", "This frequency spectrum plot shows what’s going on. With the side open, the case isn’t only quieter overall despite the same fan speeds, but its noise reduction primarily comes from the 500Hz to 4000Hz frequency range. The biggest deviation is around 850Hz, with reduced but also deviating spikes from 600Hz to 1100Hz.", "The previous chart was made with special acoustic testing software, but this next image is from something simpler: Adobe Audition, which is used for sound mixing. These are unmodified frequency visualizations. This first image shows the case with the side open. Note that most of the noise is a lower fan hum -- primarily under 200Hz. Here’s the side closed test. Notice that we have a higher volume of 600Hz, 800Hz, and 1100Hz noises now. We’ll flash between these a couple times to make it easy to see the differences. The total volume is also just higher with the sides closed in our testing with the spine biasing the CPU cooler towards the side panel, but it’s those specific ranges that make it annoying.", "As a last demo, we’ll isolate the range of about 750Hz to about 1000Hz so you can hear that specific annoying tone: ", "For noise comparisons, check out the video above.", "This last charge just shows the total noise levels. The absolute number doesn’t matter much here -- remember that you can control your fans to affect the noise, and this case has no fans, so all we’re really testing is how the cooler fans interact with the case panels. The noise level is significantly lower -- about 5.6dBA reduced -- with the panels open. That’s despite exposing the fans more directly to the outside of the case, so this just proves the slats conflict. ", "With that, we’ll move on to thermals.", "Fractal’s webpage for the Terra says, “make the most of natural airflow through the ventilated top, side, and bottom panels.” We assume Fractal is referring to the fact that hot air rises, but as we’ve said before, that doesn’t have much to do with cooling in a case when there are fans involved. They’ll overpower heat rising every time -- air will come from anywhere it can. Without case fans, you’re relying entirely on the CPU cooler, GPU, and PSU just like an open-air setup – except it’s not open air.", "It’s important to understand that the numbers we’ll show here are only comparable amongst themselves. You can’t compare them to other cases directly, unless the other case explicitly uses the same hardware, BIOS configuration, and fan speeds. For now, we only have the Terra against itself in various configurations. We’ll occasionally add competing cases to the charts as we move forward with more ITX reviews.", "Our “stock” setup in the Terra has the spine in position 3, which is as close as we could run it to the middle 4 position it comes set to out of the box. The AN600 CPU cooler has its fan at 100% speed and the RTX 4070 FE has its fans locked to 44%. Frequency and voltage are locked. ", "Remember that noise-normalized testing is only useful in the comparative. Doing such testing in a case against itself serves no value.", "Here’s the first chart. Under a full system torture workload at steady-state, the P-Cores averaged 58.6 degrees Celsius Delta T over Ambient. The full all-core average was a little lower, since E-Cores pull less power and run cooler. To determine how much the side panels are restricting air, we next tested with the side doors fully opened: Here, the P-Cores dropped by 3 degrees, so that should be considered our best possible outcome with this setup. The difference is greater with the GPU in a moment.", "Adding two slim 120mm intake fans to the bottom only improved from baseline by 1.4 degrees, which is close to run-to-run deviation. It’s not worth all the noise and hassle to add slim fans to the bottom. It’s not an advertised configuration, and for good reason: There’s not enough table clearance for these fans to breathe. ", "Sliding the spine over to position 1 for as much room on the CPU side as possible didn’t impact CPU thermals to any meaningful degree, staying within error; however, it did benefit acoustics greatly. More on that soon. ", "The alternate PSU configurations gave interesting results. The 10mm standoffs reduced baseline by about the same as the bottom fan setup; however, installing the PSU in the flipped orientation with the fan facing the GPU didn’t have a meaningful impact on CPU thermals versus stock, with the data leaning slightly warmer.", "The GPU thermal chart is next, showing delta T over ambient steady-state averages for GPU core, memory, and hotspot temperatures.", "Our stock setup resulted in the worst temperatures on the chart, due to warm air recirculation in the GPU side of the case. Without any chassis fans to force it out, you actually are relying on that slow natural movement of hot air to escape through the top or through the GPU. Opening up the Terra’s gullwing doors unsurprisingly gave us the best result – 8*C lower on the GPU core and a massive 10*C lower on the hotspot reading. These are huge swings for GPU thermals, showing the restrictions caused by this style of door ventilation. A higher porosity would help Fractal here.", "Adding fans to the bottom didn’t appreciably move the needle for GPU thermals either, so skip that idea unless extending the feet.", "Setting the spine in position 1 dropped about 4*C from the core versus stock. That might seem counterintuitive at first since that setting gives the GPU the least space, but it’s actually better since the GPU’s intake is right up against the side panel getting fresh air rather than pre-warmed recirculated air.", "The alternative PSU mounts performed identically, both better than stock for GPU thermals. Cards with a flow-through area on the cooler are naturally going to benefit from having lowered airflow restriction, which both alternate PSU installations help with. Given that the 4070 FE doesn’t totally line-up with the PSU in the Terra, this would likely matter even more with a larger or longer card like a 4080 FE or Gigabyte Aero, and less so with a traditional non-flow-through card like an RX 7900 XT. Remember that the PSU can eat more heat this way -- they can take it, but the cheapest ones could have shortened life.", "Given the better CPU thermal performance, we recommend running with the 10mm standoffs on the PSU mount with the GPU as close to the side panel as possible. Of course, since each build is so different, you may need to adjust if your card produces more noise than ours did.", " is a solid choice for an upper midrange gaming build. Our 13600KF and RTX 4070 weren’t really held back, but ultra high-end choices like a 4090 or 13900K would force you into skimping on cooling somewhere and making an imbalanced build. It’s on the expensive side at $180, and there are plenty of other options at or below that price – we’ll probably be covering the A4-H20 next.", "The most obvious improvement would be changing the vent shape away from slats to fix the noise profile. We’d also like to see a future rev. 2 incorporate better access to the bottom of the case and really focus on squeezing every millimeter of space by moving the power supply mount higher.", "Thermals were mostly fine, with the vents in the chassis being open enough to be adequate. The support for 120mm liquid coolers feels really shoehorned in there and not very thought out. This is primarily an air cooling case, and we’d like to see a spot added for at least one exhaust fan somewhere to get the hot air out. In our testing, it was best to minimize the space on the GPU side to cut down on warm air recirculation. Adding the 10mm PSU standoffs helps for flow-through GPUs too.", "While it’s certainly not the company’s first try at ITX – with cases like the Era ITX, Core 500, and Node 202 before it – the Terra has a higher level of polish consistent with Fractal’s more recent ATX releases like ", "and ", ".", "(11/9/23: Corrected a typo referring to the 'Terra' as the 'Torrent' that occurred during website setup for launch)"]},
{"title": " New Montech King 65 Pro, King 95 Mega, Sky 3 PC Cases | Computex 2024", "paragraph": ["New Montech King 65 Pro, King 95 Mega, Sky 3 PC Cases | Computex 2024", "Last Updated: ", "The Highlights", "We recently had the chance to check out Montech’s Computex 2024 booth and saw 6 interesting cases.", "Steve Burke", "Mike Gaglione", "Jimmy Thang", "First up is the Montech XR, which is a super budget case starting at $64. The case is like the ", ", but scaled down. ", "There will be 2 variants (a mesh and non-mesh). The mesh option costs $70 and comes with wood paneling. The mesh version also comes with 4 fans (3 120mm fans in the front and 1 120mm fan in the back). ", "The non-mesh variant comes with 2 120mm reverse side fans and 1 120mm ARGB fan in the back. ", "The Montech XR’s PSU shroud has perforations and holes.", "And the back has a cover for PCIe slots.", "The Montech XR just released and we plan on getting it in to review soon.  ", "Next up is the King 65 Pro, which is a follow up to the ", " but more affordable.", "The biggest change has been made to the front panel. Whereas the King 95 has a curve to its glass, the King 65 Pro does not. There’s actually a bit of a gap between the 2 pieces of glass from what we saw of the display unit but we guess that goes with the cost-savings territory. ", "We also noticed some small alignment issues as well.", "The dual-chamber case comes with 3 fans (1 120mm in the rear coupled with 2 side reverse 140 fans).", "The King 65 Pro uses dark-tinted glass. ", "And there’s lots of perforated holes on the top of the case.", "The King 65 Pro is targeting a September/Q3 release date with a price of $90. ", "Next up is a prototype for Montech’s Sky Three case. ", "What makes it interesting is that the case has some ventilation near the bottom front of the case and behind that are 2 80mm fans, which may pose some interesting noise issues. ", "This is coupled with a novel steel ramp that funnels air into the rest of the case. This is something that Montech is currently iterating on now. The company is targeting a Q1 2025 release date with a $120 target price. ", "In addition to the aforementioned fans, the case also comes with 2 120 side reverse fans and 1 140m fan in the back. ", "The HS01 is up next. The case comes in either black or gray and will cost $100. ", "It’s got 2 fans in the back.", "The case also has a sunken area for fans at the bottom of the case. This design allows the fans at the bottom to get closer to the air source.", "This relegates the power supply to the other side of the motherboard near the top of the case.", "The case will come with a shroud for the power supply and for the cable pass-through.", "In terms of fans, in addition to the aforementioned 2 fans in the back, it will come with 3 120mm fans in the front.", "Next up is the HS01 Mini. Being a 32-liter MicroATX case, it’s a relatively massive chassis for pushing the “mini” angle. ", "It offers 3 locations to install the power supply: top, middle, or bottom.", "HS01 Mini comes with 4 120mm fans: 3 reverse ones on the bottom coupled with 1 in the rear.", "Aesthetically, it features a fake leather look coupled with an optional carrying strap that we’re skeptical is sturdy enough to bear the weight of a full build without teetering. ", "Montech is aiming to release it in Q4 for $96. ", "Finally, the last case we’re highlighting is a bit of a mouthful and invokes Quake III: the King 95 Mega Pro.", "It has curved glass like the ", " before it but what makes it unique is that it has fans near the front that are angled. ", "The case will come with 7 pre-installed fans: 3 on the side, 3 on the bottom, and 1 on the back.", "Montech is aiming to release it in Q1 of 2025 and targeting a $200 price point."]},
{"title": " Impressive Fractal Era 2 & Mood Mini Cases", "paragraph": ["Impressive Fractal Era 2 & Mood Mini Cases", "Last Updated: ", "The Highlights", "Fractal had several new products to show at Computex this year that include 2 new cases, a revision to the North XL, office chairs, a wireless headset, and more. Let’s get into it.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "Starting things off is Fractal’s upcoming Mood mini-tower. It features a 180x38mm Torrent fan at the top. ", "The exterior of the entire case is almost entirely covered by fabric with the exception of the GPU side panel, which pops off. 2 of those sides are solid with one side having numerous holes that are covered by the fabric, which raises concerns around porosity.", "This exterior can slide up and provides access to the interior chamber of the case. ", "The interior chamber is extremely light.", "Inside, there isn’t a ton of space for the GPU but it has a PCIe gen 4 riser. There are also perforations within the case for the gpu that point to where the power supply fan would typically go. ", "The case has a recessed area at the bottom for cables, though it could be cramped for bulkier Display Port cables. ", "It’s a 20.4 liter-volume case, which includes the dimensions from the feet at the bottom of the case.", "The Mood supports 110mm CPU coolers, like ", ".", "It also has a drive cage, which users could remove to accommodate a 280mm liquid cooler.", "The Mood is coming out this month for $150 and includes its fan.", "The next case is the Era 2, which features a wooden top with slits. ", "It’s an 18.9 liter chassis that comes with 2 120mm fans on the base.", "The outside of the case is made of anodized aluminum that measures 2-3mm thick. ", "The Era 2 includes a PCIe gen 4 riser. ", "Inside the case, the Era 2 has a spine in the center that has at least 3 adjustable locations. ", "The bottom dust filter pulls double duty as the lock mechanism for the outer shell. Pulling the filter out slightly allows the exterior to pull up, similar to the Mood.", "Users can remove the top wood panel, which has a steel structure underneath to reinforce the wood.", "The bottom of the case has a chamfered dust filter coupled with 2 120mm intake fans. ", "It can theoretically support a 280mm cooling solution on the top as well.", "While we recently ", " the ", ", Fractal is making a version that repositions the motherboard to accommodate back-connect support. ", "Fractal is getting into the office chair business. They aren’t gaming-themed (thankfully) and will retail for around $500. There will be different options for colors and materials.", "Fractal is also making headphones. We don’t review audio products and really only want to point out that it has a magnetic base for inductive charging.", "Finally, one last thing that Fractal showed us was its Raspberry Pi Mini North. It’s not going to be an actual shipping product, but served as the Scape’s MP3 player at Computex. It features the same wood as the Fractal North and we actually really want Fractal to ship it."]},
{"title": " Best Case of 2024 So Far: Antec Flux Pro Review & Benchmarks", "paragraph": ["Best Case of 2024 So Far: Antec Flux Pro Review & Benchmarks", "Last Updated: ", "The Highlights", "The ", " is the newest case using ", ", whatever that means.", "Well, ", ", the definition of FLUX is Flow Luxury;” however, ", "’s dictionary, Flux is a flowing of fluid from the body: such as a:diarrhea b:dysentery. ", "OK, that doesn’t sound as good on the box.", "Steve Burke", "Patrick Lathan", "Vitalii Makhnovets", "Jimmy Thang", "Antec has been making its return lately. We liked the ", " that we ", " a few months ago, and we also like this one overall.", "The case has a wood accent along the border, the Pro variant has a digital display on the side, and it’s heavily perforated around the lower edge for better intake access to the PSU-mounted fans.", "Both of the new FLUX cases have 3x front intake, 1x rear exhaust, and 1x intake on top of the PSU shroud. The Flux Pro has a second fan on the shroud top for a total of 6, but sticks to the same general layout. The ", " might be some of its closest competition. Let’s get into it.", "The Antec Flux Pro is a big case, approximately the same size as a ", ". Antec bills it as a full tower, in contrast to the mid-tower non-Pro Flux which only includes five fans. The Pro is $180 (or $185 for the white SKU), while the base model is listed around $120-$125.", "By price and by size, its direct competition might be the long-standing best airflow case, the Fractal Torrent (watch ", "), which is normally $180, but has been on sale as low as $140 lately.", "Antec has hopped on the wooden bandwagon: the black SKU comes with walnut trim on the front panel and the white SKU with birch. We were told that the Pro was originally intended to use ash, but this was changed due to availability. ", "Immediately, the attention to detail is good: ", "Antec went above and beyond in coloring the white SKU. ", "All plastic and rubber pieces like the PSU supports, drive vibration dampers, velcro straps, I/O cables, USB ports, and even the fan/RGB hub are white, while hardware and written labels are silver. There are a few downsides: the white SKU is $5 more expensive, it makes grime and leftover plastic mold release visible, the color matching isn't always perfect (like on the iShift extension cable), and the silver labels are hard to read at certain angles. Despite that, we think it looks good.", "From a function standpoint, airflow is also mostly well thought-out.", "There's a small 7-segment display on the side of the PSU shroud that can report CPU and/or GPU temperatures via an internal USB header. It feels like a feature from Antec's heyday back in the 2000s, especially with the retro Antec iUnity interface that's required to activate the display. This feature has always bordered on gimmicky and the extra software only to control it is a downside, but leaving it off renders it relatively unnoticeable on the black model, and some people might like it.", "The Flux Pro includes an optional iShift 90° PSU Mount, which allows the PSU to be rotated 90 degrees. This serves the same purpose as rotated PSUs like ", ", just without the PSU change -- and with an extra letter.", "The goal is that modular connections become easier to access and route. There are some situations where this doesn't really help, like ", ", but using either a side interface PSU or the iShift mount specifically with the Flux platform is a good combination. Moving cables out of the way theoretically allows a better airflow path in some places. The Flux Pro’s wide vents were clearly designed to take advantage of this. We're excited about the solution: it reminds us of Lian Li cases like ", ", but all-in on the shroud-top cooling concept rather than just including it as an option. Of course, airflow would be even better without any bottom shroud at all, but ", ". ", " also looks promising here.", "As we discovered while hunting for the missing rubber PSU supports, the Flux Pro can be disassembled to an impressive degree. Both sides of the shroud are removable, which is helpful when using the iShift mount. The top and front fan mounts are both removable as well, which fully opens up the case. A side effect of all the removable panels is that the toolless glass panel is held in by the toolless metal shroud cover, which caused some initial concern; however, the glass panels on our samples are secure. The front panel is held in place by both snaps and magnets, which is overkill in a good way, but Antec clearly didn't want to risk sloppy tolerances in the most visually important area.", "Radiator compatibility is excellent. Having room for three 140mm fans doesn't always guarantee compatibility with 420mm radiators, but because the Flux Pro's front mount can be adjusted up or down by several notches, there's definitely room. This can also allow extra headroom for big pump-on-rad designs. ", "The top 420mm mount is tighter, but the entire tray can be lifted off of the case, and there's a massive 7cm of clearance between the top fan mount and the top edge of the motherboard. ", "Antec depicts some ridiculous configurations on the product page, like a dual 360mm plus 420mm setup with one of the 360mm rads on top of the PSU shroud in a push-pull setup. We wouldn't want to encroach on the motherboard that much, but the point stands: you can fit many radiators and many fans into this case, even UNDER the shroud, where there's technically room for another 240mm radiator. It’s comically accommodating.", "Cable management is up now:", "Using the iShift mount means committing to keeping the cable slack behind the motherboard tray, which Antec’s velcro straps enable. Cable management is more visually important on this case than some others due to the ventilation on all sides of the shroud. Cable cutouts are standard overall, with the exception of a relatively small CPU power cutout up top. ", "We also liked the tie points on the rear of the case for external cables, a feature we've complimented Fractal for in the past.", "Using the iShift mount makes connections accessible and benefits EPS12V routing, but we wouldn't go as far as saying that ", " Antec included a card in the accessory kit that describes four types of PSU layouts and the correct way to install each of them with the PSU extension cable. Full credit to Antec for including good instructions, but it isn't easier. On that subject, we tried to follow the cable routing guide in the manual when connecting our 12VHPWR cable, but the diagram just isn't readable in 2D.", "The Flux Pro also comes with a hub. We don't use built-in fan hubs or controllers during thermal testing, but even so, it's strange that the Flux Pro's hub only has five connections available when the case comes with six fans. Five of the stock fans are neatly cable managed and attached to the hub out-of-the-box, but the rear exhaust fan is not. This could be a relic of the original FLUX platform being designed around five fans. The hub is SATA powered and acts as a simple splitter for four-pin PWM fans and three-pin ARGB signals, with five outputs each. The Flux Pro does not contain any LEDs (RGB or otherwise) outside of the temperature monitor.", "For drives: There are 2x 2.5 mounts behind the motherboard tray, 2x 2.5/3.5 mounts towards the front of the case, and a cage under the shroud that can hold one more 2.5/3.5 drive inside and another on top. The hardware is freely repositionable for this: We recommend just pulling the whole assembly out and relying on the other mounts if you don’t need that many drives, as it frees up several more fan slots, removes an airflow obstruction, and the remaining two 3.5 mounting locations have rubber vibration dampers.", "So-called-E-so-called-ATX, which ", ", has support up to 285mm is listed. Larger boards up to ~330mm would technically fit, but only by overlapping the cable cutouts, and there are no standoffs beyond the standard ATX footprint.", "Antec sent us two Flux Pros, one black and one white. The black one showed up perfectly fine, but the white one was bent at the rear. ", "Whenever this happens, we inspect the packaging to try and determine if it was the manufacturer’s fault or the carrier’s fault.", "Antec’s packaging is at least as good as the industry norm, so the damage comes down to rough shipping. Four sticky rubber PSU supports also popped off and rolled into every corner of the case, so the white case also probably experienced extreme temperatures in shipping. This seems more likely to be a manufacturing issue or problem of adhesive choice not being sufficient. ", "The Flux Pro's accessories include a full set of covers for the top of the PSU shroud, a standard PSU frame (if the iShift system isn't used), and a screw sorter. There are exactly eight screws for the two possible 3.5 drives, and exactly four screws to attach the two additional shroud covers. We'd like a couple spares. There isn't a spare set of dust caps for the top I/O like there was with the ", ", but that's fine by us. Taking the top panel off pops every single dust cap out.", "The Flux Pro has six stock fans and a lot of optional mounting locations. For our baseline, we used the stock configuration with the iShift mount to rotate the PSU 90 degrees, and then we did an additional pass with the PSU in the standard orientation. Theoretically, the iShift mount should be better for airflow. Removing the bottom HDD mount would improve it even more, but we were consciously avoiding going overboard with the additional tests.", "We aren't seeing as many regular old full towers these days, like the ", " or the pricey ", " from a few years back. Among cases that we've covered recently, ", " is the most obvious comparison; the 2024 redesign of the ", " is a close match as well, although we haven't had a chance to test it. Antec's own C8 ARGB(read ", ") is in a slightly lower price bracket and a completely different form factor, but it obviously shares some Antec styling with the Flux Pro, which makes it another potential competitor. There’s also the Fractal Torrent, which is the high airflow king.  ", "First off, this is with our new test bench, so we’re still populating these results. ", "Noise normalizing all cases to 27dBA and with a full-system torture workload, the CPU averaged 41 degrees Celsius above ambient across all cores and 45 over ambient on the P-cores. This makes the Flux Pro the new chart leader when noise-normalized. This is a great start for the case and shows that its stock fans are effective. ", "That's better than the ", "'s best result of 46 degrees P-core, but still fairly close, which makes sense given the similar focus on strong front-to-back airflow in both cases. The Torrent sits between the two. ", "Bottom-to-top airflow doesn't benefit the CPU cooler in our setup as much, as demonstrated by the much warmer 54 degree P-core averages achieved by the Antec C8 in the same test. Looking at the rest of the chart, the Flux Pro scored the best result we've seen since our most recent case refresh.", "This is an incredibly strong position for Antec -- though the Torrent gets credit for hanging on as long as it has and being effectively within error.", "Now on to GPU thermals with the same combined CPU and GPU torture workload, but with case fans at 100% speed. This means that we are letting the systems run at whatever noise level they hit when maxed. CPU and GPU fans are the same controlled speeds as before.", "The Flux Pro’s baseline ran at 38 degrees Celsius above ambient for the average GPU temperature, 50 degrees for the hotspot, and 43 for the memory junction. Rotating the PSU won’t have much impact unless you have a ton of cables obstructing flow. In our rotated test, temperatures dropped by one degree across the board but that was by moving it back to the standard orientation. It was at 37 degrees Celsius above ambient on the core, 49 hotspot, and 42 memory.", "There are a few factors at work here: our setup uses a modular PSU that's only 15cm deep, and the Flux Pro is large enough that there's not a lot of slack cable, so there's not a lot of cable clutter under the shroud regardless of orientation. We still like the iShift mount, but you should view it as a cable management tool, not something that will massively improve GPU thermals. In this case, it was basically a margin of error with no meaningful difference.", "Compared to other cases, the most impressive thing here is that Antec has now chart-topped at 100% fan speed for GPU thermals in addition to its prior noise-normalized result for CPU thermals. At almost 40dBA, it is slightly quieter than the Torrent (at 42.3dBA) in our ", " while also running within error of it for thermals, or slightly cooler with the standard orientation. The ", " is also somewhat competitive with side intake, mostly because it’s technically quieter than both of these options but still close in thermals. The Antec C8 also fits this, running quieter and slightly warmer. The Fractal North XL (read ", ") is much less efficient in thermals for its noise tradeoff if you want to look at it that way.", "CPU temperatures were completely unchanged by the PSU orientation, so we'll skip those.", "Moving back to the noise-normalized results at 27dBA, the GPU averaged 41 degrees Celsius above ambient, with 53 hotspot and 47 memory. We haven't always had the best results with shroud-top fans; looking back at our old test bench and prior reviews, ", ". The Flux Pro overcomes this by just adding fans until the problem goes away.", "The North XL with its mesh side panel did well here, but the Flux Pro is better by 3-4 degrees. The C8 ARGB is similar to the Flux Pro in that it has bottom fans directly pointed into the GPU, but the Flux Pro beats it as well, with the C8 ARGB averaging about 1 degree higher. In fact, among the limited set of cases we've tested with the current bench, the Torrent is the only one with better GPU thermals. It remains king in at least one aspect for a little bit longer.", "Our standardized fan test was requested by viewers years ago and has a ", " explaining the methodology. It has pros and cons. We have detailed them in the past. One of the downsides is hindering performance of cases that come with more or better fans. Sometimes people request tests where we populate all slots, but those actually make performance worse in many cases and pass diminishing returns.", "This test uses three Noctua fans, 2x 140mm intake and 1x 120mm exhaust, all set to their maximum speeds. In the Flux Pro, we set these up in the usual front intake and rear exhaust arrangement. Average CPU temperature was 38 degrees Celsius over ambient and 42 on just the P-cores. We haven't discussed the CPU thermals with the stock fans at full speed, but the results were the same: in terms of CPU performance, this arrangement is basically the same as stock.", "The standardized fan test is most useful for case-to-case comparison when cases ship with insufficient stock cooling. That doesn't apply to the Flux Pro or the cases we're directly comparing it against, so we're not going to delve into comparisons here.", "Now for GPU thermals with standardized fans: Obviously, removing the shroud-top intake fans for our standardized fan tests didn't help GPU thermals. The average temperature climbed to 43 degrees Celsius above ambient, with a hotspot at 56 degrees average and memory at 50. If we needed any proof that the shroud intake fans were doing something, this is it.", "Back to our baseline noise-normalized results, VRM thermals averaged 27 degrees above ambient. The Flux Pro had chart-topping CPU thermal performance, and given the location of the VRM, it's logical that this temperature is chart-topping as well. The mesh-sided North XL came close at 28 degrees, while the C8 ARGB with its focus on bottom intake averaged a significantly warmer 33.", "SPD Hub temperature averaged 22 degrees above ambient, still good, but beaten by some cases like the Torrent and ", " at 21 degrees.", "Overall, Antec’s performance is exceptional.", "First of all, the ", " is our new chart leader for thermals in a case. We haven’t retested the hundreds of case entries we have from our old methodology, but we have retested the prior leader (the ", "). That Antec’s Flux Pro is overcoming the ", " in many situations firmly establishes it as a new case to beat. Antec’s fan placement and quantity is what’s getting it the rank here. ", "Right away then, the Flux Pro lands in our list of recommendations. ", "The case isn’t some revolutionary new meta in design, it doesn’t have particularly advanced styling or materials, and generally, it isn’t taking a lot of major risks. It’s just a case that performs well and in a somewhat standard layout. But that’s the key: It performs well, making it instantly worth considering.", "The Antec Flux Pro’s looks are subjective. We think it looks good -- or at least “standard.” It's well built overall, and it has better overall thermals than anything we've tested recently. Its main downside is that it has an MSRP of $180-$185, and there are some strong competitors at that price. Fractal Design's ", " carried a launch MSRP of $180, and at that price we'd say the Flux Pro wins, but the North XL is on sale (as of this writing) for as low as $130 for the top-performing mesh sided SKU. The recently released ", " (not to be confused with the ", ") has a similar focus on bottom intake GPU cooling for as low as $130 MSRP, but it only comes with three fans and again, we haven't tested it. The ", " is too expensive to directly compare. The Fractal Torrent remains a direct thermal competitor and, when it’s on sale, should remain on shortlists -- though it is an older case now, for those who care about that.", "Cases are ultimately a combination of features, performance, and looks. If you really like the ", "’s use of wood over Antec’s and have your heart set on it, it’s still a perfectly good case. But the Flux Pro is making a strong performance showing.", "Sales aside, some of the strongest competition comes from Antec's own ", " at $150 and the smaller non-Pro Flux at $120-$125. We haven't tested the regular Flux non-Pro, but we can assume that its quality is similar as the spec is similar. Reasons to choose a Flux over the C8 are the traditional non-dual-chamber layout and the shroud-top cooling, if those aspects appeal to you. Going by the spec sheet, reasons to choose specifically a Flux Pro are the multiple larger radiator mounting options (including the top of the shroud), generous clearance on all components, and extra drive support. The iShift mount is cool, but it's not a make-or-break feature. Back-connect motherboard support could be, though, so keep in mind that the regular Flux supports back-connect while the Pro does not officially support it.", "This is an extremely strong case and we're happy to see Antec continuing to come back swinging."]},
{"title": " Excellent Budget Case: Lian Li DAN A3-mATX Review & Benchmarks", "paragraph": ["Excellent Budget Case: Lian Li DAN A3-mATX Review & Benchmarks", "Last Updated: ", "The Highlights", "We liked the ", " enough that we ", " to help explain a peculiar airflow pattern that formed, where we found that adding side intake fans can dramatically hurt GPU thermal performance even though it helped the CPU.", "But we liked the case because it’s easy to pull apart, heavily ventilated everywhere, has a huge amount of space in a relatively confined size, and it’s one of the most barebones interiors you could work with -- but in a productive way. It’s also $70 for the ", " and $85 for this new ", ". It ends up being one of the cheapest cases we’ve reviewed lately, which is good, because the budget market is still pretty strong with last-gen parts.", "Steve Burke", "Jeremy Clayton", "Vitalii Makhnovets", "Tim Phetdara", "Andrew Coleman", "Jimmy Thang", "And in spite of the $70 price for the base model, the case manages to avoid feeling cheap. The panels are solid and avoid that cheap, stamped steel wobble that you’ll feel on a lot of cheaper case panels. The top gets reinforced by radius at the borders, while the sides are reinforced with nearly 2mm steel along the inner edges. The only thing that really feels cheap is the original ", " front panel.", "The above image showcases the case’s original panel (in white) against the newer wooden one. At a distance, the wooden one is almost indistinguishable from Fractal’s North styling. Beyond the wood slats, the panel significantly changes the front characteristics of the case by ventilating it heavily.", "Going micro-ATX gives access to a broader range of cheaper components, but also means simpler mechanisms that are cheaper to make. Making a case like the ", " or ", " requires a lot of fine-tuning to fit everything, but mATX makes things simpler. Sometimes, that’s all we want.", "The A3-MATX is clearly aimed at the budget market: It’s almost entirely stamped steel, has few accessories, and is generally a simple, empty box. It doesn’t include much other than the case itself and some screws.", "There are a couple of optional accessories, but they’re all sold as DLC: ", "The new panel can be bought separately for $24 for those who already bought the original case, or $10 more than the price difference. There’s also a ", " for $50 (which is a proportionally huge jump for a baseline $70-$85 case) and a ", " for $13. ", "We recommend against using both the glass panel and a vertical GPU at the same time, because the GPU would end up too close to the glass and will suffocate for air.", "To get everyone up to speed, some of the price competition looks like this:", " is $60 on sale and includes 3 fans. This is a much larger case, but competitive on price and still mATX. Sama is a supplier in the industry, but also sells to consumers. Its ", " is also $60 with 3 fans. They also have the ", " at $62 and the ", " at $70. Montech is selling its ", " case for $70 with 4 fans, ", " is also $70 with 3 fans, and ", " is available at $75 without fans. Lian Li’s own ", " is a large, more expensive alternative. Thermaltake’s ", " would be another, this one at $55.", "Compared to the preceding ", " at $150, the $70-$85 price of the A3 is aggressive. That’s true too of the ", " at $100. Both the A4 and ", " are also manufactured by Lian Li, but are limited to ITX motherboards.", "Dimensions for the A3-mATX are 456x194x322mm, coming to 28.5L in volume – larger than the claimed 26L due to the usual suspects of rear protrusions and the case’s feet. ", "The A3-mATX is heavily ventilated across the entire chassis, including the top panel, both sides, and with the wood model, also the front. The back also has large gaps in its ventilation for another fan mount, with even more holes punched out of the bottom. ", "The only truly solid panel is on the non-wood variant with its front panel. ", "The A3-mATX technically has 10 fan mounts, but some configurations force giving up one or two fans depending on the location of the PSU mount. Lian Li lists support for 360mm liquid coolers in the top, bottom, and left side – more on that bracket later. If you put a closed-loop liquid cooler in the floor with its pump in the CPU block, that pump will be much more likely to die. The liquid needs to be above the pump so that air doesn’t collect in the pump itself. The bottom could still be useful for open loop radiators or for pump-in-rad and pump-in-tube designs.", "We also noticed that some motherboards may collide with 140mm-wide top-mount radiators when coupled with fans.  ", "The case also comes with side mount options. We actually observed that the side mount makes it possible to worsen GPU thermals in a way that may seem counter-intuitive, so let’s explore that.", "We’ll get ahead of ourselves for the thermal testing later in this review. Here’s a chart showing the side configured with 2x intake fans and a top-exhaust liquid cooler as compared against just the system with just top exhaust (no extra fans) and against 2 bottom intake fans with top exhaust. This is with the plastic front, not the wood front. We’ll get to that later.", "The impact to GPU thermals is massive. We measured about an 11-degree drop in average GPU temperature by getting rid of the side intake, extra fans. To help make this easier to understand, we made a ", " and we’ll come back to thermals later.", "Our animation explains what we think is happening. When the system is configured with only the top exhaust fans, the system is in a negative pressure setup. In PC building terminology, this means there is more forced outflow through fans than intake, from the perspective of the case. As a result, air will naturally find its way in through effectively every hole in the case, but especially the two closest ones: The large, empty fan mount in the back and the empty mesh on the left side panel. This air flows straight in and out the liquid cooler through its fans.", "As for the GPU, its fans are close to the bottom and to the unused PCIe slot covers in the back. This is where the GPU will pull its air in, so it will be fed cool exterior air within mere centimeters of the outside of the case. That’s great for the GPU.", "When we add two side intake fans to this configuration, especially two which will have greater pressure than the exhaust fans, everything changes. The exhaust fans are already battling resistance from the radiator, so the two side intake fans will end up creating a new pressure system. Now, air immediately outside the mesh side panel will find itself pulled toward the fans and shot into the case above the GPU, which will greatly benefit CPU cooling in our tests later. The downside of this is that the lower third of the side panel that was previously feeding the video card intake is now less utilized for the video card, and instead, most of that air will move either directly into the fans or will draft into the case and be pulled up by the currents. The end result is that most of this lower-third side intake no longer feeds the video card, suffocating it for air.", "Instead, the video card is left to pull only from the bottom. It also isn’t pulling air in through the PCIe slot covers anymore and will instead be exhausting air through them as a result of the pressure change. There is more resistance for air to come in than for air to go out, so it will naturally want to find its way out of the computer in that region. Likewise, the flow-through of the GPU is now facing a pillar of air coming in, which will reduce the speed at which it can exit this area of the case. ", "If we remove those two side fans, the original layout allowed a straight column of air to form from the flow-through fan to the top exhaust fans, efficiently removing air from the middle ground.", "And as usual, all of this type of testing is heavily dependent on the other components within the case. Your results may vary with different fans, a different video card, or a different CPU cooler. For purposes of why the thermals behave the way they do in our configuration, the above explains it.", "The empty layout and relatively large area allows a lot of different air and liquid cooling configurations. This isn’t a true successor to the ", ", but it doesn’t appear to be intended as one. It’s doing something else.", "Internally, there’s enough space to install a custom water cooling loop without going completely insane from fitment issues – maybe even with dual 360s. It also fits much larger modern video cards. And, of course, it also brings the price floor down because microATX boards are often pretty cheap. ", "Moving to the front panel, the wood version has an easily-removable dust filter retained with magnets. There’s no extra fan mount in front with this new panel, though even if you forced one to fit, most of the mesh is obstructed by the wood. It’s best to view this as a passive area of flow.", "Coming back to the power supply, the case can support SFX and ATX PSUs up to 220mm long on the right or front walls using a slightly clumsy mounting bracket. The vertical rails alternatively support an SSD bracket. There’s also a strange optional way to mount an ATX PSU to the SSD tray using standoffs. This extreme flexibility results in such a ", " of component compatibility that Lian Li created 9 entire tables for it, separate from the manual. All of this was done without a mess of complicated and customized hardware and brackets thanks to the departure from a tinier ITX box.", "GPUs up to 4 slots thick and 415mm long can technically fit, depending on where and how long the PSU is. However, when using a GPU this large, be advised that it will effectively cut the case in half and severely change the airflow patterns. The GPU will only be able to pull from the bottom and rear PCIe slot covers, meaning side intake will significantly hurt its performance. When using the vertical GPU bracket, that’s reduced to 3.5 slots and 355mm in length. Again, we’d advise against the glass panel for a vertical GPU configuration. This would also reduce CPU cooler access to air.", "The optional vertical GPU mount is good and bad:", "On the good side, it’s a pretty universal and easy-to-install design that looks like it could be used in more than one case, as it attaches to the bottom fan mount locations, which are standard 120mm spacing.", "On the bad side, we think not integrating into the rear I/O of the case itself is a sub-optimal solution that makes plugging or unplugging display cables an annoying operation, even with how infrequent that is in normal use. It requires removing the left side panel and fishing it through the replacement PCIe bracket grommet. Unfortunately, the pass-through doesn’t line up with the GPU itself, making it that much more awkward. It does work, just not well. ", "NVIDIA 40 Series Founders Edition cards have no problem fitting inside. The ", " fits, but would require careful consideration to not put pressure on the power connector. The massive ", " just barely doesn’t fit due to how tall the card is around the PCIe bracket. But just because it fits doesn’t mean it’d be a good combination for thermals, and we’d recommend against any cards of that size in this case.", "Despite the clunkiness of the SSD and PSU mounting solution, we like how the tabs at the bottom keep them in place while securing the top with screws, and found the design simple and functional. There’s an additional 3.5” or 2.5” drive mount in the front floor of the case, but using it blocks off the forward-most fan mount.", "Front I/O is good: It has 2x USB-A, 1x USB-C, and separate mic and headphone jacks – something we prefer over single combo jacks.", "Cable management in general is a weak point. The cable management solution appears to be “it’s huge, so put them wherever.” It isn’t as crafted as some of the competition.", "There are no channels or covers and there isn’t really any space behind the motherboard. Tie-down points are limited. We’re left having to just bundle most of them up into a clump. ", "Similarly, the front panel USB 3 cable is short enough that it could pose some clean cable management challenges when using a mini-ITX motherboard depending on where the USB 3 header is, but it wouldn’t be a problem with mATX. ", "Installing a CLC in the top of the case blocks off access to the top edge of the motherboard, so pre-running those cables first is something we’d strongly advise. This could have been mitigated by the top fan bracket also being removable and allowing for cable adjustments after the fact, but would likely add cost.", "White is known in the industry to be a challenge for color matching across materials. On the white version, the color doesn’t match across some of the internal cables, connectors, and the AC power plug on the rear of the case.", "This combined with the competition in the mATX case market pushes us towards favoring the wood version – it at least doesn’t feel cheap. You also got a little bit of a visual flair without going up to the price levels of something like the ", ". ", "Time to get into thermals.", "All tests were performed with a Fractal Lumen 240mm closed loop liquid cooler with the pump and fans set to 100%. Any tests with additional fans also have those at 100%. The 4070 FE (watch ", ") has its fans controlled for all tests.", "Here’s the CPU full torture thermal chart.", "In this testing, baseline stock testing between the wood panel and plastic panel ended up about the same: 45.5 and 46.1 degrees over ambient for those means they are within error of each other. Testing the base model with a top exhaust CLC and 2x side intake fans boosts its performance massively, with a huge gain over every other configuration. The side fans really help the CPU cooling, despite hurting GPU cooling.", "The second best P-core average thermals come from the wood front panel version with the CLC in the top as exhaust, and two intake fans in the bottom. This results in 44C over ambient, with noise levels only marginally raised over the base version with its solid front panel and glass side panel.", "It’s clear throughout the results that the wood front panel with its open mesh areas lets slightly more noise escape the case in general. The thermal data leans slightly cooler for like configurations as well, but both the thermal and noise results are indistinguishable and mostly fall within margin of error. ", "Removing the two case fans puts the case in “wood stock” configuration, which is 1.5C warmer and not bad, all things considered. Other configurations filter in below, with the base vertical GPU mount and CLC side exhaust setups coming in last at about 48C over ambient. ", "For GPU thermals, the top non-problematic result from CPU thermals is now the leader in GPU thermals at 47C over ambient. Considering the reasonable 32dBA noise level in our hemi-anechoic chamber, we’ll point to this configuration as the way to go unless your aim is to minimize noise as much as possible.", "Bottom-mounted fans benefit the GPU, unsurprisingly, with the result at 47 degrees GPU core. We see another appearance at 49.8, showing that the glass panel costs us a couple degrees in this layout.", "Mounting the CLC to the side as exhaust shows an interesting 3C split between the wood front and base versions of the case, favoring the wood. ", "Unfortunately for vertical GPU enjoyers, that configuration was one of the worst results if not counting the troublesome side intake configuration we talked about earlier. We suspect recirculation is to blame for parts of this, as the exhaust coming out of both the PCIe slot area and the flow-through area don’t have easy paths to get out of the case naturally.", "Next we’ll take a brief look at RAM and motherboard VRM temperatures. We’ve started tracking these in case reviews to better understand if any hot pockets -- not that ", " -- of air build up around those components.", "Surprising nobody, it turns out that intake fans blowing air directly at the motherboard is great for the thermals of these components even in spite of the GPU thermals.", "Most of the results are within a narrow band of 2-3 degrees. Mounting the CLC to the side as exhaust raises both SPD hubs and VRM temperatures roughly 5C higher, so we wouldn’t recommend that for users who know they’ll be running particularly memory intensive workloads with hot memory.", "The ", " has the right ingredients to be a popular case among budget conscious micro-ATX builders. And if you don’t have a specific reason to want ATX, even if that reason is as basic as just liking how it looks or fills the space, then it may be time to seriously consider going micro-ATX. This case gives a lot of options.", "It’s fairly inexpensive at $70-$85 and has good build quality (not counting the plastic front on the ", "). We also think adding the option for the wood front panel was the right move by Lian Li, raising the perception of quality. We think the execution was completely fine given the $15 price bump if you buy it new. ", "Subjectively, we think it looks way better this way. The mesh front doesn’t make-or-break thermal performance, but was a nice consideration.", "Despite its larger size, it doesn’t feel like there’s any considerable wasted space or nonsensical decisions (assuming components large enough to use the volume). We suspect this is a product of Dan Cases’ long history of ITX case design, where every millimeter counts. That mindset still shows despite the ", " being pushed into larger sizes than what anyone would consider SFF. ", "Not much gets in the way while building, either. It’s a very simple build experience. We think this would make a good beginner case, contrary to what we see in more complex ITX cases.", "The cable management is relatively spartan. The size brute forces that aspect, but there are limited pre-fab cable management features. Vertical GPU mounting would have limited usefulness, and side mounting intake fans should be done with care. You also give up easy access to the top of the motherboard in some configurations.", "This market segment also has some fierce competition from other cases that may offer more absolute value from things like included fans. Micro-ATX isn’t purely about size, unlike going for ultra-small ITX builds, so some competition is also just larger. A quick list of cases to check out would include the ", ", the ", ", the ", ", the ", ", and the SAMA series of cases, like the ", ". Other than Montech’s ", " and Fractal’s Pop Air series, we do not have personal hands-on time with any of these, so can’t vouch for them; however, we wanted you to be aware of other options to help as you research other reviews.", "We’re viewing this case like an mATX-sized spiritual successor to the original ", ". That case basically became a de-facto standard in online discussions as a simple and cost effective choice for anyone that wanted ITX without too many headaches.", "We liked the A3-mATX. It’s easy to work with, fits a wide range of CPU coolers and video cards, and it’s relatively “cheap” (by modern standards) for the quality. Thermals are solid as long as you set up a good airflow pattern and avoid making the fans fight each other. ", "Overall, we’re neutral to positive on the A3-mATX. It’s straightforward, the cons are relatively inconsequential with planning, and there’s not much to complain about. The target user for this case would be those who don’t need full ATX size, but also don’t want to pay the ITX tax. It hits the “good enough” mark in just about every critical area. But for a $70 to $85 case, “good enough” becomes “good.”"]},
{"title": " Phanteks is Back: Eclipse G400A High Airflow Case Review & Thermal Benchmarks", "paragraph": ["Phanteks is Back: Eclipse G400A High Airflow Case Review & Thermal Benchmarks", "Last Updated: ", "The Highlights", "Today we’re reviewing the Phanteks Eclipse G400A. It’s $110 and includes 4x 140mm fans that are met with a swooping inlet to try and prevent recirculation and funnel the air clean into the case. Phanteks is using wide-spacing mesh for the front panel with a finer dust filter behind it, doubling-up on mesh in a way that can hurt performance; however, there’s a lot of space between the filter and the front panel, which helps avoid issues introduced by pressure drop. ", "The front mount only officially supports 140mm fans. It helps that these are included, and while this does limit front mount support for radiators, forcing a specific fan can help performance. We saw Lian Li do this with its new ", ". Eliminating support for 120mm fans means reducing the amount of metal and railing obstructing intake of a 140, so this should be the ideal approach for cooling.", "Steve Burke", "Patrick Lathan", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "The case is also elevated a lot, which will help with bottom intake (like for the PSU). That ground clearance is important. The lower side panel is a ventilated strip that’s intended to feed PSU shroud-top fans, although the porosity is relatively low.", "Overall, Phanteks is aiming to compete in the airflow and performance market with this case.", "The Phanteks Eclipse G400A has been a long time coming. Back in early 2016 we were initially unimpressed by the Phanteks Eclipse P400 (watch ", ") with the solid panel, but we had a more positive opinion of the airflow-focused P400A (D-RGB) in 2019 (watch ", "). With a launch MSRP of $90 and three stock fans behind a simple mesh front panel, the P400A remained a strong competitor in price-to-performance for years after its launch. Over those years, Phanteks has incrementally updated other Eclipse cases from P to G versions, but it's held off on the most important model for so long that some of the updated G cases ", ". Finally, though, the G400A is here, and we can see whether it's a worthy successor at $110.", "Key competition to the G400A includes the Lian Li Lancool 207 that we ", ", which takes on a similar approach to design and can currently be bought for around $80. There’s also the new ", ", which we have in for testing already and are working on. We’ll cover the other competition as we work through this review.", "Getting into the build quality and assembly notes first:", "The G400A's front panel diverges from the formula that made its predecessor so successful: the P400A just had a sheet of mesh with no additional filtration, while the G400A uses brick pattern mesh (with larger rectangular holes) backed by a filter. ", "Phanteks advertises that the mesh is now 45% open surface, versus 32% for what Phanteks calls standard mesh. We’re not sure exactly what “standard” means. ", "Both the mesh and filter are magnetic, and the filter can be removed without altering the appearance of the case; we'll test that later on. The filter has plenty of clearance (>2cm away from the intake fans), but it's one of the saggiest we've ever seen. On the plus side, the lack of reinforcement means that nothing blocks the LED lighting and nothing blocks the intake. ", "Phanteks has also ", " with two tempered glass panels and more elaborate cable management, but that version hasn't yet been released.", "The front panel includes a plastic frame that's shaped around the 3x 140mm ARGB infinity mirror fans. The choice to only support 140s in the front is in contrast to the P400A, which had more front mounting options, as well as a cheaper non-Digital variant for customers who wanted to use their own fans.", "The uniquely-shaped plastic frame might help to keep air from recirculating through the front fans, but the fans are already sealed against the metal chassis. ", "According to Phanteks it directs airflow [and] reduces turbulence. ", "The front fans are uniquely joined into a single unit, which could be useful in some contexts. In the G400A, there unfortunately isn't enough room to easily take all three fans out in one piece while a system is inside the case. In situations where that’s not possible, the remaining benefit of the uni-fan approach is that the front fans are daisy-chained together, sharing a single ARGB and fan header. All of the fans have Phanteks LINK6 connectors and need adapters to connect to standard fan and ARGB headers, which may limit how reusable they are for future builds.", "The G400A's focus on shroud ventilation with a two-part glass and mesh side panel is similar to some ", " and ", " cases we've covered, but in particular, the ", ". The 207 also has infinity mirror fans and a similar magnetic front panel, but we saw both the 207 and the G400A at Computex, so they were likely in development in isolation and at the same time. ", "The G400A has 3x 120mm mounting locations atop the shroud, but at least one of these is of limited usefulness due to the presence of the rear-mounted PSU. The biggest difference with the 207 is that it moves the PSU forward to make way for cooling with clear outside access directly into the GPU. ", "The 207 led two categories in ", ", and it's a tough act to follow with a steady price of $80 on Amazon. The G400A differentiates itself through its larger size and more conventional layout, which gives it an advantage over the 207 in cable management (our biggest complaint with the 207). The suggested routing from Phanteks' manual worked well even with our large sleeved cables, although we opted to route the GPU through the shroud. If you install fans on top of the shroud, that's not an option. The removable section of the top panel and roomy upper area makes working with EPS12V cables for the CPU and other connectors at the top of the motherboard easy. The G400A also supports motherboards with rear-mount connectors; Phanteks specifically mentions BTF and Project Zero boards as compatible.", "Surprisingly, the G400A doesn't have better radiator support in any meaningful way than the 207. The shroud cutout at the front of the G400A doesn't leave room for radiators, and although it might technically be possible to force a 280mm rad in, it's not officially supported. Headroom at the top of the case is excellent with more than 7cm of clearance from the top edge of the motherboard to the roof, and the removable top mesh panel makes the top fan mount easy to access for installing radiators up to 360mm. ", "The whole top of the case is also technically removable, although doing so requires removing 15 screws. Even though it’s kind of a pain to remove, we like the additional access without losing rigidity of the overall frame. This optional feature can help with maintenance and installation. ", "But as far as radiators, we don't generally recommend trying to fit 360mm open-loop radiators in the case (as opposed to a CLC) since the fittings will come close to the stock fans. It’s doable, but will require more effort than typical for custom loops.", "There are some minor quality-of-life issues that aren't unusual for cases in this price range:", "The top mesh section is a little stiff and difficult to grab, the steel side panel has to be pressed down on all sides to slide into place and could be executed better. The PSU filter unfortunately ejects from the rear of the case, meaning that pulling it away from a wall will be necessary in most situations. The only construction problem was an improperly installed rivet inside the drive cage, but the cage still worked fine. ", "Drive support is adequate but bare-bones, limited to either 2x 3.5 drives or 2x 2.5 drives and 1x 3.5 drive. There's no built-in vibration damping, and Phanteks didn't bother cutting extra slots for moving the cage to any alternate locations.", "As well as running our usual suite of tests on the G400A, we went back and ran the P400A, as well as the G400A without its front filter in order to match the older case. The obvious competitor to watch in these charts is the significantly cheaper Lancool 207, but the ", " is a close match to the G400A in both price and layout. ", " (non-Pro) with five stock fans is similar as well at $120, although we haven't tested that model. Let’s get into the benchmarks.", "The first test is for noise-normalized thermals on the GPU.", "With the four stock case fans slowed to hit our noise-normalized target of 27 dBA SPL, the G400A made a good start with an average GPU temperature of 45 degrees Celsius above ambient compared to the P400A's average of 49 degrees. That's near the middle of our chart, but many of the cases above it required aftermarket fans (HAVN HS420, O11D EVO side intake) or are from a higher price tier. The most relevant exception is the Lancool 207, which averaged 42 degrees above ambient in this test with its direct GPU cooling. The Lancool 207 was built for this and shows advantages in cooling. The ", " (read ", ") also does well here, though is a larger dual-chamber style.", "The G400A isn’t exceptional, but is average to above average for GPU cooling.", "Moving to CPU thermals in the same noise normalized test, the G400A again outperformed its predecessor at 41 degrees above ambient for the average all-core temperature and 45 on the P-cores versus 46 all-core and 50 P-core on the P400A. It's encouraging to see that one of the better-cooled cases we'd reviewed as of late 2019 has been outperformed by a decent selection of new cases. The G400A effectively tied the 207 here (as well as the more expensive ", ") without a solid lead in either all-core or P-core averages. Both cases are good here.", "The G400A is quiet for the level of CPU cooling that it provides at 100% fan speed, with an all-core average of 39 degrees above ambient at 37 dBA while some similarly-performing cases like the ", " (watch ", ") and ", " (read ", ") are significantly louder. That includes the 41.6 dBA Lancool 207, which still tops the chart but is less than two degrees ahead of the G400A, yet is noticeably louder.", "Removing the front filter had barely any effect on thermal performance, so we recommend leaving it in place unless the sagging causes problems.", "Taking a quick glance at the GPU thermals under full load and at max fan speeds, we can see that removing the filter also had minimal effect here. As long as it's kept clean, leaving this filter installed shouldn't hurt.", "Our standardized fan test uses the same set of three fans in every case, which is useful here for comparing the ventilation of the P400A and G400A while removing stock fans as a variable. The G400A shows definite improvement, with an average GPU temperature of 49 degrees above ambient versus 52 degrees on the original P400A. ", "Neither of the Phanteks cases perform well versus the rest of this chart, but you should plan to keep the G400A's stock fans, so its performance without those stock fans isn't particularly relevant.", "In the same standardized fan test, CPU thermals improved from 41 degrees above ambient all-core in the P400A down to 38 degrees for the G400A. It seems like Phanteks has managed to improve cooling not just through brute force, but also through panel design, while not sacrificing dust filtration.", "Circling back to the original noise normalized results, the G400A had excellent VRM thermals at 28 degrees above ambient, near both the Lancool 207 and ", " (read ", ") at 27 degrees. Memory temperatures were similarly good. This may be due to the G400A's high ceiling in combination with the four 140mm fans that provide airflow up to the very top of the case.", "In comparison to the older P400A, the G400A is a solid improvement in thermal performance and it keeps most of the feel and stylings of a Phanteks case. In our original review, we concluded that given a choice we much prefer a single layer of perforated metal to a decorative mesh panel backed by a foam or fabric filter. That's still generally true, but Phanteks deserves credit for building a case with a filter that doesn't significantly hinder airflow.", "The G400A is a good case at a good price, but it's hard for anyone to compete against the ", ". Phanteks' advantage is that the G400A is a bit larger, and therefore it fits slightly larger components. It definitely has more cable space than the ", ", for example, with cable management really being our only big complaint with the 207.", "Phanteks committed fully to the stock fans that it includes with the G400A, which we agree with for the most part. The biggest downside is that there's no front radiator compatibility, although it might be possible to get a 280mm rad installed.", "At $110 with the 4 included 140mm fans, the case is overall competitive. It’s pretty good in terms of ease of installation. The removable top is nice, though it is a bit of a pain to remove it. ", "If you like the G400A and just wanted to read a review to look for any problems, we’d say go for it. Just keep in mind any size limitations as it’s a little smaller for an ATX case. But if it’s within your budget and you like it more than the Lian Li Lancool 207, we think the G400A is a well-executed Phanteks case. It’s good to see that the company is back in a good way."]},
{"title": " Montech HS01 Pro & HS02 Pro Case Review: Thermal Benchmarks, Build Quality, & Noise", "paragraph": ["Montech HS01 Pro & HS02 Pro Case Review: Thermal Benchmarks, Build Quality, & Noise", "Last Updated: ", "The Highlights", "With removable feet that can be swapped from the top to the bottom, Montech has 2 new cases that can quickly invert. ", "Those two cases are based on the same chassis: They are the ", " and ", " Pro cases, differentiated by the glass or mesh, and each includes 5 fans.", "Steve Burke", "Patrick Lathan", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "Major points of interest include the recessed motherboard tray, ventilated rear chamber cover, and abnormal power supply location up in the front. It’s not all good news, however. The power-supply area has some ventilation problems we’re not happy about, but there are some mechanical upsides. ", "The rear fans remove as a single piece without becoming a proprietary nightmare, which is a welcomed feature. The case tries to plan around back-connect boards, running into the chicken-or-egg problem that both boards and cases are facing.", "As always, we have some critiques of the case, but we were also overall happy with its build quality and assembly. The cases land at $130 to $140 with fans or $100 to $110 without them. ", "Montech is probably best-known for its ", " chassis. The company has had some hits and some misses since it started, but the HS01 and HS02 blur the lines between a more traditional case and a dual-chamber case.", "The big marketing play is toward inversion. Cases have inverted in the past, but some of the original invertible cases we covered were difficult to flip around and required dozens of screws.", "Modern invertible cases, like the be quiet! Light Base series, have made this process way faster.", "Inversion is the headlining feature of the HS cases, and the process is extremely easy. The top cover moves to the bottom, the bottom filter and legs move to the top. That's it. ", "The process is optionally toolless: the legs are magnetic, but they can also be screwed into place when the case isn't inverted. The main downside of making the process so simple is that aspects of the case which are designed to work right-side-up aren't altered at all in the inversion process, so the side panels and rear fan bracket are installed upside-down when the case is inverted and the PSU power switch becomes inaccessible. ", "Other aspects of case configuration are also easy to deal with. The top panel is magnetic and pulls off easily. The company uses a rubber/fake leather strap at the back. The rear two-fan bracket comes off as a single unit (which we liked), and the rear expansion slots rotate vertically with minimal effort. Removing the top panel gives immediate access to the PSU switches (like power and eco mode), as well as the RGB hub connections in Pro variants.", "The HS02 has what Montech calls an 8° Curved Glass front pane. It’s not 8 degrees -- it’s 90, so maybe they meant the radius of the bend was 8mm. ", "The media kit came complete with an illustration of the corner with an 8° label though. Either way, the bend is, in fact, 90 degrees in total, and the front panel butts up against the side panel to look (sort of) like a continuous pane, similar in some parts to the King 95. It's not as impressive as the ", " (read ", "), but it's definitely less expensive. The glass panels are beveled where they meet the angled plastic pillars for a flush fit.", "The chassis design strikes us as being optimized for back-connect boards. Back-connect boards have gotten some traction, but they aren’t a significant portion of the market yet. Case makers have a challenge: It's too early to prioritize back-connect at the expense of compatibility with normal boards (unless marketing specifically for a back-connect board), but also, not building for it at all means no adoption of change.", "The motherboard and fans have what Montech describes as a sink-in design, meaning that ATX or even mATX boards are surrounded by metal on all sides. As a consequence, it's difficult to reach board connections with normal motherboards (which is most of them): for example, we were forced to use the stock flat EPS12V cables for our SilverStone PSU because our custom-sleeved CableMod replacements couldn't cleanly fit. Routing the 24-pin cable required an uncomfortable bend, and fitting the USB headers into place was nearly impossible. There's no good route for the GPU power cable either, although that's a common issue with open-bottomed cases and not specific to Montech.", "The PSU area leaves a lot to be desired: Unfortunately, we end up with 3 layers of blockages from the PSU case mesh, the interior cover door mesh, and the exterior panel mesh. The two case panels overlap and obstruct each other, which already overlap with the PSU ventilation. Stacking 3 layers atop each other reduces flow and increases resistance, which can increase noise or minimally reduce cooling. Fortunately, PSUs tend to be less thermally sensitive, but we’d like to see fewer overlapping obstructions.", "With the PSU fastened down, we found our normal SilverStone PSU pushed the cover up without screws to hold it in place, which we added.", "The PSU mounting bracket can be rotated to mount either a standard ATX or a smaller SFX PSU; this bracket then slides into place and is screwed to the top of the chassis. There's no particular reason to use an SFX PSU with this case. The extension cable that runs from the rear of the case to the bracket at the front must be routed through the bracket before it's installed.", "This is mostly an air cooling case, which is how we’re testing it. Radiator support is restricted, though. The front of the HS02 obviously doesn't support radiators since there are no mounts, but even in the HS01, the PSU placement overlaps with the front fan mount. That means there's only space for mounting on the outside of the chassis, and only normal 25mm thick fans fit (no radiators and no extra-thick fans). At the top of the case, Montech claims support for radiators up to 123mm wide, which is a strict limit due to the bumps on the ATX PSU bracket that pokes through, leaving small bumps to interfere with clearance. The bottom mount works fine for radiators other than obstructing the bottom edge of ATX boards, but Montech (correctly) doesn't claim compatibility above 240mm due to the cramped space. There's no 140mm-wide radiator compatibility in either case, and only the HS01 has support for any 140mm fans.", "Generally speaking, we don't like all the plates and covers and brackets that Montech has stuffed into the HS01 and HS02. They hide some cable clutter, sometimes at the cost of thermals, but most clutter would be invisible behind the steel side panel anyway. There are times where we like this type of feature, but with this case, there are already tradeoffs in the depth and the accessibility for some connectors in some areas. Sacrificing more of that for the metal plates can sometimes work against it. Even still, cable management space is generous, but we'd happily trade some of that space for better access to normal motherboard connectors and some small clearances in the main chamber.", "Moving on to the hardware: Cases generally include a set of SSD screws for attaching 2.5 drives. The HS01 and HS02 do not, however: as the manual notes, every screw included in the accessory kit is 6-32 TPI. The cases claim compatibility with up to four 2.5 drives, so the screws are a strange omission. It’s not a big deal to bring your own screws, but not standard for a case to cut this corner.", "The front panels of the HS01 and HS02 aren't directly interchangeable since there are some differences to the support structures, like the support corner pillar in the HS01 and some plastic trim in the HS02 that’s not on the HS01. This was inconvenient for our testing, but it's unlikely to ever come up from a customer perspective, so it doesn’t matter much unless you wanted to swap it later.", "All variants include ARGB lighting strips at the bottom of the case, with the Pro cases also including ARGB fans and a built-in controller. The fans use separate (standard) connections for ARGB and fan control, which we generally prefer, but it does lead to a confusing mess of wires. If you've bought into one of the proprietary RGB ecosystems, the Pro cases really aren't the best for working with that.  ", "The Pro variants ship with fans and the non-Pros do not, so all stock tests shown here represent Pro performance. We tested the HS01 stock and inverted, but Montech's marketing materials push the natural airflow chimney effect angle, so by that logic, inverting the case without rearranging the fans should lead to worse performance. We'll see.", "We’ll start with noise-normalized CPU thermals, which means we use our ", " in the lab to collect highly controlled noise data for comparison.", "Inverting the case didn’t produce a significant change. The HS01 Pro ran at about the same temperature in both tests. The glass panel versus mesh panel also had minimal impact.", "The stock fan layout is the same in both cases, meaning that the HS01's mesh front won’t do much unless the fans are re-arranged; if anything, it could allow some air to escape where we’d rather keep it in. The CPU averaged 49 degrees Celsius above ambient in the HS01 Pro, 52 degrees on the P-cores, and the results for the inverted HS01 and for the HS02 were within the normal range of variance. The fans were run at slightly different speeds in each of the three configurations to hit the 27 dBA threshold, which is where the chamber comes into play (as we can actually measure those tiny acoustic differences now), but that wasn't enough to make a difference thermally.", "Montech's own moderately more expensive ", " with a glass front beat the HS cases in this test with an average of 47 degrees above ambient. The ", " (read ", ") is also more expensive, but it has relatively weak CPU cooling with the stock fan layout, and the HS cases beat it by 1-2 degrees. More traditional designs like the ", " (read ", ") and ", " (watch ", ") fly past the HS01 and HS02, setting a ceiling and giving perspective on cooling. The ", " (read ", ") also accompanies these two.", "The range for the GPU thermal results was just as tight, with the inverted HS01 averaging 42.8 degrees above ambient and the HS02 averaging 43.2, which is within variance, but that’s still not even one full degree of difference. ", "It's not a surprise that the chimney effect isn't a factor when active airflow is involved, nor is it a surprise that changing the front panel has no impact when there aren’t any fans installed at the front of the case.", "Although the different configurations didn't make much difference, the HS cases performed well overall for GPU thermals, respectably close to the C8 ARGB's 42 degree average. Like the C8, the HS cases have bottom intake fans that force cool air directly into and through the GPU and with minimal obstruction beyond a dust filter. The King 95 Pro also has bottom intake fans, but they're less effective, resulting in a 48 degree average. The Flux Pro and Lancool 207 remain leaders here, but one is in a different price class and both are different styles.", "Full speed case fans are next, dropping the noise control and testing GPU thermals.", "At full speed, we can finally see a difference between at least the regular and inverted HS01 results, with the inverted layout averaging 40 degrees above ambient to the regular layout's 42 degrees above ambient. The bottom intake fans move enough air that flipping them to the top of the case where they can breathe more freely is beneficial. The inverted layout also directed slightly more noise towards our mic placement, but not enough for an audible difference at 38.5 versus 38.0 dBA. The regular HS02 result closely matched the HS01 result at 42 degrees, but the HS02 was quieter (as measured from the front) due to its solid front panel blocking noise egress. The drop to 35.8 dBA is noticeable, if barely. However, remember that at the 27 dBA threshold performance and noise levels were both equal.", "As before, the Antec C8 ARGB's GPU cooling is on par with the performance of the HS cases at 41 degrees above ambient, with noise levels equivalent to the HS01. The King 95 also averaged about 37 dBA, but with worse GPU thermals, averaging 46 degrees.", "Our standardized set of fans can't be installed in the HS02 due to the lack of 140mm mounts, which made this test simple. We installed the two 140mm intake fans at the front of the HS01 and the single 120mm exhaust in the lower of the two rear slots.", "With this layout, average CPU temperature was 41 degrees above ambient and 45 degrees for the P-cores. For this case specifically, those are lower than the stock results, but that's not surprising given the more direct airflow aimed at the CPU cooler. It’s also completely normal performance for a mesh-fronted case in this test, landing between the ", " (watch ", ") and Phanteks P400A Digital (watch ", "). The Antec C8 and King 95 Pro results on this chart were both tested with side intake, so performance is predictably worse than the HS01.", "On the other hand, moving to the normal front-to-back layout with the standardized fans hurt GPU thermals. Removing the stock bottom intake fans that made the HS01 competitive in this category led to an average GPU temperature of 45 degrees above ambient, which isn't terrible, but allowed the King 95 Pro and C8 ARGB to take the lead at 43 degrees for both. Montech's stock fan layout seems like the best compromise.", "To finish things off, we'll move back to the noise normalized testing. VRM thermals were nearly identical for each of the three tested configurations, averaging 33 degrees above ambient in the HS02 Pro, which lands the HS cases in the middle of the chart between the C8 ARGB at 33 degrees and the King 95 Pro at 31.", "The SPD Hub sensor readings from the RAM told a similar story: all three configurations averaged close to 25 degrees above ambient, close to the C8 ARGB's 24 degree average, although the King 95 Pro scored well in this specific instance at 21 degrees.", "Montech's strength has always been in the budget space. The ", " and ", ", however, are sort of in that mid-range category with their prices. The recent tariff situation is obviously going to affect that market. Montech contacted us to confirm MSRPs a few days prior to launch, so hopefully these prices will stay stable for some time.", "As a fishtank case with a curved corner, the $140 HS02 Pro is a reasonably priced alternative to the more expensive cases that match that description like the ", ", ", ", HYTE Y60 (watch ", "), or even Montech's own ", ". We seriously recommend watching the ", ", because there were some features we didn't like, but it's up to you to decide whether the savings are worth it. If you use a back-connect motherboard, that may solve many of the issues we saw, including with cabling.", "The HS02's thermal performance wasn't abysmal or amazing. It was fine. Of these two cases, we're more willing to accept middling performance from the one that looks interesting, in other words, the glass-fronted option. ", "The HS01 has greater cooling potential thanks to its mesh-front panel, but it's also more generic: there aren't a ton of fish-tank cases that can compete with the HS02's price, but there are many, many $100-$150 mesh-fronted cases that can compete with the HS01. These include options like the ", ", ", " (watch ", "), ", ", or many of the other cases we've reviewed in the past couple years are all viable alternatives to a mesh-fronted case. There’s a lot of competition at that price class. ", "If you love Montech’s case here or really like how it looks, we can say “it’s fine.” We do think the fish-tank version makes a little more sense for most people. If you really want a mesh case, there are better alternatives."]},
{"title": " AMD Fake Frame Image Quality, AFMF, & FSR 4 vs. FSR 3.1 Comparison", "paragraph": ["AMD Fake Frame Image Quality, AFMF, & FSR 4 vs. FSR 3.1 Comparison", "Last Updated: ", "The Highlights", "Today, we're giving AMD the NVIDIA treatment: We're inspecting AMD's fake frames to compare them to real frames, but we aren't yet comparing NVIDIA's fake frames to AMD's fake frames, because that'll come later.", "That means that this article will include frame-by-fake frame analysis of AMD's generated images versus native-only rendering.", "Steve Burke", "Patrick Lathan", "Jeremy Clayton", "Vitalii Makhnovets", "Tim Phetdara", "Andrew Coleman", "Jimmy Thang", "Sometimes, you can see ghost images, such as in Kratos' swing over this snowy background, where there's a blurring of the axe and arms as AFMF, or Advanced Fluid Motion Frames from AMD, interpolates in-between frames. ", "We'll also talk about FSR 4 vs. prior FSR iterations and native: In some scenes, like the one above, image clarity and stability are greatly improved over prior FSR versions. ", "The Ultramarine's armor and hanging cables both show significant improvement in the newer version versus the older.", "In other scenes, like the one above showing an air assault, we can see heavy warping with FSR 3.1, but still modulation with FSR 4 for the flying units. ", "The ground assault shows issues with shadows pulsing underneath the Tyrannids in both versions. ", "Smeared trails behind NPCs and barrels are improved upon with FSR 4, but sometimes still present.", "So, we'll be looking at AMD's Fidelity FX Super Resolution version 4 with the new RX 9070 XT (read ", ") GPUs and comparing it against the prior version. This is an image quality specific test, and like we said in the NVIDIA coverage of DLSS and MFG, not all fake frames are created fake equal. This will look at that in part. What we're not doing here yet is comparing FSR 4 and AFMF to DLSS and MFG. That might be a later piece if there's interest, but we need to lay the groundwork for each technology independently first.", "One important thing to remember with all of this, just like with NVIDIA’s that we looked at, is that we’re closely inspecting these images today for image quality. That means we’re pausing things and zooming in. In real play, it’s likely that some of these differences would go unnoticed at full speed and “zoomed out.” One other note is that YouTube/video compression makes things sometimes difficult to fully appreciate.", "Let’s get into it.", "AMD’s ", " (FSR) upscaling has finally moved into the “AI” buzzword era with FSR 4’s machine-learned ", " (CNN) model co-developed with Sony. Sony and AMD announced a collaboration effort back in December of 2024, dubbed “", ".”", "Sony strongly implied that it’s going to use a rebranded version of FSR 4 as its own “PSSR” in order to target 1080p native rendering on the PS5 Pro, but with the upscaler doing the work to output a good looking image at “4K.” ", "On the PC side, FSR 4 will only run on the new Radeon RX 9000 series graphics cards for the time being, with no official word on back-porting to RX 7000. We’re unsure at this time whether it’s a technical limitation or a product segmentation move on AMD’s part.", "The ", " has 36 games at the time of writing, which is late March. That’s not a lot, but the number will hopefully grow as more games are updated. Several of the listed games are big Sony titles as well, indicating that the company is serious about utilizing the tech, but also shows the partnership between them.", "The previous generation, FSR 3.1, is technologically distinct from its predecessor (FSR 3) by way of being implemented as a modular .dll file rather than being entirely baked-in to the game. This paves the way for future revisions of FSR to be more easily implemented by the game developers or just in general.", "FSR 4 also uses a .dll file, and can be swapped-in officially in FSR 3.1 games via a driver-level override in AMD’s Adrenaline software in a very similar way to NVIDIA’s DLSS override. However, the games have to also be on AMD’s official whitelist to get the toggle to appear in the driver software. ", "Unofficial tools like ", " open the door for a lot more flexibility, but we haven’t tested them yet so we can’t make a recommendation, but there’s stuff like that out there.", "AMD also ", ", and we haven't seen any indication from AMD that its in-game framegen algorithm has changed since FSR 3.1. ", "In AMD's words, Advanced frame generation interpolation technology when used with AMD FidelityFX Super Resolution (FSR) 3 inserts 1 frame between existing ones.", "However, AMD also has separate driver level frame generation known as ", " (AFMF) that can be applied without in-game support. ", " is a new introduction alongside FSR 4.0. To use it, you need AMD Software: ", " or newer, RX 6000 or newer, and a DX11, 12, or Vulkan game. RX 6000 ", ", while RX 7000 and newer support borderless windowed, and the AMD ", " (read ", ") reviewer guide stated that in-game display setting should be set to borderless fullscreen mode. ", "And that's a lot of rules, but keep in mind that Smooth Motion, NVIDIA's answer to AFMF, is exclusive to the RTX 50-series. ", "NVIDIA has stated that ", ". ", "We're focusing on AFMF 2.1 here, so this isn't a direct 1:1 equivalent to the piece we just ran on ", ", but we’ll also be looking at the frame generation performance for AMD. For this article, the performance we care about is image quality, and not the actual literal framerate performance. That will be a separate test along with potentially latency. ", "This is an isolated test so that we can build foundational knowledge first, just like we did for NVIDIA. The direct comparison would be NVIDIA Smooth Motion versus AMD Fluid Motion Frames, but we’re focusing on just AMD today. That comparison may come later.", "As for FSR testing, our FSR comparisons will focus on FSR 3.1 vs. FSR 4, with a couple references to native capture as an anchor. We captured everything at 4K resolution with FSR running at the Performance preset, meaning it’s upscaling from 1080p base render resolution. We disabled anti-aliasing, camera effects, and motion blur where possible to get the cleanest images we could.", "The objectives today are purely image quality, not performance. We’ll be comparing frame-by-fake-frame image quality, FSR iteration quality, and looking at behavioral patterns in general.", "Let’s get into the image quality comparisons.", "First up is Warhammer 40K Space Marine 2. Like everything else we tested for this piece, FSR 4 support comes by way of the driver-level override. We used the High graphics preset, turned off camera shake, and set motion blur to off; however, we found the latter doesn’t actually work and motion blur persists regardless, but that’s a game thing.", "We’ll start the comparisons with a scene in the Armory, or “Armouring Hall” in native Grimdark. Even before walking forward, the difference between FSR 3.1 and FSR 4 is stark. Static elements like the floor of the walkway that shift and shimmer heavily with FSR 3.1 are now stably locked-in. On top of that, the entire image is much clearer and more detailed. ", "Examples of this include the floor, where we see improved image stability and clarity, the Ultramarine’s armor showing similar improvements in a side-by-side, the distant hanging cables, and the tech priests’ hoods. Distant candle flames that can’t even be made out with FSR 3.1 are visible with FSR 4, bringing them back into existence.", "As we walk forward and the… we’ll call it a “kiosk,” drops down, the difference in clarity is so obvious it’s almost like looking at two different resolutions. No matter where you look there’s improvement. The fine details under the main monitor, the tech priest’s mask, and even just the general contrast and visual discernability of all the mechanical arms and tubes are all vastly improved. We double-checked our settings and confirmed that they were running as intended for a like-for-like comparison, so it really is just that much better in this example.", "This is a very promising start for FSR 4.", "Let’s compare FSR 4 to native 4K. Space Marine 2 forces either TAA or upscaling at all times (even at native), so we went with the default of TAA for the native capture. ", "We also did this in our ", ", which showed how some scenarios, like Cyberpunk, can actually look worse than upscaling because of TAA.", "The flickering and shimmering on the floor in Space Marine 2 we saw with FSR 3.1 is also present at native with TAA. That makes FSR 4 look even more impressive here – even at the performance preset – since it’s taming an undesirable behavior. We said this before, but we shouldn’t be seeing things that look worse with all defaults at native than with an upscaling technology. ", "General detail before moving – like in the floor, walls, and priest hoods – is a toss-up between native with TAA and FSR 4 Performance mode. That’s simultaneously a critique of TAA and a praise of FSR 4. ", "The green orb far in the distance looks very slightly better with native TAA. As the “kiosk” drops down, the level of detail between native with TAA and FSR 4 Performance is very close. However, we think FSR 4 actually comes out slightly ahead – most obviously in the round speaker-looking elements on top of a couple of the monitors.", "Like we said in the DLSS piece, upscaling should never look better than “native,” and game developers shouldn’t be leaning on upscaling technologies in this way. The only reason it ever does look better is because of issues such as those with TAA, which is the default here.", "We’ll briefly look at another indoor scene in the campaign’s command bridge before moving on to a mission. Again, everything is sharper, clearer, and easier to discern when using FSR4. Gadriel’s face, Titus’ hair, and Chairon’s armor – particularly the chest decoration – stand out as night-and-day differences.", "Looking at the bridge’s holographic map area, FSR 3.1 suffers from distracting flickering on some of the round grates (underneath the three skulls and on the right side of the main terminal). Switching to FSR 4 almost entirely eliminates this behavior. The thin lines within the hologram that shimmer and boil with FSR 3.1 come across as much cleaner with FSR 4. The other ship visible out the left windows doesn’t show much difference, however.", "It could be that the largest areas of improvement with FSR 4 are in dimly-lit or low contrast scenes. We’ll test that with the next comparison.", "Loading into the “Decapitation” Operations mission gives us a brighter outdoor area. While the marine’s armor is again visibly better-looking with FSR 4, the effect on the rest of the scene is more subtle, more like lifting a haze rather than a transformation. You can clearly see this in the texture of the ground and on the shoulders of the statues.", "Once in motion, FSR 3.1 starts to deteriorate, but FSR 4 keeps the image clean. Unfortunately, the bugged permanent motion blur makes it hard to draw a distinction between the two FSR revisions while the marine is rolling down the stairs. Elements such as the detail in the inlaid stone floor and the buildings to the right look better during motion with FSR 4. So far, it looks like most of the FSR 3-to-4 improvements are visible in motion.", "Strafing to the side shows off a huge improvement favoring FSR 4 over FSR 3.1. Every single element on screen looks better with FSR 4 – the textures on the sides of the stairs, the statues, the murals against the far wall, and the guardsmen. It again gives the impression of running at a higher resolution.", "This would be a very interesting scene to compare the most up to date implementations of DLSS and FSR head-to-head in a future piece.", "Last for Space Marine 2 is an upscaling torture test by way of a slow pan of the Tyrranid assault. The flying creatures passing over the front of the massive building cause the windows to warp and blur heavily when using FSR 3.1. It still happens with FSR 4, but to a lesser extent. This is close to a worst case scenario for any upscaler, period.", "In both the air and on the ground, FSR 3.1 causes the creatures to blur into a mass, sometimes phasing in and out of existence or blending together. FSR 4 isn’t totally immune here either, but again does a way better job than the prior version.", "Since this scenario is so hard on upscalers, let’s compare to native with its forced TAA again. Watching the flying creatures in front of the windows shows us what it’s supposed to look like, free of the heavy warping seen with FSR 3.1, or even the warping-lite modulation seen with FSR 4.", "Looking at the ground assault again shows just how well FSR 4 is handling this relative to FSR 3.1. It’s very close to the look of the native capture, but still suffers from an effect that makes the shadows underneath the Tyrranids appear to pulse and shift underneath them. At this level of fine detail and chaotic movement, even native with TAA struggles a little bit with grain and warp. Some areas are cleaner, but like we said earlier, this particular game has toss-up comparisons between them.", "Monster Hunter Wilds is up next. We used the High graphics preset, but turned off anti-aliasing and camera effects like motion blur, vignette, and depth of field. We also reduced camera shake to its minimum levels. Cutscenes are entirely in-engine, which is useful, so we got a mix of those with some actual in-game capture.", "Taking a quick look at the title screen animation shows little difference between FSR 3.1 and FSR 4. Textures and edges are slightly sharper with FSR 4. The stippled effect on fur as seen with FSR 3.1 is also almost entirely gone with FSR 4. There’s not much else to discuss here so we’ll move on.", "Jumping into the actual game at the point you choose your weapon by the small oasis shows an ugly pattern superimposed over the sand when using FSR 3.1 that goes away with FSR 4. It doesn’t make the game unplayable or anything, but it’s pretty distracting.", "When talking to Alma, we can see that FSR 4 handles the fine strands of her hair a little better than FSR 3.1 does. It also adds sharpness to the weapons immediately to her left. While running towards the training barrel, we see that FSR 4 keeps the detail of the hunter’s clothes and equipment sharper. It’s not a huge difference, however.", "The long cutscene that takes you to the main camp shows much the same. FSR 4 has a slight advantage to image quality via sharpness and minor detail enhancement. Hair, fur, and feathers benefit the most by way of FSR 4 reducing the appearance of patterns or stippling superimposed over them.", "One clear difference is in trails behind objects moving across a patterned background. For example, when the two Felynes drop the barrel, it leaves a smeared trail behind it on the wooden walkway, as does the NPC on the left side of the screen and the unfortunate Felyne as it falls backwards. We think FSR 3.1 handles this very poorly – FSR 4, while not perfect, definitely does better.", "Considering what we saw in Space Marine 2, the less drastic differences between FSR revisions in Monster Hunter Wilds is surprising.", "The final game we'll analyze for FSR upscaling is Marvel Rivals. To keep things consistent, we used the training range to gather footage.", "Static scenes don’t differ much between FSR 3.1 and FSR 4 in Rivals, possibly because of the game’s art style and strong default sharpening filter. We’ll need to look at movement to suss out the differences, and blasting forward with Rocket’s dash is a good place to begin.", "Even before dashing, we can see a blob of pixels around Rocket’s head getting distorted in the FSR 3.1 recording, which isn’t nearly as pronounced with FSR 4. As soon as we blast forward, FSR 3.1 turns into an over-sharpened, grainy mess, as seen on Rocket’s gun, jetpack, tail, and the ground below. FSR 4 is able to cope with the sudden movement far more gracefully, and only gets bad around the finer points of detail like the spikes on Rocket’s knees and the hair/fur on his head.", "Next we strafed to the side while shooting. Before moving, we can see a repeating pattern overlaid on the left side of the ground, similar to what we saw in Monster Hunter Wilds, that’s not present with FSR 4.", "Once we do start moving and shooting, FSR 4 retains more detail in the bullet trails than with FSR 3.1. After dropping off the first ledge and reloading, FSR 3.1 responds to all the motion by giving everything in the vicinity of Rocket’s model a kind of deep-fried-meme look, and ghosting on the trailing edge of his jetpack. There’s still a little bit of ghosting with FSR 4, but it’s greatly reduced – and the deep-fried look is gone.", "Last, we tried a wallrun. FSR 3.1 handled it overall better than we anticipated, but still left horrible ghost images as Rocket climbs up across the purple banner. FSR 4 still has them slightly, but they’re not noticeable to us at full speed in real-time.", "For the rest of the run, there’s not a huge difference between the two FSR revisions outside of a slight clarity advantage and reduced ghosting with FSR 4.", "We’re getting into the AFMF and frame generation comparisons now. We’ll play some side-by-side, frame-by-frame comparisons while setting this section up.", "For comparison purposes, we selected games that support in-game frame generation to compare with driver-level changes. In the real world, you should almost always opt for in-game frame generation over AFMF at the driver if in-game is available. The most obvious downside of AFMF is that it has no awareness of UI elements, so menus, text, and icons may be distorted (although ", ").", "All footage for AFMF comparisons was captured at 4K 120FPS. A ", " (watch ", ") with Adrenalin 25.2.1 was used for AFMF 2.0 capture and a ", " with Adrenalin 25.3.1 was used for everything else. AFMF Search Mode was set to High and Performance Mode was set to Quality, the recommended settings for our setup. ", "AMD is more direct than NVIDIA about ", ", and we stuck to that recommendation.", "As with NVIDIA framegen, the vendor's capture utility (Radeon ReLive in this case) was the most practical way to capture, but because we can't manipulate the rate of frame generation (like we could for NVIDIA), we'll have to rely more on frame-by-frame comparisons. We constantly had issues with AMD's Record & Stream tab disappearing after reboots, so if AMD is reading this, please fix that (and yes, our IGP is disabled).", "We used the same settings for Space Marine 2 that we did for the FSR comparisons, with Resolution Upscaling set to FSR and Render Resolution set to Native since it can't be explicitly disabled. We set Motion Blur Intensity to Off even though the setting doesn't work. Framegen worked with fullscreen enabled, so we left that setting alone.", "We’ll start with the worst-case scenario.", "We recorded an additional scene in Space Marine 2 to show the downsides of frame generation. These clips aren't tightly controlled or synchronized; we just loaded into the main hub and shook the mouse around violently, so we’ll freeze frame some parts to show the issues. Besides making it very obvious that motion blur was still on (despite being toggled off), this allows us to see multiple frames where AFMF is definitely applied on top of UI elements like the Assemble waypoint. Applying frame generation on top of UI elements can cause ghosting and duplication of UI elements, which just looks bad. We can compare this to the in-game frame generation option, which is also a garbled, muddy mess in this scenario, with distortions around the edges that almost look like eye floaters. It completely breaks in this scenario, but perfectly preserves the UI layer even in the worst frames. ", "Rapid movements like this aren't out of the question for mouse-and-keyboard users. They’re especially common in certain types of games, like shooters in particular where a fast or twitchy response necessitates them. Compared to native, these types of rapid movement scenarios are a worse experience with frame generation.", "Our armory scene is relatively slow, but we can still see the effects of frame generation on moving limbs versus native rendering. The telltale sign of generated frames here is the slight blurring of detail on the marine's armor in frame-by-frame playback, like the back of his right leg as he passes under the light, but this is only really visible when closely examining individual frames in a specific location. The mandatory motion blur and application of FSR also help disguise the generated frames, since both of these effects lead to the same kind of temporal smearing that generated frames are subject to.", "The frame-by-frame playback of AFMF 2.0 versus 2.1 reveals greater differences, with a prominent secondary image surrounding the marine's right arm in advance of its movement in the next real frame. This only affects moving elements of the scene; there's no noticeable sign of frame generation in the relatively static background even with the older version.", "By rolling down the stairs, we can see a weak point of frame generation, although the inescapable motion blur makes it harder to detect. There are multiple frames where the fine details on the marine's armor are blurred, like the bottoms of his boots where lines are lost. Moving frame by frame with native and AFMF 2.1 capture side by side, there's a clear difference between the even and predictable motion blur and the irregular, faded outlines of generated frames. The marine's feet change position more than any other part of his armor during the dive and roll, which is why they're especially prone to blurring and transparency.", "The generated frames are also identifiable by ghosting behind the bullets being fired in the background, with classic ghosting behavior causing an undesirable look. In our ", ", we noted similar behavior with raindrops that made the rain effects look softer and more transparent in motion.", "Comparing AFMF 2.0 to 2.1 at similar framerates, 2.1 appears to have less ghosting than 2.0, which should help make the effect less noticeable during gameplay. In each generated frame of the AFMF 2.0 capture, there's a clear secondary image of the marine in advance of the next real frame, as we noted to a lesser degree in the armory scene. Blurring and loss of detail can be issues, but ghosting is a much more visible downside of framegen and one that can ruin the experience. ", "A comparison to in-game frame generation at the same timestamp demonstrates that it's predictably much better at preserving detail, since it's given more information to work with directly from the game engine. ", "The in-game generation causes a crisp outline in advance of the marine's movement, visible above around his gun and his arms, but the detail within his boots isn't distorted at all. This could still lead to the shimmering outlines that we saw with NVIDIA's framegen, but the individual frames are closer to reality than with AFMF.", "We'll start off this next scene with another native comparison to establish which elements are due to regular motion blur and which are due to frame generation. The AFMF 2.1 capture matches native with its rendered frames, but it's interspersed with generated frames where the marine's armor loses sharpness on the fast-moving legs. That's clearly the area we need to focus on, so we can move to a 2.0 versus 2.1 comparison with that knowledge.", "Walking sideways in front of a light background makes the difference between 2.0 and 2.1 more obvious, with 2.1 showing some slight irregularities around the edges of the marine's legs where 2.0 shows massive secondary images. As usual, the resulting effect would be easier to notice in motion if there weren't already other blurring effects forced on us with this game.", "God of War ran well above 60FPS on the 9070 XT even at Ultra, which made it harder to capture generated frames, so we kept our testing brief. The ultra preset was used with motion blur, film grain, and camera shake disabled. We expected FSR to be forced when in-game framegen was enabled, but the options menu didn't reflect that, so the scaling method was set to TAA and the quality to Native for all tests (scaling cannot be explicitly disabled).", "As expected, the moments of rapid movement during Kratos' windup and swing are the most difficult for AFMF to deal with. Whereas the native capture clearly shows each frame of his arms and the axe as it moves, the AFMF 2.1 capture has individual frames with obvious attempts at interpolation. This is most noticeable directly on the models, since the trail of particles behind the axe is already an intentional smear.", "By swinging Kratos' axe in front of the white snowy background, we can clearly see ghost images with the older AFMF 2.0 frame generation. Direct frame by frame comparison is more difficult here due to the lower frequency of generated frames, but it's clear that the generated frames with 2.0 more commonly have ghosting around the axe and even Kratos' model. 2.1 shows some artifacts as well, but it's usually in the form of unevenness in the outline of the axe and Kratos' arm as they swing forward, while the core of his model is better preserved.", "Checking back against God of War's specific implementation of in-game frame generation, we see the same behavior as in Space Marine 2 where the details of Kratos and the axe are excellently preserved, but there's a distinct outline where framegen has done its version of content aware fill in the area that those objects will occupy in the next real frame. In comparison, the fullscreen AFMF 2.1 effect has more distortion around the usual axe and arm area.", "The movement of the axe in this small QTE was too rapid for either 2.0 or 2.1 to keep up with, with the large deltas between frames leading to a similar appearance from both AFMF versions. The head of the axe appears doubled in some generated frames, with additional distortion around the handle. It's difficult for any type of frame generation to compensate for large deltas between frames, which is part of why AMD recommends running at 60FPS before turning it on (with latency being the other part).", "Marvel Rivals is next.", "Starting with the jump pad, we can see at the beginning of this scene that both AFMF 2.0 and 2.1 show ghosting on the rings that rise up from the pad. Once in motion, both iterations have trouble keeping up with the rapid movement, but 2.1 does a moderately better job of preserving Mantis' outline. ", "The distance between the secondary image and the core of Mantis' model with 2.0 creates a greater blurring effect, and although the generated frames with 2.1 only roughly maintain the shape of her hands and feet, the resulting silhouette is stronger. As she approaches the apex of the jump, the distortion occurs in the background instead, with 2.0 more commonly showing doubling of scenery elements like the railing immediately in front of her.", "Marvel Rivals' in-game frame generation version behaved in the same way as God of War's and Space Marine 2's,  with crisp outlines around the next known position of Mantis' model, visible above the knees in these frames, coupled with some afterimages trailing behind the arms. The overall effect is still far cleaner than AFMF, especially since the artifacts only apply to Mantis' model, leaving the scene behind her almost completely clear of framegen problems.", "We don't recommend using framegen for games like Marvel Rivals where latency is a concern and rapid mouse movements are common. Framegen is kind of like v-sync in that at best it's a cosmetic upgrade maybe, and at worst it's a source of latency. ", "In this scene, we can see distortion around Mantis' hands with AFMF 2.1 in advance of the motion they're about to make as she fires, but a rendered frame was buffered in order to generate that image, whereas without framegen, rendered frames are simply delivered when they're ready.", "Notice also that with AFMF, Luna Snow's nametag is distorted on the first frame where the camera shakes, which is a further disadvantage of AFMF versus in-game frame generation. Using the in-game option, the nametag is preserved.", "In Cyberpunk, we used the High preset without ray tracing and set FSR 3 to Native AA, since FSR was required in order to enable in-game framegen.", "First is a car scene. Keeping an eye on the headlight beam as it passes over shrubs and rocks to the right of the road, we can see that the scenery appears to wiggle slightly with AFMF 2.1 as the generated frames don't place objects in precisely the correct location. With AFMF 2.0 in the same areas, there's a much simpler loss of detail as every generated frame is a blurry mess. The area on the shoulder that tracked slightly wrong with 2.1 is instead completely layered with a ghost image with 2.0; we prefer the newer version here, but native rendering without fake frames still looks cleanest.", "Moving to a 2.1 versus native comparison, we can see that the wiggling behavior is definitely an artifact of AFMF and not something carried over from the original native render. The native capture has fewer frames, obviously, but the objects to the right side of the road track in a clear, straight line between frames as opposed to the slight side-to-side shifting with AFMF 2.1. Native should typically be crisper, even if less smooth, so this makes sense.", "Using the game's built-in benchmark scene, we can again see that 2.1 is more prone to distortion in areas where 2.0 would blur and ghost, with the vertical pillar here turning into a wavy line in fake frames. ", "As the camera passes the corner with pages from the Night City Journal, 2.1 does a much better job of preserving text and fine detail where 2.0 just ghosts. ", "Moving to a later part of the scene, frame by frame playback reveals more distortion visible with 2.1 as the camera passes over the barbed wire fence: straight lines remain clear with 2.1, but they don't remain straight. As usual, 2.0's equivalent is a fully duplicated ghost image of the fence in each generated frame.", "Again, we can check back against the native footage for confirmation that the behavior we're seeing comes from AFMF. The horizontal fence bars are straight and uninterrupted in each frame of the native capture, whereas they're frequently broken up and uneven in the AFMF 2.1 footage, although AFMF 2.1 does do a fairly good job of preserving the scene behind the fence without major framegen distortion.", "In terms of image quality, FSR 4.0 is an improvement over FSR 3.1. And AFMF 2.1 is an improvement over 2.0. Both of these are good things because if those weren’t the case, then AMD is using numbers wrong. ", "Whether or not it’s worth using these technologies at all is more situational, just like with DLSS. First of all, it’s going to be highly specific to the games and also the person playing them. The use case for these, take FSR for example, is definitely a good alternative to lowering the settings, but when we’ve polled our audience in the past, there are a lot of people who prefer to lower the settings than to use an upscaling approach like FSR or DLSS. It’s really going to be something that users should toggle and decide if they like. ", "While that might sound like a wishy-washy answer, that is the answer. It is very situational. The good news is that it’s easy to turn these technologies on and off to see if you like it. ", "Some people will prefer the higher graphics quality with the potential image quality losses that upscaling technologies provide and other people won’t. ", "Going back to whether it’s worth turning on, the best answer we can provide is that we think it’s a good alternative, just like DLSS, to lowering settings in some games compared to running games at lower performance. So if you’re trying to fix performance issues and you want the higher settings, generally speaking, both the newest versions of DLSS and FSR work well for that. ", "In the games we tested using FSR 4.0 as an override was an improvement over past versions, which is good. ", "While AMD has made improvements to these technologies, the question you should ask is whether you want to use them at all. With frame generation, you still get some really nasty images that aren’t representative of how the game was intended to look. ", "You get ghosting, doubling up of images, and distortion of text. A lot of people will see that and want to turn it off. This will also depend on the game. ", "It’s a little less clear what the decision should be on the upscaling front because it will depend on how much you’re struggling to run a particular game. It becomes a choice of sacrifice between graphics settings or image quality crispness. For some people, it may not be a choice if the game is running too poorly. Overall, FSR 4, just like DLSS 4, is an improvement over its preceding version. This is what we want to see. But like DLSS, the degree of improvement on the scale of a little bit better vs totally transformative, it’s going to be closer to the a-little-better side. It won’t change how you fundamentally see games. ", "Next, we may look at FSR 4 vs DLSS vs XeSS in a future content piece. That will let us look at the direct comparison between competitors."]},
{"title": " TINY Beast: Thermalright Peerless Assassin Mini Cooler Review & Benchmarks", "paragraph": ["TINY Beast: Thermalright Peerless Assassin Mini Cooler Review & Benchmarks", "Last Updated: ", "The Highlights", "Thermalright released ", " of the ", " and they did so quietly - we didn’t even hear about it. It’s almost like it's in the name. They called it the ", ". When we covered this in the news announcement, our viewers pointed out that it looks very similar to the ", " which is one of the 8 million coolers that Thermalright released without telling anyone.", "The Assassin Mini isn’t a perfect replica of the Silver Soul. We'll cover that in this review.", "Compared to the ", ", the Mini is 22mm shorter and ships with a single fan, making it a potential compact option for cases with reduced vertical clearance from the CPU socket -- like larger ITX or micro/smaller-ATX cases. You are buying the Assassin Mini primarily if it’s going into a smaller case, so we’re going to be benchmarking this versus a ton of other cooler options on the market, including the original Peerless Assassin.", "The ", " was $35 when we bought it - no discount for the fan reduction or the reduction in cooler size in total, but maybe that has to do with lower volume production runs. It's also possible that they're just charging a premium for it being the Assassin Mini. ", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "jack Reitman", "We immediately noticed that, despite the relatively low price and small stature and stout nature of the Assassin Mini, the cooler manages to maintain many of the features that made the taller variant good enough to get our best overall award for ", ". The materials quality is also impressively good. We found that the fins are relatively sturdy despite normally coolers of this category having thinner/flimsier metal and a rigid and stout stature which helps with just feeling like a quality cooler. ", "So, let’s get into testing of this. We'll look at testing for thermals, pressure, and everything else.", "The Silver Soul 135 is the one our commenters pointed us toward when we found out about the Mini in Hardware News, so let’s briefly look at the comparison.", "Although we don’t own the Silver Soul, we can see clear differences from the retail page: The top cap and the fin stack shapes are different. The Assassin Mini has a fin stack that has a central indent and otherwise equal depth fins. Meanwhile, the Silver Soul has a cascading cut in the fin stack across the horizontal axis. The heatpipe caps are also different. The outer edge of the towers also differs, with the Silver Soul using a cheaper flat-edge plate at the borders (that protrudes), rather than the indented and recessed connective plate and sidewall on the Assassin Mini. ", "In terms of size, the Silver Soul is 94mm x 120mm x 135mm, whereas the Mini is 125mm x 110mm x 135mm, so that’s actually a fairly notable difference. Additionally, the fans are a little different. The Silver Soul fan climbs to 1850 RPM, while the Assassin Mini caps at 1500 RPM. The current (Amperage) is also lower as a result.", "They’re definitely not the same cooler. They are similar, but it’s not accurate to call them the same.", "Today we’ll be comparing the Assassin Mini to a lot of the other coolers we’ve looked at in the past, including the ", ", the single tower ", ", and NZXT’s lackluster ", ". be quiet! is in there as well and a couple others, however we haven't run too many short coolers through, like the 93mm class. That’s maybe a separate consideration, but we’d have to tweak the thermal bench a little bit to better accommodate those because they are shorter. As a result, they can’t quite handle some of the heat loads that we look at because of the surface area loss. But in our upcoming cooler methodology rework (which will follow our ATX case methodology rework, a portion of which is included in the ", "), the work includes introducing some new lower and middling heat loads to fully accommodate the stack, but today we’re focusing on 200W and 123W.", "Mechanically, the Assassin Mini uses the same dimensions in most places as the full size Assassin. The towers for both the Assassin and the Mini are about 127mm long and 40mm across. They haven’t changed the other two dimensions. What has obviously changed is the total height, but the loss of verticality will multiply for a significant total surface area loss at the benefit of being shorter.", "The vertical fin stack height ends up about an inch, or around 22mm, shorter than the original. Almost all of the height reduction comes from the fin stack. The cooler retains its 6 heatpipes and also keeps the recessed fins at the lower edge of each side, allowing clearance for taller memory modules or tall motherboard I/O covers.", "As for the fan, it sits centrally and lowered, resting directly on top of the coldplate. This means that there will be air spillover into the VRM area of the motherboard, which should benefit VRM thermals and provide some airflow to the heatsinks. We’ll look at that in our charts today as well – it’s one of the upsides of doing this design. ", "The fan also has changed from the original Peerless Assassin: The Mini uses a fan with chamfered edges and is model TL-D12W PWM, whereas our original was TL-C12 PWM. Thermalright has also shipped multiple revisions of the Peerless Assassin now, so there are probably a few fan variations across them.", "They are both 12V, 0.2A fans with a 1500 RPM target, so in spec, they’re the same. The blade count is the same, the struts are the same, but the inside of the rear of the chassis has a shallower gradient on the Mini.", "We’ll get into thermal benchmarks now. For this testing, we’re running two heat loads: 200W and 123W, and then for those, we have 100% fan speed and a noise-normalized result. This testing features the Peerless Assassin Mini vs. larger air coolers and liquid coolers in the 200W 35dBA test, whereas the other single fan solutions mostly start to show up in the 123W test. That’s because a lot of those, like the ", ", simply couldn’t handle the 200W load when its fan speeds were reduced. If you want a bigger picture of lower capability air coolers, that’ll be in the 123W test.", "We’ll start with our 200W testing at a noise-normalized level, which is a test we popularized as a means to standardize the coolers more fairly against each other.", "The ", " is equipped well enough to handle this load, but even still, it remains one of the least equipped coolers on this chart, where most are liquid or large air coolers. With its shorter tower, reduced surface area, and single fan, the Assassin Mini lands at 64 degrees Celsius over ambient for CPU load. At a 21C ambient, that has it at about 85 degrees for the actual measured Tdie. It’s borderline. In a case with lower quality ventilation, it may not be capable of handling this heat load at all.", "The FUMA2 manages to outperform the ", " here, benefiting from two fans and also a larger finstack (including a 20mm height advantage) -- but it’s not as small, so the Mini still has its unique angle.", "The original ", " is the more interesting comparison: With two fans and the taller heatsink, it held a 56-degree temperature, tied with the also impressive ", ". ", " for its value ", ", and despite having the same profession, they don’t work for the same “Assassin Master.” Maybe that’s the next Thermalright product.", "Ultimately, the dual-fan Peerless Assassin ran about 7.4 degrees cooler than the Mini. That’s a big swing, but considering that height reduction has a multiplying effect on two other axes, it aligns with what we’d expect.", "The ", " is another mini cooler that’s even lower profile, but much wider. This cooler outperformed the Assassin Mini by enough to matter. The extra fan helps. If your build can accommodate it, it’s a unique looking cooler that would work with moderate TDP CPUs. We actually liked this one a lot more than you might expect given that it looks a little gimmicky, but it works and it looks pretty cool, ", " if you want to learn more about it.", "It seems that, if you need a mini tower, the Assassin Mini at least outperforms coolers that couldn’t make it onto this chart because they were throttling. Let’s move to look at some of those.", "More coolers join the chart at 100% fan speed. Noise levels are uncontrolled now, but the heat is more tenable for them.", "The famous Vetroo V5 runs at 68 degrees over ambient, so it’s just barely capable of operating with this load. The Mini is able to reduce the CPU temperature to 60 degrees as a result of the increased fan speed, which brought it to 39 dBA. That makes it significantly more noise efficient than the V5, which operated 8 degrees worse and 4 dBA louder (which is noticeable). The FUMA 2 is about tied with the Mini here, but that’s because the FUMA 2 was maxed-out on its fan speed already. As a result, its noise efficiency is far superior to the Mini, but again, it’s taller.", "As for the ", ", that one runs at 53 degrees, so it maintains a similar ~7 degree reduction and stays alongside the Assassin IV with its Performance mode.", "The Jiushark is interesting again, improved by about 3.4 degrees over the Mini at 2 dBA louder.", "Reducing the heat to 123W makes it easier to compare against lower-end coolers that couldn’t clear the prior threshold without throttling.", "Here, we have the appearance of some new entries in air: The ", ", which was remarkably bad due to its fan quality reduction from the baseline T120, the ", ", the ", " (", "), the ", " that we ", ", the Hyper 212 RGB Black Edition, ", ", and plenty more, like the ", " and ", ".", "This chart has a ton of air coolers.", "The Peerless Assassin Mini isn’t the worst: At 59 degrees over ambient, it’s comparable to the taller (but still small) AK400. Thermalright is making up for the height loss in width. The original Peerless Assassin runs at 54 degrees over ambient here, putting it up in a different class of cooler from the Mini. The Mini is more comparable to the Assassin Spirit, which is a single-tower, normal height solution. ", " remains advantaged in the small class of coolers due to its width. How you call it “small” depends on which dimension you are referring to, but ultimately we remain fond of this cooler just for its performance given the weirdness of it.", "Overall, the Assassin Mini is doing well here against its 20mm taller counterparts. Thermalright is compensating well with the heatsink.", "At 100% fan speed and still at 123W, the ", " passes the Assassin Spirit, now at 56 degrees (and still about tied with the AK400). The Mini shows strengths in noise efficiency as compared to the louder ", " and DeepCool AK400, which are roughly equal thermally. The larger Peerless Assassin is 4 degrees cooler at 52C, but also louder. Because the heat load has reduced, the observable difference between these two coolers has also reduced.", "Finally, we’ll look at VRM thermals for the surrounding MOSFETs while under the 200W, noise-normalized load. This is mostly interesting because of Thermalright’s decision to smash the fan deeper into the cooler, which has the unintended benefit of lowering it to better cool the VRM, in addition to giving the height clearance.", "The Mini held MOSFET temperatures of 39, 43, and 37 degrees over ambient, which made it cooler than the original dual-fan Peerless Assassin by upwards of 8 degrees. That’s an impressive change for some of these numbers and shows how much impact a cooler can indirectly have on the VRM. The NH-D15 remains the chart leader, benefiting from two larger fans that both extend into the VRM area of the board. The JF13K sits between the two Peerless Assassins thanks to additional coverage over the VRM and the downdraft design.", "Pressure scans are up next. This testing uses a mixture of a special contact pressure paper and a calibrated scanner that analyzes the result and produces a pseudocolor image showing a sort of “heat map” of pressure distribution across a surface. This testing is done to evaluate the quality of the mounting hardware. As a side effect, it can sometimes illustrate the flatness of the coldplate -- but mostly, we use it for analysis of the mounting kit.", "Many years ago now, we were able to purchase this hardware as a direct result of the support of our ", " backers and GN store customers and we still use the equipment to this day. We have now produced hundreds of pressure maps and have uncovered big shortcomings (and excellent designs) in products as a result. To support us in the continued testing time to run all these benchmarks, please visit the ", " and grab one of our brand new ", ", which use an ultra soft, comfortable material that’s warm enough for cool weather but still usable inside. The team has been wearing these hoodies around the office for a year now, so we just launched them to the store a week ago. You can also find our ", ", our ", " with a special metal badge for our 15-year anniversary last year, and more. Thanks for your support. Let’s get into the pressure scans.", "Here are the pressure results of the Assassin Mini. Our two tests on the first CPU produced consistent scans showing high mounting force and contact pressure across the entire center of the IHS, extending out toward the edges. There are very slight gaps at the far central edges, but otherwise, this is one of the best pressure mounts we’ve seen in this testing. It’s up there with some of the Intel contact frame results for even distribution.", "The second CPU produced similar results, but with better distribution out to the central edges. This is natural variance between CPU lids. The result is again excellent pressure distribution, which speaks to the mounting system that Thermalright designed. It’s a simple solution that distributes pressure evenly and holds firm, which is exactly why we chose the original Peerless Assassin for our case test bench that’s coming up.", "We’re going to start with AMD first and then we’ll move over to Intel.", "The first step for AMD is to remove the stock mounting brackets. After that, place down the standoffs and attach the mounting brackets, which are threaded through the standoffs, and then tightened down with a screwdriver. You will notice that these brackets say AM4 on them, but they are compatible with both AM4 and AM5. They do not include a separate bracket for AM5. In the directions Thermalright shows the AM5 installation with the AM4 labeled brackets. ", "Now we're ready to apply thermal paste and then mount the cooler. Give the nut about a half of a turn to a full turn to get the threads engaged and then go to the other side and do the same. Then slowly go side-to-side, alternating so you get an even pressure – you'll feel a hard wall when they're tightened all the way down. Last, you put the fan on.", "Let's take a look at Intel. The first step is pulling the metal tabs out of the backplate to make them compatible with LGA 1700 (or LGA 1150 if that is the socket being used). Two adhesive pads on the back can optionally be removed to help secure the backplate, but this is not a necessary step.", "Then, slide the backplate under the motherboard and take the standoffs and begin to thread them into the backplate. These have a washer on one side; put the washer side down towards the motherboard so that it's making contact with the motherboard. This helps protect it from the metal of the standoff.", "The installation of the bracket comes next. There are three positions noted in the instructions - we want the center position of the three holes for LGA 1700 for this application. Attach the bracket to the standoffs and screw them in, making sure they are tight. Next, apply thermal paste and mount the cooler just like for AMD: give the nut about a half of a turn to a full turn to get the threads engaged and then go to the other side and do the same. Finish the process and attach the fan.", "We don’t really have any criticisms for the mounting hardware. It is very straight-forward to work with, making for easy installation on both AMD and Intel.", "The ", " is definitely warmer. In some tests, it's about 7 degrees warmer than the original ", ". At the lower heat load, we’re seeing about a 4-degree difference and at the higher heat load it’s 7 degrees. The more strain the cooler is under (the closer it is to borderline able to hold CPU die temperature just below throttling), the more that gap is going to widen, and that is exactly what we saw during our tests here.", "Obviously the larger one (the ", ") is better, and it also has an extra fan; however, the ", " was still able to handle our most intensive heat load that we’re currently running. We’re adding 250W or 300W heat loads for some of the Intel tests coming up as we start to employ the methodology.", "If you have a really restrictive case -- like an ITX case with solid paneling or something similar -- then this will struggle with higher heat loads and may throttle. If you have good airflow, then it is able to handle the 200W load as we test it.", "We think for the size and for the single fan solution, the Assassin Mini is an excellent performer. It maintains nearly perfect pressure contact, which is specifically a testament to Thermaright’s mounting kit which distributes the load very well. This is why we chose the Peerless Assassin (original) for our new case methodology: we wanted something that distributes the load basically perfectly and has good contact across the IHS, is spring-tensioned, and will stay where we put it. The Assassin Mini maintains all of those benefits of the original, with the downside of being a little bit warmer, but with the possibility of maybe fitting it in a specialized case that you could not fit the original in.", "Additionally, an interesting aspect was the VRM cooling where we saw improved VRM thermals just between these two because of the nature of the recessing the fan deeper into the Assassin Mini, where it sits right on top of the coldplate and hits the VRM heatsinks a little better. There is sometimes a significant reduction in thermals for some of the neighboring MOSFETs.", "For downsides, the lack of a price cut (compared to the Peerless Assassin) might feel a little bit bad given that it’s one fan less, less material, and still the same price (at least for right now). A big disclaimer here is that Thermalright’s prices change wildly (and all the time with the ", ").", "It's possible that Thermalright sees a gap in competition and feels like they can charge more. If we’re being charitable, it’s because of lower production runs, so maybe the material cost doesn’t actually change that much when you count labor - we really don’t know either way.", "Fortunately, it performs very well and we were happy with it. We could recommend the Mini if you’re in a case that’s small enough where the 20mm size difference is necessary. If you don’t need the extra 20mm of clearance, get the taller one. The ", " is also definitely worth considering. It's an interesting cooler that we liked in our testing, it performs better than we expected, and it looks cool."]},
{"title": " Noctua Finally Did It | NH-D15 G2 Launching, Thermosiphon, & Fans", "paragraph": ["Noctua Finally Did It | NH-D15 G2 Launching, Thermosiphon, & Fans", "Last Updated: ", "The Highlights", "It’s actually real this time, the Noctua NH-D15 G2 is in the process of shipping and is finally launching this month – June 2024.", "There’s a lot to go over at Noctua’s Computex 2024 booth, but we’ll start with details on the new D15. It’s going to be $150, expensive for an air cooler, and a lot of that comes from the new fans.", "Steve Burke", " Mike Gaglione, Vitalii Makhnovets", "Jeremy CLayton", "The $150 kit includes the cooler, the two fans, and four 1mm washers for an ILM mod. Noctua is at a point now where, as we’ve seen with air coolers in general, to further tune to get any additional performance it has to start doing tricks that may be outside of the cooler itself. The best coolers in our testing right now fall in a roughly 3-degree cluster, so fighting for an extra 1 or 2 degrees is very difficult at this point.", "Where Noctua is trying to do that with the D15 G2 is going to be with three variations on the coldplate design. Those are called Low Base Convexity (LBC), standard, and High Base Convexity (HBC). The idea is to provide a better fit between the coldplate and the particular CPU it’s being paired with. For example, Intel’s current LGA1700 CPUs form a relatively deep concave shape when clamped down with the stock ILM, and an HBC coldplate may provide better contact and therefore better performance.", "Back to the cooler itself, the D15 G2 has 8 sintered heatpipes (up from 6 on ", "), and Noctua says it’s done some heatpipe tuning as well. Additionally, fin pitch and density has changed. You can see this below – the old D15 on the left and the new D15 G2 on the right.", "The fans themselves are also different, which are a large contributor to the performance in any cooler.", "We need to test it ourselves still, but Noctua showed first party test numbers against a fixed heat load. These scenarios suggest a roughly 3 degree advantage for the new G2.", "Very quickly we’ll run through some other things at the booth.", "There was a Noctua edition Seasonic power supply on display, but we don’t really cover those right now so we’ll move on.", "There was also a prototype two-phase thermosiphon cooler that is pumpless (as in no moving mechanical pump) that cools by recirculating refrigerant through an evaporator in the coldplate and a condenser in the radiator. We’ve covered thermosiphon coolers in the past and the fact that Noctua is trying something like this is honestly super cool. Up until now we’ve only seen air cooling products from the company so this is something different. Noctua would like it to be comparable in performance to a CLC. However, Noctua doesn’t have this anywhere on its roadmap at the time of writing.", "The company also showed off a few coolers designed for the enterprise and server market, like this one for NVIDIA Grace Hopper (GH200) chips.", "More interesting for our core audience was the presence of a next generation 120mm fan, which looks like a scaled-down version of the NF-A14 G2. It’s technically unnamed, though one might say it could be called an NF-A12 G2.", "We also had another engineering discussion with Jakob Dellinger of Noctua. Go check out our video for the full thing – here’s a brief list of the major talking points from that discussion."]},
{"title": " Noctua Has Competition: Vapor Chamber Air Cooler (DeepCool Assassin IV VC)", "paragraph": ["Noctua Has Competition: Vapor Chamber Air Cooler (DeepCool Assassin IV VC)", "Last Updated: ", "The Highlights", "Our main focus at DeepCool’s Computex 2024 booth is a new air cooler with a vapor chamber cold plate called the Assassin IV VC Vision. These have been a thing in the past but it’s not something we see a lot. With Intel CPU power levels where they are these days, air coolers need to advance. The biggest challenge with vapor chambers is cost.", "In addition to that, there are a few liquid coolers to go over, some stuff on the case side, and changes to the AK 400 and 620 series air coolers.", "Steve Burke", " Mike Gaglione, Vitalii Makhnovets", "Jeremy Clayton", "The Assassin IV VC Vision (VC meaning Vapor Chamber, and Vision meaning there’s a screen on top) will launch only in this configuration, so there won’t be one without the screen. It’s pretty straightforward, with temperature, CPU utilization and frequency, and power consumption.", "Moving on to the vapor chamber itself, DeepCool is saying that it’s tuned for Intel CPUs, but it will work on AMD CPUs as well. We asked about curvature on the coldplate, and the company told us it has a “ridge bump” pattern. That likely comes from the structure of vapor chambers themselves, which have internal copper support columns. Those columns can be evident in the surface of the coldplate as small deformations.", "DeepCool claims they’ve tested the cooler with 280-300W heat loads (equivalent to a", " at full load) and measured a 3C reduction versus the standard ", ".", "DeepCool hasn’t shared pricing yet, but it’s bound to be high after the vapor chamber and screen. The standard Assassin IV is already about $100. The fan setups are going to be exactly the same as the existing Assassin IV and IV S versions.", "The heatpipes are press-fit into the fins – DeepCool could try soldering for a little more performance, but that would add even more cost. The Assassin IV VC Vision is supposed to ship this year, maybe in August. Again, we don’t have a price for it yet.", "The AK620 Digital Pro is a variation on the ", ", which we liked for its simplicity and cost effectiveness. This is sort of the opposite in the sense that DeepCool has added a large screen to it. It’s not a full-blown LCD panel, and just shows the same temperature and CPU information as the Assassin IV VC Vision. It should be coming in the July to August timeframe, but we don’t have firm pricing at this time.", "The AK400 Digital Pro is the same thing – the base ", " with a readout on top.", "Both of these coolers have been updated to have different FT120 SE fans to get rid of a low frequency noise problem on the base models.", "The AN400 is a low-profile downdraft air cooler that’s smaller than the existing ", ". Again, and to our frustration, no pricing at this time.", "The only thing we’ll point out for cases are these new “Pixel” kits. Last year we showed DeepCool playing around with these on the Morpheus case and some other designs. The new colors are seen here on a ", "case. DeepCool says that if you’ve bought one of these cases, you can submit a receipt to get a free full kit of the “pixels.” This is a cool thing to add some art to the case, but go easy on how much airflow you block off while using them.", "DeepCool didn’t show us any prices at the show, which drives us a little crazy. The CPU cooler market is really interesting right now because heat load is so high at the high-end (especially from Intel). The biggest problem is that you really have to get into liquid coolers once you’re in ", "territory if you want to maintain performance.", "You can run air coolers, but higher temperatures lead to higher power leakage – typically 4% per 10 degrees. If you can bring the temperature of the CPU down it will inherently help to control the power consumption. We’ve seen this in our own AM4 test bench, where if we run the best cooler we’ll read about 192W, and on the worst cooler we’ll read about 202W. This is where the CLCs prove themselves right now, aside from noise normalized thermals.", "The air cooler market is going to have to continue iterating if Intel keeps the power level as high as it is. Right now the best air coolers get bound up around the same region on our charts. As good as coolers like the Peerless Assassin 120 and AK 620 are, they get stuck. We’re really curious about the vapor chamber solution, though they’re typically expensive. If air coolers start costing what a CLC costs, then that’s obviously going to be a different problem."]},
{"title": " Scythe Gets Aggressive: Budget CPU Coolers & FUMA Overhaul", "paragraph": ["Scythe Gets Aggressive: Budget CPU Coolers & FUMA Overhaul", "Last Updated: ", "The Highlights", "We visited Scythe at Computex and the company showed us several new fan and cooler prototypes. Scythe’s unique approach to these fans has been shaving down the sides between the mounting posts to try and improve performance, particularly on downdraft coolers. The company also showed off its incoming FUMA 3 Rev. B CPU cooler and new Magoroku cooler, the latter of which is a straight-piped FUMA 1-style cooler, reducing efficiency loss from bending heatpipes in the newer FUMA variants.", "In general, Scythe is trying to increase performance while competing more on price. Let’s dive into what they had to show.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "First up is the Fuma 3 Revision B, which sees changes to its mounting solution over its predecessor. This tweak increases pressure by adding a nut to the screw and applying more force to the center of the crossbar, which increases overall pressure centrally from the coldplate to the IHS. This should theoretically help the coldplate better conform to the curvature of Intel style integrated heat spreaders.", "As you can see from the image above, Scythe has added a nut that its screw would go through to apply pressure in a pin-pointed way. This should solve some of the ", "’s performance limitations we’ve seen. Scythe says that the cooler should see a 2-3 degree thermal improvement as a result of its changes under a high but unspecified heat load. This would not apply universally, as the thermal improvement is contingent on the amount of heat the cooler is handling.", "The company also shaved down the backend of the cooler to help with Mini-ITX clearance, which you can see in the NR200P showcase build that Scythe had present. The trimming of the plastic allows the top of the cooler to just barely fit within the chassis of the Cooler Master NR200P while still allowing the side panel to close fully.", "The Fuma 3 Revision B will retail for the same price as the plain ", ", which is currently about $50 online.", "Next up is the Shuriken 3 downdraft cooler, which is a follow-up to Scythe’s Shuriken 2. The Shuriken 3 is a major departure from the Shuriken 2: The new cooler is ~39mm tall, down from the Shuriken 2’s 58mm height. These shouldn’t be thought of as directly comparable.", "The Shuriken 3 integrates the cold plate into the finstack, which recesses it and shrinks the height. This means it provides less overall finned surface area, which would make performance technically worse, but the goal for Scythe here is to make something that can fit into even lower profile scenarios. The company stated that it aims to compete directly against ", " in this space.", "The Shuriken 3 introduces cut-outs on the side of the fan. Scythe was willing to share prototypes of the new fan design with us, stating that it tested cut depths (in the plastic of the fan chassis) varying from 2mm to 6mm. Scythe’s stated reasoning is that this reduces the amount of backpressure on the fan blades by allowing more area for the air to exit. Simultaneously, it would also allow slightly more finned surface area to directly contact air flowing from the fan. We’d have to test this to know whether the concept works as planned.", "Scythe started its prototyping for this on an existing 120mm fan by using a simple hand saw to cut away the border, later making one-off prototypes and printed test vehicles to rapidly concept the idea. ", "For some of these new coolers, Scythe is soldering the heatpipes to the fins rather than using a press-fit solution, which the old Shuriken design used. Soldering the heat pipes with the fins will, Scythe says, improve thermal conductivity and efficient heat transfer, which should help performance. In our ", ", the competitor stated it is also moving to soldered heatpipes with fins, but the stated reason was “quality.” Thermalright said that it did not observe an impact to thermals by moving to soldering from press-fit, so the companies appear to have differing opinions or results.", "The Shuriken 3 also has a larger cold plate, which is geared for more modern CPUs. The Shuriken 3’s fan is also different, using a Kaze Flex 92 AH, which is the new cut-border fan.", "Finally, the mounting kit is also different. The Shuriken 3 will cost $40 when it launches in July.", "Next up is the Magoroku cooler, which is inspired by the Scythe Fuma 1. The Magoroku is currently a prototype that’s not ready to launch. It intends to provide an improvement on the Fuma series while sacrificing some memory clearance compatibility.", "Compared to the ", ", the Magoroku has straighter heat pipes, which Scythe claims produces a 6% thermal conductivity improvement compared to going with a more curved solution. The curvature of the pipes in the Fuma series provides increased RAM clearance. We’d like to test this and have asked the company to send us 2 versions: 1 with straight pipes and another with curved pipes, but both at equivalent lengths. This would be a follow-up to our ", " research piece we ran previously.", "The Magoroku will use two ", " fans, which are 120mm fans that are 25mm thick. This should provide higher performance than what you would see on the Fuma series, as the Fuma coolers use a short front fan (also for RAM clearance) that’s cut-down to 15mm. Slim fans lose significantly on the pressure performance, which affects their ability to efficiently push air through a dense tower. The thicker Wonder Tornado fans will contribute significantly to the claimed performance advantage of the Magoroku. It’s more of a Peerless Assassin approach to cooling.", "Scythe says the Magoroku will have 6 or 7 heatpipes. The solution is not finalized yet.", "In terms of height, the Magoroku will be 154mm tall, which is the same as the Fuma 3. The mounting solution will also be the same as the Fuma 3. ", "The Scythe Magoroku doesn’t have a release date yet, but Scythe is targeting the end of the year. The company says it’s still waiting on information from Intel regarding Arrow Lake to finish its design. Scythe is targeting a price point under $40, which would be very price competitive with Thermalright.", "As some backstory, Scythe says the name comes from a famed knife smith from Japanese culture and history.", "Finally, Scythe showed us its Big Shuriken 4 prototype, which doesn’t have a price or release date at the moment. ", "Compared to its predecessor, the Big Shuriken 3, the Big Shuriken 4 is taller to reduce the mechanical conflict with the board and has 1 more heat pipe, moving up to 6 from 5. Scythe also says that its heatpipes have better bonding this time around, also moving to soldering.", "The Big Shuriken 4 also has a new larger cold plate.", "Its fan also has 4 holes on the sides for the reasons we outlined above, making use of the new approach to fan design that Scythe appears to be rolling-out to its coolers.", "We had a lengthy engineering discussion with Scythe founder and engineer Kitagawa San, who hopes to send us one-off units for future educational engineering videos and thermal tests. We previously worked with Scythe on the coldplate engineering piece linked above, with new ideas emerging from the cut fan border design and the heatpipe straightness topic.", "For additional cooler coverage, check out ", " from Computex or our Thermaltake vapor chamber (3DVC) "]},
{"title": " Thermalright's Completely Insane Approach to CPU Coolers is Working | Royal Pretor 130 & More", "paragraph": ["Thermalright's Completely Insane Approach to CPU Coolers is Working | Royal Pretor 130 & More", "Last Updated: ", "The Highlights", "Thermalright is known for releasing neverending waves of products, and this trend continued at Computex 2024. The company had more CPU coolers than we could realistically cover including several coolers with screens. We’ll walk you through some of the highlights, which include an air cooler with two 140mm fans, a cooler with a 90mm fan, and more.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "The Royal Pretor 130 is an air cooler with two 28mm thick fans, which is 3mm thicker than standard 25mm fans. One fan is 130mm and the other is 120mm. It will retail for $50.  ", "There are variations of it including the Royal Pretor 130 Ultra. Differences we noticed include the number of heat pipes and fan thickness. The Royal Pretor 130 has 6 fans while the Ultra variant has 7. ", "The Royal Pretor 130 Ultra also has a 25mm thick front fan.", "Like we ", ", Thermalright is also soldering its heatpipes to its fins rather than using a press-fit solution. The company says it's doing this more for build quality than thermal performance. Thermalright says it’s tested the Royal Pretor 130 at 300 watts under an Intel heat load and compared to the ", ", the company says it’s seeing about a 4 degree difference on its Intel IHS test. That's a pretty big difference and probably comes mostly from the pressure generated by the fan thickness and from the 130mm fan.", "Moving on, Thermalright also showed off its new Peerless Assassin 140. It will come with 2 fans, though the version we saw on the show floor only featured 1. It will be $35, which is the same price as the ", ", and will have thicker finstacks than the Peerless Assassin 120. It’s 159mm tall and features a 140mm fan, so it’s a big air cooler. ", "The Royal Knight is almost a Fuma-style cooler with a slimmer front fan coupled with a more standard fan thickness in the center. ", "It’s also offset backwards for better RAM clearance. The downside to this design is that when you shorten the front fan, it reduces pressure. According to Scythe, setting the heat pipes at an angle rather than going straight theoretically reduces performance. So the benefit with this design will be in regards to clearance. ", "The Royal Knight will have 6 heat pipes and will cost $35 like the ", " before it.", "The Peerless Assassin 90 SE gets its name from its 90mm fan size. It’s very stout and only has 4 heat pipes, but at $20, it’s one of the cheapest coolers we’ll test, alongside the Jonsbo CR1200 (watch ", "). ", "The Burst Assassin 120 Evo has 6 heat pipes. The cooler uses a push-pull configuration with the back fan acting as the pull solution with its reverse blades. It will retail for $25.", "There will also be a Burst Assassin 120 Vision variant. It adds a screen to the top of the cooler and costs $50.", "In addition to the wide array of air coolers, Thermalright also showed off its AIO Hypervision liquid cooler, which features a 3.95-inch display. Instead of pogo pins, it uses a cable, which the company says it incorporated so users have more control over where they put its screen. It will cost $130 when it releases in July. ", "Thermalright says it’s also working on something that may compete with ", ", but we’ll leave it at that for now.", "The Warframe Pro Cooler is another Thermalright liquid cooler with a screen", "Thermalright has a variety of other air and water coolers with screens attached to the top of them.", "The company also showed off a variety of interesting color options for its fans.", "Thermalright is also working on a Liquid Crystal Polymer (LCP) Fan, which has been something Noctua has been talking about for the past year. It’s something many companies are getting into and allows the blade to get as close to the inner wall of its frame as possible without clipping. The major downside is that LCP fans are extremely expensive. ", "On the display fan we saw, we noticed there’s a little bit of a larger gap between the fan and its housing. When we asked Thermalright about this, the company told us that it was a deliberate choice to support higher RPMs, which is something we personally couldn’t validate at the show."]},
{"title": " Noctua NH-D15 G2 Review & Benchmarks, HBC & LBC Comparison, & Best CPU Coolers", "paragraph": ["Noctua NH-D15 G2 Review & Benchmarks, HBC & LBC Comparison, & Best CPU Coolers", "Last Updated: ", "The Highlights", "Today, we’ll be talking about Noctua’s brand new ", " coolers. There are 3 variations of them, which is why we have them in our 3D laser scanner to evaluate Noctua’s claims of specially tuning the curvature of the coldplates to various CPU IHS styles.", "The LBC model, or low base convexity cold plate, has one of the flattest contact patches we’ve ever seen. This should be good on AMD CPUs. Likewise, HBC, or high base convexity, is visibly more convex than the LBC variation. This should tune well for Intel’s platform CPUs, which we’ve previously scanned and shown as heavily concave in our ", ".", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "We’ll also run acoustics in our ", ". A large part of Noctua’s nearly 10-year design process has been focused on the fan acoustic-to-thermal response, so we’ll compare old and new in here. ", "And we have plenty of thermal testing in the lab across an ", " test bench and our classic AMD test bench for maximum comparative data, plus our pressure distribution chemical tests.", "All of this is about the new ", ", which is Noctua’s first major dual-tower cooler launch since ", ". Since this is apparently something that happens every 10 years, we want to produce a review that’ll stand the test of time.", "Let’s go over what Noctua is shipping. It seems complicated but is very straight-forward.", "First of all, this cooler is $150. It includes the two new ", " fans, washers for a potential washer mod, mounting hardware, and some accessories. ", "This is the most expensive air cooler we have ever tested and is more expensive than the best cooler on our charts, the ", ", by about $42. That’s insane to think about.", "There are 3 coolers and there is only one difference between them: The cold plate. Literally every other aspect of these 3 boxes is identical.", "The cold plate is the part which contacts the integrated heat spreader for the CPU. The curvature of this cold plate will affect how perfectly it mates with different CPU heat spreaders, so Noctua has a “High Base Convexity” model that is theoretically better for Intel CPUs, a “Low Base Convexity” model theoretically best for flat CPUs like AM4 and AM5, and a “standard” model that you can think of as the all-arounder, or basically the classic approach to cold plate design. These models are the ", ", ", ", and just the ", ".", "We don’t want to hold up the testing by reading the brochure and spec sheet, so the highlights aside from the washer mod and different coldplates are these:", "Enough of the spec sheet. If you want specs, you can get them on Noctua’s website or in our ", ".", "The coldplates are the first engineering wonder. It’s probably easiest to get this part out of the way first, so we’ll cut over to our high-resolution scans with our 3D laser scanner to evaluate the cold plate curvature of each model.", "This is a scientific testing machine that we bought for $60,000 with support from our community buying our ", ", ", ", and ", " on ", ". The laser in this machine has a repeatability of 0.5 microns on the vertical axis, which allows us to measure the point-to-point depth.", "Here’s a scan of the Standard NH-D15 G2, just called the G2. It looks relatively flat to the human eye, but magnifying it 100x helps to illustrate the curvature. You can see that the plate is slightly convex, protruding down toward the CPU IHS. The central spike can be ignored -- that’s from an anti-reflective coating we use where it accumulated. This is a very slight curvature and is comparable to competing coolers of all price ranges.", "Here’s a scan of the High Base Convexity plate, built mostly for Intel’s concave deformation under the stock ILM. At 1x, you can already see that the center is going to protrude more than the last one. At 100x, that protrusion becomes immediately obvious as compared to standard. It’s not just marketing -- they really are changing the coldplates.", "And now, we’re on the LBC. With so much drama in the L-B-C, we can see what is actually the flattest cold plate that can be. It’s impressive how flat Noctua got this plate, to the extent that it caused us problems we were trying to contemplate -- when we were trying to remove it from AM4 CPUs since it basically suctioned itself to the CPU. That’s a testament to flatness, and in a good way for AM4 and AM5 alike.", "We have a ", " before we even knew Noctua was working on changing its coldplates and it lines-up pretty well. ", "We conducted 2 different types of tests: 100% fan speed and noise normalized and we did them across AMD at 200 watts, Intel at 200 watts, and Intel at 250 watts.", "We kept the same mounting hardware and fans and simply swapped the tower to try and isolate the variable that is the cold plate.", "We also took Noctua’s old D15 fans and threw them on the company’s new cooler and did some A/B testing on that front. We did anywhere from 6-9 test passes at the high end.", "We’ll again start with only the full-speed Noctua results on the charts so we can compare a lot of variations. This test uses the older acoustic testing methodology, so the noise levels are presented differently despite representing the same thing. They didn’t get louder from the Intel testing -- it’s all the same. ", "The NH-D15 G2 LBC is the best result here, which makes sense. Tested with the same fans and mounting hardware as the others, it ends up functionally tied with the HBC and Standard results. This isn’t too surprising: We saw similar results on AM4 with our prior cold plate flatness testing. Despite having a theoretical best match with a flat plate, AMD isn’t as sensitive to designs as Intel. This is because you can’t end up with a massive gap centrally, unlike with Intel. With AMD, even if the base plate is highly convex like on HBC, it will still apply massive pressure dead center and relatively close to the chiplet dies. In the case of HBC, it ends up lining-up over the silicon with an offset mount applied. These numbers all make sense.", "Using the non-offset mounting produced the worst result of the G2 coolers so far, though it was still better than the older D15. The G2 without an offset landed at 52.5 degrees Celsius over ambient at 200W here, or an improvement of 0.6 degrees Celsius with the offset mount on LBC.", "The D15 that we bought in 2023 landed at 53.3 degrees Celsius over ambient at about the same noise level and slightly lower RPM. Standard is therefore about 1 degree improved and LBC is about 1.4 degrees improved. That’s a lot, considering the fan speed and noise are so similar. The old model D15 from 2015 or 2016 or so runs a little louder and faster, but has worse thermals. This cooler has been around for years and has been through a lot in our testing. While metal shouldn’t theoretically age much, this can be explained by things like potential manufacturing refinement over the decade of production, fatigue or weakening in the metal fan clips or corner rubber from age that may soften the connection with the towers, or if any changes have been made over the years.", "When noise-normalized, the G2 LBC ran at 55 degrees over ambient, leading the standard model by 0.5 degrees Celsius. We didn’t test HBC in this heat load. The D15 we bought last year allows the G2 a lead of 1.6 degrees Celsius and our original unit falls much further behind, again for reasons we mentioned in the previous section.", "Before getting to the comparative tests, let’s look at some feature tests on Intel isolated as well. This is a 250W heat load on the ", " and noise-normalized. The test uses our hemi-anechoic chamber, so the noise is collected in a different way compared to the AMD testing. The distance is further at 1 meter and the noise floor is lower, which is why the numbers are different.", "Looking at just the Noctua results here, the NH-D15 G2 HBC with the new fans ran at 57.8 degrees Celsius over ambient P-core and 50.8 all-core. Attaching the old fans from our 2023 NH-D15 unit, we end up noise normalized with a slightly slower RPM since the newer fans are marginally quieter -- when they’re matched with this tower. The older fans ran 2.4 degrees warmer with the same heat sink, same mounting hardware, and the same mount itself. With the old tower altogether running about 3 degrees warmer when noise-normalized as compared to the new one. ", "And here’s the Noctua-only Intel data at 100% fan speeds also for 250 watts. ", "In this test, the HBC model posted an improvement to 53.3 degrees from 55.9 degrees on the NH-D15 we bought in 2023, which is a 2.6-degree change in P-core average. Noise levels are equal between old and new in this test.", "Adding the washer mod brought the result down an additional 0.8 degrees Celsius -- but we wouldn’t recommend using it for the reasons we’ll talk about below. It does work, though.", "Now for the comparative 250W Intel results when noise-normalized in the chamber.", "The ", " predictably leads the charts here and is currently the only liquid cooler we have in this new dataset. At 48.1 degrees over ambient for P-cores, it leads the NH-D15 G2 HBC by 9.7 degrees. That’s a huge advantage and shows where liquid still rules, which is dealing with high heat loads. We’d still recommend liquid for running Intel at full tilt.", "The NH-D15 G2 does well, though. At 57.8 degrees P-core average, it’s the coolest air cooler we’ve run through this new testing approach when noise-normalized on Intel. It’s outperforming the ", " by 2.9 degrees Celsius, which is great since the A720 is a relatively massive cooler and is a lot cheaper than the NH-D15 G2, so it’s important that the NH-D15 G2 is ahead. That’s a huge gap for air coolers and is bigger than most of what we saw in our flatter AMD IHS testing at 200W. Larger gaps form at higher temperatures and with more concavity of the IHS.", "The G2 HBC leads the ", " by a somewhat impressive 4.4 degrees here. Now, that’s still over $100 more expensive for those 4.4 degrees, but it’s important that Noctua is the best air cooler that exists at these prices. It at least achieves that in this specific comparison.", "The lead over the AK620 and ", " from DeepCool and ID-Cooling is noteworthy, with the A620 underperforming in this test as compared to the AMD results. Our next chart will be for 200W AMD thermals comparatively.", "We’ll move to the full comparison chart at 100% fan speed now. The G2 LBC model with the offset is our reference point.", "At 100% fan speeds, the NH-D15 G2 is only outperformed by the louder coolers on this chart: The Assassin IV, which is no longer available in the US due to sanctions we ", ", is about tied with the G2 while running 2dBA louder. The ID Cooling A720 with dual 140s and a tall tower ends up better than the G2 LBC by 1.4 degrees Celsius, but is also a considerable 5.1 dBA louder. That is definitely a noticeable increase in noise. Typically, most people will notice at 3 dBA but you can definitely notice less than that. It just depends on how sensitive your hearing is. ", "The G2 LBC outperforms the $45, louder ID Cooling Frozn A620 marginally. The ", " is a similar noise level to the G2 and holds a 53.4 degree result, allowing Noctua a 1.5 degree advantage. The Peerless Assassin has a massive price advantage though, at around $120 cheaper (it tends to be about $35) -- that’s huge and cannot be ignored. In the vast majority of use cases, it makes way more financial sense to buy something else and put the money toward silicon or savings.", " is also new to this chart and underperforms massively, so we’ll skip that one. ", "The Arctic Liquid Freezer III 360 is one of the most noise-efficient coolers on this chart, and is liquid. It's at 39.8dBA for a 45-degree result, a lead of 6.5 degrees. This cooler is currently $117, or $33 cheaper than the G2. ", "As you’d expect, liquid remains superior in pure cooling capacity, despite other limitations like radiator size needs and the introduction of a pump to the system.", "The noise-normalized results on the 200W AMD heat load have the G2 cooler as tied with ID Cooling’s A720 for the best result on the chart. That has the G2 ahead of the smaller Peerless Assassin by 1.2 degrees when matched to the same noise level and ahead of the Assassin IV by the same. The Liquid Freezer III 360 runs at 47.3 degrees when noise-normalized, a 7.9-degree advantage. As expected, liquid tends to start pulling ahead even more when noise levels are brought down.", "The last one for CPU thermals is back to Intel at 250W, but now with full fan speeds.", "In this test, the NH-D15 G2 HBC ran at 53.3 without the washer mod, allowing the Liquid Freezer III a lead of 7.1 degrees, or 6.3 degrees against the washer mod. The A720 closes the gap here by running louder, with a 4.4 dBA climb and under 2 degrees of difference. The Peerless Assassin is in the 57-degree range, giving Noctua’s G2 roughly a 4-degree advantage again.", "The Liquid Freezer is the most impressive overall, with a 32dBA result and chart-topping performance. It’s quieter and cooler -- which it should be, seeing as it’s a 360mm radiator that’s relatively thick and also filled with liquid. For air, Noctua is leading what we’ve run through so far.", "This chart is for the core-to-core deltas on Intel with the 250W test at 25dBA normalized. For this, we’re measuring the range of the hottest to the coldest cores. This is a useful metric for both overclocking and borderline TjMax boosting, as it informs you how much your hottest core will limit the CPU. Although the actual CPU soldering and lid affect this, the cooler’s hotspots will likewise influence it. Hotter overall results will lead to a higher core-to-core delta by nature of increased heat overall.", "Here, the Liquid Freezer III’s core-to-core delta is 15.8 degrees Celsius, which is actually pretty great. The NH-D15 G2 HBC has a 17-degree range; sadly, this is good for Intel. Sadly because we’d like to see lower, but the Liquid Freezer III shows us that Intel eventually steps-in to bottleneck it.", "The A720 has a 19-degree delta, with the Peerless Assassin at about 20 degrees. Noctua is doing well in this one.", "We’ll look at the pressure distribution now. This evaluates a mixture of the cold plate design and the mounting hardware. ", "Intel is up first.", "The image represents columns showing HBC, HBC with washers, LBC, and standard maps.", "The HBC mount is in the first column. Here, you can see relatively good pressure application across the center of the CPU, which is where the die is. It’s a little weaker on the top edge.", "The washers were a little more variable in what they produced as a result of the mounting difficulties that we will go over later. One of these scans shows nearly perfect pressure distribution, though: It hits the central die area, but also applies more pressure across the whole IHS. The other washer mod scan is less impressive, but still good overall.", "We looked at LBC next. This one is cool and shows exactly what we’d expect: The flatter cold plate has effectively no pressure centrally. It still contacts, but will rely more on thermal paste and lacks the firmer pressure to pull heat effectively from the die area. You should definitely not buy an LBC G2 for Intel.", "Finally, the G2 represents standard. This one has an overall even distribution of pressure. It doesn’t show in the colors, but the pressure is slightly higher in pascals or PSI with the HBC solution than standard. Even still, standard is doing well. This is the cooler you’d use if you might swap it between AMD and Intel in the future.", "This is similar to the original NH-D15’s pressure distribution, which you can see in our test here.", "Here are the AMD pressure maps.", "In these, you can see that HBC applies high pressure in the chiplet area, which is the only reason it works OK. Clearly though, the LBC option is a better fit for AMD. The standard solution is lower pressure overall, but still good contact. If you’re buying exclusively for AMD, LBC makes the most sense.", "Now for some acoustics. The testing you’re about to see was performed in ", ", which was a quarter-million dollar construction project for us last year. Our current noise floor here is 13.6 dBA, and if we can bring in enough viewer support via your purchases on the ", ", we hope to upgrade our capture equipment to bring us closer to a sub 10 dBA noise floor. Our capture setup is our current limitation. That’s our next major purchase.", "For this testing, we’re measuring at a 1-meter distance from the front center of the fans, away from exhaust. The measurement methodology was created in partnership with Mike Chin, formerly of Silent PC Review and a leading PC acoustics expert whom we hired for consulting on the test methods. ", "This frequency spectrum chart shows the Noctua NH-D15 with the G2 fans mounted and running at 100% speed, which includes the RPM offset that Noctua is applying via its PPA and PPB fans.", "We observed a repeatable higher noise level in the low frequency range of about 216 Hz that appeared in two separate tests. This appears to be a real result. Lower frequencies are generally regarded as more acceptable to the human ear and less annoying. We also observed a plateau around the 800 to 1500Hz range, with a gradual reduction in acoustic power across the higher frequency end of the spectrum.", "Adding the original D15 to the chart, including the original fans for it, we see that the prior higher volume spike has shifted: Instead of occurring around the 216-230Hz range, it now happens around 330Hz. ", "Both coolers had a similar spike around 680Hz, with the original D15 spiking louder. The older cooler had a few higher frequency and repeatable spikes in the 3000Hz area as well, but overall, had lower volume levels in the higher frequency range of the chart despite a few acute break-outs.", "Ultimately, these fans are remarkably similar to each other in total volume level and in acoustic profile.", "And now we’ll get into an A/B comparison of playback. We won’t tell you which is which until after you hear both, so try to identify which you prefer. This helps to eliminate bias.", "We’ll play the first and then the second test uninterrupted. There will be a brief mute between the two so that you know it has changed. Note that these are not the exact clips we took our frequency spectrum plot from, and likewise, we have had to boost the levels so that it is audible at a similar volume to our video. You should be listening for type of noise, not necessarily the volume. You can listen to it in our video ", ".", "The first recording sounds lower pitched overall, or at least, has a lower emphasis on the higher frequencies. If you listen carefully though, you can notice a higher frequency almost rattle-like noise that might be a motor, bearing, or electrical noise, but you have to listen very closely. Here, ", ":", "The second one you listened to sounds louder in the higher frequency range overall, but lacks this potentially annoying higher pitched rattle.", "We’ll ", " and in the same order, but with the names revealed. The first is the D15 original, the second is the D15 G2.", "The G2 does end up with louder higher frequencies in total, but eliminates that potentially annoying noise we observed and isolated. Generally speaking, the acoustic profile of these is relatively close but Noctua has shifted it on the G2 to try and better accommodate human factors like getting rid of that high frequency noise or just bringing down some of the spikes to lower frequencies where possible.", "Let’s go over the installation process, then some praise and critiques of the installation and hardware.", "For AMD, you begin by removing the stock brackets that come on the motherboard. ", "Once that’s done, you place down the included gray AMD standoffs. ", "From there, Install the brackets, which are labeled by north and south and have 4 holes each. For our setup, we used the included AMD offset brackets. Noctua has moved away from Phillips screws and moved to Torx T20. Thankfully, the company has included a nice driver. ", "Ensure you’ve got thermal paste in place and install the cooler with the 2 retention screws. It’s a good idea to alternate between them to get nice, even pressure. ", "Once that’s done, install the cooler’s fans using the included fan clips.", "For installation on Intel, the first step is to assemble the backplate. In our case, we used Intel 1700, which is labeled as position 2 on the backplate. Once you have the bottom half of the standoffs in the backplate, put the little washer rings around them to secure them in place. From there, place the standoffs through the bottom of the motherboard and lay the motherboard down on a flat surface. Once that’s done, place the top half of the standoffs into place. They will be blue for LGA 1700 and black for other Intel sockets. ", "When installing on Intel, you can change the orientation of the cooler. In our case, we used the brackets labeled 2 for LGA 1700 and screwed the included nuts down into place. From there, ensure you’ve got thermal paste for the CPU and place the cooler down and tighten both screws (ideally alternating to evenly distribute pressure until they are nice and secured). The next and final step would be to install the included fans. ", "All 3 SKUs of the NH-D15 G2 come with washers and they go under the ILM and that effectively just raises the ILM up. ", "Noctua advises that you do that with the CPU in the motherboard. Once that’s done, remove the ILM, and place the 4 washers over the 4 holes where the ILM screws in and then reinstall the ILM with the washers in between the motherboard and ILM. One of the issues that we encountered here was getting the threads to catch, which was kind of difficult. From there, you can re-close the socket. ", "In terms of positives, we liked the updated fans clips as they do a great job of just staying in the fan and make installation much easier. The build quality of the cooler is very nice and is what you’d come to expect from Noctua.", "In terms of criticisms, some of the newer coolers like the ", " come with rubber around their standoffs, which retains them in place, and that’s lacking here. We also don’t recommend the washer mod as its installation gave us a fair amount of trouble. For instance, the amount of engagements you have on the threads is pretty minimal before it starts applying torque. It felt like we were going to over torque it or over-strip something. Noctua could address this by including its own screws here or making the washers thinner. ", "The core of our reviews is a value judgment. You don’t buy this for value, plain and simple. You can look at the ", " sort of like an ", ", but it doesn’t quite provide that same performance gap. You’re paying for the brand credibility, including its support system and engineering.", "Our review boils down like this: If you have your heart set on it and can afford it, go for it. It is an impressive cooler. But at the same time, we would not default to recommending the ", " at its price point. There are simply too many close competitors for cheaper, with some air coolers equal and liquid coolers better. You are buying the name with this cooler. We don’t recommend it outright for the majority of our audience, but we are impressed by it."]},
{"title": " Thermalright Strikes Again: $56.90 360mm Liquid Cooler | Frozen Prism Review", "paragraph": ["Thermalright Strikes Again: $56.90 360mm Liquid Cooler | Frozen Prism Review", "Last Updated: ", "The Highlights", "Today we’re reviewing one of the cheapest liquid coolers from an established brand in the Thermalright Frozen Prism 360 Black ARGB, which cost $60.59. There’s also a cheaper version without LEDs that cost $56.09. ", "And as you will see in our 3D laser scan, it also has a heavy focus on protruding the cold plate towards the IHS. This should benefit its cooling by focusing contact on the silicon area. Confusingly, Thermalright also has several liquid coolers at similar prices and released relatively near this one. It has the ", ", ", ", the ", ", the Mjolnir Vision, Core Vision, Warframe Pro, Warframe Black X, Frozen Guardian, and ", " of variations on these.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "Thermalright’s strategy has been to completely swarm the market with cheap solutions. Thus far, those solutions have been extremely competitive on performance as well. At least if you look at air coolers, which we’ve generally liked from Thermalright so far. The ", ", for instance, has been one of our top recommendations for an air cooler since we bought it.", "And now, we’re going to look at one of the cheapest (but still name-brand) coolers on the market. Oddly, its price competition is more in-line with air coolers than liquid. The ", " is around $50, the ", " is about $35, the ", " is $50-$55.", "This will be an interesting one.", "It’s a wonder how Thermalright is able to make any money at all with some of the prices, where it manages to undercut major cooler brands significantly. The big difference with liquid coolers versus air is one that we can’t reasonably test in a review window: If an air cooler works well, it’s unlikely to have any kind of long-term failures (other than maybe the fan, which is cheap to replace). Liquid coolers can have issues with gunk build-up, corrosion, or pump failures. Gunk build-up is the main concern and happens normally from chemical imbalances or poor flux work in the radiators. That’s not something we can evaluate in a review, and we’re frontloading that consideration because it just seems like the price would have to include some kind of downside.", "Here are the basics:", "The cooler has a standard thickness radiator at about 25mm, or 27mm when counting the outer shell. It’s120x396mm for the actual radiator size, so Thermalright isn’t doing what the likes of Arctic or Hyte are doing by tweaking other dimensions to boost performance. This is dimensionally standard.", "It also has a rat’s nest of cables, with 6 total coming out of the fan for the 360 model and another 2 out of the pump block. Thermalright doesn’t give any of the modern ease-of-installation features or daisy chaining solutions, which should be expected at around $60.", "The fans are TL-E12 V2s, which have a maximum rated speed of 1850 RPM.", "Thermalright uses plastic hose clamps to help hold the tubes closer to each other, it has silver-colored plastic joints at the barbs, and uses a pump cap with RGB LEDs of a Thermalright logo and illuminated octagonal light bar.", "And that’s enough of the basics. The cooler doesn’t have a lot going on, which is expected. ", "For this testing, we’re using both AMD and Intel heat loads. The Intel heat load is relatively new and is 250W. We only have a few coolers on it. The AMD heat load has dozens of coolers.", "We’ll start with our noise-normalized 200W heat load on AMD, then move to our Intel testing.", "With all coolers using their included fans and set to the same target noise level, the Prism 360 ends up behind the ", " by about 3 degrees. In the world of coolers, this is a big gap -- but overall, the fact that a $60-ish cooler is anywhere near the top is impressive. The long-term viability becomes the biggest question mark.", "Anyway, the ", " is about equal to the ", " when it’s in a reduced 280mm size. The closest air cooler on this chart is Thermalright’s own Peerless Assassin (watch ", ") at 56 degrees, pushed below all the liquid coolers.", "We’ve become used to every generation’s newest and highest-end liquid cooler being a new chart topper. In this instance, being anywhere near the other liquid coolers is an accomplishment for this cheap cooler and it’s certainly no chart topper but it’s definitely competitive.", "100% fan speed on all coolers is up now. Thermalright’s Frozen Prism hits 53dBA here with our prior noise testing methods, which has it louder than the now-", " DeepCool Mystique 360 and significantly louder than the not-banned Arctic Liquid Freezer III 360, which was about 40dBA in this testing process. That’s a big noise advantage for the Arctic solution. Thermally, it’s within error of the Thermalright Frozen Prism, so the Liquid Freezer III is definitely a substantially better cooler than the Frozen Prism. Even still, the Prism does OK to brute force its position. It manages a top rank, despite achieving it in an acoustically inefficient way.", "In a quick test with a 250W Intel LGA1700 heat load, we found the Frozen Prism to perform about the same as the DeepCool Mystique and its quieter solution. The ", " is noticeably quieter at 100% fan speeds, down at around 45 dBA, and was less than 2 degrees warmer than the Frozen Prism when using the Thermalright contact frame. That’s not like-for-like, though: Comparing with the Intel ILM, the ", " ran at 63 degrees to the Frozen Prism’s 57, which has the advantage of running louder but the disadvantage of radiator size.", "The Liquid Freezer III exhibits the issues we mentioned in our review of the newer Arctic cooler, where the contact frame is not allowing ideal contact with the LGA 1700 solution and is falling behind in some ways. Still, the 360 model at least managed a 58.8-degree result at a substantially and noticeably quieter noise level at 100% as compared to the Frozen Prism. The perceived noise difference to the human ear would be about 2x louder.", "With the Frozen Prism at 35dBA, it ran at 65 degrees P-core and 58 all-core average (over ambient). That means the Liquid Freezer III at 39.8 dBA has about a 6.2-degree advantage (although it is louder here).", "This dataset was intended to be for a limited time while we move over to our new numbers, so it’s relatively slim compared to our AMD numbers. We have a new Intel LGA1700 dataset rolling out in a week or so.", "Next up, our laser scanner will give us a look at the Thermalright Prism. The laser scanner is an industrial tool we bought for evaluating cold plate design, IHS curvature or convexity and concavity, and device flatness. We got heavy use out of the machine recently when we tested some custom-made “", "” coldplates for Intel and AMD.", "For the Thermalright Frozen Prism, you can see at 1x zoom, the central area is curved toward the laser, which is indicated by that red part of the heat map. That’d make it convex toward the CPU, which is typically concave for Intel CPUs. We showed this in our IHS scans previously for the ", ".", "At 100x magnification, you can see that the entire center of the cooler protrudes toward the CPU IHS. This is obviously magnified to exaggerate it, but it helps illustrate the point. It also helps explain some of the stronger performance in some tests.", "We’re looking at pressure scans next. These are taken with a special chemically reactive paper and then scanned using a special software and scanner combination. The end result allows us to evaluate the pressure applied to the IHS by the coldplate when under the mounting force of the cooler’s included mounting hardware. Effectively, it’s an evaluation of the mounting hardware and not just the cold plate. ", "We’ll start on the AMD platform. Here, we observed super high pressure almost circularly around the middle of the IHS. This appeared on both CPUs we tested. That high central pressure is what we recently found to produce the best performance when we did our ", ".", "On Intel, the pressure scans showed good contact across the center channel of the IHS. It’s lacking on the far sides nearest the ILM clamp points, but the cold plate is making good contact everywhere the silicon is present. This high pressure across the die area likely explains the performance we saw earlier -- that plus the louder fans when at 100% load.", "Now we’ll get into the installation process.", "The first step on AMD’s platform is to remove the stock mounting brackets.", "Once those are off, install the 4 standoffs that go over the protruding part of the backplate. ", "Once those are in place, it’s time to install the brackets with their respective screws.", "With the thermal paste applied, it’s time to place the cold plate down onto the IHS and tighten both screws. ", "For installation on Intel, you’ll start by grabbing the backplate and ensure that the logo/labeling faces away from the motherboard. ", "Once that’s established, it’s time to install the standoffs into place. We used the farther outer positions for LGA 1700. ", "With that done, it’s time to slide on the blue retaining washers, which help hold the standoffs in place.", "Once that’s squared away, it’s time to drop the motherboard down into place and then place down the top portion of the standoffs into position. ", "From here, install the mounting brackets, ensuring that they’re laid out in the correct position for your CPU (We used the middle position for LGA 1700), and secure them with 4 nuts. ", "Ensuring that there’s thermal paste, it’s then time to install and tighten the cooler.", "The only thing to be aware of with the cooler is that the tubes are a little stiff, which makes it potentially a poor candidate for a case that has some tight spaces.", "It’s hard to beat at $60. Thermally, the cooler isn’t the best when considering the whole picture, but it’s also not bad. When we were at Computex this year and spoke to cooler manufacturers, everyone was talking about Thermalright. The collective comment from their competition came back to an uncertainty of how Thermalright can set the prices it can and make any money. In any case, they’re managing it.", "The cooler uses a heavily convex cold plate to mate with the concave IHS of Intel, which seems to work for it. Its pressure patch is largely focused on the die area for both AMD and Intel. Acoustically, it’s not a strong performer. The ", " is weaker than competition when looking at the full picture of thermal results at a given noise level.", "But we keep coming back to the same thing: It’s $60. Air coolers can’t compete with liquid in scenarios like this, but the best ones to consider also include a Thermalright solution: The ", ".", "As for competing liquid coolers that we’ve tested, the ", " remains a GOAT and the ", " has periodically dropped to $100, which itself is an amazing price. ", "The real question is going to be the endurance and long-term viability, but maybe a roll of the dice on replacing a $60 cooler with another one isn’t so bad. Overall, though, we’re impressed with it."]},
{"title": " Best CPU Coolers We've Tested (2024): Thermals, Noise Levels, & Value", "paragraph": ["Best CPU Coolers We've Tested (2024): Thermals, Noise Levels, & Value", "Last Updated: ", "The Highlights", "Today, we’re rounding-up some of the best CPU coolers that we’ve tested in recent years, including air and liquid coolers.", "This is a continuation of our favorite series each year, where we get to have some fun comparing only the best-of-the-best products we looked at and avoid the usual disappointments. But there was some huge news this year: ", " and is now gone from the US market. With that, a power vacuum has formed among cooler manufacturers, and Thermalright’s former nemesis has been replaced with Arctic and ID Cooling aggressively trying to fill it. We can’t say that was on our bingo card.", "Steve Burke", "Vitalii Makhnovets", "Andrew Coleman", "Jimmy Thang", "These tests will include results from our new 250W and 200W Intel heat loads in addition to our 200W and 123W AMD heat loads. The categories this year are for Best Overall CPU Cooler, Best Budget CPU Cooler, Best Value CPU Cooler, Best Noise-Normalized Thermals, and Best Mechanical Design. Let’s get started.", "These Best Of articles are intended to get newcomers up to speed quickly, so we won’t go into the same crazy depth we normally do for the standalone reviews. Each of the coolers that has a review will be linked in the description below so that you can find the full details if you want them, including all the 3D laser scanning, pressure maps, and downsides. This article will be more of a flyover.", "We’re testing both air and liquid coolers for this one. We’ve added a lot of coolers to the charts that aren’t in our prior reviews, specifically tested for this round-up, so there’s new data mixed with old in here.", "Additionally, keep in mind that our noise testing methodology changes between charts. For the AMD platform, we use our old room-scale noise testing.", "For our Intel platform we just added, we’re testing in our ", " with a lower threshold of 25dBA normalization in a noise floor around 14 dBA.", "As always, for cooler round-ups, we can only discuss coolers we’ve directly had hands-on time with. There are hundreds of coolers out there. We have a pretty good cross-section of the big options, but if you don’t see exactly what you’re looking for, we’d encourage you to check other content and expand your research.", "You can find the full charts on our CPU coolers ", ". As a reminder, ", " is a free website that is totally free from third-party ads and funded by the audience. We just got done running another 18 cooler tests on a 250W and 200W Intel platform with noise-normalized results in our hemi-anechoic chamber.", "That’ll set us up. If you want to check out our ", " and ", " round-ups, those are already live. All the review links and product links are in the description. Let’s get into it.", " | ", " | ", "Up first, our category for Best Overall CPU cooler this year. This category requires the pricing to be competitive, as it considers the value, the build quality and assembly features, ease-of-installation features, the thermal and acoustic performance, and everything else. Last year, we gave this to the ", ", which is definitely a GOAT and remains one. This year, we’re giving it to two Thermalright competitors, depending on CPU: Overall, the ", " gets the award this year. For our Intel bench specifically, we’re giving a tied rank award to the ", ". ", "Let’s start with the Intel results and the ", ", since that one is isolated as a winner to just this bench.", "The most heavily weighted element in favor of the Freezer 36 (read ", ") is its price. Arctic said it’d increase the price within just months of launch, but seemingly never did. Even today, the Black model that we tested is about $28 -- an incredible value considering its performance, at least on our Intel bench, and fiercely competitive with the ", " that won our award last year.", "Our new Intel 250W noise-normalized charts also include the ", ", which was eliminated because we discovered quality control issues and variance between our two units that resulted in a 2-degree spread of results, which is actually huge. Unfortunately, one of the Assassin 140 units we have just doesn’t have a good pressure scan or laser scan, while the other is fine. We were able to prove the source of the difference was a combination of the coldplate and mounting hardware.", "You can see the two entries for the PA140 here. It’s not because the white model is better, but because the other unit has contact issues.", "Anyway, that eliminates the new PA140 even if only the best entry were here. Of the remaining coolers, the Freezer 36 is the best performer after Noctua’s D15 G2 HBC. This is impressive with the Freezer 36’s $28 price. The G2, on the other hand, is $150. Some of this comes from Arctic’s mandate of a contact frame for the Intel version of its Freezer 36, but considering that’s all included in the price, this is a strong positioning. ", "One other note here: The ", " 2023 model we have here performs a little better than our original D15 from a decade ago, which is a result of minor tweaks or refinement in manufacturing processes along the way. We talked about this in the ", ". If you’re on an older D15 from around when it launched, it’s likely it is marginally different in performance today.", "On to the A720: In our Mega Charts for 200W testing previously, the Freezer 36 fell behind compared to its Intel results with the frame. This reveals our choice that’s tied for the category: The A720, which was also among the top two performers for Intel and is the best performer behind the D15 G2 (read ", ") in this 200W, AMD noise-normalized test.", "The combined chart-topping performance in both our AMD and Intel test benches is what leads the A720 to the Best Overall rank, with its relatively high build quality and moderate price securing the position. ", "At $55, with occasional drops to $50, it’s competitive with the best (like the $150 G2) and manages a 55.2 degree over ambient result on our 200W AMD bench. This improves on the GOATed Peerless Assassin by 1-degree, which does have a little bit of an advantage in price. ", "The Intel result improved on the Peerless Assassin 120 (read ", ") by 1.6 degrees.", "We recently tested the ", " as well, but it didn’t outperform our Peerless Assassin 120. The ", " has a slightly smaller tower than the Assassin and also has a disadvantage with noisier fans, found in our chamber testing. The ", "’s fan RPM is higher than the Assassin, but that doesn’t matter when normalizing for noise.", "Overall, for the A720, we think it has surprisingly good build quality. The fans are well-fitted to the cooler, with the central fan sinking to benefit VRM cooling as well. We like the simplicity of the black model that we have. The mounting solution is overall straight-forward and the bulked-up 7-heatpipe design helps with coverage across the IHS. The cap plates are a nice touch without overdoing the branding. The central fan also levels-out nicely with the top plates and each fan has rubber bumpers on the corners to reduce vibration, which benefitted it in noise normalizing. Its biggest downside is size, where the 163mm height makes it about 6mm taller than a Peerless Assassin 120. This could limit some cases.", "We think ID Cooling and Thermalright both are worth seriously paying attention to in 2025, especially with DeepCool’s disappearance from the US and the Freezer 36 is also worth considering if you happen to go Intel.", " | ", " | ", "Our Best Value award this year goes to the ", ". Value is judged by a combination of performance for the price, not just pure price. We have a Best Budget category as well for what is simply one of the best, cheap coolers.", " is an enigma: It’s $52.71 at the time of this writing. This is somehow even cheaper than when we reviewed it. It’s cheap enough that we remain skeptical of whether it may have some sort of defect down the line. In some ways, it seems too good to be true. Concerns we have might involve gunk build-up, but we have no evidence of any such issues at this time. What we do have evidence of is impressive performance: The Frozen Prism (read ", ") was a competitive liquid cooler in our testing, brute-forcing much of its performance with a hugely protruding copper coldplate, almost comically so. Our laser scans made this protrusion even more clear, with our pressure maps showing how the cooler leverages the design to brute-force high pressure dead-center, which is where the silicon often sits. ", "Even on AMD, which has less-centered silicon than Intel’s prior monolithic CPUs, the pressure spreads wide enough that it’ll catch everything.", "In our 200W heat load thermal benchmarks from the review, the ", " ran at 49.7 degrees Celsius over ambient when noise-normalized, whereas the best liquid cooler we’d tested at the time, the ", ", ran at 46.7 degrees Celsius over ambient. That’s a big difference. At the same time, achieving such close performance at under $60 was previously unheard of.", "In our prior test bench configuration for Intel, using a 250W heat load on the ", ", the Thermalright Frozen Prism was a chart-topper when at 100% fan speeds. If you look at the 53.2dBA noise levels though, it was incredibly inefficient compared to the ", ", which ran at 39.8dBA. This is over a 2x increase in perceived noise to the human ear for the Frozen Prism, yet it drops only a couple degrees. That’s an inefficient trade-off, and although fan speed could be lowered to compensate for noise, it’s clear the cooler isn’t some mastery of thermal and acoustic engineering.", "What the Frozen Prism actually is, though, is a mastery of cost engineering. ", "The Frozen Prism doesn’t have any real quality-of-life features to speak of or anything abnormal. It delivers what it promises, which is cheap cooling. Our only criticism of the physical construction, beyond some cheaper plastic-y feel of some parts, was the stiffer tubing. This can be worked around.", "Thermalright has become known for flooding the market with countless options, to the point where it’s overwhelming even for its own staff to remember them all at ", ". The company is saturating listings and driving prices down, which is ultra-competitive and in some ways good for consumers. It’s also pretty cutthroat, and is why we now have name-brand coolers also dropping in price. Following-up its success with the Peerless Assassin 120 in years past, Thermalright is looking for a repeat in liquid. We’ll see how the Prism ages, but so far, it’s competitive, especially in thermals. That’s why the ", " gets our best value award.", "The next award is in the same vein, but simpler: Our Best Budget award goes to the ", " and it’s challenging the GOAT in Thermalright. ID-Cooling is vying for Thermalright’s strategy. Last year, we praised it for its overall value -- though it has been shifted into the pure budget category with the Frozen Prism’s addition to our charts.", "The SE-214-XT ARGB has dropped in price and is now somehow $15.19 at the time of writing. We normally wouldn’t cite the pennies, but when 19 cents is over 1% of the total price, it suddenly becomes relevant. The SE-214XT ARGB is a simple, 4-heatpipe cooler that revives the approach of the old ", ". It’s dirt cheap, its quality is flimsy, its plastics feel like they’re from McDonald’s toys, its coldplate is spartan, and yet somehow, the thing can handle moderate heat loads. It won’t handle a 250W CPU in our test suite with any level of satisfaction, but it’s good enough for cheaper and lower power CPUs with users on more extreme budgets. This would also be a good consideration if you’re buying a used CPU to save money and need something that ticks the “good enough” box.", "In our 123W heat load on AM4 last round, the ID Cooling SE-214-XT ARGB held 58 degrees delta T over ambient when at 37.9 dBA, which had it more noise efficient for the result than the lower-ranked ", ". It was bordering on Noctua’s aged ", " (watch ", "). The ", " (watch ", ") ran at the same noise levels and a little more than 1 degree cooler and is likewise a cheap cooler, but at $16.79, somehow, and this is really weird to say, it’s almost 11% more expensive. What a bizarre world of coolers we’re in.", "In our ", " 200W heat load and with 100% fan speeds, tested instead in our hemi-anechoic chamber that purchases from the store help fund, we landed at 60.6 degrees Celsius delta T. That had the SE-214-XT ARGB as the worst performer on the chart, but still somehow capable of holding a stable operating temperature. In other words, it’s fine. The next lowest performer is the ", " (watch ", ") with its combination of two fans, a massive 9 degree improvement.", "Our 25dBA noise-normalized testing still has it at the bottom of the charts for this heat load, but even at this slightly reduced speed, it’s still a capable performer.", "We wouldn’t call the SE-214-XT “good,” but we do think it’s one of the best in class at its seemingly impossibly cheap price, considering it also has to sit in freight to ship to wherever it’s sold. If you need a cooler to just get a system going, this is a good value. ID Cooling seems poised to challenge Thermalright in the future.", " | ", " | ", " | ", " | ", "This is for the Best Noise-Normalized Thermals, and because we have both liquid and air coolers in the charts for this round-up, we’re assigning the award to one liquid cooler and one air cooler.", "The ", " firmly receives the Best Noise-Normalized thermals award both overall and for liquid, but air can’t be expected to compete at the same level of liquid and large radiators (especially when dropping fan RPM). For air coolers, the award goes to the ", " for Intel (or ", " for AMD), with a runner-up award for ID-Cooling’s Frozn A720. We’ve listed the latter because it’s $100 cheaper than the NH-D15 G2.", "This is a thermal category, so we’ll focus on charts.", "Starting with the Liquid Freezer III (read ", "): Arctic’s revision of its ", " tried a number of new things, like shipping a mandatory contact frame with its Intel variation. This complicates matters and isn’t always for the best. ", "We found that Arctic’s contact frame was worse than other options on the market, but its cooler design was such that other options couldn’t be used instead. It was still better than Intel’s ILM, though.", "For thermals, the Liquid Freezer III is just as impressive as its predecessor, and its price is similarly competitive. In 200W testing on AMD with our older noise-normalized approach, the Liquid Freezer III was the clear chart topper when we limited the pump speed to 70% (which helped reduce noise and allowed higher fan RPM instead). Running the pump at 100% and sacrificing some of that noise budget for it, it was still tied for second place, behind only itself and matched with a cooler that’s now banned in the US. The next closest non-Arctic option is the ", " from Lian Li, which is specifically performance-focused in its design. ", "In our Intel 250W heat load thermals on a ", " (read ", "), also noise-normalized, the Liquid Freezer III with its mandatory frame climbs to the top of the chart. It’s ahead of the Frozen Prism by enough to not be margin of error or test variance. It’s also ahead of the ", " and predictably ahead of all the air coolers.", "The Liquid Freezer III remains a top recommendation of ours, though we do find its contact frame solution frustrating for Intel. On AMD, it’s much simpler.", "Moving to the air coolers, the victor of the noise-normalized category on pure performance is the ", " for our Intel 250W bench or ", " for AMD. Previously, we found that the G2 HBC outperformed even its closest competitor, the A720, by a couple degrees. This gap alone is impressive, as finding more than single-degree differences between air coolers is rare. Noctua’s work on the high base convexity cooler really worked for Intel -- but it’s also the recipient of our Best Mechanical Design category, so we’ll save that discussion.", "On AMD 200W testing when noise-normalized, we also found Noctua’s D15 G2 LBC (or its flatter model) to be the current best noise-normalized air cooler result, behind only a huge stack of liquid coolers.", "As some honorable mentions for runners-up here, since most are in the market for something cheaper, the ", " takes a clean second place in both our Intel and AMD CPU cooler testing. The Frozn A720 well balanced between the 2 platforms. It’s a relatively large tower that may have some clearance issues in some cases, but its $56 price-point makes it one of the more affordable, competitive coolers, and it’s $100 below the D15 G2.", " | ", " | ", "The next award is for Best Mechanical Design. This covers the total execution of every physical feature of the cooler: Pressure distribution, laser scans, ease-of-installation features, a highly usable design, aesthetics, and the cooling itself. This year, we can easily give it to the Noctua ", ". Like last year’s winner for this category, which was the Assassin IV, Noctua’s NH-D15 G2 isn’t a good value cooler (it’s $150, which is insane for an air cooler) -- but this category isn’t for value. We can still appreciate the engineering.", "It’s extremely well-built and takes careful consideration of factors often ignored by other cooling solutions. The ", " was secretly developing something similar to what we showed with some custom-made Scythe cooler coldplates that we ", ", which was trying to game the coldplate convexity to better match the CPU heat spreader’s surface concavity or flatness. ", "Noctua was working on this for years and launched three models: The standard G2, HBC (or high-base convexity), and the LBC (low base convexity, sorry, Long Beach City) models subtly modify the convexity or flatness of the coldplate to better pair with deeply deformed Intel 13th and 14th Gen CPUs or with the relative flatness of AMD’s AM5 and AM4 CPUs with the LBC. Standard is meant to work on anything. We used our 3D laser scanner that we bought for cooler testing on the D15 G2 and discovered that the names really match the curvature.", "We found that this wasn’t a gimmick and that there were actual, measurable and repeatable differences in benchmarks.", "Noctua also lands on this list for its careful attention to detail on the fans, which it pairs and matches with slight RPM offsets intentionally in order to avoid a potential beat frequency phenomenon that could be annoying for some users. We have an ", " with one of Noctua’s team members to talk about the engineering topics behind this. ", "The D15 G2 also had excellent pressure distribution as a combination of its mounting hardware and the coldplate, shown in our mix of pressure maps across AM4 and Intel. ", "An included washer mod added some further fine-tuning and small touches, though it was also clearly an attempt to try and bulk-on a value-add with the high price.", "Thermally, the D15 G2 didn’t blow away any of the other coolers by massive margins. It’s a good cooler, but spending $120 more than competition doesn’t mean it’s suddenly competing with a 360mm liquid cooler. The G2 with the HBC solution and a washer mod ran at 52.5 degrees delta T in our review results for the 250W Intel heat load, which was better than coolers like the Peerless Assassin by several degrees (and is impressive), but predictably behind a high-performance liquid cooler. The physics just won’t support beating water and the huge surface area of a radiator. Being realistic about performance expectations is healthy, though, and Noctua never claimed that.", "We appreciate what Noctua has done with its mechanical and thermal engineering. The company may move slowly, but thus far, it has moved with purpose. As we said in our ", ", this is the type of thing you buy if you have your heart set on it and can afford it. You are buying Noctua’s name with the G2 and, likewise, its support. It has already delivered one free update for owners of G2s with a relatively minor rattle complaint."]},
{"title": " Noctua NH-P1 Passive CPU Cooler Review: Benchmarks, Schlieren Photography, & Mechanics", "paragraph": ["Noctua NH-P1 Passive CPU Cooler Review: Benchmarks, Schlieren Photography, & Mechanics", "Last Updated: ", "The Highlights", "The ", " is a massive passive cooler. No fan is needed, at least sometimes. In our review, we’ll take an in-depth look at thermal performance, installation hardware, mounting pressure, flatness, and overall build quality and viability. While we would normally look at acoustics, because it has no fans, there are no acoustics to analyze. We will, however, look at some Schlieren photography of ", " in action, which will allow us to see the air density gradient change surrounding the cooler, enabling us to see the pattern in which heat rises off of it.", "Reviewing this passive cooler made us change our testing methodology a bit as the NH-P1 isn’t designed to handle 200-watt CPUs. It’s not really meant to handle 120-watt CPUs either. That’s not a knock against it, it’s just designed to be fan-less. As a result, we’re introducing a low-end CPU to account for this and we’ll be testing it against some AMD stock coolers.", "Steve Burke", "Mike Gaglione", "KeEgan Gallick", "Jimmy Thang", "The most obvious group of who the P1 is for would be anyone who can’t take noise, just as a personal preference, or doesn't want fans for functional reasons. Those might include home studios, recording studios, voice-over PCs, dust control, or acoustics labs. It's difficult to fully eliminate noise in a build as you’ll most likely have fans elsewhere inside the case (PSU, GPU, etc.). Each of those can be made passive as well, but the GPU in particular would be a challenge if running any kind of gaming PC. Passive power supplies like the ", " are (expensive) options that can at least silence the PSU while remaining quality. We use the ", " in our acoustics lab.", "Passive coolers also make sense for dust control, like if you’re building a low-maintenance and long-running server with a constant uptime. ", "It is worth mentioning that you can mount a ", " to the cooler, which is sold separately, as a solution to spin-up as needed. At $110 though, the Noctua NH-P1 is in the same price range as the ", " (that ", "), which has two fans and liquid, and also happens to perform a lot better thermally. Even active air coolers like the ", " or Noctua’s own ", ", which both retail for roughly $90 to $100, will also far and away outperform the Noctua NH-P1. We want to make sure that expectations are clear in this review that this is not some “magical” cooler. It’s a passively cooled one that's designed well. Mounting an NF-A12 fan to it would enable a specific scenario: You'd have a 0RPM option under certain temperature thresholds (configurable through BIOS), but a fan present to ramp under heavy load. The curve would be pretty flat until the ramp.", "This section will talk about the mechanical aspects of the Noctua NH-P1. If the years of delays weren’t evidence enough, the design of the cooler makes it evident that most choices were deliberate and informed rather than copying existing designs.", "Passive cooling plays by different rules than active cooling: Because we’re relying on natural convection, the fin density must be low. That means that the P1 only has 13 fins, or more appropriately, these are aluminum “plates,” up from 12 on the prototype we saw in 2019. The limited plate density is necessary to allow room for air movement and passive transfer of heat from the plates to the air, especially without assistance of a fan. With a fan, tighter fin density is preferred up to the extent it creates high flow impedance. This is because the higher surface area is more valuable on an active cooler, whereas the specific heat benefits afforded by the P1’s design is more appropriate for a passive cooler.", "The passive design also means the fins or plates need to be oriented so that one plate doesn’t obstruct heat from rising off of another plate. Noctua built the P1 such that it can be installed either horizontally, as in a test bench, or vertically, as in a standard tower, while the plates remain perpendicular to the upwards direction in both configurations.", "Each plate is 1.5mm thick, the same as the 2019 prototype, and each plate has 6x 2.8mm diameter holes numbered in sets of 1, 2, or 3, which are used for mounting fans if desired. Although active cooling can work on this, keep in mind that you’re best off with either a truly passive or truly active cooler. Hybridizing the approach is less effective than something dedicated, but does mean you can mount a fan whose fan curve stays at 0% until under a heavier load.", "6 of the plates run down towards the heatpipes, but don’t actually connect to them. They aren’t welded together as we’d normally see. For heatpipes, Noctua is using 6x 6mm heatpipes, which are solely responsible for transferring heat from the cold plate to the plates.", "The nickel-plated copper cold plate is about 39x40mm and suitable for Intel or AMD desktop CPUs, but is not a good fit for HEDT parts -- those have power consumption in excess of what this can handle, anyway.", "The cooler is about 149mm wide from the protruding heatpipes to the sealed end of the heatpipe on the other side, and about 160mm tall from the bottom of the cold plate to the top of the aluminum fins, not counting mounting hardware or socket height. Clearance at the overhang is about 40-42mm.", "Part of the manufacturing difficulty that caused delays on this one has to do with the plate or fin thickness: In 2019, Noctua’s primary supply-side factory had a press which stops at 0.5mm fin thickness, meaning 1.5mm required a new solution. The automatic interlocking of the fins was part of the challenge: As we’ve seen in factory tours in the past, fins often get stamped by 150-ton machines, then folded into themselves to automatically assemble the entire finstack.", "We’ll start with some Schlieren imaging. We took a few hours of footage in various configurations for this, so we’ll try to compress it to the most interesting stuff. Our Schlieren photography setup uses a high-end parabolic mirror and kinetic mount, made possible for purchase by support from our viewers on ", ". Schlieren photography splits light to image the air density gradient. This doesn’t show the heat and isn’t infrared, but rather shows the movement of air as density changes.", "In this ", ", we show how heat passively rises off of the P1 when it’s under a 68W heat load from a ", " CPU at steady state. Looking closely between the fins, lower down, you’ll notice little density change in the wide gaps between the plates, but you can see the air clinging closely to and drifting off of the plates. The wide spaces between the plates ensure enough space is available for passive cooling without excessive heat buildup. At the top of the fins, we can see where hot air pools and drifts up naturally, following the basic physical law of heat rising. This stops mattering when blasting 2000RPM fans at a cooler, but in passive cooling, it becomes important that the fins remain vertically unobstructed -- including from other fins -- to enable natural dissipation of heat.", "The left side of the cooler is interesting. This is where the heatpipes protrude through the plates and is where you can see the highest change in air density.", "We also tried mounting a fan to the top of it, just for perspective. This overpowers any natural processes, obviously, and funnels the air conically upwards when set as updraft. This was using the ", ".", "We also set it to Noctua’s recommended downdraft configuration. Here, the fan pulls in air that’s drafting up and off the sides of the heatpipes. It’s pushing warmed air back into the cooler. That’s still a net positive versus passive cooling, but is less efficient. The benefit is that it helps VRM components.", "Mounting a fan to the side and pushing air through the cooler resulted in chaos in the imaging. The only interesting thing we saw was the speed at which air density above the heatsink changed, despite the fan being directed through the cooler. This is one part Noctua fin design and one part fan speed: This fan is relatively low speed, so a lot of the air makes its way up-and-out before making it through the cooler. ", "We'd strongly recommend checking the video above to see this in motion.", "This section will cover installation and mounting hardware. We'll cover both AMD and Intel installation instructions for the Noctua NH-P1 Passive Cooler. We recommend installing the cooler on a flat table rather than in the case, as its size will make it difficult to work with in cramped spaces.", "On AMD, the stock backplate is used, as is typical, and four gray spacers are placed on top of the threads. Next, two brackets get installed for AM4 hardware, with an included Torx driver used to secure the screws through the brackets. We’re up to 10 pieces of hardware once the four screws are threaded into the backplate, securing all the pieces. ", "The Noctua cooler can be oriented two different ways. You can orient the heatpipes toward the RAM, allowing the cooler to overhang the VRM heatsink. You can also have it overhanging the RAM. Optimal orientation will depend on the height of your RAM, the size of the case, and clearance on either side of the socket.", "From here, the same Torx driver is used to thread two spring-tensioned screws onto standoffs from the mounting bracket.", "This is all fairly straight-forward and the included manual does excellently to explain the steps. Noctua doesn’t skip any steps and provides both visual and written instruction. Mike, our test technician working on this one, said that the manual “gives everything an OCD user would want, or close to it.” This goes down to the diameter of thermal paste dots recommended by Noctua.", "For Intel LGA115X and LGA1200, an included metal backplate and standoffs get installed first, followed by four black standoffs. Two brackets get installed next, bowed outward from the socket, at which point the cooler sockets on and has its spring-tensioned screws tightened onto the standoff on the bracket. It’s mostly the same process as AMD, just with different hardware.", "This cooler will naturally pose challenges with compatibility. Video card placement and size, especially those with large backplates, will affect the behavior of the passive cooler. Some may need to move down a slot, depending on how packed the motherboard is.", "RAM clearance isn’t too big of an issue since the cooler can be mounted to overhang the VRM heatsink, and we haven’t seen any tall enough to be a problem with this cooler. ", "Case compatibility will probably be a problem: Installed height is about 158mm, and most cases stop at 150mm depth. ", " cases to try and help with this, notably naming the Cooler Master SL600M that we’ve ", ", the ", " that we ", ", the Jonsbo U5 and UMX4, ", ", Thermaltake’s Core series, and ", " series, among others. We use the ", " for our acoustic lab test platform, which itself uses an NH-P1.", "If you are planning to mount a fan to the cooler, though, it’ll need to go on the side. Mounting it in a downdraft or updraft configuration will increase the stack height, but also obstruct the fan with a panel anyway. An open air configuration would be a good solution for the P1 as well, especially since dust is less of a concern when fans aren’t really present.", "This section will cover these tests:", "Of course, no acoustics this time.", "This pressure map illustrates how the mounting pressure gets applied to the surface of two different integrated heat spreaders from our AMD CPU pile. Pseudocolor pressure maps are mostly useful for evaluating the distribution of contact pressure from the mounting hardware. This isn’t the flatness of the cold plate, but rather the efficacy of the mount. The flatness is next.", "Remember, thermals aren’t taken during pressure mounting. It’s done with the system off, so the CPU itself is irrelevant to the test. Mounted to our 3950X IHS, we noticed overall excellent contact except for a few problem areas. Notably, the edge closest to the RAM was lacking in pressure, as was its opposite side, where a small hole in pressure formed.", "The 3800X through two mounts had less consistent results than we normally see, but was consistent in its gaps at the edge toward the RAM.", "Our surface flatness testing uses a depth needle to analyze distance from a known 0-point in microns. This one has the Noctua NH-P1 cold plate as overall flat, within the average of most other coolers. It’s not magic, but it’s doing well. The median had us at about 10 microns, with excursions to 24 and 1. Noctua sticks with the rest of the pack for this one, and that’s not a bad thing.", "We’re first going to show a chart of our 200W heat load tests just so you have a good understanding of how the coolers line-up. We’re doing this because we have the most data for this heat load, so it gives the most perspective. Noctua doesn’t advertise the P1 as being capable of cooling this much power, and in fact, markets against the use, so this is expected. The cooler, like we said, isn’t magic -- but it is good engineering once applied to the right use case. The P1 gets a “DNF” for our 3950X test -- it didn’t finish and hit TjMax within seconds of a load starting. This isn’t meant to be seen as a negative, just a reality of passive cooling. This chart is normalized to 35dBA, with the P1 at noise floor. ", "If you wanted a very quiet cooler that is capable of cooling 200W, then the ", " (which we ", "), ", ", or even ", " would make sense. The FUMA2 and ", " are among the most efficient at their price brackets and performance levels.", "With expectations set, we stopped that test nearly immediately to preserve our test platform, then moved to a 123W heat load with our 3800X and fixed frequency and voltage settings for test consistency. ", "As a reminder, the 120W heat load isn’t high enough to differentiate several of these coolers, so everything starts to look about the same when we measure the top performers.", "This one is also too much for the passive cooler, but we’ll show the chart for perspective as before. ", " at 35dBA held 61 degrees Celsius over ambient, meaning it’s in the 80s for Tdie. That’s near the cut-off for what’ll run, although there’s some room for slightly worse coolers below it.", "With the A-series fan strapped to the NH-P1 and at 100%, the cooler still couldn’t handle the 3800X heat load with our settings. We were running at about 90C before we abandoned the test, or 70 degrees over ambient, which is high enough that we shut it down before hitting full steady state. It’s quiet, thanks to the fan, but the NF-A12 fan isn’t powerful enough for this use case.", "Finally, we get to the R5 3600. Noctua technically marked this CPU as unsupported in its list, but our benchmarking has a custom Vcore set that’s lower than most auto settings. The CPU remains stable at 4100MHz locked and follows our ", " that we published previously -- just with a 68W heat load and 3600 instead. The CPU ends up working with the P1 when using our settings. This is new to our bench suite, so it’ll enable us to test lower-end hardware going forward. Of course, this also means that it’s the most barren of all the charts, since we only just added it.", "Here’s the chart at 100% fan speeds. The ", " is finally in a workload it can handle. We measured it at 64.6 degrees over ambient steady state, or about 84-86 factoring-in our ambient. We have a couple degrees of room, but not much. It’s barely doable at this power load and voltage. Overall, it’s working.", "The cooler produces no noise, so we’re at a noise floor of about 26dB. The Scythe FUMA2, at about $60, is a great example of a cheaper, thermally superior aftermarket cooler, but this is with its noise level at 34.4dBA at 20” distance. That’s quiet enough that most people won’t notice it, especially over other ambient noise like AC, but it’s still significantly louder than no noise at all. The FUMA2 runs at 37 degrees over ambient to the P1’s 65, nearly 30 degrees cooler.", "The Wraith Prism ran at a comparatively deafening 47dBA, thanks to the 90mm fan at high RPM, but did benefit from a 43-degree result. The FUMA is significantly more efficient, as is the Noctua P1 with an NF-A12 mounted to it, at 30dBA for the same temperature. The Wraith Spire ran at about 39dBA with this setup, measuring 51 degrees.", "The P1 can do it, and with a fan mounted at a low RPM, it remains quiet but drops a staggering 21 degrees off our test results. Still, if you’re going active, a true, targeted active cooler will be the most efficient. The FUMA2 could have its RPM reduced to meet the P1’s A12 noise level and would still be cheaper.", "This chart will show the time-to-max temperature at steady state under the R5 3600 heat load. This is plotted at Tdie, not delta T over ambient, so you’re looking at CPU temperature for one pass. We had to adjust our measurement time for the P1, because it took about 25 minutes to be within 1 degree of the final steady state measurement. The initial ramp to 58 degrees happened within 10 seconds, for perspective, so there’s not much soak capacity for short bursts.", "Finally, some VRM thermals. With the more doable heat load of just 68W on the R5 3600, VRM thermals are basically a complete non-issue on most motherboards -- even the lower-end ones. It’s still interesting, though: The Noctua P1 has a clear deficit here, made obvious by the fact that there’s no fan to blow air over the VRM heatsinks. The downdraft Prism does well, although it’s acoustically inefficient compared to the FUMA2 or P1 with a fan. Fortunately, because the P1 can’t really handle overclocking and high-power scenarios to begin with, the VRM cooling deficiency is unimportant.", "Installing the ", " was straightforward and the engineering on it is pretty good overall. It is very expensive at $110, though. If you’re okay with some noise and aren’t aiming to be dust-free, then don’t buy this cooler because it’s probably not meant for you. You will get much better performance and value out of something like ", ". If you prefer an active air cooler, there’s ", " or DeepCool’s Assassin III.", "The P1 is excellently constructed and is a good performer for its use cases, which will largely be media-related (voice over studios, recording studios, acoustics rooms, anechoic chamber exteriors, medical facilities like operating rooms, etc).", "For performance, what the NH-P1 can handle is something in the class of an R5 5600X. We were able to get it running on a Ryzen 5 3600. We did tune the voltage on that, though. If you have a motherboard that runs high Vcore auto, then you’ll be borderline. Certain cases can also pose challenges as you’ll need space above the cooler to be unobstructed so heat doesn’t build up. Fortunately, Noctua has a ", " and ", " list on their website. We appreciate how it feature listings from competitors. ", "The ", " has been a few years in the making and has gone through several revisions. We noticed that there are more square holes through the fin stack than what we saw in their 2019 prototype and some of the L-shaped bends within the internals of the cooler are gone as well. ", "Performance overall is good for a passive cooler but, again, it’s obviously not going to be able to compete against active air or water coolers. Still, it’s one of the best passive coolers we’ve seen so far. Even just its engineering, design, and build quality are among the best of any cooler we've tested. Ever."]},
{"title": " $50 Noctua Air Cooler Review: NH-U12S Redux vs. Stock AMD Coolers & More", "paragraph": ["$50 Noctua Air Cooler Review: NH-U12S Redux vs. Stock AMD Coolers & More", "Last Updated: ", "The Highlights", "We’re back in benchmarks again, this time with the ", ". It’s a sort-of new version of the long-standing ", " tower. It’s a fairly slim tower and has a 120mm fan (as indicated by the name) and, with the Redux version, the price has come down. The Redux is sold for $50 in most places, whereas the original is closer to $60-$70.", "We’ve added a 65W heat load to the testing for this cooler that includes some comparison to stock AMD Wraith coolers and also the ", " (NH-P1 review ", "). The NH-P1 is passive, but it's still interesting to compare to a lower performance tower. We’ll be able to tell you if it’s worth moving over from both an acoustic and a thermal perspective.", "The ", " has a few changes from the original, but not too many. They look mostly the same from the outside. There are a few cosmetic changes, but primarily this is just a cheaper version of what has already existed with a different fan: the Redux line of fans. The Noctua NH-U12S series is targeted primarily at wide compatibility, so in this review, we’ll be looking at the thermals on three different types of heat loads.", "Steve Burke", "Mike Gaglione", "keegan gallick", "jack reitman", "This review will cover everything from an R5 or i5 non-K class CPU (in terms of power consumption) up to an R7 or i7 type of CPU. We’ll even stretch up to 200W, which is more of an overclocked heat load or an Intel K-class SKU heat load, once it’s in at least tau and boosting within those first 56 seconds or so of turbo boost.", "You’ll have a great picture of how good (or not) this cooler is based on the data we’ve collected and hopefully make it clear whether it’s worth going to an $80-$90 air cooler or even a liquid cooler, as opposed to this $50 one. Additionally, we'll look at if this $50 is worth an upgrade over one of the “free” coolers that AMD has made over the years.", "The Noctua NH-U12S Redux is meant for wide compatibility with cases and motherboards. It’s relatively small and the size of the mounting system also has a small footprint to reduce risk of running into VRM components close to the socket. ", "There aren’t many changes versus the original NH-U12S or the ", ", which is the original with different mounting hardware, but there are a few. The biggest difference is a different fan, switching from the NF-F12 120mm fan to the NF-P12 Redux fan with a wider RPM range, with a slight difference in noise profile. Pricing is also different: Noctua’s Redux model brings pricing down to $50, where the cooler previously cost $70. This turns the Redux into a small tower that’s targeted at the premium-end of an otherwise low-end (or “cheap”) price class. ", "Noctua is trying to position itself still as the quality or premium brand, however it must compete with a thin single tower versus the many coolers on the market that range from $8 to $30 as more of a common price point for a competing cooler to this one. Many of the trade-offs have to do with the mounting hardware and build quality of the product in general, and not necessarily just the thermals.", "Another difference with the Redux is mechanical: the Redux has a thicker name plate on top. This seems mostly useless until you start looking at how our originals look. The thicker nameplate on the Redux is secured with four screws to the top set of fins. This adds extra strength where our original NH-U12S coolers needed it. It’ll prevent cosmetic bends and dings in the finstack. Those won’t affect the performance (at least not in any measurable way) but it doesn’t look great and that’ll help even the quality control and damage out.", "The kit includes an L-shaped Phillips #2 screwdriver, and accompanying that is a set of well-documented, clear instructions with pictures and clear language to make installation easy. Considering how annoying coolers have been in the past, we greatly appreciate and hold in high regard the clearness of language and installation guides. This is one of the easiest two-point mounting systems we’ve worked with, so Noctua gets credit for that as well.", "The driven portion on the cooler body itself is female-threaded. This made mounting slightly easier than male threads. Captive springs don’t engage until after threads have been fully engaged. This is another great attention-to-detail feature. It seems very obvious, as that’s how you should use springs in a mounting system, but if you’ve watched our videos, maybe you wouldn’t be surprised that sometimes the springs don’t really do what they’re supposed to do. It’s often overly easy to crumple them to the point where the springs do nothing, or the springs can provide too much resistance and make it difficult to securely mount the cooler to the CPU. The socket will dictate the required tension. This one makes it pretty easy and it’s designed well.", "Installation is straight-forward: on AMD, the AM4 backplate is used and four plastic, gray standoffs are installed on top of the backplate threads. This is best-done on a flat surface so that you can hold it all in place. The mounting brackets are next placed on top of the standoffs, with a screw run through each and into the backplate. Noctua smartly warns against overtorque here because it would be a potentially easy place to do it.", "With both brackets installed with the deep part away from the socket, the two spring-tensioned screws get tightened into the brackets, and that’s it.", "The Intel installation is familiar: an included backplate is first installed, using four standoff screws that pass through the holes and four plastic standoffs that sit on top of those to create appropriate spacing. The two brackets are then installed, with four cap screws to secure everything. The cooler is then installed the same way with two screws that are spring tensioned.", "This is an incredibly straightforward installation process – about as plain as you can get, and that's a good thing. Noctua hasn’t done anything overly complex: it has basically repurposed its older mounting solution and made it work here.", "Now that we’ve shown how the cooler mounts and installs, we can look at the pressure distribution across the surface of the integrated heat spreader. This doesn’t show us the flatness of the surface, but rather the quality of the hardware and its ability to evenly spread the pressure.", "For this we use specialized tools to create this pseudo-color pressure map. A huge thanks to our supporters on ", " and on the ", " for making it possible for us to afford this expensive equipment.", "On the two CPUs tested and across four passes, we observed roughly identical patterns: The Redux has good pressure distribution centrally, where the dies are located, but is lacking on contact at the outer edges. On our 3950X IHS, three of four corners have poor contact, with the left and right sides also showing limited contact. The 3800X IHS shows poor contact especially in the bottom left, except along the IHS edge, and the left side.", "This could be improved in Noctua’s mounting solution and will contribute to the ability to cool higher TDP dies; however, at lower power consumption, central contact will be sufficient for dissipation and ultimately thermal paste helps fill any gaps anyway. This is probably the weakest area so far that we’ve seen, and it’s one of the key areas that Noctua could improve.", "For the original Noctua NH-U12S, not the Redux version, we observed better overall pressure distribution across the IHS. It was more consistent. This is partly to do with unit-to-unit variance of mounting solutions, but as a reminder, consistency is an important factor in cooler design. This one is weaker on the left and right sides of the IHS, bottom oriented toward the RAM, but is overall more even than the Redux was.", "This does not mean that the original NH-U12S is a better cooler or better mount, just that in this case the pressure is more even and we need more data to extract meaning from that.", "We’ll start with noise-normalized thermals, which equalizes the playing field and controls for an important variable. This allows all coolers to run with their included fans, but configured to produce the same noise level under equal conditions. That means we’re disallowing the fan to brute force cooling performance, but we’ll look at that next. We’ll start with the 123W heat load, which would be similar to most post-Tau K-SKU Intel CPUs or AMD R7 CPUs. We’ll get to AMD stock cooler comparisons in the 65W heat load test.", "The ", " at 35dBA ran at about 61 degrees Celsius over ambient here, with the ", " at 60.2 degrees Celsius over ambient. They’re the same, in other words, and so there isn’t a huge difference thermally if any at all. This puts them ahead of the ", ", which was woefully ill-equipped when compared to the FUMA2, and that’s because of the Ninja’s obsession with silence to the point of damaging its performance. The FUMA 2 was good though, and we were happy to recommend it in its price class.", "The NH-U12 coolers are more efficient than the ", ", which was poorly received in our review, and also encroach on the NH-U14S, but allow it an advantage, partly thanks to its 140mm fan, which is able to move more air while still running at the same noise level for noise normalized thermals. As a reminder, the 123W heat load critically does not produce enough heat to space-out the high-end coolers meaningfully. Their value is perceived as worse until paired with a more appropriately power-hungry CPU. It’s definitely diminishing returns for something like an ", " when you’re talking about a 123W heat load.", "This chart shows the same test, except with the fans at 100% speed. The NH-U12S ends up at 37.1dBA at a noise floor of 26dBA measured at 20 inches distance fixed. The NH-U12S Redux was at about 40.2dBA, so it’s louder when at 100% speed, but it also runs about 200RPM higher, so this difference does make sense. As a reminder, fans are typically (as industry standard) about plus or minus 10% on the RPM one to the next, so it is possible with that 10% difference on the two that you could end up with a Redux and a non-Redux that are actually about the same RPM. ", "The Redux holds at 58 degrees to the non-Redux’s 59.5 degrees. Given the noise difference, these two remain similar overall, with a slight advantage to the Redux. They are both capable of maintaining a stable temperature on a similarly powered CPU, assuming a case that isn’t overly restrictive. That means this cooler would be suitable for an AMD R7-style CPU with a 105W TDP, an Intel i5 or i7 K-SKU, or similar; however, note that the cooler will be unable to keep up with thermally-dependent boosting like TVB, which requires a temperature below 70 degrees Celsius as a hard threshold, and will also struggle with Intel’s 56-second Tau boosting window.", "Also as a reminder, the 105W TDP number does not mean the power consumption, but it maps out to be about what this cooler can handle.", "The noise-normalized 200W heat load was predictably too much for this cooler. You should not be buying a 120mm small tower cooler like the NH-U12S if you want it to operate quietly and at a capacity that allows a CPU with this power draw running. A sufficient fan can overcome some of the surface area limitations of a fin stack of this size, but the noise will obviously ramp aggressively in step to keep up.", "This one shows the 200W 3950X heat load while at 100% speed. With the fans at full blast, the NH-U12S Redux’s result at 40dBA was 62 degrees over ambient. It technically passed the test - it didn’t die or crash. It’s just below the FUMA 2, marking the NH-U12S Redux as reasonably efficient given the workload and the price, and it’s cooler than the Ninja 5. Larger air coolers, like the ", ", produce upwards of an 8-degree difference, which is massive for an air cooler. That’s enough to make a significant difference in how you use the system. ", "The NH-U12S Redux, although it did not fail this testing, was pretty close to a potential failure. Within a hot case, this would be a no-go, and we don’t recommend it for the 200W heat loads anyway, but it is technically able to pass, just not by much. As the saying goes, “Ds get degrees” and in this case it’s a few degrees from failure. Remember that ambient temperature in our test is around 21 degrees, and that’s why once you start adding in hotter cases or a hotter environment without AC, we’d recommend just buying something bigger than this.", "Time for the 65W heat load. This is getting down to R5 class CPUs, where these coolers really make sense. We didn’t run both NH-U12 coolers for the 65W heat load test because we had already invested significant time in this piece and determined they’re roughly the same. The more important comparison is to other coolers. As a reminder, this data set is new for us, so it is relatively limited. We’re adding to it over time and it’ll take a few months to build larger charts. The test is representative of R5or non-K i5 and i3 CPUs.", "Noise-normalized at 35dBA, the Noctua NH-U12S Redux managed the best thermals of the 4 total units we’ve tested in this configuration so far. It's 39 degrees over ambient and that’s actually a  great result. Compared to the Wraith coolers we’ve tested at the same noise level the Redux improved by at least 9 degrees versus the Prism or about 13 degrees versus the Spire we tested. The Noctua Passive cooler is also able to handle this heat load, although it runs predictably much warmer, but makes 0 noise, so there’s that benefit. The Redux would be a good upgrade for those on stock coolers, which aren’t particularly good. ", "Additionally, the NH-U12S Redux could be run even quieter than these while still running stable temperatures. For example, if you were OK with 48 degrees on your Prism before, you’d presumably also be OK with 48 degrees on your Redux, except on your Redux would allow it to run with a much lower fan speed and therefore noise level, providing an acoustic benefit.", "At 100% fan speed, the NH-U12S Redux runs only marginally cooler, now at 38 degrees over ambient versus its 35dBA result. This is partly because the heat load is so low that we’re at diminishing returns for many devices. The Wraith coolers ascend the charts, now at 43 and 51 degrees over ambient, but they still can’t catch the Redux. That’s in spite of them running at 47 dBA and 40 dBA, while the Redux is at just 40 dBA. The Redux offers better cooling even at significantly quieter noise levels, and would be a good upgrade path.", "The ", "  is definitely a far better deal than it used to be when it was $60-$70 or so for the original NH-U12S. It’s still relatively “expensive”, although that may not be the right word because there are justifiable reasons for the price on this cooler, mostly relating to build quality, mount quality, ease of installation, and support. For example, recently Noctua stated that if you have one of its existing coolers, they'll provide LGA 1700 mounting hardware for that cooler if you contact them and provide proof of purchase. This is very valuable: if you spend the $50, you can potentially reuse the same cooler for multiple sockets if Noctua continues to ship the new mounting hardware for new sockets that were unsupported by the original hardware.", "It's difficult for us to review what Noctua is going to do in the future and how well they’re going to support that policy, but if the past is any indicator (and it often is) it seems like Noctua was trying to do the right thing. Noctua will also sell a LGA 1700 mounting kit for $8 if you cannot provide proof of purchase for your Noctua cooler. Noctua stated that it is doing this in part to cut down on manufacturing waste, which is a fantastic outlook on manufacturing something like a CPU cooler because it doesn't expire. Copper, nickel, and aluminum don't spoil, so as long as they can be adapted forward, you can keep using the product. Sort of like a good case or a good power supply (so long as the standards don’t change).", "The reason we're mentioning these things is because, based on Noctua’s recent statements of free or cheap mounting hardware upgrades for existing products, some of the extra cost becomes justified. You spend $50 once and don't have to spend it again for a new cooler. If you buy a $25 tower cooler you might have to buy it two or three times as the sockets change, depending on how well it's supported.", "That said, if all you want is a cheap tower cooler, this one is on the higher side. We think it is justifiable at $50, but not $70. That’s far too high for what this is. You can get a comparable (thermally) tower cooler at $25-$30, and we’re going to look at those in the future; we have ", " in those price categories coming up. ", "If all you care about is cheap performance, then keep an eye out for those, because the Redux probably isn’t it. It’s not necessarily cheap, but it is performance. Acoustically, the Redux does alright. When you noise-normalize all of the coolers at the same level for a 65W heat load against the AMD stock coolers, the Redux is a massive upgrade as would be any tower cooler of this nature. Noctua is not magic. They do good things in general, but they are certainly not breaking the laws of thermodynamics or physics. ", "That being said, the Redux is far better than the AMD stock coolers. It’s a good upgrade path if you want to get off of one of those, and the biggest thing to remember is that if you were to temperature normalize them (i.e. if your current CPU is running at 50 degrees delta t over ambient, and you’re okay with it at that temperature, then you can buy a Redux and bring the fan speed down, keep the CPU at the same temperature, and cut the perceived noise level). ", "Our point of criticism for the Redux would be the pressure. We noticed that the ", " in our original sample, despite the bend in the orientation of the tower, still had decent pressure application, and better than the Redux had. We think that comes down to more of a QC type of thing or tolerances in manufacturing of the mounting kit. Additionally, we think the QC in general appears to need work - our NH-U12S was bent, and that is just not acceptable. This would indicate to us that there needs to be some better QC either in manufacturing or somewhere else in the line – maybe packaging, because that bend should have been caught. "]},
{"title": " Top Amazon Cooler vs. AMD Stock Cooler: $30 Vetroo V5 Air Cooler Review", "paragraph": ["Top Amazon Cooler vs. AMD Stock Cooler: $30 Vetroo V5 Air Cooler Review", "Last Updated: ", "The Highlights", "We’re finally applying our in-depth CPU cooler testing methodology to lower end coolers. You may have seen recently when we did the ", " and we looked at some of the AMD stock coolers, and now we’re looking at a more traditional form of CPU cooler. The ", " is a single tower with a 120mm fan. It’s about $30, so it’s in that classic tier of CPU cooler category along with the ", ", which we’ll look at soon as well.", "This one is called the ", ". It’s gotten a lot of coverage in the last eight months or so. We’ve had this since February actually, and now it’s finally time to go through the review, look at the thermals, pressure map, and everything else and talk about if this $30 solution is worth upgrading to from something like a stock cooler.", "Steve Burke", "Mike Gaglione", "keegan gallick", "jack reitman", "We’ll start with the key points of comparison on the Vetroo V5. It’s most likely up for purchasing consideration for you if you already have something like an AMD or Intel stock cooler. The alternatives you’d consider might be the Hyper 212, maybe maxing out with something around the ", " (", ") or the Scythe FUMA 2. These coolers don’t quite crawl into the $100 territory with something like the ", ".", "We want to immediately set expectations for the Vetroo: this will not outperform a 240mm AIO liquid cooler. That simply is not going to happen. The only reason that would happen is if the liquid cooler is exceptionally bad (none that we’ve tested recently), is improperly mounted, or is improperly functioning in some other way. Do not expect a 120mm tower (which is just lower surface area before we even look at the liquid) to outperform a liquid cooler.", "Vetroo claims a 150W heat load support for the V5. How companies measure watts for cooling potential is weird -- they all do “screwy” things to make their number higher than the others, so the numbers between companies are not comparable. However, we are going to be testing on everything from an R5 class CPU up to an R9 class CPU, so that will be about 68W, and then about 123W, and then about 200W with an overclocked CPU. That will give a realistic look at where you can expect the Vetroo to top out. ", "You may be wondering how or why cooler and CPU companies can even do “screwy” things with watts since it’s just a straightforward unit of measurement, and one could assume that the CPU is outputting the heat in watts that it is consuming. The way it actually works is Intel and AMD have their own formulas for computing TDP and they are not equivalent. AMD’s formula was reverse engineered to produce a result which was roughly equivalent to Intel’s for marketing reasons (mostly to do with OEMs and SIs). That was back when AMD was trying to get back into the market with Ryzen, ", ". Power never appears in that formula.", "Typically, cooler companies will use a dummy heater. They’ll push a certain amount of power into the dummy heater and then whatever the cooler is able to keep up with within control is the rating that they will apply to the cooler. So, if their target is 70 degrees Celsius as an analog to a certain type of CPU, and the cooler is at 70 degrees Celsius at 150W, they may say that the cooler is rated for 150W. But we’ll look at this realistically in our testing.", "There are two versions of the Vetroo -- white and black, which were about $30 at the time of filming. The cooler has an ARGB 120mm fan that has two connectors on it -- a four pin PWM for power and a standard ARGB header.", "On its marketing page, the Vetroo claims “direct touching copper base is adopted to fit the CPU.” We think they mean adapted. However, the base is not copper. The heatpipes are copper with five of them (where the “V5” in the name comes), at 6mm in diameter each. The base plate itself is aluminum, which sits between the copper heatpipes.", "The aluminum is clearly the weak point in contact, but as we’ll see in testing there’s enough copper to cope with lower heat loads. There is a small aluminum finstack on top of the coldplate. This is somewhat standard – we see this on a lot of the small tower coolers, but it’s tough to know how much this really does. You would need to test it in a pure lab or R&D environment because in real world use it is difficult to get that level of precision down to these small fins. But, it’s some extra surface area so it’s not going to hurt, it just might not help much.", "Thus far, this is all pretty standard for a single tower cooler. The coldplate is about 38x44mm. The tower itself is 49mm deep, front-to-back, and about 125mm wide (depending on how you count the embellishments at the top end). The finstack is 113mm in total height, from first fin to last fin, with 85mm of that being full-width while the rest is cut short for RAM clearance, apparently. This RAM clearance is utterly pointless, though, because RAM isn’t there. It’s on the other side -- the fan-side of the cooler -- and so this makes for some bizarrely short-sighted product development or marketing. We aren’t sure which department is at fault here.", "Time to get into the installation procedure. There’s some really weird stuff in the installation manual -- just general inconsistencies with the product that makes us concerned more about the attention to detail than the performance.", "Vetroo used five plastic bags for the hardware, so we’d like to see a solution with less needless waste, but all hardware was accounted for and included. This is better than we’ve seen in some other coolers.", "Vetroo’s documentation includes images which are just completely wrong, though. The socket orientation is backwards, and Vetroo for some reason thinks that AM4 is situated long-ways. The only board we know of where this is true is the X570 Dark, but even then the RAM moves to the other side and so RAM “clearance” is unnecessary. Basically, the documentation presents an orientation for AM4 which is physically impossible in the overwhelming majority of motherboards.", "Moving on: Two brackets get mounted to the bottom of the coldplate support, each containing two spring-tensioned screws for four total. From here, on AMD, the stock AMD backplate is used and four screws are tightened into the backplate. This is straightforward, standard, and very easily done.", "On Intel, a different set of brackets is used and a somewhat standard plastic backplate is installed under the motherboard. The cooler should be installed with the fan oriented toward the RAM, once again, and the four screws socket into the backplate once again. This is a scenario where a more robust mounting mechanism, more like Noctua’s, would be better. Typically, a second set of brackets and standoffs are used to more evenly distribute load across the socket and reduce pinpointed load on the motherboard or PCB itself, particularly where the screws thread into the backplate. You’ll see more of this with the pressure map. With this setup, an uncomfortable amount of force is applied to a very specific spot on the board, and not necessarily centrally where you want it.", "The pressure map helps to illustrate how well the mounting hardware works. It’s not a measure of flatness, but a measure of how much pressure is applied across the IHS. The CPU used is irrelevant beyond its IHS as it is not on during this test.", "The 3950X that we use in this test showed low mounting pressure centrally, with pressure only visible towards the edges of the IHS. The cooler is still making contact, but the pressure is low enough that it’s leaving performance on the table. You can see the outline of the heatpipes beginning to appear, but it’s more obvious in our 3800X map.", "The 3800X clearly shows each heatpipe making contact. That’s much better pressure but as indicated by the blue coloring, it’s still at the lowest end of the sensitivity for each heatpipe. At least the heatpipes are where we see more pressure -- that’s the important part, where they are the most conductive and effective -- but it’s still relatively low overall and uneven.", "Surface flatness is as expected: the Vetroo V5 fits the profile of most other air coolers we’ve tested thus far. What we’re looking for is low variance point-to-point at a micron level, and what we’re getting is mostly that. It’s not as consistent as the Assassin III, but is overall fine. ", "This tells us that the plate is pretty flat, but the poor pressure we saw was from the mounting hardware, not the flatness of the cold plate. That means that lapping the cold plate won’t really help the pressure map much, and it might even make it worse. The pressure itself and that map is derived from the mounting hardware used. ", "The plate is fine here (which is more than we might actually expect for a $30 cooler), and mounting hardware could be improved by adding a second set of brackets with four more standoffs that would even out the pressure.", "We’ll start with our noise-normalized testing on a 200W load, which is ridiculous for this cooler but there is a reason for it. We’ll later revisit this with a lighter 125W and 68W workload that’s more reasonable for a small tower cooler. We had some viewers asking us to test the Vetroo coolers and asking if they are better than the 240mm liquid coolers on the market, so wanted to start here. To be clear, before we show this chart, this is not where you should expect the Vetroo to do well - it will not do well. That’s okay. We are checking expectations.", "So here’s the chart - it failed.", "The ", " ends up with an expected “DNF” for this -- or “Did Not Finish.” That’s not an embarrassing defeat, seeing as it’s a single-tower cooler and relatively low powered, but it is not magic that can outdo a larger liquid cooler. The CPU ended up throttling so hard that we abandoned the test early so as not to produce unnecessary thermal strain on our test bench hardware. The Vetroo is not only worse than everything else on the chart, it’s also completely incapable of cooling this heat load. For reference, a good 240mm liquid cooler like the ", " runs at about 56 degrees over ambient. A weaker one -- like the ", " -- is still far outperforming the Vetroo V5 at 58 degrees Celsius. That really shouldn’t be surprising: as long as there’s a good mount with the liquid cooler, there is nothing logical to suggest that a small tower with one fan would do better than a comparatively large radiator with two fans. ", "A more reasonable comparison would be air coolers, but even the weaker ", " at 30dBA was still running sustainably, although borderline, at 65 degrees over ambient.", "As for the Fractal Celsius, we noticed that it’s easy to get a poor mount on the Celsius S24, which is a problem with Fractal. A poor mount would result in thermals potentially worse than everything else. As long as you pay very careful attention to mounting the Celsius, and do a quick validation test afterwards, it’ll be fine -- but you may need to do a validation run after installing it to make sure the temperatures look reasonable.", "The Vetroo was able to complete the 200W test at 100% fan speed and under this initial 200W load. At 100% fan speed, the coolers are allowed to run at an uncontrolled noise level, so we’re no longer in a pure like-for-like scenario -- but it’s still a common use case for end users. The noise is indicated next to the fan count.", "In this test, the Vetroo V5 gets the illustrious rank of last place. Not many can hold this rank; some say that only one can be in last place. The Vetroo, even at 43 dBA, manages to run 3 degrees warmer than the Ninja 5 at 30dBA. That’s very inefficient for the Vetroo, but it's much smaller than the Ninja. To the human ear, that’d be perceived as multiple times louder than the Ninja 5 (we’re talking perceptive noise, not acoustic power), and yet it’s thermally inferior. The 240mm Fractal cooler, the weakest of liquid coolers we’ve put on this chart, holds a 16-degree advantage over the Vetroo V5. The ", " 240 is 18 degrees ahead at 46.6dBA (and is thus more efficient than the Celsius Prisma).", "We’ll look at smaller air coolers in comparison when we get to the 123W and 68W testing.", "Let’s move on to the 65W heat load on an AMD R5 CPU; this would be similar for hierarchy on something like a 5600X or an i5 CPU.", "Noise-normalized, the Vetroo now is more within its weight class. It does well here, actually, competing head-to-head with the much more expensive ", ". The Redux technically holds a lead of a couple degrees, but at $50, it’s not the performance that you’re paying for. Any argument favoring the Noctua cooler here would be primarily supported by Noctua’s reputation for long-standing support such as free upgrade brackets for new sockets and general RMA process, not the thermal performance. You’re paying for a known brand that has a reputation of supporting its products. ", "But if you just want cheap performance, the Vetroo makes far more sense than the NH-U12S; not everyone can justify $50 on the cooler alone, and even at that $50 range, the Scythe FUMA2 should probably be considered instead. That’s on the other charts, though we haven’t retested it in this one yet.", "The Vetroo improves over the stock Wraith Prism by a significant 7-8 degrees Celsius at the same noise level, and over the Spire by about 11 degrees. Not bad for $30.", "We also collected VRM thermals. As a reminder, in all of these test conditions, the VRM has no issue at all. We’re using a high-end motherboard that’s rated for more than the 65W CPU load could challenge even if we removed the motherboard’s heatsink; however, this still gives an idea for scale and the impact of particular designs on VRM thermals. This would be useful to know for lower-end boards or higher heat loads.", "The Vetroo V5 wasn’t much different than the NH-U12S or stock AMD coolers. It’s fine here. Nothing is horribly out of place, which is about all we’re after in a $30 tower cooler.", "Here’s the 100% fan speed chart, where the Vetroo ends up at 43dBA. That’s louder than the Noctua NH-U12S Redux, which manages to maintain a 1.4-degree advantage, and so Noctua’s cooler ends up more efficient -- but only barely, and the cost is still hard to justify for some price classes of build.", "The Scythe FUMA 2 blows it out of the water, though: The FUMA2 is running at a staggeringly low (comparatively) 34.4dBA, approaching a 10x perceived noise difference to the human ear versus the Vetroo (and again, that’s not acoustic power, it’s perceived to the human ear noise difference) while also being a few degrees cooler. It’s more efficient than the Noctua cooler, too.", "Even still, just for thermal performance, Vetroo is holding its own very well and is a strong competitor in this price class. It falls off as heat load climbs, but for something like an R5 or i5 CPU, the Vetroo is suitable and cheap. We wouldn’t begrudge you buying it.", "The Vetroo scales worse as heat ramps.", "The 123W heat load is comparable to a 5800X, 3800X, 3900X stock, or any Intel K-SKU CPU recently, like the 10900K or 11700K. This is a common heat load for stock CPU use. With those Intel CPUs it would be after tau expiry, not during tau boosting.", "The Vetroo V5 falls to the bottom of this chart, as does the NH-U12S. The Vetroo is bordering on unusable in our particular test configuration, although it’d be acceptable for auto use with some similar CPUs (provided the case has sufficient airflow). You just won’t get the full PB2 or TVB range out of those higher end CPUs. The Scythe 2 demonstrates its efficiency with the 55-degree result, and that’s while being slightly quieter than the rest.", "For a cooler that claims 150W cooling capacity, this one is cutting it awfully close to acceptable. We don’t agree with Vetroo’s claim, and we really wouldn’t recommend using this on 150W heat loads in general.", "100% fan speed is more survivable. The cooler can handle it, it’s just that poorly ventilated cases would struggle and there’s not much overclocking headroom, if any at all. The cooler is still at the bottom of the chart; however, it passes the test and it’s cheap, so while it’s not our first choice, we can completely understand and feel comfortable with this cooler for certain heat loads in a cheaper price class.", "For $30, it’s certainly better than the same priced Aigo Shadow Max we reviewed recently. It doesn’t look as unique, so the Shadow Max retains its “buy it if you want this weird-looking thing in your computer that can kind of run certain heat loads” award, but the ", " is more standard. It runs cooler in all of our tested scenarios, it’s quieter at a given temperature, and makes more sense to buy at the same price point if you’re only after performance for $30. The Shadow Max makes sense if you want something for maybe a kiosk PC, something you’re going to show off that is not going to be at a very high heat load.", "Versus the ", ", which is clearly the incumbent, Noctua has an excellent reputation and is regarded as an engineering-first company. This is a hard company to go up against and fight in CPU coolers because they’ve built their reputation on a lot of trust and a lot of engineering. ", " is doing is competing fiercely in thermals and it does well thermally versus Noctua. It is roughly in the same position for heat loads that are appropriate for both coolers. The Vetroo V5 is not built as well, and some of that comes down to material choices like copper, more of which is used in the Noctua cooler, but ultimately they’re cooling about the same in our testing. ", "However, there are downsides to the Vetroo V5. Noctua has benefits outside of these charts, like their recently re-proven history of providing free upgrade kits for new sockets. This means that their coolers will likely continue to be supported going forward as sockets and mounting mechanisms change, which means less waste both financially for you and materially for the planet. That’s a good thing. We don’t know whether Vetroo will do this. It doesn’t cost much for a company to offer upgrade kits, even if Vetroo sells them for a few bucks (like Noctua does if you can’t provide proof of purchase) that’s good enough. But the question is whether they’ll bother at all or just ship a new cooler altogether once the sockets completely change.", "The Vetroo V5 is new to us and we haven’t worked with the company before. We can’t really speak to how Vetroo plans to maintain its product. What we’ve seen so far is some criticism in Amazon user reviews of Vetroo’s customer service, and we saw concerns of DOA fans. Ours was not DOA, but that is a sample size of one - we can’t speak to everyone’s experience. There’s always going to be a DOA product somewhere in the user reviews but it’s a question of how well they replace it, and at this point we can’t speak to that, so something to be aware of with a smaller company. If you buy through Amazon you have some level of protection for a return.", "It comes down to what it always does: at $30 you are paying a lot less. You might introduce some more hassle for yourself if there is a problem and it might take a little more effort to get it resolved, for example returning to Amazon versus emailing a manufacturer asking for a quick replacement, but it’s only $30. We won’t begrudge you if you would want to buy this cooler instead and save $20 for a budget PC build where $20 will be more useful if used towards something like a CPU or GPU upgrade, or even a case upgrade. $20 at the low end is the difference between something that’s going to get more cool air than the NH-U12s would offer.", "The ", " would be our recommended upgrade at $50, if you wanted to get something with higher performance and a better noise-to-thermal profile.", "One thing is for certain: as long as liquid coolers are mounted such that they contact the CPU IHS, the Vetroo V5 will not outperform them. It’s pretty good at $30, but it isn’t magic. The Fractal Celsius has a challenge with mounting where a poor mount is easier than it should be, and the result of that would be that your thermals look worse than the Vetroo cooler. ", "The Vetroo V5 seems to be following our newest trend in reviews: it falls into the “we don’t hate it” camp of reviews. In fact, it’s actually graduated one tier up and is instead in the “it’s fine” camp. If you want this because it's $30 and it performs reasonably well, then it’s fine. We don’t think it’s a phenomenal cooler – it’s not an engineering marvel. It’s very hard to engineer something unique in the cooler world anyway. If you have a strict budget then this makes sense to us and we would recommend it over paying an extra $20 for a FUMA 2 (thermally superior) or NH-U12s (better reputation) for those on a strict budget.", "Don’t put it under a 200W load and you’ll be OK. It seems to be fine on roughly the R7, maybe an i7 non-K or non-tau window. Something like an R5 would be no problem, especially if you’re at a 65W to 100W TDP, keeping in mind that number doesn’t necessarily mean power in the same way that Vetroo is talking about it. From our testing, something like an R5 or R7 shouldn’t be a problem, even if the R7 is stretching it (so don’t overclock it). "]},
{"title": " Best Cheap CPU Coolers Benchmarked: Deepcool AK400 Review", "paragraph": ["Best Cheap CPU Coolers Benchmarked: Deepcool AK400 Review", "Last Updated: ", "The Highlights", "The air cooler market has actually gotten really exciting recently, and DeepCool and Thermalright have been pushing for a lot of that. We’ve reviewed coolers from both of them in the recent past. DeepCool we had some issues with a few years ago ", " open to find that DeepCool had falsely advertised axial grooved heatpipes on the Assassin III when it actually used sintered heatpipes. ", "However, DeepCool has been on a roll recently with some better products. We reviewed the ", " cooler and it was fairly competitive. The ", " set off all of this for budget cooler comparisons because it got a ton of momentum at its very competitive price point.  It was commonly $30-$35, with the AK620 in the $50-$60 range.", "So now we’re looking at the ", ", DeepCool’s new single-tower,120mm cooler.  In this benchmark and review suite we’re going to be looking at thermals, pressure testing, and flatness of the coldplate for the cooler’s performance versus other competing CPU air coolers, alongside other scientific metrics we've taken.", "During our original testing and filming ", ", we learned that the ", " had vanished from Amazon, which was one of our main comparisons to the AK400.  It turns out that Thermalright had coopted its own listing to redirect people to the ", ".", "Steve Burke", "Mike Gaglione", "Michael Kerns", "Andrew Coleman", "jack reitman", "The AK400 is a $35 CPU cooler, which seems to be about the standard price these days for an air cooler.  There are some in the $20 range, but this is about where the price point is for brands that have some kind of name recognition and maybe a good warranty policy. And of course there is more to a CPU cooler than just performance. We also consider noise (the type of noise, the volume, cooling efficiency at a given noise level), warranty, and ongoing support. ", "For this comparison, ", " comes in two types - the normal model and white (there is no other difference between them, and supports all current socket types (LGA 1200, 115X, and AM4). ", "One of the things we want to pay attention to as we go through the charts is the difference between something like the AK400 and something like the ", ", which previously ", ".  The differences between them will become much more apparent as the heat load increases from 68W up to 123W, as that's when you start to see these pull apart a little more.  At 68W, they look much more similar performance wise.  ", "We also have the ", ", DeepCool’s own AK620, and the Scythe Fuma 2, which is probably the most relevant cooler to really pay attention to.  It’s more expensive than the AK400, but this is the best acoustic to thermal ratio we’ve looked at at really any time recently, other than larger liquid coolers that are large, which is worth considering if you can stretch the budget a little.", "But at around $35, the main comparisons are going to be between the AK400, AK620, 34 Esports Duo, and the Assassin Spirit.", "The AK400 has a separable 120mm fan mounted by standard wire clips, which allows you to attach a second fan to the other side of the cooler with the extra clips included in the mounting hardware.  The fin stack itself is made of standard aluminum, but the heatpipes are embedded in the coldplate such that they make direct contact with the IHS rather than having the coldplate wrap around and encompass the heatpipes.  ", "The naming of the AK400 is an indicator of how many heatpipes it has (4).  If you look at the AK620, it has six heat pipes, so it appears that the third digit in the model number indicates the number of heatpipes in the cooler.  ", "DeepCool is utilizing an interesting checkered pattern on the fin stacks that we’re pretty sure in marketing they would argue has some sort of thermal or acoustic benefit. Realistically, there is no way to actually prove that - you could maybe simulate it in software, but for all intents and purposes this is just cosmetic. Additionally, the top of the cooler has a plastic cap that can be removed which will give you an extra two to three millimeters clearance. ", "The only reason it is not more (because the cap is clearly thicker than 3mm) is because the heatpipes stick up out of the fin stack and get encapsulated by the plastic cap. ", " on the ", " with this cap on and off for both of the towers and it did not have a meaningful impact on thermals, even though it is “capping” the top of the heatpipe where you have some natural heat rise coming off of it, so the aesthetics are not taking away from the thermal performance, which is good.", "If you look at the fan at a glancing angle, you’ll see that it’s concave towards the hub with the blade design.  This is another one of the small fan design features where we’ll see how it does in thermal testing, but it’s just a small deviation from how some of the other vendors have designed their fans.  ", "The corners of the fan have small blocks of rubber wrapped around the plastic border - you’ll see these on most fans (Thermalright, Scythe, and Noctua to name a few). For example, the standard Noctua approach is to do these rubber corners that you can replace for different color variants. The point of the rubber corner covers is that it keeps the plastic housing of the fan from contacting the actual heatsink while the rubber does contact the heatsink. This allows the rubber to absorb vibration and reduce the noise that would be generated by the operating fan rattling against the heatsink.  ", "As for the fan type, this is a new fan from DeepCool - the FC120P. It is a 0.13 amp fan at a standard 12 volts and has a max RPM of 1850. The fans on the AK620 are FK120, rated at 0.12 amps at 12 volts with an RPM difference as compared to the FC120P.", "The ", " itself is approximately 120mm wide (as you would expect because it has a 120mm fan), and 155mm tall, which may lead to some fitment issues on certain mid-tower cases that cap out at 150mm for CPU cooler height. You can take off the plastic cap for a few millimeters of extra clearance, but if you have to do that you’re throwing away part of the actual value of the cooler. ", "For width with respect to clearance, you're not going to be in the RAM socket area of basically any motherboard - you won’t have to raise or lower the fan to clear anything, except maybe certain mini-ITX configurations. If you look at the actual depth of the mounting screws on the base versus the fan, the fan itself does not go that far past the screw.", "The packaging on the AK400 is very simple - it ships in a standard white box with a picture of the cooler on the side.  Internally, they’ve packed the cooler in a foam block (top and bottom of the cooler) with a plastic protector sheet for the coldplate, which is again direct contact heatpipes. DeepCool hasn’t gone overkill with a ton of plastic and waste, but they also haven’t skimped on it too much.", "The included mounting hardware comes with spare fan clips if you want to add a second fan (this is not super worthwhile based on the thermal results, but it is available). The hardware is packaged in reusable plastic bags which we like to see as it is less waste overall instead of a bunch of single use plastic, provided of course that you have a reuse purpose for those plastic bags. The cooler also comes with a physical manual as well as the online option.", "Let’s quickly look at installation.", "AMD installation uses the stock AM4 backplate, after which the 4 included standoffs are placed over the backplate’s own standoffs. Next, the Deepcool bracket gets screwed into the backplate through the standoffs. This utilizes the central 4 of 8 total holes in the bracket, which is designed universally for use on AMD and Intel. For AMD, the more center-of-mass screws shift some of the force further inward, which reflects in pressure testing momentarily and also in the “wiggle factor” (which is the scientific metric) for the cooler moving around.", "At this point, two cap screws in a mounting plate below the tower get threaded onto screws in the universal bracket.", "Intel installation is almost the same, except it uses an included Intel backplate and the retaining screws move to the outer holes.", "The system is easy enough and we don’t have too many complaints from an ease of installation perspective, but we did find that it’s more difficult to restrict the cooler’s side to side movement when fully mounted than on some competing product designs. This can be compensated for, but it's just something you need to be aware of. Deepcool’s mounting hardware and retention kit are among the poorest aspects of an otherwise competitive product in the AK400, and we can show why in our first test.", "First up on our tests is the coldplate pressure scan. This test uses chemically reactive materials and a special NIST-traceable scanner to measure the distribution of pressure across the CPU’s IHS. This test evaluates the design of the coldplate and mounting system and how effectively they work together to hold the coldplate to the IHS. ", "This test was made possible through all of our supporters on ", " and those who buy merch like ", ", ", ", ", ", and other items from our ", ". Thanks to all of you for making what we do possible. ", "The", "AK400 mounted to our 3800X shows weak pressure centrally overall and clear outlines for the heatpipes. Contact around the outer edge is good, but most of the heat generation will be dead center. Thermal paste will fill this gap, and low pressure doesn’t necessarily mean no contact, but there is performance left on the table here.", "The 3950X mount shows mostly the same: It’s lacking pressure centrally and along the edge nearest the I/O, but we’ll need thermal tests for more.", "Our surface flatness testing is next, using even more specialized testing equipment in our test lab. This tests the actual consistency of the coldplate surface as it mates with the IHS. This bonds well with the pressure testing to form a full picture of the contact quality.", "The AK400 has poorly distributed pressure, as we saw before, which is a result of its somewhat wobbly mounting hardware. The flatness is good, though: It’s about the same as everything else here and doesn’t encounter the massive outliers we saw on the ", " or ", ". This helps to make-up for the lacking central pressure on the AK400, and flatness is especially important when heatpipes are directly exposed.  You need those heatpipes to make good contact with the IHS, otherwise you just don’t have good cooling potential. ", "The pressure map and the flatness testing/chart are what make our cooler reviews some of the best on the internet because you get the full picture of what really constitutes the thermal performance of a given cooler.", "Starting off our performance tests, we’re taking a look at our 68-watt overclocked 3600 with each cooler set to a normalized noise level of 35dBA. We explained this in our in-depth testing methodology piece previously: This test is designed to test the efficiency of each cooler and provide an even playing field by using a consistent noise level, disallowing brute force. We will be testing max cooling performance next. This heatload is representative of R5, i3, and i5 CPUs. As a reminder, each cooler uses its included fans for all our tests.", "Here’s the chart. At 35dBA, ", " runs the CPU at 39 degrees Celsius over ambient. This places it within error of the ", ", the ", ", and the ", " that we reviewed fairly highly for its price. For context, the NH-U12S Redux and Freezer 34 are both about $15 more than the AK400 at the time of filming. ", "Following closely behind, the ", " is 2 degrees warmer than the AK400 in this test while being the same price, but that gap will widen as we increase the heat load. Overall, the AK400 performs within the margin of error of the top performing coolers in our dataset. Ignoring all other factors, like dimensions, ease-of-installation, and warranty, each of these provides about the same result.", "It is worth noting that the AK400’s fan is already at 80%, so there’s little room for it to ramp up in the upcoming tests.", "The next test is the same low heatload, but with each cooler’s fans set to 100%. This test enables coolers with more powerful – or simply more – fans to pull ahead of other coolers, although they often do so at the cost of noise. It’s no longer fully controlled and instead is fully unleashed.", "At 100% fan speed, the AK400 comes in at 38 degrees Celsius over ambient at 39dBA when measured with our standardized practices. Once again, this places it within margin of error of the NH-U12S Redux and the Assassin Spirit 120, each of which is within range of inaudible differences. The Freezer 34 is technically ahead here, but it’s also at 42dBA -- so that makes sense. 3dBA is about when people start to notice the volume increase.", "Compared to the same-priced Vetroo V5, the AK400 is 2 degrees cooler and 4dBA quieter -- a clear winner, showing some inefficiencies of the V5. All of this places the AK400 among the best coolers we’ve tested for both performance and acoustics with a 68-watt heatload. The Fuma 2 remains the overall victor here, and by an impressive margin -- you just pay for it.", "Our next benchmark is a 123-watt heatload, representative of something like an AMD R7, Intel i5, and some post-Tau Intel i7 or AMD R9 CPUs. We’ll start this one noise-normalized, but we have 100% numbers next -- including the AK400 with two fans.", "Here’s the chart. With a 123-watt heatload and at 35dBA, the AK400 runs 59 degrees Celsius over ambient. With this heatload, it’s still within the margin of error of the Noctua NH-U12S Redux and the Thermalright Assassin Spirit 120; however, with a higher heatload, the Freezer 34 Duo is able to pull ahead and is now over 2 degrees cooler than the AK400. That distance is widening, allowing the Arctic option an advantage.", "The gap between the Vetroo V5 and the AK400 has also grown: the AK400 is now 4 degrees cooler in this test than the V5 -- that’s far better. 4 degrees makes a lot of difference when you’re running warm like this, especially in a case. 123 watts is slightly more than we’d typically recommend for a mid-budget cooler like the AK400, but it’s serviceable and even leaves a bit of room for overclocking or lowering the fan speed.", "Now, each cooler’s fans are set to 100%. ", "In this benchmark, the DeepCool AK400 runs 58 degrees Celsius over ambient -- it’s barely moved as we were near max already, meaning the AK400 has more limited headroom at the top-end for performance to compensate for higher heat. For some context, 20 to 22 degrees Celsius is room temperature, so it’d be about 80 degrees when factoring in ambient temperature – warm, but not immediately problematic. With two fans, the AK400 ran at 55.5 degrees - so about 2 degrees of improvement but also a louder noise level.", "In comparison to other coolers, this puts the AK400 within error of the NH-U12S Redux and the Assassin Spirit 120. Once again, the gap between the Freezer 34 Duo and the AK400 has grown, with the 34 Duo now almost 4 degrees cooler. Considering the Noctua NH-U12S is $15 more than the AK400, and the Thermalright Assassin Spirit 120 is $6 less than the AK400, this places it in a good position for both thermal and acoustic performance compared to similarly priced coolers.", "Wrapping this up, just the ", " standalone is fine at the least and we’re OK with saying that this cooler makes sense at its price point. Its performance is not that impressive to us, it's just kind of standard. This isn't necessarily bad - it is a much better result than us saying the cooler is terrible and that you shouldn't buy it, which we've said about a lot of other coolers. In fact, this is probably most of what we've said for the last 14 years. So it's at least in the “fine” camp, which as it turns out is an exclusive group of products.", "The other coolers to consider here are the ", " and the ", ". Between these, what you end up with is the Freezer 34 is about $15 more than the AK400 at the time of filming, and thermally that has these coolers about equal. But the Arctic option costs more as it has an extra fan, but the fan isn't doing a whole lot. For a 68W CPU (R5, i5-non k), the Arctic is functionally the same as the AK400.  ", "However once you move up to a higher heat CPU (R7, post-tau expiry i5, and maybe some i7s), the gap between these two widens and it favors the Arctic 34 by a few degrees (up to 4C), which can start to matter at the high end. In the end it's really going to depend on the CPU you’re using. The AK400 is not necessarily a cooler we’d really recommend for that 120W range, but it is capable and as long as you’re using a case that doesn’t suffocate the cooler’s access to air you should be fine, unless you start overclocking.", "For ", ", it’s really pretty simple. It is a cheap tower cooler - cheaper than the AK400, when you can find it, and that makes it viable. Part of the reason for the pricing difference is the lack of native LGA 1700 support on the Assassin Spirit, but Thermalright would ship you a bracket if you bought it (however it is not included with the cooler itself).", "DeepCool includes all brackets and mounting hardware with the AK400 that are currently relevant and so does Arctic. If you want to go higher end, the Scythe Fuma 2 is a great option for air cooling. There's ", " as well. Liquid cooling of course has its own advantages but you’re basically doubling the price at that point, so we’d say that the Fuma 2 is the one to look at if you are really concerned about acoustics and noise efficient performance. We’ve tested that you can bring the fan speed and noise level down and still achieve a good thermal result, far quieter than what you would achieve for the same thermal performance on a single tower or single fan cooler like the AK400.", "Overall, the ", " is pretty good for DeepCool and it is competitive with the other offerings currently on the market.  "]},
{"title": " The Champ: $41 Thermalright Peerless Assassin CPU Cooler Review & Benchmarks", "paragraph": ["The Champ: $41 Thermalright Peerless Assassin CPU Cooler Review & Benchmarks", "Last Updated: ", "The Highlights", "The market for dual tower air coolers has been shaken up in the last few years with a lot of good options, but nothing could prepare us for what Thermalright claimed it’s going to do: unlock the “CHILL FORCE.”", "Today, we’re looking at the dual tower ", ". Depending on where you buy it and which model you buy, it’s in the range of $40 to $55, with multiple models: a base model (the subject of the review, which also comes in white), ", ", and ", ".", "These coolers are fairly affordable and they’re in the really packed dual-tower market. The main competition for these is primarily the ", " (which did extremely ", "), or the ", ", which is the single tower version. The AK400 is more of a direct competitor to the ", ". Finally in this range is the Scythe FUMA 2, which did ", ". ", "Steve Burke", "Mike Gaglione", "jeremy clayton", " Andrew Coleman ", "VITALII MAKHNOVETS", "jack reitman", "We’ll start with the physical design of the Peerless Assassin. The cooler measures 125mm wide x 135mm deep x 157mm tall. For the average case (most mid-towers on the market), the max cooler height is in the range of 155mm to 165mm, and with the the advent of the RTX 40 series, that has increased even further because now they have to fit the extremely large 40-series cards.", "The Peerless Assassin fits right in the range where if you have a cheaper mid-tower you’re going to want to check for compatibility as it is right up against the threshold where we normally see these types of cooler fitting in a case. The cooler includes mounting hardware for LGA1700, AM4, and AM5.", "As is the case with all of our reviews, our main focus is performance. We will be testing the Peerless Assassin on our standard cooler test bench with heat loads up to 200W. We use standardized heat loads with 68W, about 125W, and about 200W. You can learn more about our test methodology ", ".", "Depending on what you mount the cooler on, whenever you have a two-point mount or a four-pole post, you potentially end up with an almost off-camber pressure map where the pressure is heavier on one side than the other. It could be on two sides in the instance of this design, which can be a downside as you need more thermal paste to fill in those gaps. We’ll talk later in the review regarding the quality of the mount and the installation process. The fans are a standard clip design for the two included fans.", "With respect to mounting, this will best fit on an AM4 or AM5 CPU - you can throw it on Alder Lake, but you may need to buy a mounting kit which they ", " for about $9, unless they just send it to you if you make a warranty claim.", "The cooler heatpipes are biased to one side vertically (in relation to how it would be mounted in a standard case) allowing the user to get more clearance above or below the CPU, depending on where you need space.", "This is an intentional part of design to provide some extra clearance where the user requires it. A little bit of extra thought never hurts with these types of considerations - it’s attention to detail and when you are talking about cheaper coolers there’s not really a ton of room to do unique things.", "For the heatpipes it's a six-pipe design, which has become very standard at this price point. What's most important is maximum contact at the patch where the silicon is most commonly located, with three or four of them out of the six having direct coverage over the CPU and the IHS. The fin stacks are uncoated, with four friction-fit pins holding two metal top-plates on the fin stack.", "The heatpipes and base are nickel-plated copper and the fins are aluminum. The top plates are also aluminum.", "The two-tone gray PWM fans attach with standard metal wire fan clips, and the fans have rubber corners to help absorb the fans’ vibrations. The fan cables themselves are fully sleeved in black, with black wires inside. There’s also a black unsleeved Y-splitter included for the fans, which is a nice touch.", "We don’t normally talk about packaging or the unboxing experience, but we want to call attention to Thermalright’s well-fitting foam and good use of space inside the box. The included accessory kit fits between the towers of the cooler neatly. Thermalright even avoided gross overuse of plastic bags, with only three in the original packing.", "Overall, the fit and finish of the Peerless Assassin 120 is good externally, and better than we would expect from the average $40 to $45 cooler. That expectation is changing as more and more coolers ship at this quality level and price, especially at the $50 price point. That extra $5 might change your expectation of fit and finish depending on what this costs when you see it online. The only negative thing we noticed is a slight slant to the whole cooler, independent of the offset. This is a small detail and we only noticed when looking at the cooler from the side.  Overall, the exterior of this cooler is well put together.", "For AM4, mounting starts with removal of the stock plastic mounting brackets, but the stock backplate remains. Next, secure standoffs and the two AM4 brackets to the backplate by threading the provided screws through the bracket, into the standoffs. Once the brackets are secure, apply thermal paste.", "Place the cooler on top of the IHS, doing your best to line up the two captive, spring-loaded nuts over the male threads of the brackets. Thread the nuts onto the screws by applying downward pressure to compress the springs on the nuts. Take care not to tip the cooler or cross-thread the nuts; you may need to use gentle but firm pressure from your other hand to hold the cooler in place as you do this. Once you have one-half to a full turn on the nut, move to the other side and repeat. Alternate tightening it until done. Installation of the fans is simple using the standard fan clips for the 120mm fans.  ", "Intel starts with identical steps for LGA 1700, but with a custom metal backplate. The Intel kit has different hardware for 115X and 1700, so the right set has to be used. Once the backplate is secured in place, secure the two Intel brackets with the four provided screws. Apply thermal paste and exercise the same caution as before while compressing and screwing the nuts into place.", "Our main criticism concerns the captive springs for the spring-loaded nuts requiring so much pressure to get them threaded onto the bracket.  Having to push down with a screwdriver towards the motherboard is unnerving, especially considering how much pressure is required to get them to start threading. Beyond that, everything else works really well and has a nice fit and finish.", "Pressure tests are first. The test uses chemically reactive film and a NIST-traceable scanner to show how even the mounting pressure is between the IHS and coldplate. This test was made possible by our ", " backers and purchases at the ", ".", "The test on the 3950X produced one of the best pressure maps we’ve seen yet, with full coverage of the center and gaps only forming along the perimeter. Paste will mostly help with that, and versus the others the ", " does it better than the Peerless Assassin, but this is on the better side for air coolers.", "The 3800X maintains consistent central pressure on the CPU, but was generally more lacking at the borders. The second pass especially shows this, with a horseshoe pattern around the right edge.", "In all of the pressure tests, we can also see an artifact of the mounting hardware trouble that Mike encountered during installation. The left and right edges correspond to the top and bottom of the motherboard when socketed in standard orientation. As seen here, they have heavy contact from having to hold the cooler in place while compressing the springs on the mounting posts. ", "We work hard to avoid any further influence in testing data because we do this a lot and there are certain methods we can employ to make sure it doesn’t impact the overall results of our testing. However, this points to a potential issue for the end user who isn’t taking all of those controls into consideration and leaves the potential to have uneven thermal paste spread – not the biggest deal (as long as you use enough paste you should be fine), but if you are using a smaller amount of paste it may spread out unevenly.", "Ideally, Thermalright would redesign this mounting mechanism so that the spring and nut can all meet with the posts without requiring compression first. Noctua and EK have both managed as much.", "Flatness of the coldplate is next. We use a special tool to measure in microns from a calibrated zero-point.  This helps us show the pits and valleys within the coldplate design. The ", " is impressive here, with one of the flattest results we’ve seen, coming in just ahead of the Scythe FUMA 2, and far better than coolers like the ", ".", "The Peerless Assassin 120 has a very narrow range of results, meaning average flatness is incredibly consistent, and the deepest outlier measurement is shallower than most other coolers’ average range. It doesn’t get much better than this, and we believe this has a direct correlation with the thermal results up next. In this regard, the flatness will help make up for places where the cooler might otherwise be facing more of a fight like in just general size of the fin stack.", "We’ll kick off the thermal testing with our 198W high heat test, similar to an overclocked AMD R9 CPU or a stock Intel i9 Alder Lake CPU. This first set of results is for 35dBA noise-normalized, so all coolers have equal noise levels.", " came in at 56.4 degrees Celsius over ambient, which ranks it tied for the top-performing air coolers we’ve tested, within error and indistinguishable from the ", ". That has it 3.5 degrees cooler than the Scythe FUMA 2, forming a significant lead versus an otherwise highly efficient cooler.", "Liquid coolers outperform the Peerless Assassin 120, especially the ", " at 3.5 degrees Celsius cooler. It’s a noticeable difference, and the newer offset brackets for the Liquid Freezer would give you another 1-2 degrees on top of that, but it’s also over 2x the price. Still, you could run the Liquid Freezer II even quieter than the Peerless Assassin while getting the same thermals, so there is some benefit there depending on what type of user you are.", "Our next test shows all of the coolers with their fans at 100% speed. This allows coolers with more powerful fans to brute force their way higher in the chart with the trade-off being higher noise levels.", "The ", " posted a CPU load temperature of 53.4 degrees Celsius over ambient at 42.5 dBA – a 3-degree improvement over the 35dBA test. This is again within error of the top performing air coolers in our chart, such as the ", ". So, the cooler has headroom to ramp the fans for better cooling when necessary, but with far more noise.", "This result even narrowly beats the massive and expensive ", " in thermals by 1.8 degrees and noise by 1.6dBA – so it’s reducing thermals and reducing noise levels, hitting on two fronts, and highlighting that the old guard coolers need to step up their game to remain competitive. There are other value-adds in going with something like a Noctua cooler, namely support and accessories, but the value is fading with each year. You’d be better off spending that money on a liquid cooler instead at this point.", "Our next set of tests is at a lower 123W heat load, similar to an R7, likely future R5 CPUs in the 7000 series, and similar to the Intel i5 CPUs today. We’re reducing the heat load now, so more coolers are in contention.", "Here’s the chart for 35dBA noise-normalized thermals. The Peerless Assassin 120 charted at 54.1 degrees Celsius over ambient, placing it barely at the top of the list of air coolers we’ve tested.", "The ", " tested within margin of error, but costs roughly $12 more. Going just below the Peerless Assassin 120 in price, the popular $35 ", " came in at 8.4 degrees warmer. That’s a huge difference for $6 and will affect CPU Precision Boost frequency.", "Now for the 100% fan version of the 123W test. The Peerless Assassin 120 came in at 52.1 degrees Celsius over ambient at 42.3 dBA.", "Making the same comparisons as the last chart, the Arctic Freezer 34 Esports Duo tested 1.9 degrees warmer at roughly the same noise level, and the Vetroo V5 was 7 degrees warmer also at the same noise level.", "The bottom line is that the ", " is a really compelling value and beats out all competition we’ve tested in that regard. It’s one of the strongest air coolers we've tested anytime recently in terms of value positioning. At the current price of roughly $41 dollars, it is a solid, worthwhile purchase. The Peerless Assassin series has gained new entrants as well, like the ", " (now a similar price) and the ", " (second edition)", "However as that price creeps up (as is the case with third-party sellers), do not buy this thing at $80 plus, as it is a massive ripoff at that price point. Not Thermalright, Amazon, or Newegg ripping you off, but likely a third-party seller through those services. But at $40, we think this is a good buy as it makes sense for a simple air cooled setup where you don’t want a lot of complications, but do want a smaller tower that can pick up the cooling required of a 200W CPU.", "Once you get into the $50 plus category, there are some other coolers worth looking at, but are coolers we still need to run through the bench, so stay tuned for those updates.  ", "There is an even ", ", but we cannot confirm the performance characteristics as we did not test it. But overall Thermalright is really striking a great balance between price and performance, but keep in mind that there are other factors like warranty and support at play. The only warranty information we were able to find was in this Amazon Q&A post by a company representative, which claims customers in the US market can receive a refund within one year by messaging the seller on Amazon. ", "One year isn’t that long for a cooler (Deepcool’s is 3 years on the ", "), but realistically it’s a giant piece of metal with a cheap fan attached to it, so the metal shouldn’t break. If the fan does break that is unfortunate if it is out of warranty, but it is also a very cheap fix as you can just put any 120mm PWM fan you have in its place, so we won’t come down too hard on Thermalright for that aspect. The ", " has also come out and is a more expensive competitor.", "As a cooler, the Peerless Assassin 120 is pretty standard but it performs well and the price at $40 to $45 is pretty competitive.  As always, go to the ", " or our ", " page to support us directly.  We’ll see you next time."]},
{"title": " GN Mega Charts: CPU Cooler Benchmarks & Comparisons", "paragraph": ["GN Mega Charts: CPU Cooler Benchmarks & Comparisons", "Last Updated: ", "The Highlights", "This is another of our GN Mega Charts series! You can find all Mega Charts on the ", " page, such as our ", ".", "This page will be regularly updated with the latest of our CPU cooler benchmark performance numbers, including links to CPU cooler reviews, comparisons against stock coolers (and discussion over whether it’s worth upgrading something like an AMD Wraith or Prism cooler), and more. The page will run on a slight latency from our latest reviews, but will be updated a few times a year with larger charts than you’ll find in those latest reviews. There are a few reasons for the truncated reviews charts, but the main one is simply legibility: Particularly in video format, it’s hard to fit much more than ~20 items (with 2-3 bars each) while still maintaining usefulness, like on mobile. The other is to focus the discussion or viewer in the short time a chart is on screen. This page doesn’t have those limitations.", "We’d like our audience to think of these Mega Charts round-ups as an “LTS” (or Long-Term Support) version of our data. They don’t get updated constantly, but allow us to maintain publication of quick-reference material and a stable set of data. This is a permanent page. This URL will always contain the Mega Charts round-ups for coolers.", "Steve Burke", "Mike Gaglione", "As a note, we’re currently working on revising our CPU cooler test methodology to move to a new platform. When we do and eventually update this page, we’ll probably split the sections into “chaptered” headers for old and new test benches. For now, all of this was conducted on the same bench.", " but we’re going to provide all the charts right up front to make this as convenient and accessible as possible! If you want to learn about the methodological choices, the limitations, and the individual coolers (with links to their reviews), you can continue down past the charts gallery. We’re not yet sure how we’re going to change this Mega Charts page when we refresh our cooler benches soon, but we may end up keeping both sets of data here (with the 2019-2023 bench lower down and the new bench higher up). ", "In either event, you can find an update log at the bottom of the page. You can ", ". Presenting the gallery first assumes some knowledge of the user. If you are unfamiliar with the nuances, we’ll provide some resources below it. Here it is!", "There are some very specific notes for this one that we’d encourage you to read before going too far with this information. Those are below.", "This page will contain all of the updated information, as explained above, as we continually roll-out reviews. The reviews will always contain the newest and freshest data, along with the analysis, but this page will serve as long-term reference material. This page will not contain individual cooler analysis. This page also won’t talk about mounting quality, installation, pressure maps (which are a major part of our reviews), or individual gripes, criticisms, or praise of coolers. Instead, it will be fully data-focused (again, sans pressure). If you identify a cooler you’re interested in on this page, we’d encourage you to check our review. Remember that good thermal performance does not necessarily mean it’s a good product.", "For coolers listed, you can ", "to find whether the one you’re interested in is included in any of these charts. We’ll have a table below that links to Amazon and Newegg pages for the coolers (with affiliate links) and links to the original reviews, if present.", "Mega Charts pages should serve as bookmark-able reference material. The URL will remain the same, so save it for regular reference. An update log will be maintained at the bottom. As we are currently an ad-free website, we ask that if you find this page routinely useful and want to support our maintenance of it, that you please support our efforts. You can do this a few ways:", "Results, as always, are fully dependent on methodology. One of the most often user errors we see is people saying “my CPU runs at 80 degrees,” then looking at a 60-degree result on our chart as a clear improvement. Keep in mind that unless everything is the same, they really can’t be compared this way. Thermals are one of the most isolated tests we run, and as opposed to a 3D Mark score, they cannot be compared cross-platform to yield any useful information. They can be compared intra-platform (as we’re doing here) to determine the most likely “best” CPU coolers, or to do tests like ", ", and then you can use that information to apply to your build.", "This is the bench we used for all of the testing shown here. The bench was built in ~2019 and fully publicly launched in 2020, following about 6 months of internal data validation.", "The heat loads represented in this testing include:", "This was conducted on an AM4 platform with an ", " that has now been in service for about 4 years. We’ve been impressed with its resilience to non-stop thermal stress. Given its survival, we’ll be using an ", " for our new AM5 benches.", "Again, this is described in detail in the methods piece. The basics are below:", "Thermals are measured with a mix of HWiNFO64 Engineering Edition and a thermocouple reader. We use a calibrated K-type thermocouple to monitor ambient temperature at the inlet of the CPU cooler, then subtract that from the averaged Tdie readings (at steady state) to produce a “Delta T over ambient” number. That’s what’s presented in the charts. We find that, within the small deviations in ambient air temperature in our test environment, this is functionally completely linear. If we see a +/- 0.5 degree Celsius fluctuation in the course of the test, this approach helps to smooth that change to isolate only the true impact to thermals from the CPU and the cooler. Testing is done in a 21C environment that is carefully controlled.", "With our original methodology, flatness is measured point-to-point with a precision needle instrument that measures the distance in microns from a known 0-point (calibrated annually with certification). The instrument allows us to measure the point-to-point deviations in surface flatness. A “flatter” surface, generally, is not inherently better; however, our test mostly looks for major craters or pitting in the surface of the coldplate. The best example of where we found an issue was in the ", ", which had some large gaps that caused it to actually sheer paper when mounted on top of a sheet of it.", "Power is arguably the most important aspect of cooler testing, as it’s what dictates the end result. We measure power into the EPS12V rails constantly throughout the test with a clamp. This is primarily for internal use so that we can ensure the bench is not drifting with time and that BIOS hasn’t applied some sort of unexpected voltage somewhere. EPS12V cable measurements allow us relatively ‘true to life’ measurement of the current, just with VRM efficiency losses included. One thing we’ve noticed is that power does drift with higher temperature “coolers” (technically, the CPU runs hotter, but that’s because of the cooler): In such instances, this is part of the test. We’ve found that there is typically a 4% reduction in power leakage for every 10-degree reduction from the cooler, although this isn’t a perfect science. For instance, one of our tests has a 48-degree result at 191W. Adjusting the fan speed to worsen the performance to ~65 degrees (over ambient for both) led to a 206W measurement, which is approximately a power reduction of about 7.28% for a ~17-degree reduction in performance.", "With this older methodology, we were still using our room acoustic measurements. These are being retired as we replace them with our hemi-anechoic acoustics chamber, which was a ", ". You should check it out! This methodology uses a room measurement in a ~26-27dBA noise floor at 20” measurement. The bench is fully passive other than the cooler.", "This testing, like all testing, has limitations. There are aspects of cooler performance not represented here, and likewise, some results could be more specific to the bench and methods used than other results. We always want our audience to be aware of the limitations of testing, as there is no such thing as a fully representative, perfect test, so it’s all about knowing how to leverage the information within the limits of its capabilities and usefulness.", "Although much of this is discussed in our methodology piece, a few basics are below:", "First, this testing was done on an AM4 platform. Generally speaking, methodologically, what matters most is the amount of power going into the chip and the heat load being tested. In theory, two parts that both draw 200W should have a somewhat familiar or largely similar hierarchical ranking of coolers. But this isn’t always that clean: A few of the biggest limitations are IHS shape and design, die or chiplet location, IHS size, and mounting hardware included with the cooler (for instance, if a manufacturer includes a to-spec kit for AMD, but an undertorqued spec for Intel).", "One of the reasons we’ve moved on from our AM4 standardized cooler test platform and are working on rolling-out an AM5 + LGA1700 platform is to do with IHS curvature and shape. AMD’s IHS is relatively flat, all things considered, and Intel has a slight curvature to it. Intel also uses a more oblong design (in the LGA1700 generation), whereas AMD is generally square. One of these isn’t necessarily better than the other, but they can have an impact on cooler performance. In some cases, it’s a dramatic impact. In many, particularly with lower-end coolers, it’s not as noticeable since less engineering goes into matching the coldplate to the IHS. It’ll be double the work to test both AMD and Intel in the future, but doing so will account for any coolers that tune for IHS design.", "In other words, while you can (generally speaking) assume the same or similar hierarchical ranking of “best” CPU coolers from these charts, you should also be mindful of differences in your intended use. If you intend to build an LGA 1700 system, then the ranking may be altered. Barring a major oversight by the cooler manufacturer (which, of course, is half of our job to look for -- hence adding both CPU types), good performance on AM4 should lead to good performance on LGA 1700. But it’s not always the case, so that’s the limitation of testing here.", "A lot of times though, we’re talking about single-degree differences. For many people, these don’t matter.", "Let’s get into the charts from our galleries earlier, but with some extra information.", "The below table contains all coolers tested and present on these charts.", "The above charts gallery includes data from our ~200W CPU heat load, representative of many modern high-end gaming CPUs. These are the most power-intensive tests we ran with the AM4 methodology.", "The charts include a noise-normalized test and a 100% fan speed test (irrespective of noise): in the noise-normalized test, we define whether the coolers are liquid or air next to their names; in the 100% speed tests, we define their noise levels at that speed. In all tests, the stock (included) fans are used unless otherwise noted. Some coolers include an extra fan and are noted if so. We average the RPM between all fans present for simplified representation.", "Remember that 100% fan speed tests do not control for noise levels, and so generally speaking, with a similar radiator or tower, faster (louder) fans will “win” on 100% charts. The noise-normalized result is what we generally weigh as the most important for a cooler, as it shows us a more like-for-like scenario. 100% results are still useful though, as they give an understanding for the maximum performance potential. In those charts, the “efficiency” of the result matters: You can look at the noise level (next to the cooler) against the temperature. If there’s a result that scores better than another while being quieter or the same, that result is more “noise efficient” (by our terminology) for the temperature we get.", " We are now moving to lower heat loads. As heat load reduces, the differences between high-end coolers diminish. It is not fair to judge a high-end cooler’s peak performance based on an underwhelming heat load, sort of like how it wouldn’t be fair to judge a CPU based on a load that’s GPU-bound; however, we still include those results because they’re real-world numbers that may help put into perspective the possibility of over-buying your cooling solution. Typically, the biggest advantage from an “overbought” cooler is that you can reduce noise levels more notably.", "Now for the lowest heat load charts. This data also gives us a look at stock CPU cooler performance vs. ‘aftermarket’ coolers, like the AMD Wraith Prism and AMD Wraith Spire stock coolers vs. the Thermalright Assassin Spirit, Cooler Master Hyper 212, and more.", "Now we’ll get into VRM thermals. These results can be wildly variable depending on how the platform is tested. VRM thermals are influenced by coolers primarily from the position of the fans: If a liquid cooler has a VRM fan atop it, that’ll obviously benefit the VRM thermals. ", ". Likewise, if an air cooler uses 140mm fans that sit low in the heatsink, they’ll pull air over or push it into the VRM heatsinks to cool the MOSFETs that we measure.", "Liquid coolers are side-mounted on the test bench in such a way that would represent a top-mounted orientation (intake) in a case. If you intend to front-mount your AIO, the fans will not benefit the VRM -- likely not at all -- and you’d need case fans to help it. Air coolers can be directly compared here, but liquid coolers can only be compared under the assumption of the same mount as tested.", "Likewise, for noise-normalized testing, you’ll see some liquid coolers seriously struggle with VRM thermal performance. The EVGA CLC 360 is a great example of this in our charts, as its pressure wanes significantly after the reduction for acoustics, causing it to lose pressure through the radiator and lack power when it hits the VRM heatsink.", "These charts are also most useful for low-end motherboards where VRM thermals are a concern. A lot of modern boards are overbuilt, which reduces the necessity for ancillary VRM cooling."]},
{"title": " Best Air Coolers for CPUs in 2023: Thermals, Noise, & Value", "paragraph": ["Best Air Coolers for CPUs in 2023: Thermals, Noise, & Value", "Last Updated: ", "The Highlights", "We’ve been blown away by the performance and value of modern air coolers, and now we’re rounding-up the best ones that we’ve tested in the past years. ", "This year in particular, the air cooler market was packed with good options in all price ranges, including the ", " at the high-end, the ", " in the middle (with ", "), and some hangers-on from prior years have remained relevant, like the ", " passive cooler.", "This article is also special because it’s kind of a send-off for our test platform that we’ve done all this benchmarking on. We’ve been using ", " for 3 years now, but it’s time to move to new hardware and methods that we’ve improved in that time. But all of these air coolers get at least one last send-off.", "Steve Burke", "Vitalii Makhnovets", "Tim Phetdara", "Jimmy Thang", "We have a massive list of air coolers we’ve tested recently. This set of data includes some new entries from be quiet!, NZXT, ID-Cooling, and more. We also just published these and the results in our ", ". A lot of the coolers aren’t necessarily strictly from this year, but they’re still relevant today. In our upcoming, new dataset, we’ll also be looking at several of the new coolers from be quiet! and others.", "There are a lot of coolers we haven’t tested that may also be viable, but we've tried to cover a wide range of air coolers. This article is meant to provide a top-level overview to get people quickly acquainted with the best options we’ve seen. For more depth on each cooler, make sure to check out their individual reviews. ", "| ", " | ", " | ", "First up is the Best Overall, which is awarded for a balance of affordability or cost, thermal performance across all tested heat loads, pressure compliance with the IHS, flatness, and build quality. This one goes to the ", " (also available ", "), which also wins another category in this story for thermals, so we’ll save most of the thermal discussion for that section.", "Thermalright has been around a long time, but just recently started making major waves for affordable coolers of reasonable build quality. Thermalright put pressure on the market with its single-fan ", " (find our ", "). It has also been spun-off into other options, by pricing it at around $20-$26. The ", " was highly requested by our audience for review, and we quickly saw why: With its price tag commonly in the $30-$40 range, it’s one of the best coolers for the money if you’re looking for air cooling capabilities that can handle moderate heat load devices. This would still struggle with infinite turbo on a modern i9, but for a 200W heat load and especially for most of ", " and many of ", ", this handles itself well.", "Other than its chart-leading thermal performance that we’ll talk about later, the Peerless Assassin gets this rank for its nearly perfect pressure map that we saw in our review.", "Its cold plate flatness point-to-point was also among the best we tested. That particular test is to identify point-to-point, microscopic pits or craters that cause gaps in contact, and the median measurement for the Peerless Assassin was the best we’d seen at that time.", "Thermalright has some minor attention to detail elements, like biasing the heatpipes toward one side to allow for better clearance of surrounding VRM heatsinks or clearance for top-mounted components. ", "Build quality overall also surprised us. The cooler doesn’t have the same cheap, low-quality feeling you’d get on some of the $2 coolers we’ll talk about later. Thermalright mostly makes its cost savings on the fans, the lack of LCP in the blades, and the lack of RGB LEDs. These are extremely function-focused coolers.", "The mounting solution and process was straight-forward as well. Our main criticism was the pressure required by the captive springs to thread them onto the bracket, which is done better by Scythe’s newer coolers. That’s an area Thermalright could improve. The looks aren’t special, but they’re good enough for someone who’s OK with a function-first build. You could look at the ", " for a comparable cooler with more focus on the visuals. We’ll cover thermals more in a moment.", " | ", " | ", "The next award is for Best Value. This category primarily considers price-to-performance. It somewhat factors-in build quality, features, and noise, but most heavily judges performance to cost. This is focused on single tower coolers - we’ll come back to higher heat load performance in the Best Noise-Normalized Thermals category. We’re looking at under 125W here. We’re not weighing build quality, ease-of-installation, or extra features much for this one.", "The winner for the low heat load best value award is the ", ". This cooler packs a lot of performance for its price. But at around $17, it’s worth noting that it’s not the cheapest cooler in our lineup, that would go to the ", ", which we'll talk more about down below. ID-Cooling has been around for about a decade now, but recently has made a big push with these air coolers.", "The ", " includes a single 120mm fan -- it’s not high quality, but it’s fine for the job -- and simple, standard metal clips secure it to the heatsink. The cooler is also about as short as a 120mm cooler can be, benefiting from a narrow tower that allows it distance from RAM.", "The cold plate has 4 direct contact heatpipes without a nickel plated base and uses a 2-point contact mount to secure it to a pair of 4-point brackets. There’s not much in the way of looks: ID-Cooling has an RGB fan, a black top plate, some black caps for the heatpipes, and that’s about it. The cooler really isn’t anything special, but that’s the point: it’s affordable while still being widely available. ", "In our 68W R5 heat load at 35dBA, the ID-Cooling 214-XT was just behind the more visually refined DeepCool ", " and ", " coolers, and not distant from the single-fan Assassin Spirit.", "At 123W and 35dBA normalized, the same cooler was again behind ", " and ", ", although it left about 5 degrees of room between itself and the Peerless Assassin. It’s not good enough for high heat load CPUs, but overall, the results are good here.", "The ID-Cooling SE-214-XT ARGB impressed us, not only with how its name feels like an onomatopoeia, but also its cooling for the price. And the installation is good, too. ", "And that’s something we want to recognize: The ", " has incredibly straight-forward, simple, and secure mounting. It’s nothing advanced, but ID-Cooling is at least using the same approach that most of the $30+ coolers use, rather than leaning on AMD’s clip-based mounting solution. The AMD stock clip mount is passable, but it has some severe weaknesses in pressure distribution in the non-clip sides and also is just more prone to ripping the CPU out of the socket and at an angle when being removed, especially for someone not expecting it. ID-Cooling’s mount is among the easiest on our list today and is overall trouble-free.", " | ", " | ", " | ", "The next award is for Best Thermal Design. This one is given irrespective of cost or value, and instead focuses solely on what the cooler is trying to achieve thermally.", "This one easily goes to Noctua for its ", " passive CPU cooler. We use this cooler in two of our acoustic chamber test benches ", ": One is on the GPU acoustics test bench, another is on the data logging bench for the acoustics room. We used these because we needed something that made 0 noise so as to avoid influence on results, but also something that could handle moderate heat load from the test applications. If we think it’s good enough for those use cases, that means it already went through heavy consideration.", "We’ve been incredibly ", " with the cooler’s capabilities for a fanless solution. Passive coolers aren’t easy to make and involve a lot of hurdles to design. You can’t brute force an inefficient design with fans, making them more of an engineering challenge.", "Unlike many of these dual-fan and single-fan solutions we’re covering today, Noctua couldn’t work with thousands of existing prior products on the market and couldn’t re-use and tune its own more standard heatsink designs. A good passive heatsink requires an entire, ground-up approach to design.", "Coolers like this have a lot of considerations: Noctua went with fewer, thicker fins and spaced them out more, which helps give space for the air to escape passively. A more accurate descriptor for this would be “cooling plates” rather than fins, given their size and design. The spacing is designed to limit heat trap while maximizing both surface area and mass. ", "Noctua also cut slats through the cooler. This is also to help the air find its way out of the cooler naturally, as an orientation that causes the plates to run horizontally would create an inefficient route for air to escape through the far sides. By cutting holes through it like this, Noctua provided additional paths for the air to escape.", "We actually showed this in operation in our ", ", where we took Schlieren photography using a parabolic mirror, a razor blade, and a light. ", "This was the result. This imaging shows the air density gradient across the image. You can see how in an orientation with the plate openings upward, the air finds its way out of the cooler in an almost conical pattern. You can see the air clinging to the plates to find an exit, demonstrating in a practical sense why all that spacing between them is helpful. This is an instance where heat rising is a critical consideration for design, as opposed to something with a fan that can overcome the relatively slow rate of heat rising.", "Noctua’s engineering wasn’t just on the passive cooling, though. Our pressure testing found that the NH-P1 had phenomenally good pressure distribution across the IHS overall, with only a few gaps. Every aspect of design matters when there isn’t a fan, so even pressure helps efficiently transfer heat to the cold plate.", "Flatness was also excellent in the NH-P1, where we found its point-to-point range in the median was relatively tight together, indicating a consistent surface finish with minimal pits or craters.", "Noctua is also using a 6-pipe design to maximize the coverage through the cold plate. That and the combined surface area and mass make the cooler slow to ramp to steady state -- and that’s a good thing. You can see that it took around 25 minutes to hit the peak steady state values in our original 68W heat load test.", "The cooler is straight-forward to install as well. Its biggest downside is size, so you’ll need to plan fitment of everything.", "Thermally, these would do great with lower heat loads. Our original testing had the P1 throttling but technically running at 123W, or more than acceptable with a 68W R5 heat load. It held about 65 degrees there. Noctua has a helpful page on its ", " showing CPUs where it judges performance. We’ve done some validation on this and largely agree with it.", "If you need a passive cooler for a home studio, a voice over setup, acoustic testing, or just because noise bothers you, we highly ", " for CPUs with a heat load it can manage. You can always strap a fan to it if necessary to give both 0RPM and high load options.", " | ", " | ", " | ", "| ", " | ", " | ", "Our next category is for Best Noise-Normalized Thermals. Or in other words, “best out of the box thermals.” There are 3 heat loads we’re awarding this one for. At 200W, this award is taken by both the ", " and the ", ". At 123W, this award is once again taken by the ", ".", "At 68W, where we don’t run the highest-end coolers since it’s not a heavy enough load, this one is taken by the ", " -- apparently assassins really hate heat -- and the ", ".", "This one is a simple ranking of thermal performance. Using the stock fans, we normalize everything to the same 35dBA floor at a 20” distance (we’re changing this going forward to move to our new acoustic chamber).", "Here’s the 200W chart. The liquid coolers are there just for perspective.", "The Peerless Assassin ran at 56 degrees here, with the Assassin IV within error. They’re the same. The AK620 is also about the same. The ", " sets the floor - but we didn’t particularly like that cooler. The ", " is actually one of the reasons we’re retiring this bench: We expect it’ll perform better on a modern IHS, as some of the tuning that Scythe did was to the cold plate. That tuning may have affected the AM4 performance, or at least, the changes to the finstack are further hampered by the changes to the cold plate not meshing well with this test bench. With a couple days of retesting, we ended up at the same results. ", " will have to go through our new test platforms to see if it does better there -- we suspect it will. It was a good push to move platforms though.", "And here’s the 200W load at 100% fan speed, so there’s no like-for-like in the noise department. In this one, the Assassin IV with 3 fans blasted to the top, but also ran relatively loud. It’s about tied with the ", ". The 2-fan solution is just behind it. The Peerless Assassin is also up at the top. ", " remains as a great example of an inefficient solution: At 51.1dBA, it’s barely keeping up with 44dBA and 46dBA alternatives. ", "In this one, the FUMA 3 is doing better than the ", ", but it’s also louder, so the improvement is at the cost of noise efficiency.", "The ", " also enters this chart, setting the floor as a single-tower, single-fan solution.", "Here’s the 123W load chart at 35dBA. This one introduces a bunch of coolers we hadn’t previously published. Introduced here, we have the single-fan ", ", ", ", the ", " (which has a higher flow fan), the ", ", the ID-Cooling SE-214 XT ARGB, ", ", and FUMA 3 were all added for this final round of charts before we move to our new platforms.", "Of these, the leaders remain the Peerless Assassin and FUMA 2 when noise-normalized. The Assassin IV wasn’t run here as it’s overkill for the load. The AK620 and Dark Rock Pro 4 rank alongside the FUMA 2. For single-fan coolers, the ", " leads, followed by the Thermalright Assassin Spirit at 58 degrees -- kind of a wide gap between the two. ", ", ID-Cooling SE-214, and ", " are all similar. ", " doesn’t do great, down at 60 degrees over ambient, but it’s OK. The RGB variant consistently ran about 4-5 degrees worse in our testing here, which aligns with the reduced flow on the fan. ", "Finally, at 68W and noise-normalized, the Assassin Spirit, Esports Duo, AK400, and ID-Cooling SE-214-XT ARGB are all about the same. The 214 is impressive here for its value. The T120 and T120 RGB again punch below the average result for a single tower, but at least are doing better than the small coolers on the chart. Almost everything is doing better than the stock coolers. The NH-P1, which has no fan, is within spec and not throttling.", "| ", "The next award is for the Best Ultra Budget cooler. The objective here is the cheapest possible cooler that technically gets the job done, even if it’s not great -- and this is obviously aside from included coolers.", "We’re giving this to the ", ". We ", " it previously. We bought it on sale for... $2.27. This model is only compatible with AM4, not AM5, and also doesn’t list LGA1700 support -- it’s not that useful unless you’re working with older systems and don’t want a stock cooler.", "But to its credit, when we reviewed it, it was able to sustain the 68W load at 35dBA normalized, keeping it below the ", " and about tied with the ", ". At 100% speed, it ran at about 39dBA and was quieter than the Wraith Prism, or about the same as the Spire, with the results landing accordingly. ", "This cooler is cheap, it feels cheap, its fins are flexible, it makes metallic noises when you breathe on it the wrong way from the flimsiness of the fins, and generally speaking, it’s not particularly good. The fan is only 92mm, but somehow, it manages to still have LEDs. The mounting uses AMD’s clip-based mount. ", "But in spite of all of these things, the cooler passes on the technicality of getting the job done -- and because it’s $2-$3, it’s kind of amazing. Depending on use, this is basically a small upgrade over a stock cooler -- but maybe not worth it. It might make more sense in situations where you have no cooler at all and where you can wait a few weeks to get it. But we still wanted to mention this dinky cooler for its oddly good thermal performance. It seems physically impossible that this is profiting, so maybe there’s some kind of subsidy going on -- but either way, $2.27 (or whatever it is at the moment) is comically low.", "| ", " | ", " | ", "The next award is for Best Mechanical Design. This section covers the overall considerations and quality of life features, the pressure distribution, the installation, cable routing and cleanup, aesthetics, and usability.", "For this, we’re giving it to the ", ". The Assassin IV isn’t a good ", "cooler, and we talked about that in our ", ". At about $100, +/-$10, it’s an expensive, dual-tower, dual-fan solution, but DeepCool put a lot of effort into making a flagship that looks good, cools competitively, and considers usability. ", " is a brick of a cooler. It’s a dual-fan cooler, with one 120mm fan on the back as a pull fan and one 140mm fan that sockets centrally. It’s hard for cooler manufacturers to differentiate themselves at the high-end once they’ve reached performance limits. ", "Small attention to detail elements set them apart: We liked that DeepCool includes a hidden cable channel that’s notched into both the plastic fan housing and the finstack, allowing clean, pinch-free cable pass-through. ", "The back of the cooler also uses a slightly concave design that allows more of a gap to form between the rear fan hub and the fins, which helps reduce the hub deadzone that can form.", "The central socketing fan has a downside, which is that not just any 140mm fan will fit. That reduces compatibility severely to just exact replacements or one older DeepCool model. The upside of this is that it allowed DeepCool to reduce the overall height of the cooler, thus enabling them to fit a 140mm fan without hurting case compatibility. The fan sinks deeper into the channel as a result. On the positive side, mechanically, the socketing and unsocketing of the fan is well-designed and of good function.", "DeepCool additionally includes a fan mounting kit to add a third fan, something we tested in our ", " and with which we found a small improvement in performance. These can fit most 120mm fans.", "It’s also extremely easy to adjust the fan height for motherboard I/O area clearance, like heatsinks, or for RAM clearance if you add the third fan. We had some critiques of the mounting solution, but overall, its pressure maintained good contact centrally on the AM4 CPUs we tested.", "Other small touches are primarily aesthetic, but at this cost, they need some of that too: The cooler has a checkerboard pattern on the front that has become a bit of a DeepCool theme. Functionally, any benefit would be irrelevant and probably nearly impossible to measure outside of simulation. But it looks cool.", "The cooler also uses easily removable mesh cover plates to hide the central fan. These aren’t designed as part of the heatsink itself, but provide a mechanically simple cover.", "We also like that the cooler includes a physical hardware switch for a “quiet” mode and “performance mode.” This is done by using a resistor to reduce the power delivery to the fans, thus slowing them down. You could do this in BIOS, but adjusting the curve with hardware can be easier for some builds. ", "In our testing, we found the Quiet variant to run at 37.5dBA when at 100% speed, resulting in a 55-degree result at 200W. The performance result ran at 43.5dBA at 100% speed and 20” distance, resulting in a 53-degree result. ", "Our biggest complaint was of a fan whine that we heard. We have ", " in our video review if you’d like to listen. It’ll go unnoticed in builds with sufficient neighboring noise, but would be noticeable in silence-focused builds. Overall though, ", " had the highest build quality of any air cooler we tested this year.", "We’ll be back with two brand new test platforms for our CPU cooler methodology, and we’re thrilled to introduce them because it’ll be alongside full deployment of our ", ". We’ve shown it in use in some one-off pieces, but coolers will be the first to get it as standard treatment. We’ve already run nearly a dozen coolers through it. You can also check out our Mega Charts for ", ", featuring every cooler we've tested.", "The new platforms will be both AM5 and LGA1700, which gives us a look at two distinctly different heat spreader designs. We couldn’t do this before because we didn’t have the manpower or processes in place to double the work, especially because one cooler already takes about 40 hours to review. But now we can, and we’re hyped to get into it with the new setup.", "In the meantime, this gives you a look at a mature test methodology that has had 3 years to bake. Even outside of AM4, for the most part, this gives you a good representation of performance as a baseline. And besides, AM4 is still getting heavily bought right now."]},
{"title": " The New Best: Arctic Liquid Freezer III 360 & 280 CPU Cooler Review & Benchmarks", "paragraph": ["The New Best: Arctic Liquid Freezer III 360 & 280 CPU Cooler Review & Benchmarks", "Last Updated: ", "The Highlights", "Today we’re reviewing the brand new ", ". What makes it interesting is that you can pull off its pump cap, which has the VRM fan inside it. It also forces a contact frame for Intel CPUs. This new cooler follows-up the best liquid cooler we’ve tested in the last 4 years -- the ", ". It’s... it’s sequential.", "And in the 4 years since we crowned it, our test capabilities have grown: This review features lasers to try and root-cause a particular pressure problem we found, it features our hemi-anechoic chamber, and it features us complaining about the installation.", "Here’s the quick list of interesting features:", "Steve Burke", "Patrick Lathan", "Mike Gaglione", "Jimmy Thang", "First, the separable pump cap stores the VRM fan within it. The cap looks like a fan, but it’s not -- it’s just a cap. The actual VRM fan is inside, and it’s much larger than the prior one. This should improve airflow significantly as long as it’s directed in the right places.", "Next, Arctic has decided to force AMD offset mounting with its AMD installation kit. That’s a good thing. This means it’ll offset the coldplate down on the IHS, but it moves the densest part of the microfins closer to the chiplets. ", "They also are forcing use of a contact frame for Intel. This is a huge change. ", "In theory, making the frame and being in control of the cold plate, which they are, should make for the best possible pressure and contact distribution across an IHS that you could get. If you buy a solution from Thermal Grizzly or Thermalright, they're just selling you the frame, so being able to mate the cold plate to a particular frame is a strength that the others don't currently have. It's something we hope that Arctic is able to leverage properly. Spoiler alert: It's not perfect.", "The separable pump cap is one of the more interesting features. This is done for a few reasons: The first is to change the mounting hardware to be easier to access while also including its leaf spring. Another is to make the product a lot easier to repair and maintain: For RMA purposes, a user now wouldn’t need to disassemble the housing to replace a failed VRM fan. Instead, you’d get a replacement unit (and you’d need a replacement fan for a failure anyway, so the excess plastic isn’t too bad). It can also be done without removing the cooler from the board, which we think is a great maintenance feature.", "The PCB under the pump cap is also meticulously labeled and has exposed probe points, which is great for troubleshooting and advanced users. We’ll talk more about the construction in an upcoming tear-down.", "Another change with the cooler is that the pump cap now lights up. ", "The Liquid Freezer III has blackout and RGB versions. Pricing for the most relevant options is $130 for the ", ", $150 for the ", " of it, $120 for the ", " (Black), $140 for its ", ", and $140 for the LF III 420 (Black). They’ll also have a ", ", but we generally try to stay at 280 and up these days for liquid.", "Arctic’s biggest competition right now will be itself: Presumably because they’re trying to vacate the inventory, the ", " can be had for $92 now, with the ", " at $82. Other competition includes the DeepCool Mystique coming up and the Lian Li Trinity line when they’re not busy dealing with RMA issues.", "Let’s just get into the data. ", "Our thermal testing will start at 200W and noise-normalized between all tested coolers. ", "We have a few Liquid Freezer III entries here: One has the pump speed reduced to 70%, with the fan speed slightly increased to still hit the noise normalized target. Another is with the pump speed at 100%, which meant slightly lower fan speed because the pump is consuming more of that noise budget so to speak. Finally, we have one with the same settings, but the VRM fan disabled. That one isn’t shown in the chart above and will be highlighted during the VRM fan comparisons. And then there’s the ", ". ", "The Liquid Freezer III 360 is the new chart leader, up at 46.7 degrees Celsius over ambient. It’s the new “technical best,” only leading the brand new DeepCool Mystique 360 by margin of error. Between these, you’d buy on other features -- like looks, ease-of-installation, VRM cooling, or most likely, price and value.", "The new LF III 360 outperforms the prior ", " even when it had its offset bracket, which is an impressive place for Arctic to land. The Lian Li Trinity Performance is even behind the new Liquid Freezer III and Mystique coolers, and that’s a cooler that performed well for a 360.", "As for the ", ", it held about a 50-degree average and landed alongside the non-offset mounted 420 Liquid Freezer. The forced offset mounting on the LF III was a good choice.", "Arctic is doing well for performance, as is the ", ".", "Let’s look at the 100% performance before moving to VRM thermals.", "100% fan speed has the Liquid Freezer III at about 40dBA when using our non-chamber methods and tested at 20”. Remember that noise is totally relative to how it is tested, so what matters is the comparison to other devices in the same test.", "Of those at the top of this list, Arctic is the most efficient as a result of its high-ranking performance while maintaining sometimes significantly lower noise levels. That makes sense when considering the noise normalized results being so strong previously.", "The LF III 360 ran at 45 degrees over ambient while holding 40dBA. Most of the devices surrounding it run minimally at 50dBA, and as a reminder, in psychoacoustics, every 10dBA increase is roughly a doubling in noise perceived to the human ear (not to be confused with acoustic power). That is impressive performance for the LF III because anything at 55 dBA in this example would be perceived about 2 times louder.", "Alongside the ", " series, the Mystique is among the newest coolers here. These both perform 1-2 degrees better, but while running significantly louder. The 56 dBA result for the Trinity Performance is comparatively deafening when matched against the Liquid Freezer III.", "Compared to the prior LF II 360 at a similar fan RPM and before the offset mount, the new unit is slightly quieter and also 4 degrees cooler. That’s an impressive uplift.", "The LF III 280 runs at 46.6 degrees over ambient here, about tied with the prior 420 cooler. We’ll need to do a tear-down to fully explore where all these improvements came from.", "The original, day-one LF II 280 ran at almost equal noise levels, making it a clean like-for-like comparison. That one was 50.9 degrees over ambient without the offset mount.", "The next testing is to determine the VRM fan’s performance versus the prior model. We previously verified that the old VRM fan design wasn’t a gimmick and actually did work, so we need to do the same with this one. That involves both thermal and airflow testing, and we’ll start with airflow since it’s the most immediately demonstrative of functionality.", "This testing is not comparable to our prior VRM fan testing. We slightly changed the measurement locations, so we reran all the tests with the Liquid Freezer III 360 and LFII 360.", "Testing was done by taking a hot wire anemometer to various places around the pump block. We positioned the anemometer mostly atop inductors, as that’s where the air needs to hit in order to reach the heatsink, and oriented the inlet toward the fan. The same test locations were used for the LF II (watch our ", ")and LF III.", "Here’s a quick and simplified overview map. This shows only the flow of each measurement point with the VRM fan on and radiator fans off. This compares the LF II and LF III 360 options directly. The LF III is always the top entry with the LF II as the bottom. This is with each fan at full speed and the results are directly comparable using our new hot wire anemometer testing updated from the last time. As for fan RPM, the new fan maxes-out at about 2,500 RPM. ", "Broad observations are that the Liquid Freezer III VRM fan seems to mostly direct its air toward the top-right and mid-left. The 488 FPM and 425 FPM results are very high and indicate significantly higher flow in these areas than elsewhere, where the VRM fan’s airflow stays around 110 to 165 FPM.", "The original VRM fan more evenly split its airflow between the top-right, upper-left, and bottom-left regions, but at significantly lower flow rates than the new fan when both are at 100% speed. It also had a weak spot in the top left as a result of the old mounting hardware blocking airflow to this region from the VRM fan, which the LF3 resolves.", "Overall, the Liquid Freezer III's air flow is hitting the correct areas. The center left is probably the most important as that's where a lot of heat builds up and then some extra flow up in the top right helps with any VRM components that are up north of the board especially where the heat sink typically is located. One final observation is that the bottom left inductor gets less flow with the new Liquid Freezer III VRM fan than the older one, however, the Liquid Freezer III's fan can reach a little bit below that whereas the II gets cut off by the chassis.", "This simple chart shows the reduction in temperature, so a bigger bar is better and means a larger impact. 0 would be the performance with the VRM fan off.", "With both VRM fans at their maximum speeds, the new Liquid Freezer III posts significantly higher total cooling headroom for VRM components. It manages a 7-degree reduction on MOS0, which is huge, and two 6.3-degree reductions for the other FETs. This is a clear improvement for Arctic and the new fan is definitely working.", "We did some acoustic testing in our hemi-anechoic chamber (watch our ", " on it). This testing is specifically to evaluate the VRM fan and pump noise in a highly controlled environment. We typically test at distances of either 1 meter or half a meter, but in this instance, we brought that into 10” (or about a quarter meter) because we need the proximity to really capture the noise of the relatively silent pump and VRM fan. This testing is done with the radiator fans off.", "Here’s the chart. In this benchmark, you can see that when both fans and pumps are at maximum speed -- so we’re not normalizing for fan speed, we’re just letting them run flat-out -- and the new pump and fan combo at 100% definitely runs louder; in fact, the perceived increase to the human ear is nearing 2x louder. As for frequency spectrum, the new pump and fan have a spike around the 5,000Hz range and compared to the predecessor, a louder bump in the 1800Hz range.", "To help aurally illustrate this, we’re providing two noise samples. This is IMPORTANT: The samples here were taken at only 10 inches away and in a chamber with a noise floor of 13.6 dBA with our current measurement equipment. This is NOT representative of what you will hear unless you literally put your ear against your case side panel. Although if you use your system in an open bench style and have no other fans active, it is representative.", "The reason for demonstrating it this way is to help everyone understand where the frequency plot we just saw is coming from. Note that it is not these precise clips we sampled for the plot.", "Take a listen with the two links below:", ".", ".", "The III has more pump noise coming through, which contributes a lot to the noise difference overall. One thing we can’t account for in a short test period is how pump noise settles. Acoustically though, at 100% speeds for the pump and the fan, the Freezer III is definitely louder", "in a demonstrable way versus the original.", "Our pressure scans will start with the new Intel LGA1700 contact frame since it’s the most unique aspect of the cooler.", "We conducted 4 tests passes on the 360, but we’re showing 2 since they’re all similar.", "First on the left, we have the Intel stock ILM when using a Liquid Freezer II 420 -- the same one we used for our debut contact frame analysis almost two years ago. We can’t use the Liquid Freezer III here because, again, it doesn’t have an ILM mounting option. The Intel stock ILM was sorely lacking in pressure on the bottom edge of the CPU, with the right edge pointed toward the VRM. Intel is weak here overall and has its pressure in the wrong places.", "Next, the Thermal Grizzly frame that sort of created and validated this market smooths-over the contact across the entirety of the IHS. There are some gaps toward the I/O boardside at the top, but the distribution is significantly better than the ILM from Intel and is more central, which is where the die is.", "The cheaper Thermalright frame is next, with the first pass distributing more pressure across the entire IHS, but with some weaker areas. A re-mount improved pressure and produced the best scan yet, but as we discussed in ", ", its downside is the less precise installation process that can result in variable outcomes.", "Examining the Liquid Freezer III, it’s definitely not as good as the Thermalright or Thermal Grizzly frames, but is improved over the stock ILM. Some of that could be the coldplate too, but we can’t isolate that variable given the mounting options. Arctic is lacking pressure on the long sides of the CPU, and likely due to the coldplate behavior, also has a weak spot of pressure about 8mm in from the side of the CPU nearest the VRM, oriented right in our image. ", "This consistently appeared, including in an entirely different unit with the 280. This leads us to believe it is a design issue and not a one-off. Contact is good centrally, but there’s a lot of room for improvement here. We’ll talk about our disappointment in this aspect more in the conclusion, so make sure to read that section.", "To try and understand why this pattern was emerging, we took the cold plate to our $60,000 laser scanner that we bought last year. This machine has an accuracy to about 0.05 microns and allows us to represent cold plate flatness like we never have been able to before. It’s certainly an upgrade from our manual needle probing method. ", "We most recently used this in our ", " -- you can check that out for more background. This equipment allows us to not only identify a problem, but try to pinpoint the cause. To help fund our efforts and equipment purchases like this, as we’re still getting the money back on it, please go to ", " and grab a ", " (featuring a high-quality badge) for our 15th anniversary, a rugged ", " for your next PC build, or one of our memory explosion diagram ", ". Thanks for your support.", "Here’s the scan. After adjusting the scanlines and levelness of the cold plate, we eventually ended up with this result. Without magnifying it, everything looks relatively flat. We have a maximum point-to-point delta of 60 microns, but an overall good consistency one point to its adjacent neighbor. We were hoping this would reveal that channel we identified in the LGA1700 mounting pressure map, but because we can’t conduct this scan while the cold plate is mounted to an IHS, we can only see the unsprung version.", "Fortunately, magnifying the plate reveals the channel even without installing the cooler: When magnified 100x, you can see the channel very slightly in the cold plate at the weak pressure spots we saw previously. This is present on both units we tested. The channel is likely amplifying under the spring load of the mount. We now know that the plate is at least partially responsible for this shortcoming and not just the mounting hardware, and likely derives from how it’s mounted to the pump block. We’ll investigate that in our separate tear-down video coming up.", "Now we’re going to run the Intel LGA1700 thermals. We don’t have many entries for this and are only interested in evaluating the included contact frame. For this testing, we used other contact frames and also a DeepCool Mystique cooler for a competitive offering. ", "This data is not comparable to our prior contact frame testing, as we have changed the power load and some voltage settings. Testing is done at 100% fan speed with noise levels listed next to the coolers.", "Here’s the chart. The Intel stock ILMs perform the worst for the Arctic tests, both down at around 63 degrees Celsius over ambient. The Mystique also used the Intel stock ILM; however, at 49dBA, it’s able to brute force past the limitations and land at the top of the chart.", "The Liquid Freezer III 360 with the included Arctic frame had it between two LF II 420 entries: One with the Thermalright frame and one with the Thermal Grizzly frame. These two are within error of each other, but are 5 degrees better than the ILM. Unfortunately, we can’t determine how much of the LF III’s improvement is from the frame versus the pump and cold plate changes since the frame can’t be isolated. What we can say is that the Liquid Freezer III remains impressively noise efficient: At just 40dBA, it is equaling a 45dBA entry from a significantly larger 420mm radiator. Likewise, it’s encroaching on the louder Mystique 360. Even still, DeepCool holds a slight advantage here. ", "Against the original 360 with the Intel ILM, the improvement is about 5 degrees -- a noteworthy generational gain. ", "For both AMD and Intel platforms, Arctic recommends getting started by placing foam under the motherboard (we recommend using anti-static foam). ", "From there, install the CPU into its socket. Now we’ll go over specific instructions for Intel and AMD. ", "Start by removing the stock ILM. The next step is to mount the Artic contact frame down into place, making sure that the arrow on it aligns with the one on the CPU. ", "From there, drop the four corresponding screws into place and tighten them. ", "Once that’s done, ensure the CPU has thermal paste then mount and tighten the cooler’s cold plate onto the contact frame. ", "Finally, install the VRM fan, which connects via magnets.", "On the AMD side, once the aforementioned initial steps are completed, you will need to remove the motherboard’s stock CPU brackets. ", "From there, place the four standoffs onto the board then install the included brackets onto the board, making sure the left and right ones are correctly lined up. ", "From there, make sure your CPU has thermal paste applied and install the cold plate down onto the contact frame until both screws are snug. ", "Finally, the last step is to install the magnetic VRM fan.", "One criticism we had against the installation is that the leaf springs made it difficult to mount on AMD’s platform due to the fact that you have to compress down onto them, which we found to be tedious to get threaded. ", "The tubes are also very stiff, which made installation on AMD’s platform even more difficult. ", "The conclusion is straight-forward: We think that the value and performance are both good, but that Arctic also has some key areas it can do small product refreshes to continue improving on its base concepts. It’s trying a lot of new things here, and although they worked out well enough in aggregate to create a cooler that gets our recommendation, they didn’t all work out.", "Although price has increased slightly for MSRP -- and again, we expect competitive sales on these -- the value remains strongly competitive in a market flooded with LCD-emblazoned coolers that sell closer to $200 than where these are. The value at $120 to $130 is strong for the ", " coolers.", "In terms of cooling efficiency at a given noise level, our noise-normalized testing shows that the ", " is currently the best we’ve ever tested. When at 100% speed, it’s achieving similar performance to coolers 10dBA louder, which is a massive change in noise level. ", "We do have some disappointments. ", "We’re disappointed with the contact quality of the frame. Despite improving on the IHS, you’d have been better off with normal mounting hardware and buying a $7 Thermalright frame -- but that’s not an option here. You have to use Arctic’s with the way they designed it, which we think is a major weak point as it limits options and eliminates customers unwilling to remove the ILM. If it were the best we’d ever seen, that’d be a different story.", "But we think Arctic has the capability to execute on this. They control the cold plate and the frame, unlike separate frame-only solutions.", "Additionally, the VRM fan is more effective, but we found the combined pump and VRM fan at max speed to be louder than the predecessor. ", "On the positive side: History also plays an important role. In the last generation, Arctic introduced its offset mounting kit that significantly improved AMD performance -- something that was a new discovery at the time. They also got in front of a bad production batch and offered a good replacement program with user service kits. We did a whole ", " on that and found their handling to be master class.", "At the very least, it's good value. It is the most effective for noise normalized cooling performance that we've looked at. They have a couple key areas to work, but overall, we can say we would recommend the "]},
{"title": " Why Most Cooler Tests Are Flawed: CPU Cooler Testing Methodology", "paragraph": ["Why Most Cooler Tests Are Flawed: CPU Cooler Testing Methodology", "Last Updated: ", "The Highlights", "Much of this information will remain relevant even as we move to refresh our cooler bench at the end of 2023; however, parts of it will change when we switch to new methods. This was originally written in 2020 and remains representative of all cooler reviews published between 2020 and November of 2023 for GN, and most of it will remain representative after that, but with changes to the core components.", "The biggest rule in testing coolers is to never trust anything: Don’t trust the numbers, don’t trust the software, don’t trust firmware, and don’t trust the test bench. Every step of the way is a trap lying in wait to sabotage data accuracy. We’ve spent the last 3 years refining our liquid cooler bench and the last 6 months refining our new testing that will feature air coolers and liquid coolers alike. With millions of cells of data, we now know enough to have identified every relevant hidden pitfall in testing on ", " and finally feel confident in providing a full picture for accurate CPU cooler performance. But that's the key phrase: ", ". With our future cooler testing methods, we'll have to revisit all of this again.", "Steve Burke", "Keegan Gallick", "Josh Svoboda", "Andrew Coleman", "Jeremy Clayton", "The upside is that we can finally start really collecting data. This write-up will cover the most common and the most obscure landmines for testing, laying a plan for our ", " and helping establish a baseline for quality and data accuracy. We promised a CPU air cooler round-up back at the end of 2016 or 2017, and we’re finally getting around to it and will be publishing a lot of cooler content over the next month or so. We’ll start with ", " after this methodology piece goes live, then we’ll break ", ", then we’ll be back to coolers.", "This content is detailed and specific to CPU cooler testing methodology and processes. ", " Most user data out there regarding CPU coolers is flawed in some way or another, especially the stuff posted in random reddit comments, but the trick is minimizing flaws to the extent possible while remaining real-world, because total elimination of variables and pitfalls is impossible on PC hardware. Users will often randomly post a temperature number and say something like, “my Spire is at 70 degrees,” but the trouble is that this doesn't mean anything. Not only is the CPU a (key) variable, but even how that CPU is configured by the board is a big variable. The performance is completely dependent on each configuration, and so unless the testing is looking at relative performance by swapping coolers in a controlled environment, it isn't very useful as a barometer. Even with alternative coolers tested on the same user's platform, variable workloads (e.g. if someone tests in game that has a bursted load pattern) can cause issues with drawing comparisons. The same is true for motherboards that automatically adjust voltages in ways ", ".", "In this content, we’re going to show you 6 months of rigorous testing adventures that we’ve embarked on, including several months’ worth of discovering flaws in testing, ", "Several of these issues will exist in other reviewer configurations without technician knowledge, but the trick is to have the right tools to flag errant testing. These concepts will range from extremely basic to advanced.", "Within a couple days, we’ll be publishing a mini round-up of coolers, then we’ll add to it one cooler at a time over the next few weeks. Expect a lot of cooler content from us in the immediate future. It’ll mostly kick off after our factory tour series in Taiwan, which begins this week.", "We’ve nearly fully automated our testing procedure on both the real-world and the dummy heater test benches. Our dummy heater is something we’ll talk about more in a separate piece and briefly here, but the main focus today is on outlining the pitfalls of real-world testing and how we’ve circumvented most of them.", "A lot of bad test results arise from mounting pressure deviation or only testing a single mount. Other technician error can also produce variance in results, but generally, once the platform is set and the SOP is defined, most bad results are related to a bad mount.", "As part of our automated testing, we’ve introduced automated system monitoring and have built software and spreadsheets that will flag us with warnings if any number exits expected results or standard deviation (or even a fixed value) in the testing, depending on which numbers we’re looking at. Red flags alert technicians that human oversight is needed, and that although the result may be accurate, it needs a closer look before it’s passed to content production. We collect hundreds of thousands of data points for every single cooler and have at least 45 final numbers (averages) that we evaluate for each one tested, most of which are for data accuracy validation. At the end, 5 averaged sets of averages – so these numbers average thousands of rows of steady state data – are produced for each of the four primary charts that we’ll be publishing.", "Our dummy heater is currently used for ", " and is primarily useful for checking the hierarchy of the data. The numbers won’t be identical in an absolute sense, because it’s a difference of Tdie versus Tcase, but the scaling and positional orientation will match. We also use our dummy heaters for rapid prototyping of concepts, like that of scaling more power without needing to find “stable” CPU settings. We have one LGA115X-style heater and one AM4-style heater, both designed to GN’s spec.", "The AM4 heater is special: For this one, we designed it such that resistors are in roughly identical locations to AMD’s three chiplets on AM4 DT CPUs, so we’ve got resistors representing an IO die and two core chiplets. These can be powered in any configuration, so if we want to simulate a ", ", we can pull power from the second core chiplet and power only the IO die and first chiplet. We use $10,000 worth of benchtop power supplies, monitoring equipment, and custom dummy heaters to do all of this, and we thank our ", " and ", " customers for making this possible. We always reinvest into the business and testing procedures heavily, and this wouldn’t be possible with only advertising revenue.", "Anyway, the heaters can be dialed to specific heat loads to simulate processors and eliminate all the variables incumbent in a motherboard or computer. We still need real-world testing and largely rely on it, but dummy heaters eliminate any question in our minds about if our hierarchical scaling is accurate and free of technician or test error. We’ll save the rest of the details on this for now.", "This section will break-down our analysis of some of the most common or likely errors that could be encountered during the course of CPU cooler benchmarking. Trying to find the best CPU cooler is difficult, and it'll vary for every platform (so AM4 can't represent LGA115X precisely, for instance), but we can get as close as reasonably possible with some careful controls.", "Since this will be a reference piece for a long time and we expect some of our readers are new to PC hardware reviews, we'll start with some fundamentals: Terminology, then the hardware.", "We'll refer to several of these during cooler reviews and this methods piece:", "First: The exact same CPU (or CPUs, but on different charts) has to be used for all testing. You can’t compare coolers against one another with different CPUs – even if it’s the same model – under the coolers. Two 3800X CPUs will not produce the same results under identical usage conditions, and neither will two 9900K CPUs. The dies are all different, SMUs are different, the package is sealed differently, the thickness of the silicone adhesive between the substrate and IHS is variable, the solder thickness and quality is variable. One CPU to the next, it's not uncommon to see the core-to-core delta differ by 5-10 degrees.", "Additionally, the same exact motherboard should ideally be used for all tests, and all voltages and power settings must be manually controlled on the board. Resetting BIOS with auto settings in play can change the voltages being driven to different parts of the CPU, and that includes more than just Vcore. Firmware should also remain fixed once the platform is up and running. We also use identical RAM, PSU, and everything else – we’ve tied-up a whole stack of components that will only ever be for a dedicated CPU cooler test bench.", "The system should also be disconnected from the internet. We do this to avoid Windows updates that could alter CPU behavior in a way that would potentially shuffle cooler performance without us knowing. If Windows launches an update to change scheduling behavior, it could result in a change in how coolers appear to perform (even if the actual performance is unchanged). For cooler tests, all we care about is consistency: If Windows improves scheduling, that's no factor to how well one block of metal cools versus another, but it could change the observed results if one test had the improvement and the other didn't.", "On that front, we also lock the power plan within Windows and power behavior within BIOS.", "The next one is the means used to take the final measurements: Easily the most common error is to spot-check some logging program for temperature, typically done by allowing the test to run some semi-arbitrary amount of time and then glancing at the numbers in the “maximum” column in HWINFO. We see this a lot in forum posts. It's OK for a quick check of if there's a mount issue (like obvious throttling), but isn't a repeatable approach for reviews where we're advising thousands of users.", "The “maximum” column in HWINFO numbers can spike hard and may not represent the average at steady state. They also fluctuate pursuant to ambient and, without logging (rather than spot-checking), you could be off by a couple degrees if ambient fluctuates. That's fine for an end user's purposes of just making sure the CPU is running at an acceptable temperature, but a couple of degrees' worth of fluctuation could be enough to completely change the tone of which product is better in a comparative review.", "To get enough data for meaningful averaging, we also have to run the tests sufficiently long to achieve steady state. Running Blender’s BMW test for 3 minutes or Cinebench R15's single pass isn't going to be enough to load the cooler fully and demonstrate its performance under real load conditions. This can disproportionately affect how liquid coolers will look in the stack since they have a longer soak time.", "Because cooling is defined in most instances by the speed and capabilities of the attached fan, fan speeds also have to be controlled.", "Setting all fans to “100%” isn't helpful for like-for-like testing, but at least establishes how a cooler will perform if a user maxes-out the fan. It's at least better than arbitrarily picking a percentage - like 50% - and setting all coolers to that percentage.", "In order to get a gauge for performance at a level playing field, we need noise-normalized performance (ours is 35dBA @ 20”, straight on, always with the air directed away from the meter). This allows us to get an ", " at the same noise level, since any cooler can brute force its way to the top with high RPM fans. Arbitrarily applying a 50% or similar speed to all fans also doesn’t make sense, since they’re all going to run at different RPM and noise levels with such a setting. More critically, some fans are optimized for performance in ways that’ll have hard fall-offs at certain PWM values and might be built to best deal with the accompanying heatsink’s impedance at a certain RPM.", "CPU coolers really can’t be tested well in a case, because then you’re basically just testing the capabilities of that case. We do that in ", ": Our general philosophy, to try and limit variables and produce consistent data, is to isolate components in reviews. Cases get their own reviews, so we leave that analysis to those tests in order to keep reviews of approachable length and complexity.", "Cases are so varied in design that there’s no point in trying to pick a “standardized” case to test against all coolers, and instead we think it's better to test open air where the field is level and relatively easy to extrapolate across other conditions. Using a case also gets ", ", where some cases won’t fit certain radiators in certain locations, and so a technician might end up moving the radiator mounting around depending on cooler. That invalidates the test, because it’s no longer standard: A radiator mounted in the top will be under different case ambient conditions than a radiator mounted in the front. Further, this would change the fans installed in the case, also invalidating results and making them incomparable. Other coolers will react differently with the pressure system of a case, where a sufficiently tall cooler might draft air from the top venting (if no fans are present and a negative pressure system exists near the cooler). This wouldn’t be equal across all devices. While it’d be a valid result, it’d only be valid for that case. We have case reviews for that.", "We’ll talk about each of these points in the ensuing paragraphs, but here’s what you can expect us to cover:", "Again, these will be addressed in paragraph form below, but we’ll start the items here:", "When we compare the thermal performance of one cooler to the next, we need to know what that really looks at. Ultimately, it’s the ability of the cooler to dissipate a known, fixed amount of energy being shed as heat. Knowing this, the most important control is power. If you don’t control the power that the CPU consumes, you won’t have any accuracy or like-for-like comparisons. Variables in BIOS or software will invalidate tests, and a lack of controls means the technician will never know. Power is the single most important aspect of cooler testing, and once that’s accounted for, everything else falls into place.", "This chart of intentionally bad data illustrates the most common oversight. These are some test passes we threw out because they were invalid from software variance, not from operator error. In other words, the operator did everything according to the SOP, but the application produced unexpected variance.", "Every one of the lines drawn should be equal to the lines marked in the legend as “GOOD DATA,” so orange and two of the blues. They all line-up with each other. The bad data is first illustrated with one of our Deepcool Assassin III test passes, where power consumption spiked from an expected mean of 156W to 163W. This spike can influence the rankings and would put the Assassin III under an unfairly high heatload compared to the others. 7 watts might not sound like a lot, but when everyone is fighting over fractions of a degree of difference, every minute deviation from the mean matters. 7W is still an increase in power consumption of about 3.8%, so that matters and the data is stricken from the results. In a scenario where this happens, we’d investigate it and run more tests, then determine if it’s a technician error or software error. If it's from our SOP, then we'd put new steps in place to fix the configuration. If it's from software variance, we'd re-evaluate use of that software or figure out how to better control it.", "Another example would be the Cooler Master 200mm cooler: In this bad data: In the bright yellow line above, we can see that the initial power spike in the soak test doesn’t go high enough, plateauing at 150W instead of 156W. The floor also comes down lower, to 144W instead of 150W, and the next spike is latent despite being an automated test. This is an instance where the software didn’t behave as usually expected, and although our test benches are disconnected from internet and stripped of services as a matter of practice, it’s possible that Windows did something anomalous in the background with scheduling.", "Even if you control the voltages, the frequencies, the ambient temperature, mounting pressure, and everything else, it’s still possible for test data to be completely wrong. This most typically happens because applications can occasionally exhibit spikes in power behavior from run-to-run, and most people just trust that it’s going to work the same way each time. In order to eliminate this concern, we have hooked up a current clamp to the EPS12V lines on our test bench and are monitoring power input constantly with physical, external tools, but we’re also using software to keep an eye on things. Software alone isn’t good enough – you really need both solutions to do it right.", "Here’s an example of how the power consumption should look. This is our new test bench with refined methods and software that GN custom-built to improve automation and reliability of testing. This doesn’t exist publicly and took months of testing for us to fine-tune. The first few lines here are from the Deepcool Assassin III with different speeds and some validation passes. The cooler performed strongly even with reduced fan speed as a result of its surface area and contact, clearly, and so power is almost perfectly equivalent from one cooler to the next. There are some spikes up-and-down, as you can see, but the peak-to-peak delta is 3W when looking at initial start of the test and the hottest point at the end. Our data is averaged at steady state at the end; the bench must be allowed to warm up for a sufficient period of time prior to averaging data, as there will be some power leakage over time as the CPU gets hotter. In this test, power leakage is low since the cooler is among the best performers.", "That brings up another point, though: separate from software variance and issues shown previously, we also have to keep an eye on power leakage with lower-end coolers that run hotter.", "We can next plot one of the lower performers.", "For this one, the ", " is behind the Assassin III in thermals in a significant way, to the extent that some additional power leakage shows up in testing. This isn’t error and is part of life with a lower-end cooler. We can control for this on dummy heaters that we’ve also built, but at some point, you do have to look at the real-world implications of using silicon that has additional power leakage external from software testing. In this instance, the power leakage is caused from running hotter, and so this is considered a valid metric in the test. The increase is about 4-5W from leakage. The best way to report on this is to inform viewers of the power leakage change while reporting thermal results. We want to make extremely clear that the previous sample data with variance was specifically from software behavior and the software’s inability to behave precisely the same way each time, whereas this test shows software behaving the same way, but power numbers changing as a result of cooler inefficiency. That’s an important distinction and is another item that most cooler reviews won’t notice or point-out.", "We’re next going to show you an example of a test bench that was controlled the same way as every other test, but anomalously produced bad data for one run. This chart is zoomed intentionally.", "In this one, we used the same BIOS profile as all the other tests and nothing changed on the bench or with software, and remember that it’s not connected to internet, but VCore still behaved in a non-fixed way. We ultimately resolved this issue by loading defaults and re-applying the BIOS changes, but this is another item that would produce errors in data and must be closely watched. That's a concern, because that means something assumed to be fixed (BIOS and voltage) became unexpectedly variable. At a technician level, this can create a lot of anxiety for data consistency.", "But we try to reduce anxiety caused by software and testing around here. We built some custom charting software to flag these types of deviations for us and notify the technician automatically. Since this isn’t even technician error, it’s an important thing to be aware of.", "In this chart, you’ll notice that the voltage should be a fixed 1.237V constantly for this particular test. It should be nearly a perfectly flat and predictable line. In reality, these rare test instances ran an average voltage of 1.240V to 1.244V instead of 1.237V, with the range from 1.237V to 1.244V on the second bad data set, and a fixed 1.244 on the worst. This impacts the power consumption of the chip and will impact thermal results during testing, potentially invalidating the result, contingent upon severity. When we’re already contending with potential software challenges, compounding that with erratic voltage behavior can create upwards of 15W difference run-to-run, which is a massive change. We’ve solved the software problem with our own automation programming, and as for the motherboard’s decision to randomly change voltage despite a profile being in play, we solve that with internal and automated red flags and careful technician oversight and retesting. Our future dummy heaters will completely eliminate this concern as well, but we still need real-world testing.", "One of the biggest mistakes is that people will just run “auto” without setting any controls on voltages or anything else. We see this a lot in our comments, where people will tell us their cooler performs at temperature Y, but without at least knowing the CPU and its VCore (not every board is the same), that doesn't mean anything. The case also matters, as does room ambient, the workload (AVX or non-AVX), and everything else we've explained.", "First, if you don’t control the frequency on a modern CPU – like AMD’s Zen architecture – then you’re no longer primarily testing temperature, you are primarily testing frequency. Temperature would be the secondary metric, but the sustained frequency under auto frequency settings would be the first. Voltage still must be controlled so that the power load remains fixed, otherwise the entire test is invalid, but frequency doesn’t ", "to be controlled and is still a valid metric if understood and presented properly. It'd be a frequency benchmark.", "For instance, if you want to show the frequency range produced between the best and worst coolers tested, that could be done without controls on frequency but with controls on everything else. Thermals could be useful as a secondary metric, but because they will no longer be comparable head-to-head as a result of changing frequencies, they are not the primary comparison.", "Here’s an example of how frequency changes on the 3800X with full auto settings, aside from XMP and 100% fan speed. The rest is automatic. Frequency bounces between 4125MHz and 4200MHz across the cores. Average core frequency is 4165MHz, but it’s all over the place. Voltage, not shown here, goes between 1.28 and 1.32, and in a pattern which is not repeatable from one test to the next. Voltage needs to be controlled in the least, and frequency needs to be reported as a result if not controlled. That’s useful anyway, since it puts an actual value aside from “well, it runs cooler” on the CPU cooling products. Frequency can be extrapolated to performance in a more direct way than simply being lower temperature.", "This is different on every motherboard and there’s no formula to it, but some motherboards will either report fan speeds as drastically different one header to the next, but actually be the same, while others will genuinely crank certain headers faster. For this reason, it’s very important to use the same fan headers every time and in the same order for the fans. It’s also just good testing practice, because it’ll reduce chance for error when working with data logging and analytics. We always plug the CPU fan into CPU_FAN on the motherboard, we keep CLC pumps in PUMP, and the second fan goes in SYS_4.", "This chart shows the speed differences. For the most part, we’re within error with our laser tach – about 2000 to 2006RPM. The CPU fan header runs reliably at 2030RPM, despite reporting about the same as the others. Inversely, the SYS 5 fan reports significantly higher, at 2070RPM, but reads about the same speed with a physical tachometer.", "It’s best to use the same exact headers in the same order each time.", "One of the larger variables is that of mounting pressure. Ideally, this would be controllable with a simple torque driver, but it’s not really that straight-forward. Each of the coolers has a slightly different torque spec for these desktop platforms, whereas Intel HEDT platforms are typically more conformed to a spec. In this situation, where backplates can change, standoffs might or might not be present, and hardware changes unit to unit. We can’t always rely on torque drivers. AMD provides a recommendation, but each vendor can deviate, and it’s not always possible to get a torque number from the manufacturers. It’d be nice if they published it, but most don’t, and we’ve even had trouble getting answers when asking our contacts. Ultimately, we’ve determined that the best approach is to use torque drivers where specifications are present, and to otherwise rely on reason and experience, but then perform multiple full re-mounts for validation.", "Mounting pressure has some of the highest potential to influence performance, but it’s also difficult to screw-up if you know what you’re doing. That’s the good side. It’s also easy to adjust for by doing full mount-and-remounts of each cooler under test. When remounting a cooler for additional test passes, we fully remove all mounting hardware and start from scratch. If any differences greater than +/- 1-degree Celsius emerge during this process, we know something is wrong and start isolating possible flaws in our testing versus the cooler. This is rare, but it does happen, and the only way to know about it is to actually re-mount and re-paste the cooler. Relying on a single mount and paste job means you’d never know if your pressure or paste just happened to be wrong that time.", "Here’s an example of some data where the mount was a problem.", "In this scenario, the first test pass with the stock cooler paste we invalid. First of all, it’s basically impossible for paste to be this different, and secondly, Thermaltake uses Asetek’s paste anyway, and so do we, so the only actual difference is that the pre-application is slightly less coverage on this particular platform than our manual application. We further determined this data was bad by re-mounting the cooler and identifying that the mounting hardware was not fully seated, thus creating erroneous data that did not represent performance. Our software and spreadsheets flag deltas this large within a single cooler and we receive a notification to go investigate why a such a large gap could exist on one product with the fans at a fixed speed. 10 degrees is obviously not a real result.", "It’s all about being equipped to identify test errors and differentiate them from product flaws, and that’s what we’ve specialized in for over a decade now. This is an inside look at what we normally do silently behind-the-scenes. Rather than just proclaim that the stock paste is garbage, we investigated to ensure it wasn’t our fault. Separately, we have the same silk screens that most factories use to pre-apply paste, and we also have their stock pastes – often Shin etsu or Dow Corning – and so we can effectively re-test the pre-application by using the same process as the factories. We picked-up tools and pastes for this while touring factories last year.", "Some of the charts above are on our old bench, some are on the new bench, but they’re all fully self-contained (chart-to-chart) and aren’t going to be used in future results. Most are to illustrate bad data and the high chance for test error if you’re not building around the expectation of bad data. Trusting the system is bad.", "The hardware we’re using will vary only contingent upon whether it’s a “real” workload or a simulated workload, but for the most part, it is as follows:", "Our tests for finding the best CPU coolers include:", "Data analytics are diverse, but primarily boil-down to:", "For frequencies and voltages, we are using a mix, so you’ll need to check information per review to double-check what was used for each chart. We primarily use these:", "The only goal is to generate a known, ", ". For this reason, the ", "as long as it is known reliable. We could push our 3950X to about 4.3GHz all-core, and sometimes 4.4GHz all-core, but then the problem becomes that we lose the ability to test lower-end coolers on the same platform (gets too hot for anything but large liquid coolers); further, 4.4GHz isn’t always stable, so it’s best to increase voltage to generate the desired amount of heat (power) and then set a frequency that’s known good.", "As a note, the system runs entirely passively other than the CPU cooler when taking noise measurements.", "CPU cooler reviews are remarkably challenging for how simple the product seems. Even today, we've seen improvements in air coolers despite decades of refinement. It's an exciting component to test that mixes aspects of acoustic and thermal performance with visuals.", "Writing an updated sentence here, now in 2023 (the rest of this article was written in 2020), we are working on our next major advancement in methodology. Most of these methods remain, but we'll be changing our test bench components and focusing on some new and emerging trends within the CPU side of the industry. We're excited to bring that update to you -- it'll be the next major methodological overhaul to our cooler tests, now incorporating the past 3 years of using the above methodology.", "Note that there is some additional information in the accompanying video, mostly relating to the dummy heater. We'll talk about that more separately."]},
{"title": " Mega Size Air Cooler: Deepcool Assassin IV CPU Cooler Review & Benchmarks", "paragraph": ["Mega Size Air Cooler: Deepcool Assassin IV CPU Cooler Review & Benchmarks", "Last Updated: ", "The Highlights", "We’re back with a high build-quality air cooler today: The ", " has strong points in mechanical design and usability. As a dual-tower, dual-fan cooler, its biggest weak point will be price. The cooler is $100, meaning its closest price competition will be liquid coolers and its closer air cooler competition costs around $60 less.", "But the ", " does a lot that we like from a design, build quality, and functionality standpoint, even if it will be challenged on the value front.", "In our review, we’ll be looking at pressure, thermals, and acoustics in-depth.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "The air cooler market has gotten unbelievably fierce in the last couple of years. A lot of this is because of the ", ", which has recently become a first-party supplier of its own coolers. DeepCool is also in this camp, able to manufacture its own products rather than relying on contract manufacturing like Noctua. This gives both DeepCool and Thermalright a price advantage where others can’t compete. There’s no middleman.", "Let’s fly over the Assassin IV’s features.", "The most obvious is that this dual-tower uses a reverse 120mm fan on the back-side to pull air through and a central 140mm to draw air into the cooler. The benefit of the 140mm central fan is that it’s shifted downward, keeping good compatibility for height clearance while still utilizing the 140mm size to push air over the heatpipes and into the VRM area of the motherboard.", "The front of the cooler doesn’t include a fan, but DeepCool includes a bracket that can be installed on any 120mm fan to add a third and front intake fan to the cooler. The metal mesh top piece is for looks and can be easily removed to reveal the central 140mm fan, which pulls out with some simple clips.", "The cooler looks large, but it’s a bulked-up dual-tower design with a lot of plastic and mesh metal embellishments. The actual finstack is still sizable, but smaller than the outside appearance: The plastic helps act as a flow guide to retain flow through the center of the cooler, while the mesh is strictly for looks since it’s encasing a solid plastic fan housing.", "This brick of a cooler has 7 heatpipes that run through a nickel-plated copper cold plate. It also has a “toggle” for performance or quiet modes: In other words, DeepCool includes a resistor in-line which can connect to both fans. In “quiet” mode, the resistor reduces the maximum power delivered to reduce the effective RPM. It’s a physical switch to instantaneously toggle the fan speed. This is primarily useful if you want to more granularly tune the lower-end of the PWM curve.", "The front of the cooler has a checkerboard pattern that’s only for looks -- there’s no meaningful change in performance. The back is interesting, though: There’s a gap between the fan and the heatsink and the fins draw inward to form a concave dip centrally. This allows the dead zone behind the fan hub sufficient distance to get more even pull across the entirety of the finstack. That central area right against the fans is often dead and underutilized.", "That covers the cooling-centric aspects of the Assassin IV. DeepCool also has a number of finer attention-to-detail items that we noticed. One such detail is a small channel for cable routing for both of the included fans. DeepCool notched-in a gap in the finstack (and in the plastic fan housing of the rear fan) to make it easy to nest the cable out of sight. The cooler also has very clear markings indicating the orientation for each bracket or fan, and the included fan bracket was made in a way that it retains compatibility with non-DeepCool fans.", "Unfortunately, the middle fan isn’t so compatible. The central 140mm fan uses an odd body shape to keep the vertical clearance and minimize loss of surface area of the heatsink, but that also means that there aren’t any alternatives that could go here. We will delve more into that below. ", "We also noticed that the fans produce an annoying whine. We tried, but were unable to eliminate it. Check out the noise ", ". ", "The 120mm fan is easy to shift up and down to clear rear IO covers, so we tried moving that around to eliminate the noise -- but it was still there. The overall noise of the cooler is low enough that we think most people won’t notice this through the walls of a case and the other noises of a system, but this is one of the main areas of improvement for DeepCool -- and also an underappreciated area where Noctua excels. We talk about that in ", " at Computex.", "That’s enough of the basics. Let’s look at cooling performance, then we’ll talk about the installation, our criticisms of the process, and the compatibility issues with 140mm fans.", "This CPU cooler testing will look at the best air coolers and liquid coolers for high-end CPUs. Although the data was collected on a specific set of Ryzen hardware, it is largely scalable to other CPU heat loads -- especially AM5. Intel will have some differences, but the concepts are there. We will soon be updating our cooler test bench, but for now, this one remains our primary and battle-hardened solution.", "Our first thermal test is at 100% fan speed, so we’re allowing the coolers to run however loud they’re going to run when maxed-out. We’ll look at the noise-normalized testing momentarily to establish the more directly comparable numbers, but this is a battle when run all-out. Fan RPM for the Assassin IV will be listed as an average of all present fans, which is important for you to know since they spin at different speeds.", "We tested at 100% in a few configurations: The first was stock and with the performance option on the RPM switch; the second was with the “quiet” option on the switch, which is really just a lower RPM; the third and final was at 100%, performance, and with 1x 120mm fan added to the front. We used the fan from the ", " from another cooler.", "Here’s the chart.", "The Assassin IV’s “default” setting -- performance and with 2 fans -- logged a result of 53 degrees Celsius above ambient. That has it roughly tied with the ", ". The noise level between these two is also functionally the same and within error and variance. The Assassin has a big VRM cooling advantage, but we’ll come back to that. For CPU thermals, the Peerless Assassin is fiercely competitive. That’s made easier by the fact that Thermalright is now owned by a factory.", "Adding an extra fan to the Assassin improved thermals by 2 degrees, which is significant and outside of error -- that’s a real benefit. Not necessarily worthwhile, but real. Noise also increased, but only on the edge of being noticeable.", "The “quiet” setting dropped RPM average between the two to 1287RPM and the noise level from 44dBA to 37.5dBA at 20” distance in a noise floor of 26dBA. That’s a big drop in noise levels. The result was a 2-degree increase, landing it between the quieter ", " and other DeepCool solutions, like the ", " and ", ".", "VRM thermals are up now. For this test, we’re pulling from the same dataset as the prior chart and using the same test conditions. We’re measuring the thermal response of two MOSFETs under the CPU cooler. Liquid coolers have their radiators mounted next to the VRMs in a way that would be equivalent to a top-mount in a case, so they are mostly comparable against each other.", "In the chart, the Assassin IV with 3 fans ended up running a 37-degree and 31-degree (over ambient) set of FET temperatures. That’s a slight improvement in VRM1 over the dual-fan setup, although VRM2 is unchanged. Realistically, they’re about the same.", "Compared to the ", " though, the ", " is 7 degrees cooler when using the stock 2-fan setup and performance mode. The main takeaway here is that these 140mm fans extend down below the finstack more, deeper into the motherboard, and so are able to get more air into the VRMs. 7 degrees is a big difference. We saw this also on the Assassin III with its 140mm fans.", "Moving on to the noise-normalized tests, we really only need to look at one number. “Performance” and “quiet” modes no longer matter because we take control of RPM.", "The Assassin IV ran at 56 degrees over ambient, still leaving a 10-degree range up to the best liquid coolers, but tying itself among the best for air coolers. That’s marginally better than ", " and Assassin III and about tied with the Peerless Assassin.", "Ultimately, for the quietest cooler capable of the most cooling, you’re still best off with a liquid cooler. It’s just not possible to achieve the same performance with so much less surface area (and a less efficient medium), but air coolers are often in the “good enough” category for their users. This is one such example. The biggest difference is that soak time is longer on a liquid cooler, so the fan ramp is more gradual and less noticeable when using a curve.", "Pressure testing is up next. This evaluates the quality of the mounting system, but not the flatness of the cooler. This test allows us to examine how evenly the hardware distributes the pressure. This testing is made possible with our pressure map scanner, which we bought thanks to support from our Patreon backers. You can go to ", "to throw a few bucks our way to help us continue to self-fund our biggest testing investments without outside influence, or grab one of our GN store products!", "First with the 3950X, we observed a central high pressure area of good contact in both scans. The outer corners had limited contact, but since the die is in the center, it ended up working well overall. ", "Adding our 3800X scans to this image, you can see a similar pattern on a different CPU. The cooler applies high pressure centrally. The corner pressure you’re seeing in all of these scans is an artifact of the test setup: In reality, it’s almost no contact, and the corner pressure represented here isn’t the loaded pressure. Rather, that’s a natural course of installation.", "Flatness is our final test. In this testing, we use a high-precision needle to measure depth from a known 0-point. This is taken in microns of deviation in flatness. A flatter surface is not necessarily better, but what is better is a lack of significant deviations that may indicate pitting or uneven leveling.", "The box indicates the median, while the upper and lower points on the line indicate the extremities of the quarterlies in this plot.", "The Assassin IV is one of the better coolers we’ve tested. It’s far more consistent than the Spirit 120 or the Amazon Basics coolers, and overall, we’d call this good.", "To get a visual breakdown of the installation process from Mike on our team, we suggest you check out our ", ". Consider grabbing one of ", " for your PC builds as well -- it directly supports this work!", "As mentioned, the DeepCool Assassin IV comes with a 120mm fan and a 140mm one. The 120mm fan is a reverse in-take solution, which you can swap out with any other standard 120mm fan. ", "The 140mm fan, however, has external fan hub dimensions that are unique to the Assassin IV, which means using the provided bracket on other fans proved troublesome. We couldn’t find a fan in our inventory that would properly fit it. We also couldn’t find an exact replacement online either. There are technically options from DeepCool, but not formally. You can see one in our video.", "In terms of installation, we started on our AM5 X670E motherboard, removing the stock mounting brackets. From there, we screwed in the cooler’s standoffs and added the cooler’s brackets. One thing we liked about the brackets is that they have arrows pointing towards the CPU, which help orient installation. Once we had that in place, we secured it with 4 nuts.", "Before mounting the Assassin IV onto our CPU, we removed the fans to make it a little easier to work with. From there, we place the cooler down onto the CPU, line up the standoffs with the captive screws on the Assassin, and tighten them up. Once that’s done, we snapped the fans back on. The 140mm one clicks into place nicely, and then you add the magnetic top cover back into position. ", "Finally, the top channel (with the central fan removed) is used to tighten the cap screws to secure the cooler to the brackets:", "You can adjust the fan bracket up and down on the cooler to make room for RAM clearance, which is a nice touch. ", "Mounting the cooler to our Intel build, the Assassin IV comes with a metal back plate that came pre-assembled, which is a nice touch that saves time and frustration. The backplate is secured by 4 screws/standoffs.", "From there, we line up the cooler’s brackets to our LGA 1700 socket, and the rest of the installation is the same as the aforementioned AMD build. ", "One criticism worth calling out is that we would have preferred Phillips head screws as opposed to the provided hex head ones. The tool DeepCool provides is also cumbersome and awkward to use. ", "Overall though, the Assassin IV was easy to work with. The mounting hardware was intuitive, and installing and adjusting the fans was also easy. ", "The most favorable aspect of the ", " is its overall attention to detail and build quality. This cooler is built well. The ease-of-installation and attention to detail features are also excellent, like the cable channeling, markings on the fans and brackets, and even the in-line resistor and switch.", "None of these things fix the value: This is built like a high-end cooler and it has a price to match. The Assassin IV is expensive. At $100, liquid cooling options (especially the ", ") can outperform it by several degrees in a like-for-like test, especially when noise-normalized. If you cringe at the idea of a liquid cooler, then even the ", " -- which shares half of a name -- is a competitive alternative at a much lower price.", "DeepCool is trying to sell on other features, namely: Better VRM cooling (a fact it may not even realize, but now will), better build quality, and subjectively, maybe some advantage in the looks department. You pay a big premium for that.", "The biggest downside is the fan whine and the 140mm compatibility, which we think DeepCool can resolve with some fan tuning as the blades interact with the finstack and the latter can be solved by selling the 140mm fan separately.", "Our conclusion then is a fairly simple one: We like how this cooler is built and it has managed to become the #1 air cooler on our charts, it also excels in VRM cooling. We would be happy to recommend buying it, but only for users who aren’t value seekers. You buy this if you’re looking for a “best-in-class” air cooler and you want the premium feel. You don’t buy this if you want something that achieves nearly all of the performance for less than half the price -- which you can get from Thermalright as a strong alternative.", "The market is competitive right now. This isn’t a value cooler. It’s fighting more similarly to Noctua -- performance and fine-tuning. But Noctua wins on the noise profile, while DeepCool is winning on the thermal profile in our testing."]},
{"title": " Arctic Liquid Freezer II Cooler Review: New Best CPU Thermals on AMD Ryzen", "paragraph": ["Arctic Liquid Freezer II Cooler Review: New Best CPU Thermals on AMD Ryzen", "Last Updated: ", "The Highlights", "Today’s review has been the most-requested review from our commenters for about 6 months now, and it’s not even a piece of silicon. The ", " series has gotten heavy community interest because of high reported performance in the enthusiast forum user base. We wanted to look at it with our ", " that we started developing in the last half of 2019 (when the Liquid Freezer came out) to see how the Liquid Freezer performs against incumbents, including the NZXT Kraken X62 (similar to the ", "), the ", ", and a growing list of others. The Liquid Freezer’s biggest marketing point, currently wedged in between being a gimmick and a useful feature, is its included VRM fan on the coldplate housing. Our review includes benchmarks of VRM thermal performance with and without this fan, tested in A/B fashion, and also tests surface levelness, CPU core thermals on the 3950X and 3800X at 200W and 123W, noise tests, and time-to-max temperature.", "As with most liquid coolers there’s a lot of different radiator sizes for this, but we have the 280mm that we’re reviewing today. We’ve done dozens of ", " over the past three years or so, and we’ve just booted up our new test bench that includes air cooler reviews. Critically, our new test bench bakes in the new VRM thermal testing. We've been slowly collecting this information and we can finally look at whether this included 40mm VRM fan on top of the pump housing actually does anything or if it’s a complete – as opposed to partial – gimmick.", "Steve Burke", "keegan gallick", "jack reitman", "The pump is part of the block on the Liquid Freezer - you can actually see the part on the bottom of the pump where the impeller is located. We also have a ", ". The VRM fan plugs in separately to the underside of the block. You cannot control the VRM fan through BIOS, but it’s also fairly quiet – you can’t hear it over the rest of the system noise. You can disconnect the fan if you want to, which is how we performed our “AB” test for VRM thermals. ", "Other key features for the Liquid Freezer include the fact that they’ve shoved the cables inside the tube sleeving, which is something Fractal did a couple of years ago on its subpar ", " series. There are no fancy RGB LEDs to speak of, but that also benefits the price. The reason this one is so interesting to a lot of people is because reportedly it’s a very good performer, but it’s also $95 for the ", ". At that point you’re competing with the ", ", which was the ", " 280mm CLC you could get, at close to $120 for a while. Something like an NZXT Kraken series X52, X63, or X62 will cost $150-$160 for basically a bunch of LEDs, because otherwise the thermal performance from one 280mm CLC to the next (especially if they’re all Asetek) is not all that different. So the delta in price alone is massive.", "The next big question outside of thermal performance is endurance, which we can’t obviously test within a review cycle, so that’s going to be something we’ll have to revisit if something goes wrong in the future. We can speak to the modern Asetek coolers lasting generally a very long time, such as the NZXT units we’ve had – eight or so X61 and X62s in deployment since they came out – have a warranty of six years. Extreme permeation is expected to set in around the six year mark at which point you could maybe refill it if you had to, but depending on the climate you’re in, the use case, and how intensive it is, you may have already had extreme permeation set in. ", "We don’t know where that is going to hit with the Liquid Freezer, but if it follows the design philosophy of most coolers then it should be around the same period, but it has a much shorter warranty (two years, depending on region).", "Before we get into the thermal numbers, we revised our testing methodology - we have a ", " and ", " version available. It’s the same content, so pick whichever you prefer and catch up on how we do this test. We are not going to recap the methodology in full here. When we do noise-normalized testing, we set the product as it is to the same noise level as every other product (to some fixed noise level that we’ve chosen at a 20-inch distance from the product), but we don’t change the fans. So, normalizing for noise does not mean normalizing for fans – we use the fans as they are mounted on the product.", "Our next chart will be of the VRM fan performance, but we’ll start with the one everyone is used to. For this one, we’re using a 200W workload with the AMD R9 3950X, which is more useful for stressing the differences in high-end coolers. This test is equalized to 35dBA in order to level the playing field so that coolers can’t just brute-force their way to the top, like the ", " would do at its 60dBA baseline for noise at 100% speed. ", "The Liquid Freezer II ends up as the top-performer on the bench when noise-normalized to 35dBA across the board. The Arctic Liquid Freezer results were benched six times each, with and without the VRM fan, and with 2 sets of re-mounts, plus additional tests of three to six times each for the 3800X and the 100% results. The deviation run-to-run across the board was under 1 degree, so consistency was good. The 52-degree load result has the Liquid Freezer II about 2 degrees cooler than the X62 at the same noise level. It’s outdoing the NZXT X72 and ", ", which both struggle at these lower noise levels because they have too many fans at too small of a size, and so they lose pressure, which they need to push air through the radiator effectively. The NH-D15 is outdone by about 6 degrees Celsius by the Liquid Freezer, which is enough to allow some potential for additional overclocking headroom. ", "At the $95 price, Arctic II 280mm solution is kicking everyone’s ass, especially the NZXT Kraken. The NZXT Kraken X62 isn’t anywhere close in pricing, and although the newer X63 is $10 cheaper at $150, its performance isn’t much different, and the price is massively hiked over the Arctic solution. If you’re only going for function and cooling (outside of reliability which is yet untested) the Arctic is doing better. The ", " air cooler gets buried even deeper than it was at launch. The NH-D15 or ", " still have the same uses they always had, mostly related to those discussed in the air vs. liquid content (like reliability and overall simplicity). Other CLCs will mostly come down to LEDs or warranties. The Liquid Freezer isn’t yet tried for reliability, and that’s a huge component of coolers that we have no way of accelerating for a review.", "The next test will be for the VRM fan. For this, we’re going to start with an overlay demonstrating the linear feet per minute flow, often called FPM or LPM, as measured with a hotwire anemometer at the edge of the chassis for the cooler. The measurement is taken at an angle toward the VRM heatsink and the chassis is defined as the pump block housing typically (where the coldplate is). We measured at a few points and under a few conditions.", "For this image, the VRM fan was enabled and the radiator fans were disabled, as was room AC. The FPM baseline was 0 – meaning air was almost literally not moving in the room (we like to simulate a tomb where we work). North of the socket, aligned with the top-center of the cooler and center of the fan opening, the FPM measured between 190 and 212. It fluctuates as usual with fine air movements. The northwest corner of the cooler, measured at the top-left screw of the mount, measured at about 197FPM toward the VRM. The upper-left side measured at 422FPM, as we seemed to find the exact angle at which air exits the chassis the fastest and hits the VRM. The mid-left side fell to 96FPM, as we were at the edge of the chassis opening.", "The next measurement is at 100% radiator fan speed, with the radiator mounted approximately 1cm away from the edge of the board. This is a similar distance to what you’d find in a lot of cases, with fans blowing toward the motherboard. In this configuration, linear feet per minute flow is about 266-275. With the radiator fans blowing and the VRM fan off, measured on the other side of that solid VRM heatsink, FPM predictably drops to 64-66. ", "This is obviously still plenty high on the other side of the heatsink (the side towards the fans) – north of 400FPM, actually – so it’s not like all cooling has vanished. That said, if you front-mount the radiator, having the VRM fan on the block could be somewhat beneficial in scenarios where an overly hot configuration is used and you have no fans at all in the top or rear of the case. However, most people should have at least one fan in one of those positions.", "Before moving to the VRM thermal chart, a few important points that we need to go over: first, this is all relative, so our measurement points aren’t designed to test the motherboard, but rather to test the cooling capabilities of the CPU cooler on top of it. We’re taking VRM measurements at points that will work better for testing cooler impact, since we don’t care about comparative VRM performance from one board to the next and we’re not looking to see if the VRM is any good. ", "Second, we’ll show the numbers with the radiator mounted to the side of the bench. That’s how we tested all the liquid coolers so far, as it is more similar to a top-mounted radiator in a case. This means there’s always airflow over the VRM heatsink in all the CLC tests, whereas testing it on the table, away from the VRM, would paint a picture of Arctic’s VRM fan having a higher relative impact since you’d be taking away all other cooling otherwise. We have these numbers too, but let’s focus on 3950X OC numbers at 35dBA radiator fan speed first, with the Arctic VRM fan at 100%. The test is also tough to standardize since every motherboard will have different heatsinks and positioning, so although you can mostly extrapolate out a hierarchy, it’s not perfectly comparable to every configuration. And again, please also remember that case configuration has the greatest impact on VRM thermal performance outside of the VRM design and cooling solution. What we’re saying is that this test will create an objective hierarchy, but that in all reality, a couple degrees here-and-there in a controlled test won’t really matter much when considering the VRM is unlikely to melt itself in the majority of instances anyway.", "Here’s the chart. ", "The Arctic Liquid Freezer’s VRM fan is both a gimmick and not a gimmick. It’s not a gimmick because it actually works: the top result is with the VRM fan on, measuring at 34.7, 38.3, and 28.4 degrees over ambient for our three measurement points; reminder that these are averages of averages, a couple thousand cells of data at that point. The Liquid Freezer with the VRM fan off loses a few ranks, consistent across all 12 total test passes for this one chart (and we have about 24 test passes for the other 3 configurations we ran). The result falls from 28.4 for VRM2 to 33.6, a change of about 5 degrees Celsius, and from 38.3 to about 42.6 on VRM1. So yes, it works and is therefore not a complete gimmick. ", "At the same time, it’s not really relevant. It doesn’t hurt to be cooler of course, but this one feature shouldn’t be the tipping point between you buying the product and not. If it’s between this and another cooler, and you mostly have your heart set on the other one for visual or compatibility or warranty reasons, don’t let the VRM alone sway the decision. If your board is going to run so hot that you need an extra 5-degree reduction, it’s probably time to find another board or case solution altogether. ", "That said, this does reduce temperature and it does work, and in cases that are really hot and closed-off, with a 3950X or higher-power chip, with overclocking, and with a VRM which is undercooled and overheated, this would be a value add. We just don’t think that’s going to be a very common scenario for people spending that kind of money on a 3950X, and while it gets praise for doing a good job and chart-topping, we don’t think it should be the deciding factor in the purchase since an extra couple of degrees if it’s already that hot would mean you likely have bigger problems and it’s time to find more than just that solution.", "This next chart is quick. This is our time to steady state at a noise-normalized 35dBA, or the time at which we reach equilibrium on the 3950X. Liquid coolers take longer to reach equilibrium than air coolers as a result of their water capacity that soaks rapid heat changes better. Big air coolers have well-marked advantages, mostly the install-and-forget benefit, but also reach steady state in a quicker time - just 90 with the thermal load that we are testing. Liquid coolers afford longer periods of low thermals for bursty workloads, which can also help with controlling or soaking fan speed changes with any kind of fan curve. That’s discussed in the previous video, but the Arctic cooler is the new item for this chart. ", "We found the ", " reaching steady state in approximately 311 seconds, or about 5.2 minutes. That’s a longer period than the Kraken X62’s 260-second interval (4.3 minutes), which is one of our bench-toppers currently. The X72 and ", " do poorly here, mostly because the noise requirement is low enough while the fans are small and plentiful enough that they struggle to reach the static pressure required to compete with the 280 CLCs. The CLC 360 takes the longest to reach steady state because it’s burning in this test, so it becomes a matter of the liquid temperature running higher on average than the Kraken or Arctic series. That’s why it has an asterisk next to it – the data isn’t directly comparable.", "Our next chart continues with the 3950X 200W load, but allows all the coolers to run at 100% fan speed during the test. This doesn’t move the needle much for Arctic, which seems to top-out in its efficiency at around 1200RPM rather than its maximum 1600RPM. The results were +/-1C as usual, but our average ended up at 50.9 degrees over ambient. That’s not enough of a change, so there’s room to reduce noise level without much loss of overall performance. ", "At the 1610RPM speed, the Arctic cooler ran at 42.5dBA at the normal 20” distance. This puts it about equal in thermal performance to the NZXT Kraken X62 and X72, which run at 51-53dBA, or a perceived noise increase to the human ear between the Arctic and Kraken cooler of about 2x. Again, that’s perceived noise loudness to the human ear, not acoustic power, which is a different scale. Arctic’s solution is significantly quieter at the same performance. The EVGA CLC 360 shows that we’re not limited by our test bench (there is room to improve still), but also that jet engine levels of noise are needed to drive the temperature down further.", "Moving briefly to the 3800X, we have to issue a reminder that this CPU is tested with completely different voltage and overclock settings, not to mention the fact that it’s physically a different CPU in dies and as a CPU. This would be the same if we tested it with a different 3950X too - the IHS is different, the silicone adhesive is different, so these results are not directly comparable to the 3950X results. It’s just a lower power test to show you another look at things.", "The 3800X was intended to be our standardized platform before we got to these higher-end coolers, the charts level-off a bit with the big air coolers and the liquid coolers as discussed in the two recent cooler videos we did. The reason they level off is because the heat load isn’t enough and the gap between coolers begins to shrink. These larger coolers do better at showing their differences once there’s a higher heat load that can stress the smaller coolers beyond what they’re really capable of. This is why the ", " does so well relative to the large air coolers in this specific test.", "For the Arctic Freezer at 35dBA, we see a 51-degree load temperature, putting the cooler just below the Kraken X62 while remaining significantly cheaper. Idle temperatures also plot the lowest for Arctic, not that this is particularly useful, and that’s partly because of the VRM fan slightly reducing heat in the area of the socket, which does end up affecting CPU temperature as well.", "For tests which leave the frequency to auto but control the voltage, we instead report on frequency rather than thermal outcome. Note that the best frequency doesn’t mean it’s the coolest – it becomes a touchier subject, since frequency jumps around to begin with, and because a better cooler means Precision Boost 2 will kick into higher frequency automatically, which creates more heat. This is not as reliable or simple of a metric, but so long as you have the error baked in, it’s okay. ", "For auto frequency and normalized to 35dBA, the Liquid Freezer II chart-tops with the 3800X at 4253.5MHz all-core average, followed closely by the big air coolers. The ", ", ", ", and ", " are all within error and test variance, as is the ", ". Gaining an extra 50MHz over a high-end air cooler is about the difference you can expect if you’re not planning to overclock - the X62 would be in here as well with the Arctic cooler. ", "It’s not like that’s going to equate an FPS advantage that’s noticeable to the human eye, and it’ll only help render times extremely marginally – we’re talking seconds on the hour, maybe up to half-a-minute on the hour. It’s not worth stressing about, but it’s another small benefit of having a better cooler.", "Our next test is for the levelness of the coldplate surface, measured with special precision instruments for testing that we debuted in our Corsair A500 review to show its biggest pitfalls. This testing helped illustrate where the A500 went wrong, and it was in the levelness of the coldplate, causing large gaps that required more TIM to fill than was reasonable for a $100 product.", "This shows the delta in height, measured in microns, from a calibrated 0-point. The A500’s box plot shows the largest range, illustrating the chaotic levelness that hurt its performance so much, while the DeepCool Assassin III and original Wraith coolers have some of the best surface levelness. The Arctic Liquid Freezer II averaged about 8-10 microns depth from the 0-point, with minimums and maximums at 2 microns and 48 microns respectively. The Liquid Freezer II has a couple deep points in the coldplate, but is overall closer to smooth than unlevel.", "Our last point is on installation and mounting hardware. Coolers typically differentiate themselves by falling into one of two categories for ease-of-installation: you can either install it literally single-handedly or you need three hands, a forehead, and some tape to install it. Liquid coolers typically fall into the easier camp, and that’s because the mass on the socket isn’t as stressful for the board, so less meticulous, fine-tuned mounting hardware is required than with a massive heavy cooler. It’s easier to seat a couple of threaded screw caps onto a backplate to hold it all in place, and then drop the cooler down and install some more cap screws.", "The Arctic Liquid Freezer is not one of those. It’s not the easiest we’ve worked with, but it’s not terrible. But basically you’ll want to install this flat on the table. If you can (without installing the radiator into the case first), ideally what you do is seat the AM4 (or Intel) backplate under the motherboard, put it flat on a table, and then socket it because you only have four screws for this. If the board is suspended in any way (test bench or case), you’ll need one hand to hold the plate, one hand to align the cooler housing, and a third hand (we typically grow them out of our stomach) to install the screws. Arctic has cut down on their mounting hardware as much as possible - it cuts down on cost and in theory is simpler. The only downside is that in the instance where the motherboard is already installed, then it becomes inconvenient.", "However, you can grab some tape to hold the backplate in place for a bit, and then you’ll be fine. It is just annoying to do, but not a deal breaker in any way. You typically install a cooler once every couple of years, so you’ll rarely ever need to worry about it. There’s not a major point other than to say that we’d like to see Arctic consider moving to a system similar to Asetek or some of the other companies where it’s a backplate and then you have a threaded rod that holds it in place, and then you socket the cooler on that and put a cap screw on top. ", "For the fans, you’ll be working with small 2-3 inch fan cables attached to the fans, so you may want a cable extension if you are planning to run the cables to the motherboard. This is what we do because we like to control things directly through different headers so that we can fine-tune it. If you’re ok with it, you can connect to this splitter, but even this is kind of short and also you lose some of the control - the finer control that you get by going into the motherboard. We are normally hesitant to request that a company include extension cables in the box because if most people don’t use them, then it’s wasteful. Even if you don’t care about the e-waste aspect, you should care about the fact that your money is still going into it - it’s not free. However, if it is something most people are going to buy, then it does help to include it and brings the cost down to economies of scale.", "At $95,  the 280mm version of ", " kicks the ass of the other liquid coolers we’ve tested so far. The closest thing to this (which is not on this bench) would be the ", " and they’re both stripped down for LEDs and are somewhere similar in price, but the ", " is just a better product. We were surprised to see it do as well as it did, not because it should do poorly, but because at the price, you really don’t expect it to outperform something like a ", " or X62 in a way that is measurable and repeatable; not error or lost from run to run variation. ", "We ran this thing at least 12 times for one configuration and we ran multiple configurations, so it should have been at least 24 separate mounts, but probably closer to 36, and the results were reproducible every single time, so a very good product with a good price.", "However, we can’t speak to the endurance of the cooler, which is something we always have to caution with liquid cooling products, but to be very clear the failure rate of liquid coolers overall is extremely low. It’s just that the ones that fail are catastrophic and can get a lot of coverage. You can learn all about that on ", " where we break these aspects down.", "The only thing you really have to consider is air instead of this because in terms of liquid, if you don’t care about the looks and you’re okay with just blackout and don’t need a bunch of LEDs and an infinity mirror, then this is the one we would buy for liquid at the price - it wins. With respect to air, the air coolers are close enough that you can still buy those if you prefer the install-and-forget-it nature or if you’re really paranoid about potential failure of a liquid cooler (which is not common, but is common enough where it is a consideration for a critical system).", "That’s it for this one. Go to the", " or", " to help us out directly. We’ll see you next time."]},
{"title": " Arctic's New $28* Freezer 36 Air Cooler & Contact Frame: CPU Cooler Review & Benchmarks", "paragraph": ["Arctic's New $28* Freezer 36 Air Cooler & Contact Frame: CPU Cooler Review & Benchmarks", "Last Updated: ", "The Highlights", "Hot on the heels of its chart-topping ", " series, Arctic is trying its hand at making another air cooler in the ", ". It also forces an Intel contact frame for LGA1700. This cooler follows the prior ", ". Arctic previously also made the ", ", which we ", ". But this doesn’t make the same mistakes of strapping plastic appendages to a cooler and chewing away at memory clearance, so we’re off to a much better start.", "Arctic tells us that the launch price of the ", " will be much lower than its official longer-term price, similar to what happened with the ", ". For 3 months, this cooler is supposed to be $27.71 on Amazon. The extra $0.71 shows that Arctic is innovating once again: Where some companies use $0.99, Arctic is discovering new numbers that can go in a price.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "Officially, this is a $52 cooler, which immediately makes it less interesting than the ", " at $35 or some other incumbents. But we’ll see how it does, and at least while it’s at $28 -- sorry, $27.71 -- it may be able to undercut Thermalright, which has played the game of undercutting everyone. ", "The most “different” aspect of the Freezer 36 is its fan mount, which snaps in four fat Phillips 2 screws on the back of the fan that push into plastic snap-ins on the heat sink. This is definitely “reinventing the wheel” territory: It’s an unnecessarily complex design that, although it makes a firm connection and a satisfying snap, is not a particularly wanting area of improvement in air coolers. The downside to this approach is mostly the relatively large tradeoff in finned surface area for the track that’s provided, plus the deeper cut for the plastic pop-in locations. Fortunately, this would work on any fan, so that’s a big upside. You could just screw these into another standard fan and theoretically pop it in the same way, although the indent in Arctic’s fan backside helps to ensure a flusher fit -- you’d possibly lose that with alternative fans, which might hover just off the surface of the heatsink.", "We’ll give them credit for a good design.", "The Freezer 36 is a single-tower air cooler, but it uses a fat tower. The dual-fan approach helps resolve issues of maintaining pressure through this 54mm deep tower by pulling the air through faster. As a reference, the ", " is about 43mm across, while the ", " uses 2x 40mm towers.", "This single-tower approach is still less total surface area than some of the popular dual-towers out there, but allows a compromise that still shrinks the total size. The Freezer 36 is 104mm across in total.", "The cooler is a simple 4x heatpipe design that uses a direct contact approach rather than a nickel-plated copper cold plate. ", "The total contact patch of the Freezer 36 is relatively small, at 31mm x ~41m, counting the aluminum part of the plate and depending how you count the staggered pattern of the heatpipes. That is enough to cover most modern heat spreaders though: LGA1700 CPUs are about 39x28, AM5 is about 34x34, and AM4 is about 37x37. ", "We’d expect the Freezer 36 to have its weakest performance on both AMD platforms as compared to competition. That’s part of why, for our testing today, we’re looking at Intel performance as well -- with the contact frame and fuller contact patch, it should perform disproportionately better there.", "But between the fan mount and the dimensions, Arctic manages to get an extremely clean-looking total package by establishing a flush mount on all sides. That also helps feed air through the cooler efficiently, at the cost of losing some “overspray” air that’d normally cool the VRM.", "Time to get into testing. We’ll be looking at thermals first and then we’ll talk about installation instructions and get into pressure distributions on both platforms. Then we’ll go over our thoughts on the pros and cons of the cooler’s installations. ", "Our noise-normalized 200W heat load on AMD is first. This one has the Arctic Freezer 36 at 59 degrees Celsius over ambient, or about 80 degrees when factoring in our ambient temperature. That still gives plenty of headroom thermally for even cases on the mediocre side. The result has it about the same as the venerable ", ", which was at one point the most noise-to-temperature efficient cooler on our charts. The reigning champion for Best Overall last year, the ", ", lands at 56 degrees over ambient and maintains an advantage over the new Freezer 36. The primary differentiator between these will be looks and price. Arctic has shown that it wants to compete on pricing this year, so these two may be closer than previously.", "Another noteworthy entry is the ", ", a 2-fan solution that is almost 2 degrees cooler than the Freezer 36.", "So far, the Freezer 36 handled the heat load, so that’s a good start; however, it has competition from several other dual-fan air coolers. In some respects, it has a slight size advantage favoring slimness as it is a relatively narrow heatsink with the single tower. If Arctic hits the $28 Amazon sale price for launch of this cooler like it told us -- and we have no way of verifying that since we’re filming before launch -- then its biggest strength would be comparable performance, if sometimes slightly weaker, while being cheaper than most of these other options.", "Moving to 100% fan speeds, we unbind the cooler’s fans to allow them to run as fast as they can. This eliminates noise equivalence but shows a natural point of differentiation.", "The Freezer 36 at 1,861RPM and about 39dBA held a 57-degree result, tying it with the Dark Rock Pro 4 (which was quieter) and the ", " (which was louder). The ", " remains one of the most acoustically efficient on this chart, but is showing its age. ", "The Peerless Assassin (watch our ", ") is up at 53 degrees, establishing a temperature reduction from the Freezer 36 of 3.3 degrees but running louder than Arctic’s solution.", "Our 123W heat load opens up the charts to add a lot more air coolers.", "Here, the Freezer 36 held at 56.5 degrees over ambient, which is about the same as the ", " single-tower, single-fan solution -- so that’s impressive for Noctua -- and improved on the ", ". The AK620 dual-fan cooler runs about 1-degree cooler than the new Freezer 36, with the FUMA 2 equivalent to the AK620. The Freezer 36 isn’t bad, but it’s also not a chart leader. It doesn’t get the same level of superlative positioning as the Liquid Freezer III (read our ", ") series does. The Freezer 36 mostly tries to compete on price (at least initially) and on looks.", "For 100% fan speed on the 123W AMD heat load, before moving to Intel thermals, which are pretty interesting, the results positioned the 39dBA Freezer 36 effectively tied with the FUMA 2 and ", " with 2 fans. The Peerless Assassin leads by 3 degrees on this chart, but the temperature range shrinks as a result of the reduced heat load.", "The Freezer 36 is again not particularly impressive for thermals here, but also not bad. It’s just OK. The result reinforces our earlier commentary, which is that this is more of a price or looks purchase than raw performance. There are better options for raw performance, even at the relatively affordable end (although the sub-$30 initial sale price makes this extremely competitive on cost).", "VRM thermals are interesting on this one. With our 200W load and noise normalized, the Freezer 36 had the worst VRM thermals of the air coolers on this chart. It’s still “fine,” in that this VRM can definitely handle running in the 70s without even an ounce of concern, but the point is to see where the air is going. On a hotter board with a worse VRM, this is where a top or rear fan in the case would benefit the MOSFETs. In this instance, this higher temperature happens because the Freezer 36 is a straight-through funnel of air. The fans are flush against it. The dual-tower design of other coolers allows some air to exit and hit the VRM, and not sinking the fans also means all the air goes straight in and out of the cooler mostly over the VRM heatsink.", "Finally, we move to Intel thermals. We ran a limited suite of a new 208W CPU PKG heat load with LGA1700 to represent air coolers and test the stock ILM against the included contact frame. We did not test other contact frames in this benchmark, and instead stuck with whatever mounting hardware came with the cooler as this is the most likely intended use. Of course, using a contact frame on another cooler will also improve its thermals.", "Here’s the chart. This tells an entirely different story, which is that the Freezer 36’s contact frame really works. Rather than underperforming against the Peerless Assassin as in the AMD tests with stock hardware, it now equates the Peerless Assassin. We can prove why by looking at the pressure tests momentarily. This frame levels the playing field significantly for Arctic on Intel specifically. Now, again, if you were to mount a contact frame for the Thermalright cooler also, it’d pull slightly ahead. But we’ve already proven that in the past and don’t need to keep doing it. This is about the included hardware.", "The AK400 (watch our ", ") helps set the limitations of performance. It wasn’t quite throttling, but was bordering on it with a 72-degree delta T over ambient. The ", " is about 3x the cost of the sale price of the Freezer 36, making Arctic and Thermalright look like a steal. We’ll have a separate review of the Corsair cooler with full depth soon.", "But the frame works. The core-to-core deltas listed on this chart help to illustrate some of that, where it is reduced from an 18-19 degree core-to-core delta to 16.8, closer to the cooler ", ".", "Let’s look at how it’s doing this.", "Up now, we’re going to use our specialized mounting pressure analysis software and machine to evaluate the contact pressure distribution across the heatspreader. This looks at the quality of the mounting hardware.", "As always, this section of our review is sponsored by our Patreon supporters. Thank you to everyone who contributes and helps fund our efforts over on ", ". It’s our Patreon backers who helped us foot the bill to buy this equipment. You can also go to ", " to donate one time at the bottom of the page or buy one of our brand new, ultra-comfortable ", " with soft interior. Our ", " are also almost sold out for this production run and won’t be back for a while, so if you want one anytime soon, now is a good time to order.", "Here’s the result for LGA1700 on the Freezer 36.", "We did two mounts. In the first on Intel, you can see the heatpipes making high pressure contact with the IHS. This is exactly what needs to happen. There’s a weaker spot toward the lower edge of this scan and on the second-from-the-top heatpipe, but otherwise, distribution is good. The second scan shows high pressure and even distribution across the entirety of the cold plate, with one exception up along the top edge. This is why Arctic is able to put up a fiercer fight with the Peerless Assassin 120 in our LGA1700 testing.", "As for AMD contact pressure, it’s also good. AMD doesn’t need a contact frame thanks to the overall flatter IHS design and lower flex of the substrate. That flatness allows Arctic to evenly contact the IHS in most places. Its biggest weakness is the heatpipes themselves, where we see lower pressure than the outer edges of the IHS. Ideally, the heatpipes would be lit-up as higher pressure in this test. It’s still good distribution and leaves few areas unsupported, but not as strong as the Intel mount.", "Up next, we’re going to go over Arctic Freezer 36 installation, starting with Intel before moving onto AMD.", "After installing the CPU, Intel users will have to install the cooler’s included contact frame. ", "To begin, Arctic recommends placing a piece of foam under the motherboard to capture the backplate that holds in the ILM. ", "From there, open the CPU socket latch and unscrew the stock ILM using the included right-angle wrench. ", "Once that’s done, install the Freezer 36’s contact frame, making sure the triangle on it lines up with the one on the CPU before screwing it down into place. ", "If there’s no pre-applied thermal paste on the cooler, make sure to apply thermal paste to the CPU. From there, mount and tighten the cooler down onto the motherboard, making sure to orient it correctly by having the Arctic logo legible like it would be if it were in an upright case. This is important because the exhaust side has an indentation that allows for better efficiency for the exhaust fan. ", "Finally, install the 2 fans by snapping them into place on both sides of the cooler. ", "With the CPU installed, remove the stock AMD brackets. ", "From there, place the included 4 standoffs into position and install the cooler's 2 mounting brackets. ", "If there’s no pre-applied thermal paste on the cooler, make sure to apply thermal paste to the CPU. Once that’s done, mount and screw down the cooler, making sure to alternate applying pressure between the screws to ensure even distribution.  ", "Finally, like with the Intel installation, you’ll snap the 2 fans into place.", "One thing we liked is the cooler’s fan-retention system. It’s simple to use and makes fan installation easy. ", "However, we didn’t like how the cooler forces you to use a contact frame on Intel systems. It would have been nice to be able to use the stock ILM in case a user wasn’t comfortable removing it. ", "Our AMD bench has the most data in the charts, so we’ll start there.", "Performance was overall middling in that set of tests. It can handle our 200W heat load, which is great, and it stays around the center of the pack for similar coolers. That means the ", " isn’t in a position to impress in big ways, nor does it win rights to superlatives about thermals in the title. It’s not “the new best” like the ", " was. But it’s good enough, and in no way was this a “bad” performer in our testing.", "From this dataset, that relegates the cooler mostly to a category of purchasing for price and looks. The pricing is the main reason to consider it: With Arctic’s promise of a price at $25.40 to $27.71 for the non-RGB models for 3 months, that’s extremely competitive with the ", ", the ", " (and undercuts it by a lot), the Scythe FUMA series, and most other big name coolers out there. ID Cooling still cuts lower and Thermalright has some models competing, but overall, that’s where Arctic does the best and is the most compelling. If you’re into this cleaner look, maybe that’s a selling point.", "As for Intel, the performance on our quickly built 208W heat load (or nearing 250W at the EPS12V cables), has it significantly better than a single-tower, single-fan solution like the ", " and about tied with the ", ". It’s also encroaching on Corsair’s new large cooler. A lot of this is thanks to the contact frame, which seems to work much better on this cooler than it did on Arctic’s new ", ". For Intel, we think it’s a more competitive option than for AMD. Beyond the contact frame, part of that is also due to contact surface area: The ", " can’t cover the full AMD IHS, despite getting close. There’s some loss of potential there.", "Overall, this falls in the camp of “it’s fine.” If the sale price were intended to be the permanent price, we’d probably give it more praise for value -- but we don’t want to commit that hard to praise of temporary value, as it’s going to change in just 3 months. But we’ll see. Maybe Arctic decides to keep it at this mark."]},
{"title": " We Made the Perfect CPU Cooler | Intel vs. AMD Curvature & Coldplate Engineering", "paragraph": ["We Made the Perfect CPU Cooler | Intel vs. AMD Curvature & Coldplate Engineering", "Last Updated: ", "The Highlights", "We’re using our $60,000 laser scanner to create a 3D map of CPU heat spreaders and CPU cooler with microscopic accuracy. We also had CPU cooler coldplates custom manufactured to match the curvature of the heat spreader when under clamping pressure from Intel’s ILM, which theoretically makes for a perfect match with the CPU IHS. The plan was to create a “golden sample” cooler for a specific CPU.", "Next, we used chemically reactive pressure paper and a calibrated scanner to test for contact between the different coldplates and IHS, then created a pseudocolor map of the pressure distribution.", "Steve Burke", "Mike Gaglione", "Vitalii Makhnovets", "Jimmy Thang", "And all of that brings us to our thermal testing, where we’ll finally get around to evaluating a long-running weak point in cooler reviews. When a cooler review only considers one IHS style, it’s possible that the cooler performs better on the other. We’ve been open about this weakness for years but made the decision to go with one platform since a proper review takes so much time. But a few months ago, we added Intel to our cooler test suite to accommodate both styles. Now we get to show you why we did that. ", "This will be a fun science piece on the design of coolers, coldplates, and heat spreaders.", "This is what makes cooler reviews complicated: In our laser scanner, you will see scans of cooler coldplates for the same model of CPU cooler -- except we had one of them custom manufactured. ", "Actually, these were custom-made by Scythe at our request for this testing. They didn’t sponsor this content, but shared a similar scientific curiosity. We wanted to test the same cooler in every single facet, except with only the cold plate changing to optimize for Intel or for AMD.", "It’s not news that an IHS has a slight curvature, but we’ve always heard that Intel had a more pronounced curvature while AMD is flatter. We’re validating that common industry topic today. We asked Scythe to custom manufacture coolers that would best fit the ", ", but we’ll see how it works in practice.", "The CPU is a known and fixed quantity. The only external factor is the ILM, which applies uneven pressure that can slightly bend the IHS and CPU under load. Let’s start with the CPU.", "Here’s a modern Intel CPU with the ILM clamped-down and at a 100x magnification. You can see that at the points where the clamp applies the force, at the middle edges on the long side, the CPU is clearly pushed downward and deforms centrally. ", " back when we reviewed the contact frames, which are known to flatten the CPU. We’ve already proven that they do in the past.", "That indent will absolutely manifest itself in the form of contact with a cold plate. We’d ideally want a coldplate to mate with it perfectly.", "What’s interesting is that an unsocketed Intel CPU just sitting flat in the scanner is almost completely flat, even if it’s been mounted before. ", "This is magnified at 100x, and even still, we’re really only seeing the usual microscopic imperfections but very little curvature. This CPU has been used a lot too, so if it were to be permanently bent, we’d see it by now.", "That clamp is definitely deforming it in ways for which the cold plate could be tuned. ", "Here’s a look at an AM4 CPU. Even at 100x and clamped, the CPU is almost perfectly flat. The old PGA socket doesn’t change anything from flat, so we’re just showing this. There’s a slight ripple in the surface, but that’s a mix of the magnification and the imperfect process of leveling the device being scanned. You can consider this as functionally flat. That means Intel and AMD AM4 would have different cold plate curvature optimizations from a cooler manufacturer’s perspective.", "AM5 has an ILM though, and that’s where this gets interesting.", "AM5’s pattern is woefully opposite of Intel’s: You can see that it bows upward in the center, at the points perpendicular to the clamping direction. This is going to be problematic. ", "In terms of maximum cooler compatibility, this is actually the worst possible outcome. That means if a cooler tunes for Intel or AMD in a very precise way, it’ll be at possibly the worst intersection with the opposite IHS. Most coolers don’t fine-tune to this level, but the fact that the CPU indentations effectively intersect means the ideal setup would be CPU-specific.", "But let’s try it.", "Based on our findings, to truly make a perfect cold plate, you’d need to make two versions of the same cooler. One would need a more curved cold plate, while the other would need a flatter one for AM4. If you wanted to accommodate AM5 optimally, you’d need 3 variations: The third would have to rotate the plate to align a concave plate with the convex AM5 IHS. For many boring reasons like economies of scale and customers getting confused and buying the wrong thing, most companies opt for a single solution that does its best to appeal to both IHS styles.", "Here are our four coolers today:", "All of these are the ", ". One is a retail unit we bought from Amazon, the second is custom machined to have a flatter cold plate, the third was made with a more curved cold plate, and the fourth is a final retail-ready unit that Scythe hand-picked as being one of its best performers from the production line. Cooler variance, overall, is extremely low if you have good test processes, and because of the changes made to the cold plate in each of these, any change outside of a 1-degree difference will be considered as outside of error.", "Here’s a scan of a normal ", " without modifications. When unmagnified, it just looks kind of flat. ", "You can see some coloring indicating depth changes at the micron-level, but to really see the curvature, we need to magnify this. ", "Here’s the same scan boosted at a 100x magnification to reveal details invisible to the human eye. You can see that the cold plate is curving towards the laser. Imagine that the laser is actually the CPU: It is convex and curving centrally towards the CPU IHS; however, as this is magnified at 100x, it’s so slight that it may have no real impact on contact. Pressure distribution and flexing of the plate occur during install, so it’s further possible that this flattens out.", "Either way, the normal FUMA 3 (watch ", ") is heavily curved as compared to our custom-made AM4 samples. ", "This is Golden Sample E, which you can see is incredibly flat by contrast. It’s impressive how flat they got this plate -- it should work well for AM4. ", "This is Sample B, which likewise is overall very flat.", "Finally, here’s the actual golden sample unit. This one should be amazing for Intel since the indentation lines-up with the concavity in the IHS when ILM pressure is applied.", "The scientific process involves disclosing limitations. For this test, they are:", "1 - We can’t control the actual heatpipes. It’s possible that there are slight quality variances in heatpipe selection; however, Scythe told us that it regulates its heatpipe supply tightly.", "2 - We can control the fans, so we used the same fans at the same speeds and positions for all testing.", "Now we need a hypothesis:", "Here’s how everything should work:", "This Golden Sample cooler should work the best on both AMD AM4 and Intel LGA1700. The reason is because it’s a clever combination of engineering from Scythe in the process of tweaking this cold plate. ", "When we asked them to curve the cold plate in a convex way to mate with the Intel CPU, we both realized that this curve could be slightly offset to bias it towards the hottest part of the Intel CPU and still land right between most of the Silicon on the AMD CPU, like the IO die. That means that while it mates perfectly with LGA1700, even though it’s not flat, we can apply the most pressure to the chiplet area of the flat AM4 CPU. In theory, this makes it the best possible for each, but would be sub-optimal for AM5 due to the perpendicular intersecting curve. ", "Sample E and Sample B coolers are flatter, so those should theoretically work better on AM4 than on Intel. Sample E is the best of these two. ", "The flatness means that Intel, if we exaggerate its curvature, will end up with reduced pressure centrally where the die is. ", "While AMD will end up with evenly distributed pressure across the IHS but less than the golden sample on the chiplet location.", "Here are the Intel thermal results. We theorized that the Golden Sample would do best on Intel, and it does -- by a lot. This is really exciting data, because everything about the way the cold plate is shaped for this one says that it should mate nearly perfectly with that indent on Intel. The end result is almost 3 degrees improved over one of the flattest plates. It’s no wonder Scythe asked us last year if we thought they should sell separate AMD and Intel coolers and no wonder why Noctua has done that sparingly in the past. An extra 2 degrees in the world of air coolers is the difference between the top and the middle of the chart -- that’s huge. The core-to-core delta remained similar, so we’re still limited there by the IHS design, silicone adhesive, and solder there. ", "Sample B has a very slight curvature to it, and so outperforms Sample E here as a result on Intel.", "This is super exciting. Let’s look at the flattest CPU we have: AMD AM4.", "The top-to-bottom range is 1.8 degrees. That’s relatively tight together, but definitely outside of our typical 1-degree target for a review. In this instance, with 3 specially tuned samples, our retail unit ends up the warmest. The “golden sample” we requested at Computex ran at 58.2 degrees, so that’s about a 1-degree difference from our typical acceptable margin of error when measured against the retail unit. Some of that is run-to-run variance, but there is a real difference here.", "This shows that the Golden Sample we had made still works optimally on AM4 as a result of the highest point of pressure being with the chiplet area, while on Intel, it’s the mating that benefits the design. Sample E is functionally the same: Because of how flat it is, its performance is tied for the best performer on AM4 out of these samples. That’s a big change from the Intel result, where E was the worst performer by 3 degrees. The theory is proving itself to be real. Sample B wasn’t quite as flat and didn’t do as well. Despite being mostly flat, it had an unbiased, slight curvature that wasn’t focused on the chiplets. That worked against it on AM4, but slightly helped it on Intel earlier.", "We also ran some quick AM5 tests. Using a ", " set to a clock and VCore that had it pulling 185W. We found Sample E to be the best performer by a lot against retail. Going flatter was better than a curve intersecting the wrong direction. Sample B was also up there, followed by the golden sample. As expected, the golden sample unit lost rank with AM5, otherwise they’d just make it for all platforms.", "Retail is unfortunately low for all of these. It does okay since, realistically, we're talking a couple degrees but it appears that there might be a better way to make this. Maybe this is an indication that Scythe should consider adopting one of the experimental designs. ", "In fact, here’s a quick table to rank them in each test. You can see that the retail unit was the worst in two tests and basically tied for that rank on LGA1700. Now, there’s one downside to the way we did this testing: Since we did ask for finely tuned coolers, it’s possible that we also intersected an area of other sampling bias: For instance, maybe because we bought the retail unit 6 months after the custom one was made, something changed.", "Either way, generally speaking, the Golden Sample did best in two places and was only slightly disadvantaged on AM5. This seems to be the best one for the future overall. We’ll regroup with Scythe later at Computex to talk about the findings and see if they apply them to manufacturing.", "This next section is super cool.", "Here’s a pressure scan of an AM4 CPU. The far left scan of the golden sample shows extremely high pressure centrally, right down across the middle of the CPU. If you look at the flatter samples B & E, you can see that we have a wider area of coverage across the entire CPU surface, but reduced pressure centrally. That higher pressure mattered more in our thermal testing for this one. The retail sample has a mixture of higher spread across the IHS and higher pressure centrally, but it has some spotty weak points. ", "And here’s the LGA1700 Intel CPU. In this one, you can see the golden sample unit has extremely high pressure centrally. The two flat samples do exactly what we expected: They lose contact along the critical edges of the central channel and have reduced pressure centrally, with only spotty areas of high pressure. This is the most exciting part of the job for us: We get to test a concept and see how it works. Not every aspect worked as we expected, but in this one, it’s exactly what you’d predict from a flat plate on a CPU that gets curved inwards by the ILM. It’s super cool. The retail unit is more similar to the golden sample, just with its less pronounced curve resulting in slightly reduced contact along the top edge.", "Finally, just for some quick physical visuals with the real product, we took a bunch of footage of the coolers with a high-precision Engineer’s Square and a flashlight. We’ll just show some of that now. ", "You can see in some situations where the light really cut under the square, illustrating the amount of curvature in the plate. But as we’ve learned now, that curvature can be a powerful tool to improving performance in some CPUs by focusing pressure in key areas or by matching the IHS. ", "There were others we tested with the Engineer’s Square that blocked most of the light from shining through, and those were generally the custom flat ones that we had made.", "Part of our findings didn’t work out how we thought, while others did.", "Here’s what didn’t work: The flat plates weren’t as successful as we thought they would be on AMD’s AM4 platform, but in one instance, it tied with the golden sample. Our original hypothesis was that, since AM4 is flat, those plates should perform the best. What we accidentally found was that a slight curvature benefits even AM4 as long as it is biased to intersect the chiplets and maintain high pressure there. ", "What did work was the golden sample: Having the cold plate shaped to mate with Intel definitely gave that cooler the best Intel performance, and it even worked well on AM4 since it applied the highest pressure to AM4. ", "From a product perspective: It looks like the perfect cold plate for LGA1700 and AM5 might be opposing each other, but that tuning for LGA1700 can at least get a wide cross-section with AM4. Manufacturers might have a few degrees of performance they can extract from custom tuning, but then they’d have multiple SKUs and would introduce new problems with customer service.", "Here’s why we’re doing this: We follow the scientific process, and that means isolating variables. It also means validation. To do all of the validation we do on a single cooler, we spend 40 hours just to test it on a single AM4 platform across 2-3 CPUs and get numbers that anyone can begin to trust. We’ve detailed that process before, but it requires multiple mounts and passes per mount -- each cooler is about a week of testing work for Mike. But that scientific process also means exploring known weaknesses in approach and then trying to solve for them.", "We’ve long been open that one of our longest-standing weaknesses in our cooler reviews methodology has been in CPU IHS representation, but due to practical limitations of it costing a lot of money and time, we had to choose a platform we could test and test well, as accurate data on one platform mattered more than inaccurate data across two platforms. ", "But Intel needs a different shape cold plate for optimal performance, and we’ve finally figured out how to optimize some of our reviews to accommodate both IHS shapes. That’s why the last 3-4 cooler reviews have had Intel and AMD CPUs alike. And now, we get to explore the shape differences and impact on thermals."]}
]