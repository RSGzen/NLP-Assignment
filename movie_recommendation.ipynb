{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab5c1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import contractions\n",
    "import emoji\n",
    "import json\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from numpy.dtypes import StringDType\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2915bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For tokenization\n",
    "nltk.download('punkt')\n",
    "\n",
    "# For removing stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# For lemmatization\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a62f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     movie_id                                         movie_name  year  \\\n",
      "0   tt3915174                       Puss in Boots: The Last Wish  2022   \n",
      "1   tt6718170                        The Super Mario Bros. Movie  2023   \n",
      "2  tt26537229  Demon Slayer: Kimetsu No Yaiba - To the Swords...  2023   \n",
      "3   tt1488589                     Guillermo del Toro's Pinocchio  2022   \n",
      "4  tt14668630                              Lyle, Lyle, Crocodile  2022   \n",
      "\n",
      "  certificate  runtime                         genre  rating  \\\n",
      "0          PG  102 min  Animation, Adventure, Comedy     7.9   \n",
      "1          PG   92 min  Animation, Adventure, Comedy     NaN   \n",
      "2           R  110 min  Animation, Action, Adventure     6.6   \n",
      "3          PG  117 min      Animation, Drama, Family     7.6   \n",
      "4          PG  106 min  Animation, Adventure, Comedy     6.1   \n",
      "\n",
      "                                         description  \\\n",
      "0  When Puss in Boots discovers that his passion ...   \n",
      "1  The story of The Super Mario Bros. on their jo...   \n",
      "2  All the Upper Rank Demons assemble at the Infi...   \n",
      "3  A father's wish magically brings a wooden boy ...   \n",
      "4  Feature film based on the children's book abou...   \n",
      "\n",
      "                                 director       director_id  \\\n",
      "0       Joel Crawford, \\r\\nJanuel Mercado  /name/nm3150455/   \n",
      "1      Aaron Horvath, \\r\\nMichael Jelenic  /name/nm1739338/   \n",
      "2                          Haruo Sotozaki  /name/nm1417038/   \n",
      "3  Guillermo del Toro, \\r\\nMark Gustafson  /name/nm0868219/   \n",
      "4             Josh Gordon, \\r\\nWill Speck  /name/nm0330347/   \n",
      "\n",
      "                                                star  \\\n",
      "0  Antonio Banderas, \\r\\nSalma Hayek, \\r\\nHarvey ...   \n",
      "1  Chris Pratt, \\r\\nAnya Taylor-Joy, \\r\\nCharlie ...   \n",
      "2  Zach Aguilar, \\r\\nKira Buckland, \\r\\nGriffin B...   \n",
      "3  Ewan McGregor, \\r\\nDavid Bradley, \\r\\nGregory ...   \n",
      "4  Javier Bardem, \\r\\nWinslow Fegley, \\r\\nShawn M...   \n",
      "\n",
      "                                             star_id    votes  gross(in $)  \n",
      "0  /name/nm2591093/,/name/nm0000104/,/name/nm0000...  93143.0  168464485.0  \n",
      "1  /name/nm2398585/,/name/nm0695435/,/name/nm5896...      NaN          NaN  \n",
      "2  /name/nm6450743/,/name/nm2299231/,/name/nm4232...   1316.0          NaN  \n",
      "3  /name/nm0348993/,/name/nm0000191/,/name/nm0103...  86296.0          NaN  \n",
      "4  /name/nm0817447/,/name/nm0000849/,/name/nm9121...   9351.0   46888441.0  \n"
     ]
    }
   ],
   "source": [
    "base_wd = os.getcwd()\n",
    "\n",
    "csv_path = os.path.join(\"data\", \"animation.csv\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe0755a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis is a dataset scraped from the IMDB movie rating website regarding movies of the 'animation' genre.\\n\\nThis dataset is provided from: https://www.kaggle.com/datasets/rajugc/imdb-movies-dataset-based-on-genre?select=animation.csv \\n\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a dataset scraped from the IMDB movie rating website regarding movies of the 'animation' genre.\n",
    "\n",
    "This dataset is provided from: https://www.kaggle.com/datasets/rajugc/imdb-movies-dataset-based-on-genre?select=animation.csv \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0180e40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies: 8419\n",
      "\n",
      "Example movie:\n",
      "movie_id                                               tt3915174\n",
      "movie_name                          Puss in Boots: The Last Wish\n",
      "year                                                        2022\n",
      "certificate                                                   PG\n",
      "runtime                                                  102 min\n",
      "genre                               Animation, Adventure, Comedy\n",
      "rating                                                       7.9\n",
      "description    When Puss in Boots discovers that his passion ...\n",
      "director                       Joel Crawford, \\r\\nJanuel Mercado\n",
      "director_id                                     /name/nm3150455/\n",
      "star           Antonio Banderas, \\r\\nSalma Hayek, \\r\\nHarvey ...\n",
      "star_id        /name/nm2591093/,/name/nm0000104/,/name/nm0000...\n",
      "votes                                                    93143.0\n",
      "gross(in $)                                          168464485.0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of movies: {len(df)}\\n\")\n",
    "\n",
    "print(\"Example movie:\")\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab699071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After retaining wanted features: \n",
      "\n",
      "                                          movie_name  year  \\\n",
      "0                       Puss in Boots: The Last Wish  2022   \n",
      "1                        The Super Mario Bros. Movie  2023   \n",
      "2  Demon Slayer: Kimetsu No Yaiba - To the Swords...  2023   \n",
      "\n",
      "                          genre  \\\n",
      "0  Animation, Adventure, Comedy   \n",
      "1  Animation, Adventure, Comedy   \n",
      "2  Animation, Action, Adventure   \n",
      "\n",
      "                                         description  \\\n",
      "0  When Puss in Boots discovers that his passion ...   \n",
      "1  The story of The Super Mario Bros. on their jo...   \n",
      "2  All the Upper Rank Demons assemble at the Infi...   \n",
      "\n",
      "                             director  \\\n",
      "0   Joel Crawford, \\r\\nJanuel Mercado   \n",
      "1  Aaron Horvath, \\r\\nMichael Jelenic   \n",
      "2                      Haruo Sotozaki   \n",
      "\n",
      "                                                star  \n",
      "0  Antonio Banderas, \\r\\nSalma Hayek, \\r\\nHarvey ...  \n",
      "1  Chris Pratt, \\r\\nAnya Taylor-Joy, \\r\\nCharlie ...  \n",
      "2  Zach Aguilar, \\r\\nKira Buckland, \\r\\nGriffin B...  \n"
     ]
    }
   ],
   "source": [
    "## Removing unnessary features\n",
    "\n",
    "\"\"\"\n",
    "Important informations about a movie that is memorable and easily identified which users can remember:\n",
    "    --> Movie name\n",
    "    --> Year\n",
    "    --> Genre\n",
    "    --> Description\n",
    "    --> Director\n",
    "    --> Star\n",
    "\n",
    "We will only save these informations since other fields of data are not that significant for the users.\n",
    "\n",
    "Hence, we will drop features of:\n",
    "    --> movie_id\n",
    "    --> certificate\n",
    "    --> runtime\n",
    "    --> rating\n",
    "    --> director_id\n",
    "    --> star_id\n",
    "    --> votes\n",
    "    --> gross(in $)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "new_df = df.drop('movie_id', axis='columns')\n",
    "new_df = new_df.drop('certificate', axis='columns')\n",
    "new_df = new_df.drop('runtime', axis='columns')\n",
    "new_df = new_df.drop('rating', axis='columns')\n",
    "new_df = new_df.drop('director_id', axis='columns')\n",
    "new_df = new_df.drop('star_id', axis='columns')\n",
    "new_df = new_df.drop('votes', axis='columns')\n",
    "new_df = new_df.drop('gross(in $)', axis='columns')\n",
    "\n",
    "print(\"After retaining wanted features: \\n\")\n",
    "print(new_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceb86c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in movie_name: 0\n",
      "Missing values in year: 1369\n",
      "Missing values in genre: 0\n",
      "Missing values in description: 0\n",
      "Missing values in director: 902\n",
      "Missing values in star: 2849\n"
     ]
    }
   ],
   "source": [
    "## Check for any missing values in the dataset\n",
    "\n",
    "def nan_counter(feature_name: str, df: pd.DataFrame):\n",
    "    nan_count = df[feature_name].isnull().sum()\n",
    "\n",
    "    print(f\"Missing values in {feature_name}: {nan_count}\")\n",
    "\n",
    "nan_counter(\"movie_name\", new_df)\n",
    "nan_counter(\"year\", new_df)\n",
    "nan_counter(\"genre\", new_df)\n",
    "nan_counter(\"description\", new_df)\n",
    "nan_counter(\"director\", new_df)\n",
    "nan_counter(\"star\", new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d3b9779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies after cleansing dataset: 5291\n",
      "\n",
      "Example of movie:\n",
      "movie_name                                        Bigfoot Family\n",
      "year                                                        2020\n",
      "genre                               Animation, Adventure, Family\n",
      "description    Follow up to Son of Bigfoot: Father uses his n...\n",
      "director                        Jeremy Degruson, \\r\\nBen Stassen\n",
      "star           Jules Medcraft, \\r\\nKylian Trouillard, \\r\\nAle...\n",
      "Name: 457, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Dropping rows of data which are missing values\n",
    "\n",
    "# Due to the nature of movie recommendations must provide real data, we cannot replace missing data using simple techniques such as imputation technique or forward/backward fill\n",
    "\n",
    "# As such we must drop them\n",
    "\n",
    "new_df = new_df.dropna(axis=0)\n",
    "\n",
    "print(f\"Number of movies after cleansing dataset: {len(new_df)}\\n\")\n",
    "\n",
    "print(f\"Example of movie:\\n{new_df.iloc[450]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88a20c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies after cleansing dataset: 5245\n"
     ]
    }
   ],
   "source": [
    "## Dropping rows of duplicate values\n",
    "\n",
    "new_df = new_df.drop_duplicates(subset=['movie_name'])\n",
    "\n",
    "print(f\"Number of movies after cleansing dataset: {len(new_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f519a8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies after cleansing dataset: 4521\n"
     ]
    }
   ],
   "source": [
    "## Remove movies that don't have plot description or filler descriptions\n",
    "\n",
    "new_df = new_df[new_df[\"description\"].str.contains(\"Add a Plot\") == False]\n",
    "\n",
    "print(f\"Number of movies after cleansing dataset: {len(new_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a58114e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    movie_name  year      genre  \\\n",
      "count                                     4521  4521       4521   \n",
      "unique                                    4521    98        151   \n",
      "top     Dive Olly Dive: A Hero's Magical Quest  2019  Animation   \n",
      "freq                                         1   306        791   \n",
      "\n",
      "                                              description   director  \\\n",
      "count                                                4521       4521   \n",
      "unique                                               4509       3206   \n",
      "top     Short animation film from the series 'Garabatos'.  Leon Ding   \n",
      "freq                                                    7         32   \n",
      "\n",
      "                                                     star  \n",
      "count                                                4521  \n",
      "unique                                               4300  \n",
      "top     Nobuyo Ôyama, \\r\\nNoriko Ohara, \\r\\nMichiko No...  \n",
      "freq                                                   20  \n"
     ]
    }
   ],
   "source": [
    "## Creating a short description of dataset\n",
    "\n",
    "print(new_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77403ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_12364\\317998513.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_str = temp_str + str(new_df.iloc[i][j]) + \" \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies: 4521\n",
      "\n",
      "Example of movie information string: \n",
      "Puss in Boots: The Last Wish 2022 Animation, Adventure, Comedy When Puss in Boots discovers that his passion for adventure has taken its toll and he has burned through eight of his nine lives, he launches an epic journey to restore them by finding the mythical Last Wish. Joel Crawford, \n",
      "Januel Mercado Antonio Banderas, \n",
      "Salma Hayek, \n",
      "Harvey Guillén, \n",
      "Florence Pugh \n"
     ]
    }
   ],
   "source": [
    "## Create a huge array to store BagOfWords of each movie information\n",
    "\n",
    "df_str = []\n",
    "\n",
    "for i in range(len(new_df)):\n",
    "    temp_str = \"\"\n",
    "    for j in range(len(new_df.iloc[0])):\n",
    "         temp_str = temp_str + str(new_df.iloc[i][j]) + \" \"\n",
    "    \n",
    "    df_str.append(temp_str)\n",
    "\n",
    "print(f\"Number of movies: {len(df_str)}\")\n",
    "print(f\"\\nExample of movie information string: \\n{df_str[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6592e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create preprocess pipeline for the text strings per movie\n",
    "\n",
    "def preprocess_text(text_str: str):\n",
    "\n",
    "    \"\"\"\n",
    "    Remove characters that are not characters of \n",
    "        --> a - z\n",
    "        --> A - Z\n",
    "        --> 0 - 9\n",
    "    \"\"\"\n",
    "\n",
    "    clean_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text_str) \n",
    "\n",
    "    # Turns all uppercase alphabets to lowercase\n",
    "    clean_text = clean_text.lower()\n",
    "\n",
    "    # Tokenize string of text into individual units\n",
    "    tokenized_text = word_tokenize(clean_text)\n",
    "\n",
    "    # Remove stopwords which provide little to none useful information\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    filtered_text = [token for token in tokenized_text if token not in stop_words]\n",
    "\n",
    "    # Lemmatization of tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = []\n",
    "\n",
    "    for token in filtered_text:\n",
    "        lemmatized_text.append(lemmatizer.lemmatize(token))\n",
    "    \n",
    "    # Process contractions (words with apostrophe) by replacing them with words of similar meaning\n",
    "    expanded_text = [contractions.fix(token) for token in lemmatized_text]\n",
    "\n",
    "    # Handle emojis and emoticons\n",
    "    emoji_clean_text = [emoji.demojize(token) for token in expanded_text]\n",
    "\n",
    "    return emoji_clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "564bb856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      " Puss in Boots: The Last Wish 2022 Animation, Adventure, Comedy When Puss in Boots discovers that his passion for adventure has taken its toll and he has burned through eight of his nine lives, he launches an epic journey to restore them by finding the mythical Last Wish. Joel Crawford, \n",
      "Januel Mercado Antonio Banderas, \n",
      "Salma Hayek, \n",
      "Harvey Guillén, \n",
      "Florence Pugh \n",
      "\n",
      "After:\n",
      " ['pus', 'boot', '2011', 'animation', 'adventure', 'comedy', 'outlaw', 'cat', 'childhood', None, 'seductive', 'thief', 'kitty', 'set', 'search', 'egg', 'fabled', 'golden', 'goose', 'clear', 'name', 'restore', 'lost', 'honor', 'regain', 'trust', 'mother', 'town', 'chris', 'miller', 'antonio', 'bankers', 'salsa', 'hayes', 'zach', None, 'billy', 'bob', 'thornton']\n"
     ]
    }
   ],
   "source": [
    "## Example of Text Preprocessing\n",
    "\n",
    "print(f\"Before:\\n {df_str[0]}\\n\")\n",
    "\n",
    "print(f\"After:\\n {preprocess_text(df_str[10])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4ebfd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing BagOfWords:   1%|          | 31/4521 [00:35<1:26:17,  1.15s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m preprocessed_bow = []\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df_str)), desc=\u001b[33m\"\u001b[39m\u001b[33mPreprocessing BagOfWords\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     processed_tokens = \u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_str\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     preprocessed_bow.append(processed_tokens)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBoW Preprocessing Completed\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mpreprocess_text\u001b[39m\u001b[34m(text_str)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Check for spelling errors in text\u001b[39;00m\n\u001b[32m     39\u001b[39m spell_checker = SpellChecker()\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m corrected_text = [\u001b[43mspell_checker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcorrection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m emoji_clean_text]\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m corrected_text\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\spellchecker\\spellchecker.py:159\u001b[39m, in \u001b[36mSpellChecker.correction\u001b[39m\u001b[34m(self, word)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"The most probable correct spelling for the word\u001b[39;00m\n\u001b[32m    153\u001b[39m \n\u001b[32m    154\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[33;03m    word (str): The word to correct\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[33;03mReturns:\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[33;03m    str: The most likely candidate or None if no correction is present\"\"\"\u001b[39;00m\n\u001b[32m    158\u001b[39m word = ensure_unicode(word)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m candidates = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidates:\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\spellchecker\\spellchecker.py:186\u001b[39m, in \u001b[36mSpellChecker.candidates\u001b[39m\u001b[34m(self, word)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# if still not found, use the edit distance 1 to calc edit distance 2\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._distance == \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     tmp = \u001b[38;5;28mself\u001b[39m.known(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__edit_distance_alt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tmp:\n\u001b[32m    188\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tmp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\spellchecker\\spellchecker.py:253\u001b[39m, in \u001b[36mSpellChecker.__edit_distance_alt\u001b[39m\u001b[34m(self, words)\u001b[39m\n\u001b[32m    251\u001b[39m tmp_words = [ensure_unicode(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[32m    252\u001b[39m tmp = [w \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._case_sensitive \u001b[38;5;28;01melse\u001b[39;00m w.lower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp_words \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_if_should_check(w)]\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [e2 \u001b[38;5;28;01mfor\u001b[39;00m e1 \u001b[38;5;129;01min\u001b[39;00m tmp \u001b[38;5;28;01mfor\u001b[39;00m e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.known(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43medit_distance_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43me1\u001b[49m\u001b[43m)\u001b[49m)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\spellchecker\\spellchecker.py:213\u001b[39m, in \u001b[36mSpellChecker.edit_distance_1\u001b[39m\u001b[34m(self, word)\u001b[39m\n\u001b[32m    210\u001b[39m     tmp = [w \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._case_sensitive \u001b[38;5;28;01melse\u001b[39;00m w.lower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp_words \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_if_should_check(w)]\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._word_frequency.dictionary}\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34medit_distance_1\u001b[39m(\u001b[38;5;28mself\u001b[39m, word: KeyT) -> typing.Set[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    214\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute all strings that are one edit away from `word` using only\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[33;03m    the letters in the corpus\u001b[39;00m\n\u001b[32m    216\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[33;03m        set: The set of strings that are edit distance one from the provided word\"\"\"\u001b[39;00m\n\u001b[32m    221\u001b[39m     tmp_word = ensure_unicode(word).lower() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._case_sensitive \u001b[38;5;28;01melse\u001b[39;00m ensure_unicode(word)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "## Preprocess BagOfWords\n",
    "\n",
    "preprocessed_bow = []\n",
    "\n",
    "for i in tqdm(range(0, len(df_str)), desc=\"Preprocessing BagOfWords\"):\n",
    "    processed_tokens = preprocess_text(df_str[i])\n",
    "\n",
    "    preprocessed_bow.append(processed_tokens)\n",
    "\n",
    "print(\"\\nBoW Preprocessing Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f3d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save processed BoW as json format\n",
    "\n",
    "base_wd = os.getcwd()\n",
    "\n",
    "jsonfile_name = \"ori_BoW.json\"\n",
    "\n",
    "jsonfile_path = os.path.join(base_wd, \"data\", jsonfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e1bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(jsonfile_path, \"w\") as jsonFile:\n",
    "    json.dump(preprocessed_bow, jsonFile)\n",
    "\n",
    "print(\"BagOfWords array has been converted into a json file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a19963",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load BoW from json file\n",
    "\n",
    "if os.path.isfile(jsonfile_path):\n",
    "    with open(jsonfile_path, 'r') as file:\n",
    "        bagOfWords = json.load(file)\n",
    "\n",
    "        print(bagOfWords[:3])\n",
    "else:\n",
    "    print(\"\\nJson file is not found in directory. Please save it first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e6b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract features from BagOfWords\n",
    "\n",
    "# Create a vectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "vectorizer.fit(bagOfWords)\n",
    "\n",
    "# Encode document\n",
    "\n",
    "vector = vectorizer.transform(bagOfWords)\n",
    "\n",
    "print(f\"Shape of vector matrix: {vector.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8214b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the vector into a compressed sparse matrix format known as CSR "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
